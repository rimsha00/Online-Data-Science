{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(url=\"https://en.wikipedia.org/wiki/Web_scraping\")\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"h1\", id=\"firstHeading\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraping\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraping used for extracting data from websites\n",
      "This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: \"Web scraping\" – news · newspapers · books · scholar · JSTOR (June 2017) (Learn how and when to remove this template message)\n",
      "For broader coverage of this topic, see Data scraping.\n",
      "Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. The web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.\n",
      "Web scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, then extraction can take place. The content of a page may be parsed, searched, reformatted, its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be to find and copy names and telephone numbers, or companies and their URLs, or e-mail addresses to a list (contact scraping).\n",
      "Web scraping is used for contact scraping, and as a component of applications used for web indexing, web mining and data mining, online price change monitoring and price comparison, product review scraping (to watch the competition), gathering real estate listings, weather data monitoring, website change detection, research, tracking online presence and reputation, web mashup, and web data integration.\n",
      "Web pages are built using text-based mark-up languages (HTML and XHTML), and frequently contain a wealth of useful data in text form. However, most web pages are designed for human end-users and not for ease of automated use. As a result, specialized tools and software have been developed to facilitate the scraping of web pages.\n",
      "Newer forms of web scraping involve monitoring data feeds from web servers.  For example, JSON is commonly used as a transport storage mechanism between the client and the web server.\n",
      "There are methods that some websites use to prevent web scraping, such as detecting and disallowing bots from crawling (viewing) their pages. In response, there are web scraping systems that rely on using techniques in  DOM parsing, computer vision and natural language processing to simulate human browsing to enable gathering web page content for offline parsing.\n",
      "\n",
      "Contents\n",
      "\n",
      "1 History\n",
      "2 Techniques\n",
      "\n",
      "2.1 Human copy-and-paste\n",
      "2.2 Text pattern matching\n",
      "2.3 HTTP programming\n",
      "2.4 HTML parsing\n",
      "2.5 DOM parsing\n",
      "2.6 Vertical aggregation\n",
      "2.7 Semantic annotation recognizing\n",
      "2.8 Computer vision web-page analysis\n",
      "\n",
      "\n",
      "3 Software\n",
      "4 Legal issues\n",
      "\n",
      "4.1 United States\n",
      "4.2 European Union\n",
      "4.3 Australia\n",
      "4.4 India\n",
      "\n",
      "\n",
      "5 Methods to prevent web scraping\n",
      "6 See also\n",
      "7 References\n",
      "\n",
      "\n",
      "History[edit]\n",
      "This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2018) (Learn how and when to remove this template message)\n",
      "The history of the web scraping dates back nearly to the time when the World Wide Web was born.\n",
      "\n",
      "After the birth of World Wide Web in 1989, the first web robot,[1] World Wide Web Wanderer, was created in June 1993, which was intended only to measure the size of the web.\n",
      "In December 1993, the first crawler-based web search engine, JumpStation, was launched. As there were not so many websites available on the web, search engines at that time used to rely on their human website administrators to collect and edit the links into a particular format. In comparison, JumpStation brought a new leap, being the first WWW search engine that relied on a web robot.\n",
      "In 2000, the first Web API and API crawler came. API stands for Application Programming Interface. It is an interface that makes it much easier to develop a program by providing the building blocks. In 2000, Salesforce and eBay launched their own API, with which programmers were enabled to access and download some of the data available to the public. Since then, many websites offer web APIs for people to access their public database.\n",
      "Techniques[edit]\n",
      "Web scraping is the process of automatically mining data or collecting information from the World Wide Web. It is a field with active developments sharing a common goal with the semantic web vision, an ambitious initiative that still requires breakthroughs in text processing, semantic understanding, artificial intelligence and human-computer interactions. Current web scraping solutions range from the ad-hoc, requiring human effort, to fully automated systems that are able to convert entire web sites into structured information, with limitations.\n",
      "\n",
      "Human copy-and-paste[edit]\n",
      "The simplest form of web scraping is manually copying and pasting data from a web page into a text file or spreadsheet. Sometimes even the best web-scraping technology cannot replace a human's manual examination and copy-and-paste, and sometimes this may be the only workable solution when the websites for scraping explicitly set up barriers to prevent machine automation.\n",
      "\n",
      "Text pattern matching[edit]\n",
      "A simple yet powerful approach to extract information from web pages can be based on the UNIX grep command or regular expression-matching facilities of programming languages (for instance Perl or Python).\n",
      "\n",
      "HTTP programming[edit]\n",
      "Static and dynamic web pages can be retrieved by posting HTTP requests to the remote web server using socket programming.\n",
      "\n",
      "HTML parsing[edit]\n",
      "Many websites have large collections of pages generated dynamically from an underlying structured source like a database. Data of the same category are typically encoded into similar pages by a common script or template. In data mining, a program that detects such templates in a particular information source, extracts its content and translates it into a relational form, is called a wrapper. Wrapper generation algorithms assume that input pages of a wrapper induction system conform to a common template and that they can be easily identified in terms of a URL common scheme.[2] Moreover, some semi-structured data query languages, such as XQuery and the HTQL, can be used to parse HTML pages and to retrieve and transform page content.\n",
      "\n",
      "DOM parsing[edit]\n",
      "Further information: Document Object Model\n",
      "By embedding a full-fledged web browser, such as the Internet Explorer or the Mozilla browser control, programs can retrieve the dynamic content generated by client-side scripts. These browser controls also parse web pages into a DOM tree, based on which programs can retrieve parts of the pages. Languages such as Xpath can be used to parse the resulting DOM tree.\n",
      "\n",
      "Vertical aggregation[edit]\n",
      "There are several companies that have developed vertical specific harvesting platforms. These platforms create and monitor a multitude of \"bots\" for specific verticals with no \"man in the loop\" (no direct human involvement), and no work related to a specific target site. The preparation involves establishing the knowledge base for the entire vertical and then the platform creates the bots automatically. The platform's robustness is measured by the quality of the information it retrieves (usually number of fields) and its scalability (how quick it can scale up to hundreds or thousands of sites). This scalability is mostly used to target the Long Tail of sites that common aggregators find complicated or too labor-intensive to harvest content from.\n",
      "\n",
      "Semantic annotation recognizing[edit]\n",
      "The pages being scraped may embrace metadata or semantic markups and annotations, which can be used to locate specific data snippets. If the annotations are embedded in the pages, as Microformat does, this technique can be viewed as a special case of DOM parsing. In another case, the annotations, organized into a semantic layer,[3] are stored and managed separately from the web pages, so the scrapers can retrieve data schema and instructions from this layer before scraping the pages.\n",
      "\n",
      "Computer vision web-page analysis[edit]\n",
      "There are efforts using machine learning and computer vision that attempt to identify and extract information from web pages by interpreting pages visually as a human being might.[4]\n",
      "\n",
      "Software[edit]\n",
      "There are many software tools available that can be used to customize web-scraping solutions. This software may attempt to automatically recognize the data structure of a page or provide a recording interface that removes the necessity to manually write web-scraping code, or some scripting functions that can be used to extract and transform content, and database interfaces that can store the scraped data in local databases. Some web scraping software can also be used to extract data from an API directly.\n",
      "\n",
      "Legal issues[edit]\n",
      "The examples and perspective in this section deal primarily with the United States and do not represent a worldwide view of the subject. You may improve this section, discuss the issue on the talk page, or create a new section, as appropriate. (October 2015) (Learn how and when to remove this template message)\n",
      "The legality of web scraping varies across the world. In general, web scraping may be against the terms of use of some websites, but the enforceability of these terms is unclear.[5]\n",
      "\n",
      "United States[edit]\n",
      "In the United States, website owners can use three major legal claims to prevent undesired web scraping: (1) copyright infringement (compilation), (2) violation of the Computer Fraud and Abuse Act (\"CFAA\"), and (3) trespass to chattel.[6] However, the effectiveness of these claims relies upon meeting various criteria, and the case law is still evolving. For example, with regard to copyright, while outright duplication of original expression will in many cases be illegal, in the United States the courts ruled in Feist Publications v. Rural Telephone Service that duplication of facts is allowable.\n",
      "U.S. courts have acknowledged that users of \"scrapers\" or \"robots\" may be held liable for committing trespass to chattels,[7][8] which involves a computer system itself being considered personal property upon which the user of a scraper is trespassing. The best known of these cases, eBay v. Bidder's Edge, resulted in an injunction ordering Bidder's Edge to stop accessing, collecting, and indexing auctions from the eBay web site. This case involved automatic placing of bids, known as auction sniping. However, in order to succeed on a claim of trespass to chattels, the plaintiff must demonstrate that the defendant intentionally and without authorization interfered with the plaintiff's possessory interest in the computer system and that the defendant's unauthorized use caused damage to the plaintiff. Not all cases of web spidering brought before the courts have been considered trespass to chattels.[9]\n",
      "One of the first major tests of screen scraping involved American Airlines (AA), and a firm called FareChase.[10] AA successfully obtained an injunction from a Texas trial court, stopping FareChase from selling software that enables users to compare online fares if the software also searches AA's website. The airline argued that FareChase's websearch software trespassed on AA's servers when it collected the publicly available data. FareChase filed an appeal in March 2003. By June, FareChase and AA agreed to settle and the appeal was dropped.[11]\n",
      "Southwest Airlines has also challenged screen-scraping practices, and has involved both FareChase and another firm, Outtask, in a legal claim. Southwest Airlines charged that the screen-scraping is Illegal since it is an example of \"Computer Fraud and Abuse\" and has led to \"Damage and Loss\" and \"Unauthorized Access\" of Southwest's site. It also constitutes \"Interference with Business Relations\", \"Trespass\", and \"Harmful Access by Computer\". They also claimed that screen-scraping constitutes what is legally known as \"Misappropriation and Unjust Enrichment\", as well as being a breach of the web site's user agreement. Outtask denied all these claims, claiming that the prevailing law, in this case, should be US Copyright law and that under copyright, the pieces of information being scraped would not be subject to copyright protection. Although the cases were never resolved in the Supreme Court of the United States, FareChase was eventually shuttered by parent company Yahoo!, and Outtask was purchased by travel expense company Concur.[12]\n",
      "In 2012, a startup called 3Taps scraped classified housing ads from Craigslist. Craigslist sent 3Taps a cease-and-desist letter and blocked their IP addresses and later sued, in Craigslist v. 3Taps. The court held that the cease-and-desist letter and IP blocking was sufficient for Craigslist to properly claim that 3Taps had violated the Computer Fraud and Abuse Act.\n",
      "Although these are early scraping decisions, and the theories of liability are not uniform, it is difficult to ignore a pattern emerging that the courts are prepared to protect proprietary content on commercial sites from uses which are undesirable to the owners of such sites. However, the degree of protection for such content is not settled and will depend on the type of access made by the scraper, the amount of information accessed and copied, the degree to which the access adversely affects the site owner's system and the types and manner of prohibitions on such conduct.[13]\n",
      "While the law in this area becomes more settled, entities contemplating using scraping programs to access a public web site should also consider whether such action is authorized by reviewing the terms of use and other terms or notices posted on or made available through the site. In a 2010 ruling in the Cvent, Inc. v. Eventbrite, Inc. In the United States district court for the eastern district of Virginia, the court ruled that the terms of use should be brought to the users' attention In order for a browse wrap contract or license to be enforced.[14] In a 2014 case, filed in the United States District Court for the Eastern District of Pennsylvania,[15] e-commerce site QVC objected to the Pinterest-like shopping aggregator Resultly's 'scraping of QVC's site for real-time pricing data. QVC alleges that Resultly \"excessively crawled\" QVC's retail site (allegedly sending 200-300 search requests to QVC's website per minute, sometimes to up to 36,000 requests per minute) which caused QVC's site to crash for two days, resulting in lost sales for QVC.[16] QVC's complaint alleges that the defendant disguised its web crawler to mask its source IP address and thus prevented QVC from quickly repairing the problem. This is a particularly interesting scraping case because QVC is seeking damages for the unavailability of their website, which QVC claims was caused by Resultly.\n",
      "In the plaintiff's web site during the period of this trial, the terms of use link are displayed among all the links of the site, at the bottom of the page as most sites on the internet. This ruling contradicts the Irish ruling described below. The court also rejected the plaintiff's argument that the browse-wrap restrictions were enforceable in view of Virginia's adoption of the Uniform Computer Information Transactions Act (UCITA)—a uniform law that many believed was in favor on common browse-wrap contracting practices.[17]\n",
      "In Facebook, Inc. v. Power Ventures, Inc., a district court ruled in 2012 that Power Ventures could not scrape Facebook pages on behalf of a Facebook user. The case is on appeal, and the Electronic Frontier Foundation filed a brief in 2015 asking that it be overturned.[18][19] In Associated Press v. Meltwater U.S. Holdings, Inc., a court in the US held Meltwater liable for scraping and republishing news information from the Associated Press, but a court in the United Kingdom held in favor of Meltwater.\n",
      "Internet Archive collects and distributes a significant number of publicly available web pages without being considered to be in violation of copyright laws.\n",
      "\n",
      "European Union[edit]\n",
      "In February 2006, the Danish Maritime and Commercial Court (Copenhagen) ruled that systematic crawling, indexing, and deep linking by portal site ofir.dk of estate site Home.dk does not conflict with Danish law or the database directive of the European Union.[20]\n",
      "In a February 2010 case complicated by matters of jurisdiction, Ireland's High Court delivered a verdict that illustrates the inchoate state of developing case law. In the case of Ryanair Ltd v Billigfluege.de GmbH, Ireland's High Court ruled Ryanair's \"click-wrap\" agreement to be legally binding. In contrast to the findings of the United States District Court Eastern District of Virginia and those of the Danish Maritime and Commercial Court, Justice Michael Hanna ruled that the hyperlink to Ryanair's terms and conditions was plainly visible, and that placing the onus on the user to agree to terms and conditions in order to gain access to online services is sufficient to comprise a contractual relationship.[21] The decision is under appeal in Ireland's Supreme Court.[22]\n",
      "On April 30, 2020, the French Data Protection Authority (CNIL) released new guidelines on web scraping.[23] The CNIL guidelines made it clear that publicly available data is still personal data and cannot be repurposed without the knowledge of the person to whom that data belongs.[24]\n",
      "\n",
      "Australia[edit]\n",
      "In Australia, the Spam Act 2003 outlaws some forms of web harvesting, although this only applies to email addresses.[25][26]\n",
      "\n",
      "India[edit]\n",
      "Leaving a few cases dealing with IPR infringement, Indian courts have not expressly ruled on the legality of web scraping. However, since all common forms of electronic contracts are enforceable in India, violating the terms of use prohibiting data scraping will be a violation of the contract law. It will also violate the Information Technology Act, 2000, which penalizes unauthorized access to a computer resource or extracting data from a computer resource.\n",
      "\n",
      "Methods to prevent web scraping[edit]\n",
      "The administrator of a website can use various measures to stop or slow a bot. Some techniques include:\n",
      "\n",
      "Blocking an IP address either manually or based on criteria such as geolocation and DNSRBL. This will also block all browsing from that address.\n",
      "Disabling any web service API that the website's system might expose.\n",
      "Bots sometimes declare who they are (using user agent strings) and can be blocked on that basis using robots.txt; 'googlebot' is an example. Other bots make no distinction between themselves and a human using a browser.\n",
      "Bots can be blocked by monitoring excess traffic\n",
      "Bots can sometimes be blocked with tools to verify that it is a real person accessing the site, like a CAPTCHA. Bots are sometimes coded to explicitly break specific CAPTCHA patterns or may employ third-party services that utilize human labor to read and respond in real-time to CAPTCHA challenges.\n",
      "Commercial anti-bot services: Companies offer anti-bot and anti-scraping services for websites. A few web application firewalls have limited bot detection capabilities as well. However, many such solutions are not very effective.[27]\n",
      "Locating bots with a honeypot or other method to identify the IP addresses of automated crawlers.\n",
      "Obfuscation using CSS sprites to display such data as telephone numbers or email addresses, at the cost of accessibility to screen reader users.\n",
      "Because bots rely on consistency in the front-end code of a target website, adding small variations to the HTML/CSS surrounding important data and navigation elements would require more human involvement in the initial set up of a bot and if done effectively may render the target website too difficult to scrape due to the diminished ability to automate the scraping process.\n",
      "Websites can declare if crawling is allowed or not in the robots.txt file and allow partial access, limit the crawl rate, specify the optimal time to crawl and more.\n",
      "Load database data straight into the HTML DOM via AJAX, and use DOM methods to display it. No visible data in the source document means that it can't be scraped.\n",
      "See also[edit]\n",
      "\n",
      "Archive.today\n",
      "Comparison of feed aggregators\n",
      "Data scraping\n",
      "Data wrangling\n",
      "Importer\n",
      "Job wrapping\n",
      "Knowledge extraction\n",
      "OpenSocial\n",
      "Scraper site\n",
      "Fake news website\n",
      "Blog scraping\n",
      "Spamdexing\n",
      "Domain name drop list\n",
      "Text corpus\n",
      "Web archiving\n",
      "Web crawler\n",
      "Offline reader\n",
      "Link farm (blog network)\n",
      "Search engine scraping\n",
      "Web crawlers\n",
      "\n",
      "References[edit]\n",
      "\n",
      "\n",
      "^ \"Search Engine History.com\". Search Engine History. Retrieved November 26, 2019.\n",
      "\n",
      "^ Song, Ruihua; Microsoft Research (Sep 14, 2007). \"Joint Optimization of Wrapper Generation and Template Detection\" (PDF). The 13th International Conference on Knowledge Discovery and Data Mining: 894. doi:10.1145/1281192.1281287. ISBN 9781595936097. S2CID 833565. Archived from the original (PDF) on October 11, 2016.\n",
      "\n",
      "^ Semantic annotation based web scraping\n",
      "\n",
      "^ Roush, Wade (2012-07-25). \"Diffbot Is Using Computer Vision to Reinvent the Semantic Web\". www.xconomy.com. Retrieved 2013-03-15.\n",
      "\n",
      "^ \"FAQ about linking – Are website terms of use binding contracts?\". www.chillingeffects.org. 2007-08-20. Archived from the original on 2002-03-08. Retrieved 2007-08-20.\n",
      "\n",
      "^ Kenneth, Hirschey, Jeffrey (2014-01-01). \"Symbiotic Relationships: Pragmatic Acceptance of Data Scraping\". Berkeley Technology Law Journal. 29 (4). doi:10.15779/Z38B39B. ISSN 1086-3818.\n",
      "\n",
      "^ \"Internet Law, Ch. 06: Trespass to Chattels\". www.tomwbell.com. 2007-08-20. Retrieved 2007-08-20.\n",
      "\n",
      "^ \"What are the \"trespass to chattels\" claims some companies or website owners have brought?\". www.chillingeffects.org. 2007-08-20. Archived from the original on 2002-03-08. Retrieved 2007-08-20.\n",
      "\n",
      "^ \"Ticketmaster Corp. v. Tickets.com, Inc\". 2007-08-20. Retrieved 2007-08-20.\n",
      "\n",
      "^ \"American Airlines v. FareChase\" (PDF). 2007-08-20. Archived from the original (PDF) on 2011-07-23. Retrieved 2007-08-20.\n",
      "\n",
      "^ \"American Airlines, FareChase Settle Suit\". The Free Library. 2003-06-13. Retrieved 2012-02-26.\n",
      "\n",
      "^ Imperva (2011). Detecting and Blocking Site Scraping Attacks. Imperva white paper..\n",
      "\n",
      "^ Adler, Kenneth A. (2003-07-29). \"Controversy Surrounds 'Screen Scrapers': Software Helps Users Access Web Sites But Activity by Competitors Comes Under Scrutiny\". Archived from the original on 2011-02-11. Retrieved 2010-10-27.\n",
      "\n",
      "^ \"QVC Inc. v. Resultly LLC, No. 14-06714 (E.D. Pa. filed Nov. 24, 2014)\" (PDF). 2014-11-24. Retrieved 2015-11-05.\n",
      "\n",
      "^ \"QVC Inc. v. Resultly LLC, No. 14-06714 (E.D. Pa. filed Nov. 24, 2014)\". United States District Court for the Eastern District of Pennsylvania. Retrieved 5 November 2015.\n",
      "\n",
      "^ Neuburger, Jeffrey D (5 December 2014). \"QVC Sues Shopping App for Web Scraping That Allegedly Triggered Site Outage\". The National Law Review. Proskauer Rose LLP. Retrieved 5 November 2015.\n",
      "\n",
      "^ \"Did Iqbal/Twombly Raise the Bar for Browsewrap Claims?\" (PDF). 2010-09-17. Retrieved 2010-10-27.\n",
      "\n",
      "^ \"Can Scraping Non-Infringing Content Become Copyright Infringement... Because Of How Scrapers Work? | Techdirt\". Techdirt. 2009-06-10. Retrieved 2016-05-24.\n",
      "\n",
      "^ \"Facebook v. Power Ventures\". Electronic Frontier Foundation. Retrieved 2016-05-24.\n",
      "\n",
      "^ \"UDSKRIFT AF SØ- & HANDELSRETTENS DOMBOG\" (PDF) (in Danish). bvhd.dk. 2006-02-24. Archived from the original (PDF) on 2007-10-12. Retrieved 2007-05-30.\n",
      "\n",
      "^ \"High Court of Ireland Decisions >> Ryanair Ltd -v- Billigfluege.de GMBH 2010 IEHC 47 (26 February 2010)\". British and Irish Legal Information Institute. 2010-02-26. Retrieved 2012-04-19.\n",
      "\n",
      "^ Matthews, Áine (June 2010). \"Intellectual Property: Website Terms of Use\". Issue 26: June 2010. LK Shields Solicitors Update. p. 03. Retrieved 2012-04-19.\n",
      "\n",
      "^ \"La réutilisation des données publiquement accessibles en ligne à des fins de démarchage commercial | CNIL\". www.cnil.fr (in French). Retrieved 2020-07-05.\n",
      "\n",
      "^ FindDataLab.com (2020-06-09). \"Can You Still Perform Web Scraping With The New CNIL Guidelines?\". Medium. Retrieved 2020-07-05.\n",
      "\n",
      "^ National Office for the Information Economy (February 2004). \"Spam Act 2003: An overview for business\". Australian Communications Authority. p. 6. Retrieved 2017-12-07.\n",
      "\n",
      "^ National Office for the Information Economy (February 2004). \"Spam Act 2003: A practical guide for business\" (PDF). Australian Communications Authority. p. 20. Retrieved 2017-12-07.\n",
      "\n",
      "^ Mayank Dhiman Breaking Fraud & Bot Detection Solutions OWASP AppSec Cali' 2018 Retrieved February 10, 2018.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Web_scraping&oldid=1070889749\"\n"
     ]
    }
   ],
   "source": [
    "data = soup.find(\"div\", id=\"mw-content-text\").text\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Internet of things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Steve Jobs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Names\n",
       "0  Artificial Intelligence\n",
       "1               Blockchain\n",
       "2       Internet of things\n",
       "3          Cloud Computing\n",
       "4                   Amazon\n",
       "5                   Laptop\n",
       "6                   Mobile\n",
       "7                 Computer\n",
       "8                  Windows\n",
       "9               Steve Jobs"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence\n",
      "Blockchain\n",
      "Internet of things\n",
      "Cloud Computing\n",
      "Amazon\n",
      "Laptop\n",
      "Mobile\n",
      "Computer\n",
      "Windows\n",
      "Steve Jobs\n"
     ]
    }
   ],
   "source": [
    "for i in data['Names']:\n",
    "    data.replace(\" \",\"_\")\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Artificial Intelligence\n",
       "1                 Blockchain\n",
       "2         Internet of things\n",
       "3            Cloud Computing\n",
       "4                     Amazon\n",
       "5                     Laptop\n",
       "6                     Mobile\n",
       "7                   Computer\n",
       "8                    Windows\n",
       "9                 Steve Jobs\n",
       "Name: Names, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Names'].replace(to_replace=' ', value='_', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Artificial Intelligence\n",
       "1                 Blockchain\n",
       "2         Internet of things\n",
       "3            Cloud Computing\n",
       "4                     Amazon\n",
       "5                     Laptop\n",
       "6                     Mobile\n",
       "7                   Computer\n",
       "8                    Windows\n",
       "9                 Steve Jobs\n",
       "Name: Names, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Names changed'] = data['Names'].str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Artificial_Intelligence\n",
       "1                 Blockchain\n",
       "2         Internet_of_things\n",
       "3            Cloud_Computing\n",
       "4                     Amazon\n",
       "5                     Laptop\n",
       "6                     Mobile\n",
       "7                   Computer\n",
       "8                    Windows\n",
       "9                 Steve_Jobs\n",
       "Name: Names changed, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Names\"]\n",
    "data['Names changed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(val):\n",
    "    val2 = val.split(\" \")\n",
    "    val2 = \"_\".join(val2)\n",
    "    print(val2)\n",
    "    return val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial_Intelligence\n",
      "Blockchain\n",
      "Internet_of_things\n",
      "Cloud_Computing\n",
      "Amazon\n",
      "Laptop\n",
      "Mobile\n",
      "Computer\n",
      "Windows\n",
      "Steve_Jobs\n"
     ]
    }
   ],
   "source": [
    "data[\"Names New\"] = data['Names'].apply(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Names changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Artificial_Intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blockchain</td>\n",
       "      <td>Blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Internet of things</td>\n",
       "      <td>Internet_of_things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cloud Computing</td>\n",
       "      <td>Cloud_Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Names            Names changed\n",
       "0  Artificial Intelligence  Artificial_Intelligence\n",
       "1               Blockchain               Blockchain\n",
       "2       Internet of things       Internet_of_things\n",
       "3          Cloud Computing          Cloud_Computing\n",
       "4                   Amazon                   Amazon"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(data[\"Names changed\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial_Intelligence',\n",
       " 'Blockchain',\n",
       " 'Internet_of_things',\n",
       " 'Cloud_Computing',\n",
       " 'Amazon',\n",
       " 'Laptop',\n",
       " 'Mobile',\n",
       " 'Computer',\n",
       " 'Windows',\n",
       " 'Steve_Jobs']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial intelligence', 'Blockchain', 'Internet of things', 'Cloud computing', 'Amazon', 'Laptop', 'Mobile', 'Computer', 'Microsoft Windows', 'Steve Jobs']\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "data2 = []\n",
    "for i in names:\n",
    "    page = requests.get(f\"https://en.wikipedia.org/wiki/{i}\")\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    \n",
    "    title = soup.find(\"h1\", id=\"firstHeading\").text\n",
    "    content = soup.find(\"div\", id=\"mw-content-text\").text\n",
    "    titles.append(title)\n",
    "    data2.append(content)\n",
    "\n",
    "\n",
    "print(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Names            Names changed\n",
      "0  Artificial Intelligence  Artificial_Intelligence\n",
      "1               Blockchain               Blockchain\n",
      "2       Internet of things       Internet_of_things\n",
      "3          Cloud Computing          Cloud_Computing\n",
      "4                   Amazon                   Amazon\n",
      "5                   Laptop                   Laptop\n",
      "6                   Mobile                   Mobile\n",
      "7                 Computer                 Computer\n",
      "8                  Windows                  Windows\n",
      "9               Steve Jobs               Steve_Jobs\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\"Names\":titles, \"Data\":data2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Names': ['Artificial intelligence',\n",
       "  'Blockchain',\n",
       "  'Internet of things',\n",
       "  'Cloud computing',\n",
       "  'Amazon',\n",
       "  'Laptop',\n",
       "  'Mobile',\n",
       "  'Computer',\n",
       "  'Microsoft Windows',\n",
       "  'Steve Jobs'],\n",
       " 'Data': ['Intelligence demonstrated by machines\\n\"AI\" redirects here. For other uses, see AI (disambiguation) and Artificial intelligence (disambiguation).\\n\\n\\nPart of a series onArtificial intelligence\\nMajor goals\\nArtificial general intelligence\\nPlanning\\nComputer vision\\nGeneral game playing\\nKnowledge reasoning\\nMachine learning\\nNatural language processing\\nRobotics\\n\\nApproaches\\nSymbolic\\nDeep learning\\nBayesian networks\\nEvolutionary algorithms\\n\\nPhilosophy\\nChinese room\\nFriendly AI\\nControl problem/Takeover\\nEthics\\nExistential risk\\nTuring test\\n\\nHistory\\nTimeline\\nProgress\\nAI winter\\n\\nTechnology\\nApplications\\nProjects\\nProgramming languages\\n\\nGlossary\\nGlossary\\nvte\\n\\nArtificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans. Leading AI textbooks define the field as the study of \"intelligent agents\": any system that perceives its environment and takes actions that maximize its chance of achieving its goals.[a]\\nSome popular accounts use the term \"artificial intelligence\" to describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem-solving\", however, this definition is rejected by major AI researchers.[b]\\nAI applications include advanced web search engines (e.g., Google), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Tesla), automated decision-making and competing at the highest level in strategic game systems (such as chess and Go).[2][citation needed]\\nAs machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect.[3]  For instance, optical character recognition is frequently excluded from things considered to be AI,[4] having become a routine technology.[5]\\nArtificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism,[6][7] followed by disappointment and the loss of funding (known as an \"AI winter\"),[8][9] followed by new approaches, success and renewed funding.[7][10] AI research has tried and discarded many different approaches since its founding, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior. In the first decades of the 21st century, highly mathematical-statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.[11][10]\\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and the ability to move and manipulate objects.[c] General intelligence (the ability to solve an arbitrary problem) is among the field\\'s long-term goals.[12] To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques—including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, probability and economics. AI also draws upon computer science, psychology, linguistics, philosophy, and many other fields.\\nThe field was founded on the assumption that human intelligence \"can be so precisely described that a machine can be made to simulate it\".[d]\\nThis raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction, and philosophy since antiquity.[14]\\nScience fiction and futurology have also suggested that, with its enormous potential and power, AI may become an existential risk to humanity.[15][16]\\n\\nContents\\n\\n1 History\\n2 Goals\\n\\n2.1 Reasoning, problem-solving\\n2.2 Knowledge representation\\n2.3 Planning\\n2.4 Learning\\n2.5 Natural language processing\\n2.6 Perception\\n2.7 Motion and manipulation\\n2.8 Social intelligence\\n2.9 General intelligence\\n\\n\\n3 Tools\\n\\n3.1 Search and optimization\\n3.2 Logic\\n3.3 Probabilistic methods for uncertain reasoning\\n3.4 Classifiers and statistical learning methods\\n3.5 Artificial neural networks\\n\\n3.5.1 Deep learning\\n\\n\\n3.6 Specialized languages and hardware\\n\\n\\n4 Applications\\n5 Philosophy\\n\\n5.1 Defining artificial intelligence\\n\\n5.1.1 Thinking vs. acting: the Turing test\\n5.1.2 Acting humanly vs. acting intelligently: intelligent agents\\n\\n\\n5.2 Evaluating approaches to AI\\n\\n5.2.1 Symbolic AI and its limits\\n5.2.2 Neat vs. scruffy\\n5.2.3 Soft vs. hard computing\\n5.2.4 Narrow vs. general AI\\n\\n\\n5.3 Machine consciousness, sentience and mind\\n\\n5.3.1 Consciousness\\n5.3.2 Computationalism and functionalism\\n5.3.3 Robot rights\\n\\n\\n\\n\\n6 Future\\n\\n6.1 Superintelligence\\n6.2 Risks\\n\\n6.2.1 Technological unemployment\\n6.2.2 Bad actors and weaponized AI\\n6.2.3 Algorithmic bias\\n6.2.4 Existential risk\\n\\n\\n6.3 Ethical machines\\n6.4 Human-Centered AI\\n6.5 Regulation\\n\\n\\n7 In fiction\\n8 See also\\n9 Explanatory notes\\n10 Citations\\n11 References\\n\\n11.1 AI textbooks\\n11.2 History of AI\\n11.3 Other sources\\n\\n\\n12 Further reading\\n13 External links\\n14 Sources\\n\\n\\n\\nHistory\\nMain articles: History of artificial intelligence and Timeline of artificial intelligence\\n Silver didrachma from Crete depicting Talos, an ancient mythical automaton with artificial intelligence\\nArtificial beings with intelligence appeared as storytelling devices in antiquity,[17]\\nand have been common in fiction, as in Mary Shelley\\'s Frankenstein or Karel Čapek\\'s R.U.R.[18] These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.[19]\\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing\\'s theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable act of mathematical deduction. This insight that digital computers can simulate any process of formal reasoning is known as the Church–Turing thesis.[20]\\nThe Church-Turing thesis, along with concurrent discoveries in neurobiology, information theory and cybernetics, led researchers to consider the possibility of building an electronic brain.[21]\\nThe first work that is now generally recognized as AI was McCullouch and Pitts\\' 1943 formal design for Turing-complete \"artificial neurons\".[22]\\nWhen access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to step-by-step symbol manipulation, known as Symbolic AI or GOFAI. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.\\nThe field of AI research was born at a workshop at Dartmouth College in 1956.[e][25]\\nThe attendees became the founders and leaders of AI research.[f]\\nThey and their students produced programs that the press described as \"astonishing\":[g]\\ncomputers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[h][27]\\nBy the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[28]\\nand laboratories had been established around the world.[29]\\nResearchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.[30]\\nHerbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".[31]\\nMarvin Minsky agreed, writing, \"within a generation\\xa0... the problem of creating \\'artificial intelligence\\' will substantially be solved\".[32]\\nThey failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill[33]\\nand ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an \"AI winter\", a period when obtaining funding for AI projects was difficult.\\n[8]\\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[34]\\na form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan\\'s fifth generation computer project inspired the U.S and British governments to restore funding for academic research.[7]\\nHowever, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[9]\\nMany researchers began to doubt that the symbolic approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches to specific AI problems.[35] Robotics researchers, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move, survive, and learn their environment.[i]\\nInterest in neural networks and \"connectionism\" was revived by Geoffrey Hinton, David Rumelhart and others in the middle of the 1980s.[40]\\nSoft computing tools were developed in the 80s, such as neural networks, fuzzy systems, Grey system theory, evolutionary computation and many tools drawn from statistics or mathematical optimization.\\nAI gradually restored its reputation in the late 1990s and early 21st century by finding specific solutions to specific problems. The narrow focus allowed researchers to produce verifiable results, exploit more  mathematical methods, and collaborate with other fields (such as statistics, economics and mathematics).[41]\\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".[11]\\nFaster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.[42]\\nAccording to Bloomberg\\'s Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects.[j] He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets.[10] In a 2017 survey, one in five companies reported they had \"incorporated AI in some offerings or processes\".[43] The amount of research into AI (measured by total publications) increased by 50% in the years 2015–2019.[44]\\nNumerous academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Much of current research involves statistical AI, which is overwhelmingly used to solve specific problems, even highly successful techniques such as deep learning. This concern has led to the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.[12]\\n\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.[c]\\n\\nReasoning, problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[45]\\nBy the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.[46]\\nMany of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.[47]\\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[48]\\n\\n An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.\\nKnowledge representation\\nMain articles: Knowledge representation, Commonsense knowledge, Description logic, and Ontology\\nKnowledge representation and knowledge engineering[49]\\nallow AI programs to answer questions intelligently and make deductions about real-world facts.\\nA representation of \"what exists\" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them.[50]\\nThe most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge and act as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). A truly intelligent program would also need access to commonsense knowledge; the set of facts that an average person knows. The semantics of an ontology is typically represented in description logic, such as the Web Ontology Language.[51]\\nAI research has developed tools to represent specific domains, such as objects, properties, categories and relations between objects;[51]\\nsituations, events, states and time;[52]\\ncauses and effects;[53]\\nknowledge about knowledge (what we know about what other people know);.[54]\\ndefault reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);\\n[55]\\nas well as other domains. Among the most difficult problems in AI are: the breadth of commonsense knowledge (the number of atomic facts that the average person knows is enormous);[56]\\nand the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[48]\\nFormal knowledge representations are used in content-based indexing and retrieval,[57]\\nscene interpretation,[58]\\nclinical decision support,[59]\\nknowledge discovery (mining \"interesting\" and actionable inferences from large databases),[60]\\nand other areas.[61]\\n\\nPlanning\\nMain article: Automated planning and scheduling\\nAn intelligent agent that can plan makes a representation of the state of the world, makes predictions about how their actions will change it and make choices that maximize the utility (or \"value\") of the available choices.[62]\\nIn classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions.[63]\\nHowever, if the agent is not the only actor, then it requires that the agent reason under uncertainty, and continuously re-assess its environment and adapt.[64]\\nMulti-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.[65]\\n\\nLearning\\nMain article: Machine learning\\nMachine learning (ML), a fundamental concept of AI research since the field\\'s inception,[k]\\nis the study of computer algorithms that improve automatically through experience.[l]\\nUnsupervised learning finds patterns in a stream of input. Supervised learning requires a human to label the input data first, and comes in two main varieties: classification and numerical regression. Classification is used to determine what category something belongs in—the program sees a number of examples of things from several categories and will learn to classify new inputs. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. Both classifiers and regression learners can be viewed as \"function approximators\" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, \"spam\" or \"not spam\".[69]\\nIn reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent classifies its responses to form a strategy for operating in its problem space.[70]\\nTransfer learning is when the knowledge gained from one problem is applied to a new problem.[71]\\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[72]\\n\\n\\n A parse tree represents the syntactic structure of a sentence according to some formal grammar.\\nNatural language processing\\nMain article: Natural language processing\\nNatural language processing (NLP)[73]\\nallows machines to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of NLP include information retrieval, question answering and machine translation.[74]\\n\\nSymbolic AI used formal syntax to translate the deep structure of sentences into logic. This failed to produce useful applications, due to the intractability of logic[47] and the breadth of commonsense knowledge.[56] Modern statistical techniques include co-occurrence frequencies (how often one word appears near another), \"Keyword spotting\" (searching for a particular word to retrieve information), transformer-based deep learning (which finds patterns in text), and others.[75] They have achieved acceptable accuracy at the page or paragraph level, and, by 2019, could generate coherent text.[76] Feature detection (pictured: edge detection) helps AI compose informative abstract structures out of raw data.\\nPerception\\nMain articles: Machine perception, Computer vision, and Speech recognition\\nMachine perception[77]\\nis the ability to use input from sensors (such as cameras, microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition,[78]\\nfacial recognition, and object recognition.[79]\\n\\nComputer vision is the ability to analyze visual input.[80]\\nMotion and manipulation\\nMain article: Robotics\\nAI is heavily used in robotics.[81]\\nLocalization is how a robot knows its location and maps its environment. When given a small, static, and visible environment, this is easy; however, dynamic environments, such as (in endoscopy) the interior of a patient\\'s breathing body, pose a greater challenge.[82]\\n\\nMotion planning is the process of breaking down a movement task into \"primitives\" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. Robots can learn from experience how to move efficiently despite the presence of friction and gear slippage.[83]\\n Kismet, a robot with rudimentary social skills[84]\\nSocial intelligence\\nMain article: Affective computing\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood.[85] \\nFor example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.[86]\\n\\nModerate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.[87]\\nGeneral intelligence\\nMain article: Artificial general intelligence\\nA machine with general intelligence can solve a wide variety of problems with breadth and versatility similar to human intelligence. There are several competing ideas about how to develop artificial general intelligence. Hans Moravec and Marvin Minsky argue that work in different individual domains can be incorporated into an advanced multi-agent system or cognitive architecture with general intelligence.[88]\\nPedro Domingos hopes that there is a conceptually straightforward, but mathematically difficult, \"master algorithm\" that could lead to AGI.[89]\\nOthers believe that anthropomorphic features like an artificial brain[90]\\nor simulated child development[m]\\nwill someday reach a critical point where general intelligence emerges.\\n\\nTools\\nSearch and optimization\\nMain articles: Search algorithm, Mathematical optimization, and Evolutionary computation\\nMany problems in AI can be solved theoretically by intelligently searching through many possible solutions:[91]\\nReasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule.[92]\\nPlanning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[93]\\nRobotics algorithms for moving limbs and grasping objects use local searches in configuration space.[94]\\nSimple exhaustive searches[95]\\nare rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use \"heuristics\" or \"rules of thumb\" that prioritize choices in favor of those more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies, heuristics can also serve to eliminate some choices unlikely to lead to a goal (called \"pruning the search tree\"). Heuristics supply the program with a \"best guess\" for the path on which the solution lies.[96]\\nHeuristics limit the search for solutions into a smaller sample size.[97]\\n\\n A particle swarm seeking the global minimum\\nA very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other related optimization algorithms include random optimization, beam search and metaheuristics like simulated annealing.[98]\\nEvolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Classic evolutionary algorithms include genetic algorithms, gene expression programming, and genetic programming.[99]\\nAlternatively, distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[100]\\n\\nLogic\\nMain articles: Logic programming and Automated reasoning\\nLogic[101]\\nis used for knowledge representation and problem-solving, but it can be applied to other problems as well. For example, the satplan algorithm uses logic for planning[102]\\nand inductive logic programming is a method for learning.[103]\\nSeveral different forms of logic are used in AI research. Propositional logic[104] involves truth functions such as \"or\" and \"not\". First-order logic[105]\\nadds quantifiers and predicates and can express facts about objects, their properties, and their relations with each other. Fuzzy logic assigns a \"degree of truth\" (between 0 and 1) to vague statements such as \"Alice is old\" (or rich, or tall, or hungry), that are too linguistically imprecise to be completely true or false.[106]\\nDefault logics, non-monotonic logics and circumscription are forms of logic designed to help with default reasoning and the qualification problem.[55]\\nSeveral extensions of logic have been designed to handle specific domains of knowledge, such as description logics;[51]\\nsituation calculus, event calculus and fluent calculus (for representing events and time);[52]\\ncausal calculus;[53]\\nbelief calculus (belief revision); and modal logics.[54]\\nLogics to model contradictory or inconsistent statements arising in multi-agent systems have also been designed, such as paraconsistent logics.[citation needed]\\n\\nProbabilistic methods for uncertain reasoning\\nMain articles: Bayesian network, Hidden Markov model, Kalman filter, Particle filter, Decision theory, and Utility theory\\n Expectation-maximization clustering of Old Faithful eruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption.\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[107]\\nBayesian networks[108]\\nare a very general tool that can be used for various problems, including reasoning (using the Bayesian inference algorithm),[n][110]\\nlearning (using the expectation-maximization algorithm),[o][112]\\nplanning (using decision networks)[113] and perception (using dynamic Bayesian networks).[114]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[114]\\nA key concept from the science of economics is \"utility\", a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[115]\\nand information value theory.[116] These tools include models such as Markov decision processes,[117] dynamic decision networks,[114] game theory and mechanism design.[118]\\n\\nClassifiers and statistical learning methods\\nMain articles: Classifier (mathematics), Statistical classification, and Machine learning\\nThe simplest AI applications can be divided into two types: classifiers (\"if shiny then diamond\") and controllers (\"if diamond then pick up\"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. Classifiers are functions that use pattern matching to determine the closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class is a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[119]\\nA classifier can be trained in various ways; there are many statistical and machine learning approaches.\\nThe decision tree is the simplest and most widely used symbolic machine learning algorithm.[120]\\nK-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s.[121]\\nKernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[122]\\nThe naive Bayes classifier is reportedly the \"most widely used learner\"[123] at Google, due in part to its scalability.[124]\\nNeural networks are also used for classification.[125]\\nClassifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, distribution of samples across classes, dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as \"naive Bayes\" on most practical data sets.[126]\\n\\nArtificial neural networks\\nMain articles: Artificial neural network and Connectionism\\n A neural network is an interconnected group of nodes, akin to the vast network of neurons in the human brain.\\nNeural networks[125]\\nwere inspired by the architecture of neurons in the human brain. A simple \"neuron\" N accepts input from other neurons, each of which, when activated (or \"fired\"), casts a weighted \"vote\" for or against whether neuron N should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed \"fire together, wire together\") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes.\\nModern neural networks model complex relationships between inputs and outputs and find patterns in data. They can learn continuous functions and even digital logical operations. Neural networks can be viewed as a type of mathematical optimization — they perform gradient descent on a multi-dimensional topology that was created by training the network. The most common training technique is the backpropagation algorithm.[127]\\nOther learning techniques for neural networks are Hebbian learning (\"fire together, wire together\"), GMDH or competitive learning.[128]\\nThe main categories of networks are acyclic or feedforward neural networks (where the signal passes in only one direction) and recurrent neural networks (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are perceptrons, multi-layer perceptrons and radial basis networks.[129]\\n\\n\\nDeep learning\\n Representing images on multiple layers of abstraction in deep learning[130]\\nDeep learning[131]\\nuses several layers of neurons between the network\\'s inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.[132] Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification[133] and others.\\nDeep learning often uses convolutional neural networks for many or all of its layers. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron\\'s receptive field. This can substantially reduce the number of weighted connections between neurons,[134] and creates a hierarchy similar to the organization of the animal visual cortex.[135]\\nIn a recurrent neural network the signal will propagate through a layer more than once;[136] \\nthus, an RNN is an example of deep learning.[137]\\nRNNs can be trained by gradient descent,[138]\\nhowever long-term gradients which are back-propagated can \"vanish\" (that is, they can tend to zero) or \"explode\" (that is, they can tend to infinity), known as the vanishing gradient problem.[139]\\nThe long short term memory (LSTM) technique can prevent this in most cases.[140]\\n\\nSpecialized languages and hardware\\nMain articles: Programming languages for artificial intelligence and Hardware for artificial intelligence\\nSpecialized languages for artificial intelligence have been developed, such as Lisp, Prolog, TensorFlow and many others. Hardware developed for AI includes AI accelerators and neuromorphic computing.\\n\\nApplications\\nMain article: Applications of artificial intelligenceSee also: Embodied cognition\\n For this project the AI had to learn the typical patterns in the colors and brushstrokes of Renaissance painter Raphael. The portrait shows the face of the actress Ornella Muti, \"painted\" by AI in the style of Raphael.\\nAI is relevant to any intellectual task.[141]\\nModern artificial intelligence techniques are pervasive and are too numerous to list here.[142]\\nFrequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.[143]\\nIn the 2010s, AI applications were at the heart of the most commercially successful areas of computing, and have become a ubiquitous feature of daily life. AI is used in search engines (such as Google Search),\\ntargeting online advertisements,[144][non-primary source needed]\\nrecommendation systems (offered by Netflix, YouTube or Amazon),\\ndriving internet traffic,[145][146]\\ntargeted advertising (AdSense, Facebook),\\nvirtual assistants (such as Siri or Alexa),[147]\\nautonomous vehicles (including drones and self-driving cars),\\nautomatic language translation (Microsoft Translator, Google Translate),\\nfacial recognition (Apple\\'s Face ID or Microsoft\\'s DeepFace),\\nimage labeling (used by Facebook, Apple\\'s iPhoto and TikTok)\\nand spam filtering.\\nThere are also thousands of successful AI applications used to solve problems for specific industries or institutions. A few examples are \\nenergy storage,[148]\\ndeepfakes,[149]\\nmedical diagnosis, \\nmilitary logistics, or \\nsupply chain management.\\nGame playing has been a test of AI\\'s strength since the 1950s. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[150] \\nIn 2011, in a Jeopardy! quiz show exhibition match, IBM\\'s question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[151] \\nIn March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[152]\\nOther programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus[p]\\nand Cepheus.[154]\\nDeepMind in the 2010s developed a \"generalized artificial intelligence\" that could learn many diverse Atari games on its own.[155]\\nBy 2020, Natural Language Processing systems such as the enormous GPT-3 (then by far the largest artificial neural network) were matching human performance on pre-existing benchmarks, albeit without the system attaining a commonsense understanding of the contents of the benchmarks.[156]\\nDeepMind\\'s AlphaFold 2 (2020) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[157]\\nOther applications predict the result of judicial decisions,[158] create art (such as poetry or painting) and prove mathematical theorems.\\n\\n AI Patent families for functional application categories and sub categories. Computer vision represents 49 percent of patent families related to a functional application in 2016.\\nIn 2019, WIPO reported that AI was the most prolific emerging technology in terms of number of patent applications and granted patents, the Internet of things was estimated to be the largest in terms of market size. It was followed, again in market size, by big data technologies, robotics, AI, 3D printing and the fifth generation of mobile services (5G).[159] Since AI emerged in the 1950s, 340000 AI-related patent applications were filed by innovators and 1.6 million scientific papers have been published by researchers, with the majority of all AI-related patent filings published since 2013. Companies represent 26 out of the top 30 AI patent applicants, with universities or public research organizations accounting for the remaining four.[160] The ratio of scientific papers to inventions has significantly decreased from 8:1 in 2010 to 3:1 in 2016, which is attributed to be indicative of a shift from theoretical research to the use of AI technologies in commercial products and services. Machine learning is the dominant AI technique disclosed in patents and is included in more than one-third of all identified inventions (134777 machine learning patents filed for a total of 167038 AI patents filed in 2016), with computer vision being the most popular functional application. AI-related patents not only disclose AI techniques and applications, they often also refer to an application field or industry. Twenty application fields were identified in 2016 and included, in order of magnitude: telecommunications (15 percent), transportation (15 percent), life and medical sciences (12 percent), and personal devices, computing and human–computer interaction (11 percent). Other sectors included banking, entertainment, security, industry and manufacturing, agriculture, and networks (including social networks, smart cities and the Internet of things). IBM has the largest portfolio of AI patents with 8,290 patent applications, followed by Microsoft with 5,930 patent applications.[161]\\n\\nPhilosophy\\nMain article: Philosophy of artificial intelligence\\nDefining artificial intelligence\\nThinking vs. acting: the Turing test\\nMain articles: Turing test, Dartmouth Workshop, and Synthetic intelligence\\nAlan Turing wrote in 1950 \"I propose to consider the question \\'can machines think\\'?\"[162]\\nHe advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".[163] \\nThe only thing visible is the behavior of the machine, so it does not matter if the machine is conscious, or has a mind, or whether the intelligence is merely a \"simulation\" and not \"the real thing\".  He noted that we also don\\'t know these things about other people, but that we extend a \"polite convention\" that they are actually \"thinking\". This idea forms the basis of the Turing test.[164][q]\\n\\nActing humanly vs. acting intelligently: intelligent agents\\nMain article: Intelligent agents\\nAI founder John McCarthy said: \"Artificial intelligence is not, by definition, simulation of human intelligence\".[166] Russell and Norvig agree and criticize the Turing test. They wrote: \"Aeronautical engineering texts do not define the goal of their field as \\'making machines that fly so exactly like pigeons that they can fool other pigeons.\\'\"[165] Other researchers and analysts disagree and have argued that AI should simulate natural intelligence by studying psychology or neurobiology.[r]\\nThe intelligent agent paradigm[168]\\ndefines intelligent behavior in general, without reference to human beings. An intelligent agent is a system that perceives its environment and takes actions that maximize its chances of success. Any system that has goal-directed behavior can be analyzed as an intelligent agent: something as simple as a thermostat, as complex as a human being, as well as large systems such as firms, biomes or nations. The intelligent agent paradigm became widely accepted during the 1990s, and currently serves as the definition of the field.[a]\\nThe paradigm has other advantages for AI. It provides a reliable and scientific way to test programs; researchers can directly compare or even combine different approaches to isolated problems, by asking which agent is best at maximizing a given \"goal function\".  It also gives them a common language to communicate with other fields — such as mathematical optimization (which is defined in terms of \"goals\") or economics (which uses the same definition of a \"rational agent\").[169]\\n\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history.[s] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, neat, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\\n\\nSymbolic AI and its limits\\nMain articles: Symbolic AI, Physical symbol systems hypothesis, Moravec\\'s paradox, and Dreyfus\\' critique of artificial intelligence\\nSymbolic AI (or \"GOFAI\")[171] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"[172]\\nHowever, the symbolic approach failed dismally on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec\\'s paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.[173]\\nPhilosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.[174]\\nAlthough his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree.[t][48]\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as  Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[176][177] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision.\\n\\nNeat vs. scruffy\\nMain article: Neats and scruffies\\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. This issue was actively discussed in the 70s and 80s,[178]\\nbut in the 1990s mathematical methods and solid scientific standards became the norm, a transition that Russell and Norvig termed \"the victory of the neats\".[179]\\n\\nSoft vs. hard computing\\nMain article: Soft computing\\nFinding a provably correct or optimal solution is intractable for many important problems.[47] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\n\\nNarrow vs. general AI\\nMain article: Artificial general intelligence\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence (general AI) directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field\\'s long-term goals[180][181]\\nGeneral intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focussing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\n\\nMachine consciousness, sentience and mind\\nMain articles: Philosophy of artificial intelligence and Artificial Consciousness\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field. Stuart Russell and Peter Norvig observe that most AI researchers \"don\\'t care about the [philosophy of AI] — as long as the program works, they don\\'t care whether you call it a simulation of intelligence or real intelligence.\"[182] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\n\\nConsciousness\\nMain articles: Hard problem of consciousness and Theory of mind\\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[183] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all. Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[184]\\n\\nComputationalism and functionalism\\nMain articles: Computationalism, Functionalism (philosophy of mind), and Chinese room\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[185]\\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[u]\\nSearle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[188]\\n\\nRobot rights\\nMain article: Robot rights\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so, then it could also suffer, and thus it would be entitled to certain rights.[189]\\nAny hypothetical robot rights would lie on a spectrum with animal rights and human rights.[190]\\nThis issue has been considered in fiction for centuries,[191]\\nand is now being considered by, for example, California\\'s Institute for the Future, however, critics argue that the discussion is premature.[192]\\n\\nFuture\\nSuperintelligence\\nMain articles: Superintelligence, Technological singularity, and Transhumanism\\nA superintelligence, hyperintelligence, or superhuman intelligence, is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. Superintelligence may also refer to the form or degree of intelligence possessed by such an agent.[181]\\nIf research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement.[193]\\nIts intelligence would increase exponentially in an intelligence explosion and could dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario the \"singularity\".[194]\\nBecause it is difficult or impossible to know the limits of intelligence or the capabilities of superintelligent machines, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.[195]\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.[196]\\nEdward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler\\'s \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.[197]\\n\\nRisks\\nPlay media Lecture by Fillipo Santoni de Sio (Delft University of Technology) on the risks of  artificial intelligence and how we can keep artificial intelligence under control\\nTechnological unemployment\\nMain articles: Workplace impact of artificial intelligence and Technological unemployment\\nIn the past technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we\\'re in uncharted territory\" with AI.[198]\\nA survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[199]\\nSubjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classifies only 9% of U.S. jobs as \"high risk\".[v][201]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist states that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[202]\\nJobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[203]\\n\\nBad actors and weaponized AI\\nMain articles: Lethal autonomous weapon and Artificial intelligence arms race\\nAI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes aid in producing misinformation; advanced AI can make centralized decision making more competitive with liberal and decentralized systems such as markets.[204]\\nTerrorists, criminals and rogue states may use other forms of weaponized AI such as advanced digital warfare and lethal autonomous weapons. By 2015, over fifty countries were reported to be researching battlefield robots.[205]\\nMachine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.[206]\\n\\nAlgorithmic bias\\nMain article: Algorithmic bias\\nAI programs can become biased after learning from real-world data. It is not typically introduced by the system designers but is learned by the program, and thus the programmers are often unaware that the bias exists.[207]\\nBias can be inadvertently introduced by the way training data is selected.[208]\\nIt can also emerge from correlations: AI is used to classify individuals into groups and then make predictions assuming that the individual will resemble other members of the group. In some cases, this assumption may be unfair.[209]\\nAn example of this is COMPAS, a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. ProPublica claims that the COMPAS-assigned recidivism risk level of black defendants is far more likely to be overestimated than that of white defendants, despite the fact that the program was not told the races of the defendants.[210] Other examples where algorithmic bias can lead to unfair outcomes are when AI is used for credit rating or hiring.\\n\\nExistential risk\\nMain articles: Existential risk from artificial general intelligence and Superintelligence\\nSuperintelligent AI may be able to improve itself to the point that humans could not control it. This could, as physicist Stephen Hawking puts it, \"spell the end of the human race\".[211] Philosopher Nick Bostrom argues that sufficiently intelligent AI if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI\\'s goals do not fully reflect humanity\\'s, it might need to harm humanity to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal. He concludes that AI poses a risk to mankind, however humble or \"friendly\" its stated goals might be.[212]\\nPolitical scientist Charles T. Rubin argues that \"any sufficiently advanced benevolence may be indistinguishable from malevolence.\" Humans should not assume machines or robots would treat us favorably because there is no a priori reason to believe that they would share our system of morality.[213]\\nThe opinion of experts and industry insiders is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.[214]\\nStephen Hawking, Microsoft founder Bill Gates, history professor Yuval Noah Harari, and SpaceX founder Elon Musk have all expressed serious misgivings about the future of AI.[215]\\nProminent tech titans including Peter Thiel (Amazon Web Services) and Musk have committed more than $1\\xa0billion to nonprofit companies that champion responsible AI development, such as OpenAI and the Future of Life Institute.[216]\\nMark Zuckerberg (CEO, Facebook) has said that artificial intelligence is helpful in its current form and will continue to assist humans.[217]\\nOther experts argue is that the risks are far enough in the future to not be worth researching,\\nor that humans will be valuable from the perspective of a superintelligent machine.[218]\\nRodney Brooks, in particular, has said that \"malevolent\" AI is still centuries away.[w]\\n\\nEthical machines\\nMain articles: Machine ethics, Friendly AI, Artificial moral agents, and Human Compatible\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[220]\\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[221]\\nMachine ethics is also called machine morality, computational ethics or computational morality,[221]\\nand was founded at an AAAI symposium in 2005.[222]\\nOther approaches include Wendell Wallach\\'s \"artificial moral agents\"[223]\\nand Stuart J. Russell\\'s three principles for developing provably beneficial machines.[224]\\n\\nHuman-Centered AI\\nHuman-Centered Artificial Intelligence (HCAI) is a set of processes for designing applications that are reliable, safe, and trustworthy. These extend the processes of user experience design such as user observation and interviews. Further processes include discussions with stakeholders, usability testing, iterative refinement and continuing evaluation in the use of systems that employ AI and machine learning algorithms. Human-Centered AI manifests in products that are designed to amplify, augment, empower and enhance human performance. These products ensure high levels of human control and high levels of automation.\\nHCAI research includes governance structures that include safety cultures within organizations and independent oversight by experienced groups that review plans for new projects, continuous evaluation of usage, and retrospective analysis of failures.\\nThe rise of HCAI is visible in topics such as explainable AI, transparency, audit trail, fairness, trustworthiness, and controllable systems.\\n\\nRegulation\\nMain articles: Regulation of artificial intelligence, Regulation of algorithms, and AI control problem\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.[225]\\nThe regulatory and  policy landscape for AI is an emerging issue in jurisdictions globally.[226]\\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[44]\\nMost EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, USA and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[44]\\nThe Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[44] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[227]\\n\\nIn fiction\\nMain article: Artificial intelligence in fiction\\n The word \"robot\" itself was coined by Karel Čapek in his 1921 play R.U.R., the title standing for \"Rossum\\'s Universal Robots\"\\nThought-capable artificial beings have appeared as storytelling devices since antiquity,[17]\\nand have been a persistent theme in science fiction.[19]\\nA common trope in these works began with Mary Shelley\\'s Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke\\'s and Stanley Kubrick\\'s 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[228]\\nIsaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov\\'s laws are often brought up during lay discussions of machine ethics;[229]\\nwhile almost all artificial intelligence researchers are familiar with Asimov\\'s laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[230]\\nTranshumanism (the merging of humans and machines) is explored in the manga Ghost in the Shell and the science-fiction series Dune.\\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek\\'s R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[231]\\n\\nSee also\\n\\n\\nComputer programming portal\\nA.I. Rising\\nAI control problem\\nArtificial intelligence arms race\\nArtificial general intelligence\\nBehavior selection algorithm\\nBusiness process automation\\nCase-based reasoning\\nCitizen science\\nEmergent algorithm\\nFemale gendering of AI technologies\\nGlossary of artificial intelligence\\nRobotic process automation\\nSynthetic intelligence\\nUniversal basic income\\nWeak AI\\nExplanatory notes\\n\\n\\n^ a b Definition of AI as the study of intelligent agents, drawn from the leading AI textbooks.\\nPoole, Mackworth & Goebel (1998, p. 1), which provides the version that is used in this article. These authors use the term \"computational intelligence\" as a synonym for artificial intelligence.\\nRussell & Norvig (2003, p.\\xa055) (who prefer the term \"rational agent\") and write \"The whole-agent view is now widely accepted in the field\".\\nNilsson (1998)\\nLegg & Hutter (2007)\\n\\n^ Stuart Russell and Peter Norvig characterize this definition as \"thinking humanly\" and reject it in favor of \"acting rationally\".[1]\\n\\n^ a b This list of intelligent traits is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2003), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998)\\n\\n^ This statement comes from the proposal for the Dartmouth workshop of 1956, which reads: \"Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it.\"[13]\\n\\n^ \\nDaniel Crevier wrote \"the conference is generally recognized as the official birthdate of the new science.\"[23] Russell and Norvifg call the conference \"the birth of artificial intelligence.\"[24]\\n\\n^ \\nRussell and Norvig wrote \"for the next 20 years the field would be dominated by these people and their students.\"[24]\\n\\n^ \\nRussell and Norvig wrote \"it was astonishing whenever a computer did anything kind of smartish\".[26]\\n\\n^ \\nThe programs described are Arthur Samuel\\'s checkers program for the IBM 701, Daniel Bobrow\\'s STUDENT, Newell and Simon\\'s Logic Theorist and Terry Winograd\\'s SHRDLU.\\n\\n^ \\nEmbodied approaches to AI[36] were championed by Hans Moravec[37] and Rodney Brooks[38] and went by many names: Nouvelle AI,[38] Developmental robotics,[39]\\nsituated AI, behavior-based AI as well as others. A similar movement in cognitive science was the embodied mind thesis.\\n\\n^ \\nClark wrote: \"After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever.\"[10]\\n\\n^ Alan Turing discussed the centrality of learning as early as 1950, in his classic paper \"Computing Machinery and Intelligence\".[66] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: \"An Inductive Inference Machine\".[67]\\n\\n^ This is a form of Tom Mitchell\\'s widely quoted definition of machine learning: \"A computer program is set to learn from an experience E with respect to some task T and some performance measure P if its performance on T as measured by P improves with experience E.\"[68]\\n\\n^ \\nAlan Turing suggested in \"Computing Machinery and Intelligence\" that a \"thinking machine\" would need to be educated like a child.[66] Developmental robotics is a modern version of the idea.[39]\\n\\n^ \\nCompared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. AdSense uses a Bayesian network with over 300\\xa0million edges to learn which ads to serve.[109]\\n\\n^ Expectation-maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown latent variables.[111]\\n\\n^ \\nThe Smithsonian reports: \"Pluribus has bested poker pros in a series of six-player no-limit Texas Hold\\'em games, reaching a milestone in artificial intelligence research. It is the first bot to beat humans in a complex multiplayer competition.\"[153]\\n\\n^ \\nThe distinction between \"acting\" and \"thinking\" is due to Russell and Norvig.[165]\\n\\n^ \\nThe distinction between \"acting humanly\" and \"acting rationally\" is due to Russell and Norvig.[165] Pamela McCorduck wrote in 2004 that there are \"two major branches of artificial intelligence: one aimed at producing intelligent behavior regardless of how it was accomplished, and the other aimed at modeling intelligent processes found in nature, particularly human ones.\"[167]\\n\\n^ Nils Nilsson wrote in 1983: \"Simply put, there is wide disagreement in the field about what AI is all about.\"[170]\\n\\n^ \\nDaniel Crevier wrote that \"time has proven the accuracy and perceptiveness of some of Dreyfus\\'s comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier.\"[175]\\n\\n^ \\nSearle presented this definition of \"Strong AI\" in 1999.[186] Searle\\'s original formulation was \"The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states.\"[187] Strong AI is defined similarly by Russell and Norvig: \"The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the \\'weak AI\\' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the \\'strong AI\\' hypothesis.\"[182]\\n\\n^ See table 4; 9% is both the OECD average and the US average.[200]\\n\\n^ Rodney Brooks writes, \"I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional intelligence.\"[219]\\n\\n\\nCitations\\n\\n\\n^ Russell & Norvig (2009), p.\\xa02.\\n\\n^ Google (2016).\\n\\n^ McCorduck (2004), p.\\xa0204.\\n\\n^ Ashok83 (2019).\\n\\n^ Schank (1991), p.\\xa038.\\n\\n^ Crevier (1993), p.\\xa0109.\\n\\n^ a b c \\nFunding initiatives in the early 80s: Fifth Generation Project (Japan), Alvey (UK), Microelectronics and Computer Technology Corporation (US), Strategic Computing Initiative (US):\\nMcCorduck (2004, pp.\\xa0426–441)\\nCrevier (1993, pp.\\xa0161–162, 197–203, 211, 240)\\nRussell & Norvig (2003, p.\\xa024)\\nNRC (1999, pp.\\xa0210–211)\\nNewquist (1994, pp.\\xa0235–248)\\n\\n^ a b \\nFirst AI Winter, Lighthill report, Mansfield Amendment\\nCrevier (1993, pp.\\xa0115–117)\\nRussell & Norvig (2003, p.\\xa022)\\nNRC (1999, pp.\\xa0212–213)\\nHowe (1994)\\nNewquist (1994, pp.\\xa0189–201)\\n\\n^ a b \\nSecond AI Winter:\\nMcCorduck (2004, pp.\\xa0430–435)\\nCrevier (1993, pp.\\xa0209–210)\\nNRC (1999, pp.\\xa0214–216)\\nNewquist (1994, pp.\\xa0301–318)\\n\\n^ a b c d Clark (2015b).\\n\\n^ a b \\nAI widely used in late 1990s:\\nRussell & Norvig (2003, p.\\xa028)\\nKurzweil (2005, p.\\xa0265)\\nNRC (1999, pp.\\xa0216–222)\\nNewquist (1994, pp.\\xa0189–201)\\n\\n^ a b \\nPennachin & Goertzel (2007); Roberts (2016)\\n\\n^ McCarthy et al. (1955).\\n\\n^ Newquist (1994), pp.\\xa045–53.\\n\\n^ Spadafora (2016).\\n\\n^ Lombardo, Boehm & Nairz (2020).\\n\\n^ a b \\nAI in myth:\\nMcCorduck (2004, pp.\\xa04–5)\\nRussell & Norvig (2003, p.\\xa0939)\\n\\n^ McCorduck (2004), pp.\\xa017–25.\\n\\n^ a b McCorduck (2004), pp.\\xa0340–400.\\n\\n^ Berlinski (2000).\\n\\n^ \\nAI\\'s immediate precursors:\\nMcCorduck (2004, pp.\\xa051–107)\\nCrevier (1993, pp.\\xa027–32)\\nRussell & Norvig (2003, pp.\\xa015, 940)\\nMoravec (1988, p.\\xa03)\\n\\n^ Russell & Norvig (2009), p.\\xa016.\\n\\n^ Crevier (1993), pp.\\xa047–49.\\n\\n^ a b Russell & Norvig (2003), p.\\xa017.\\n\\n^ \\nDartmouth workshop:\\nRussell & Norvig (2003, p.\\xa017)\\nMcCorduck (2004, pp.\\xa0111–136)\\nNRC (1999, pp.\\xa0200–201)\\nThe proposal:\\nMcCarthy et al. (1955)\\n\\n^ Russell & Norvig (2003), p.\\xa018.\\n\\n^ \\nSuccessful Symbolic AI programs:\\nMcCorduck (2004, pp.\\xa0243–252)\\nCrevier (1993, pp.\\xa052–107)\\nMoravec (1988, p.\\xa09)\\nRussell & Norvig (2003, pp.\\xa018–21)\\n\\n^ \\nAI heavily funded in 1960s:\\nMcCorduck (2004, p.\\xa0131)\\nCrevier (1993, pp.\\xa051, 64–65)\\nNRC (1999, pp.\\xa0204–205)\\n\\n^ Howe (1994).\\n\\n^ Newquist (1994), pp.\\xa086–86.\\n\\n^ \\nSimon (1965, p.\\xa096) quoted in Crevier (1993, p.\\xa0109)\\n\\n^ \\nMinsky (1967, p.\\xa02) quoted in Crevier (1993, p.\\xa0109)\\n\\n^ Lighthill (1973).\\n\\n^ \\nExpert systems:\\nRussell & Norvig (2003, pp.\\xa022–24)\\nLuger & Stubblefield (2004, pp.\\xa0227–331)\\nNilsson (1998, chpt. 17.4)\\nMcCorduck (2004, pp.\\xa0327–335, 434–435)\\nCrevier (1993, pp.\\xa0145–62, 197–203)\\nNewquist (1994, pp.\\xa0155–183)\\n\\n^ Nilsson (1998), p.\\xa07.\\n\\n^ McCorduck (2004), pp.\\xa0454–462.\\n\\n^ Moravec (1988).\\n\\n^ a b Brooks (1990).\\n\\n^ a b \\nDevelopmental robotics:\\nWeng et al. (2001)\\nLungarella et al. (2003)\\nAsada et al. (2009)\\nOudeyer (2010)\\n\\n^ \\nRevival of connectionism:\\nCrevier (1993, pp.\\xa0214–215)\\nRussell & Norvig (2003, p.\\xa025)\\n\\n^ \\nFormal and narrow methods adopted in the 1990s:\\nRussell & Norvig (2003, pp.\\xa025–26)\\nMcCorduck (2004, pp.\\xa0486–487)\\n\\n^ McKinsey (2018).\\n\\n^ MIT Sloan Management Review (2018); Lorica (2017)\\n\\n^ a b c d UNESCO (2021).\\n\\n^ \\nProblem solving, puzzle solving, game playing and deduction:\\nRussell & Norvig (2003, chpt. 3–9)\\nPoole, Mackworth & Goebel (1998, chpt. 2,3,7,9)\\nLuger & Stubblefield (2004, chpt. 3,4,6,8)\\nNilsson (1998, chpt. 7–12)\\n\\n^ \\nUncertain reasoning:\\nRussell & Norvig (2003, pp.\\xa0452–644)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0345–395)\\nLuger & Stubblefield (2004, pp.\\xa0333–381)\\nNilsson (1998, chpt. 19)\\n\\n^ a b c \\nIntractability and efficiency and the combinatorial explosion:\\nRussell & Norvig (2003, pp.\\xa09, 21–22)\\n\\n^ a b c \\nPsychological evidence of the prevalence sub-symbolic reasoning and knowledge:\\nKahneman (2011)\\nWason & Shapiro (1966)\\nKahneman, Slovic & Tversky (1982)\\nDreyfus & Dreyfus (1986)\\n\\n^ \\nKnowledge representation and knowledge engineering:\\nRussell & Norvig (2003, pp.\\xa0260–266, 320–363)\\nPoole, Mackworth & Goebel (1998, pp.\\xa023–46, 69–81, 169–233, 235–277, 281–298, 319–345)\\nLuger & Stubblefield (2004, pp.\\xa0227–243),\\nNilsson (1998, chpt. 17.1–17.4, 18)\\n\\n^ Russell & Norvig (2003), pp.\\xa0320–328.\\n\\n^ a b c \\nRepresenting categories and relations: Semantic networks, description logics, inheritance (including frames and scripts):\\nRussell & Norvig (2003, pp.\\xa0349–354),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0174–177),\\nLuger & Stubblefield (2004, pp.\\xa0248–258),\\nNilsson (1998, chpt. 18.3)\\n\\n^ a b Representing events and time:Situation calculus, event calculus, fluent calculus (including solving the frame problem):\\nRussell & Norvig (2003, pp.\\xa0328–341),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0281–298),\\nNilsson (1998, chpt. 18.2)\\n\\n^ a b \\nCausal calculus:\\nPoole, Mackworth & Goebel (1998, pp.\\xa0335–337)\\n\\n^ a b \\nRepresenting knowledge about knowledge: Belief calculus, modal logics:\\nRussell & Norvig (2003, pp.\\xa0341–344),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0275–277)\\n\\n^ a b \\nDefault reasoning, Frame problem, default logic, non-monotonic logics, circumscription, closed world assumption, abduction:\\nRussell & Norvig (2003, pp.\\xa0354–360)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0248–256, 323–335)\\nLuger & Stubblefield (2004, pp.\\xa0335–363)\\nNilsson (1998, ~18.3.3)\\n(Poole et al. places abduction under \"default reasoning\". Luger et al. places this under \"uncertain reasoning\").\\n\\n^ a b \\nBreadth of commonsense knowledge:\\nRussell & Norvig (2003, p.\\xa021),\\nCrevier (1993, pp.\\xa0113–114),\\nMoravec (1988, p.\\xa013),\\nLenat & Guha (1989, Introduction)\\n\\n^ Smoliar & Zhang (1994).\\n\\n^ Neumann & Möller (2008).\\n\\n^ Kuperman, Reichley & Bailey (2006).\\n\\n^ McGarry (2005).\\n\\n^ Bertini, Del Bimbo & Torniai (2006).\\n\\n^ \\nPlanning:\\nRussell & Norvig (2003, pp.\\xa0375–459)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0281–316)\\nLuger & Stubblefield (2004, pp.\\xa0314–329)\\nNilsson (1998, chpt. 10.1–2, 22)\\nInformation value theory:\\nRussell & Norvig (2003, pp.\\xa0600–604)\\n\\n^ \\nClassical planning:\\nRussell & Norvig (2003, pp.\\xa0375–430)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0281–315)\\nLuger & Stubblefield (2004, pp.\\xa0314–329)\\nNilsson (1998, chpt. 10.1–2, 22)\\n\\n^ \\nPlanning and acting in non-deterministic domains: conditional planning, execution monitoring, replanning and continuous planning:\\nRussell & Norvig (2003, pp.\\xa0430–449)\\n\\n^ \\nMulti-agent planning and emergent behavior:\\nRussell & Norvig (2003, pp.\\xa0449–455)\\n\\n^ a b Turing (1950). sfnp error: no target: CITEREFTuring1950 (help)\\n\\n^ Solomonoff (1956).\\n\\n^ Russell & Norvig (2003), pp.\\xa0649–788.\\n\\n^ \\nLearning:\\nRussell & Norvig (2003, pp.\\xa0649–788)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0397–438)\\nLuger & Stubblefield (2004, pp.\\xa0385–542)\\nNilsson (1998, chpt. 3.3, 10.3, 17.5, 20)\\n\\n^ \\nReinforcement learning:\\nRussell & Norvig (2003, pp.\\xa0763–788)\\nLuger & Stubblefield (2004, pp.\\xa0442–449)\\n\\n^ The Economist (2016).\\n\\n^ Jordan & Mitchell (2015).\\n\\n^ \\nNatural language processing (NLP):\\nRussell & Norvig (2003, pp.\\xa0790–831)\\nPoole, Mackworth & Goebel (1998, pp.\\xa091–104)\\nLuger & Stubblefield (2004, pp.\\xa0591–632)\\n\\n^ \\nApplications of NLP:\\nRussell & Norvig (2003, pp.\\xa0840–857)\\nLuger & Stubblefield (2004, pp.\\xa0623–630)\\n\\n^ Modern statistical approaches to NLP:\\nCambria & White (2014)\\n\\n^ Vincent (2019).\\n\\n^ \\nMachine perception:\\nRussell & Norvig (2003, pp.\\xa0537–581, 863–898)\\nNilsson (1998, ~chpt. 6)\\n\\n^ \\nSpeech recognition:\\nRussell & Norvig (2003, pp.\\xa0568–578)\\n\\n^ \\nObject recognition:\\nRussell & Norvig (2003, pp.\\xa0885–892)\\n\\n^ \\nComputer vision:\\nRussell & Norvig (2003, pp.\\xa0863–898)\\nNilsson (1998, chpt. 6)\\n\\n^ \\nRobotics:\\nRussell & Norvig (2003, pp.\\xa0901–942)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0443–460)\\n\\n^ \\nRobotic mapping and Localization:\\nRussell & Norvig (2003, pp.\\xa0908–915)\\nCadena et al. (2016)\\n\\n^ Motion planning and configuration space:\\nRussell & Norvig (2003, pp.\\xa0916–932)\\nTecuci (2012)\\n\\n^ MIT AIL (2014).\\n\\n^ \\nAffective computing:\\nThro (1993)\\nEdelson (1991)\\nTao & Tan (2005)\\nScassellati (2002)\\n\\n^ Waddell (2018).\\n\\n^ Poria et al. (2017).\\n\\n^ \\nThe Society of Mind:\\nMinsky (1986)\\nMoravec\\'s \"golden spike\":\\nMoravec (1988, p.\\xa020)\\nMulti-agent systems, hybrid intelligent systems, agent architectures, cognitive architecture:\\nRussell & Norvig (2003, pp.\\xa027, 932, 970–972)\\nNilsson (1998, chpt. 25)\\n\\n^ Domingos (2015), Chpt. 9.\\n\\n^ \\nArtificial brain as an approach to AGI: \\nRussell & Norvig (2003, p.\\xa0957)\\nCrevier (1993, pp.\\xa0271 & 279)\\nGoertzel et al. (2010)\\nA few of the people who make some form of the argument: \\nMoravec (1988, p.\\xa020)\\nKurzweil (2005, p.\\xa0262)\\nHawkins & Blakeslee (2005)\\n\\n^ \\nSearch algorithms:\\nRussell & Norvig (2003, pp.\\xa059–189)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0113–163)\\nLuger & Stubblefield (2004, pp.\\xa079–164, 193–219)\\nNilsson (1998, chpt. 7–12)\\n\\n^ \\nForward chaining, backward chaining, Horn clauses, and logical deduction as search:\\nRussell & Norvig (2003, pp.\\xa0217–225, 280–294)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0~46–52)\\nLuger & Stubblefield (2004, pp.\\xa062–73)\\nNilsson (1998, chpt. 4.2, 7.2)\\n\\n^ \\nState space search and planning:\\nRussell & Norvig (2003, pp.\\xa0382–387)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0298–305)\\nNilsson (1998, chpt. 10.1–2)\\n\\n^ Moving and configuration space:\\nRussell & Norvig (2003, pp.\\xa0916–932)\\n\\n^ Uninformed searches (breadth first search, depth first search and general state space search):\\nRussell & Norvig (2003, pp.\\xa059–93)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0113–132)\\nLuger & Stubblefield (2004, pp.\\xa079–121)\\nNilsson (1998, chpt. 8)\\n\\n^ \\nHeuristic or informed searches (e.g., greedy best first and A*):\\nRussell & Norvig (2003, pp.\\xa094–109)\\nPoole, Mackworth & Goebel (1998, pp.\\xa0pp. 132–147)\\nPoole & Mackworth (2017, Section 3.6)\\nLuger & Stubblefield (2004, pp.\\xa0133–150)\\n\\n^ Tecuci (2012).\\n\\n^ Optimization searches:\\nRussell & Norvig (2003, pp.\\xa0110–116, 120–129)\\nPoole, Mackworth & Goebel (1998, pp.\\xa056–163)\\nLuger & Stubblefield (2004, pp.\\xa0127–133)\\n\\n^ \\nGenetic programming and genetic algorithms:\\nLuger & Stubblefield (2004, pp.\\xa0509–530)\\nNilsson (1998, chpt. 4.2)\\n\\n^ \\nArtificial life and society based learning:\\nLuger & Stubblefield (2004, pp.\\xa0530–541)\\nMerkle & Middendorf (2013)\\n\\n^ \\nLogic:\\nRussell & Norvig (2003, pp.\\xa0194–310),\\nLuger & Stubblefield (2004, pp.\\xa035–77),\\nNilsson (1998, chpt. 13–16)\\n\\n^ \\nSatplan:\\nRussell & Norvig (2003, pp.\\xa0402–407),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0300–301),\\nNilsson (1998, chpt. 21)\\n\\n^ \\nExplanation based learning, relevance based learning, inductive logic programming, case based reasoning:\\nRussell & Norvig (2003, pp.\\xa0678–710),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0414–416),\\nLuger & Stubblefield (2004, pp.\\xa0~422–442),\\nNilsson (1998, chpt. 10.3, 17.5)\\n\\n^ \\nPropositional logic:\\nRussell & Norvig (2003, pp.\\xa0204–233),\\nLuger & Stubblefield (2004, pp.\\xa045–50)\\nNilsson (1998, chpt. 13)\\n\\n^ First-order logic and features such as equality:\\nRussell & Norvig (2003, pp.\\xa0240–310),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0268–275),\\nLuger & Stubblefield (2004, pp.\\xa050–62),\\nNilsson (1998, chpt. 15)\\n\\n^ \\nFuzzy logic:\\nRussell & Norvig (2003, pp.\\xa0526–527)\\nScientific American (1999)\\n\\n^ \\nStochastic methods for uncertain reasoning:\\nRussell & Norvig (2003, pp.\\xa0462–644),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0345–395),\\nLuger & Stubblefield (2004, pp.\\xa0165–191, 333–381),\\nNilsson (1998, chpt. 19)\\n\\n^ \\nBayesian networks:\\nRussell & Norvig (2003, pp.\\xa0492–523),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0361–381),\\nLuger & Stubblefield (2004, pp.\\xa0~182–190, ≈363–379),\\nNilsson (1998, chpt. 19.3–4)\\n\\n^ Domingos (2015), chapter 6.\\n\\n^ \\nBayesian inference algorithm:\\nRussell & Norvig (2003, pp.\\xa0504–519),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0361–381),\\nLuger & Stubblefield (2004, pp.\\xa0~363–379),\\nNilsson (1998, chpt. 19.4 & 7)\\n\\n^ Domingos (2015), p.\\xa0210.\\n\\n^ \\nBayesian learning and the expectation-maximization algorithm:\\nRussell & Norvig (2003, pp.\\xa0712–724),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0424–433),\\nNilsson (1998, chpt. 20)\\nDomingos (2015, p.\\xa0210)\\n\\n^ Bayesian decision theory and Bayesian decision networks:\\nRussell & Norvig (2003, pp.\\xa0597–600)\\n\\n^ a b c Stochastic temporal models:\\nRussell & Norvig (2003, pp.\\xa0537–581)\\nDynamic Bayesian networks:\\nRussell & Norvig (2003, pp.\\xa0551–557)\\nHidden Markov model:\\n(Russell & Norvig 2003, pp.\\xa0549–551)\\nKalman filters:\\nRussell & Norvig (2003, pp.\\xa0551–557)\\n\\n^ \\ndecision theory and decision analysis:\\nRussell & Norvig (2003, pp.\\xa0584–597),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0381–394)\\n\\n^ \\nInformation value theory:\\nRussell & Norvig (2003, pp.\\xa0600–604)\\n\\n^ Markov decision processes and dynamic decision networks:\\nRussell & Norvig (2003, pp.\\xa0613–631)\\n\\n^ Game theory and mechanism design:\\nRussell & Norvig (2003, pp.\\xa0631–643)\\n\\n^ \\nStatistical learning methods and classifiers:\\nRussell & Norvig (2003, pp.\\xa0712–754),\\nLuger & Stubblefield (2004, pp.\\xa0453–541)\\n\\n^ \\nDecision tree:\\nDomingos (2015, p.\\xa088)\\nRussell & Norvig (2003, pp.\\xa0653–664),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0403–408),\\nLuger & Stubblefield (2004, pp.\\xa0408–417)\\n\\n^ \\nK-nearest neighbor algorithm:\\nDomingos (2015, p.\\xa0187)\\nRussell & Norvig (2003, pp.\\xa0733–736)\\n\\n^ \\nkernel methods such as the support vector machine:\\nDomingos (2015, p.\\xa088)\\nRussell & Norvig (2003, pp.\\xa0749–752)\\nGaussian mixture model:\\nRussell & Norvig (2003, pp.\\xa0725–727)\\n\\n^ Domingos (2015), p.\\xa0152.\\n\\n^ \\nNaive Bayes classifier:\\nDomingos (2015, p.\\xa0152)\\nRussell & Norvig (2003, p.\\xa0718)\\n\\n^ a b \\nNeural networks:\\nRussell & Norvig (2003, pp.\\xa0736–748),\\nPoole, Mackworth & Goebel (1998, pp.\\xa0408–414),\\nLuger & Stubblefield (2004, pp.\\xa0453–505),\\nNilsson (1998, chpt. 3)\\nDomingos (2015, Chapter 4)\\n\\n^ \\nClassifier performance:\\nvan der Walt & Bernard (2006)\\nRussell & Norvig (2009, 18.12: Learning from Examples: Summary)\\n\\n^ \\nBackpropagation:\\nRussell & Norvig (2003, pp.\\xa0744–748),\\nLuger & Stubblefield (2004, pp.\\xa0467–474),\\nNilsson (1998, chpt. 3.3)\\nPaul Werbos\\' introduction of backpropagation to AI:\\nWerbos (1974); Werbos (1982)\\nAutomatic differentiation, an essential precursor:\\nLinnainmaa (1970); Griewank (2012)\\n\\n^ \\nCompetitive learning, Hebbian coincidence learning, Hopfield networks and attractor networks:\\nLuger & Stubblefield (2004, pp.\\xa0474–505)\\n\\n^ \\nFeedforward neural networks, perceptrons and radial basis networks:\\nRussell & Norvig (2003, pp.\\xa0739–748, 758)\\nLuger & Stubblefield (2004, pp.\\xa0458–467)\\n\\n^ Schulz & Behnke (2012).\\n\\n^ \\nDeep learning:\\nGoodfellow, Bengio & Courville (2016)\\nHinton et al. (2016)\\nSchmidhuber (2015)\\n\\n^ Deng & Yu (2014), pp.\\xa0199–200.\\n\\n^ Ciresan, Meier & Schmidhuber (2012).\\n\\n^ Habibi (2017).\\n\\n^ Fukushima (2007).\\n\\n^ \\nRecurrent neural networks, Hopfield nets:\\nRussell & Norvig (2003, p.\\xa0758)\\nLuger & Stubblefield (2004, pp.\\xa0474–505)\\nSchmidhuber (2015)\\n\\n^ Schmidhuber (2015).\\n\\n^ \\nWerbos (1988); \\nRobinson & Fallside (1987);\\nWilliams & Zipser (1994)\\n\\n^ \\nGoodfellow, Bengio & Courville (2016);\\nHochreiter (1991)\\n\\n^ Hochreiter & Schmidhuber (1997); Gers, Schraudolph & Schraudolph (2002)\\n\\n^ Russell & Norvig (2009), p.\\xa01.\\n\\n^ European Commission (2020), p.\\xa01.\\n\\n^ CNN (2006).\\n\\n^ \\nTargeted advertising:\\nRussell & Norvig (2009, p.\\xa01)\\nEconomist (2016)\\nLohr (2016)\\n\\n^ Lohr (2016).\\n\\n^ Smith (2016).\\n\\n^ Rowinski (2013).\\n\\n^ Frangoul (2019).\\n\\n^ Brown (2019).\\n\\n^ McCorduck (2004), pp.\\xa0480–483.\\n\\n^ Markoff (2011).\\n\\n^ \\nGoogle (2016); BBC (2016)\\n\\n^ Solly (2019).\\n\\n^ Bowling et al. (2015).\\n\\n^ Sample (2017).\\n\\n^ Anadiotis (2020).\\n\\n^ Heath (2020).\\n\\n^ Aletras et al. (2016).\\n\\n^ \"Intellectual Property and Frontier Technologies\". WIPO.\\n\\n^ \"WIPO Technology Trends 2019 - Artificial Intelligence\" (PDF). WIPO. 2019.\\n\\n^ \"WIPO Technology Trends 2019 - Artificial Intelligence\" (PDF). WIPO. 2019.\\n\\n^ Turing (1950), p.\\xa01. sfnp error: no target: CITEREFTuring1950 (help)\\n\\n^ Turing (1948).\\n\\n^ \\nTuring\\'s original publication of the Turing test in \"Computing machinery and intelligence\":\\nTuring (1950) harvtxt error: no target: CITEREFTuring1950 (help)\\nHistorical influence and philosophical implications:\\nHaugeland (1985, pp.\\xa06–9)\\nCrevier (1993, p.\\xa024)\\nMcCorduck (2004, pp.\\xa070–71)\\nRussell & Norvig (2003, pp.\\xa02–3 and 948)\\n\\n^ a b c Russell & Norvig (2003), p.\\xa03.\\n\\n^ Maker (2006).\\n\\n^ McCorduck (2004), pp.\\xa0100–101.\\n\\n^ \\nThe intelligent agent paradigm:\\nRussell & Norvig (2003, pp.\\xa027, 32–58, 968–972)\\nPoole, Mackworth & Goebel (1998, pp.\\xa07–21)\\nLuger & Stubblefield (2004, pp.\\xa0235–240)\\nHutter (2005, pp.\\xa0125–126)\\nThe definition used in this article, in terms of goals, actions, perception and environment, is due to Russell & Norvig (2003). Other definitions also include knowledge, learning and autonomy as additional criteria.\\n\\n^ Russell & Norvig (2003), p.\\xa027.\\n\\n^ Nilsson (1983), p.\\xa010.\\n\\n^ Haugeland (1985), pp.\\xa0112–117.\\n\\n^ \\nPhysical symbol system hypothesis:\\nNewell & Simon (1976, p.\\xa0116)\\nHistorical significance:\\nMcCorduck (2004, p.\\xa0153)\\nRussell & Norvig (2003, p.\\xa018)\\n\\n^ \\nMoravec\\'s paradox:\\nMoravec (1988, pp.\\xa015–16)\\nMinsky (1986, p.\\xa029)\\nPinker (2007, pp.\\xa0190–91)\\n\\n^ \\nDreyfus\\' critique of AI:\\nDreyfus (1972)\\nDreyfus & Dreyfus (1986)\\nHistorical significance and philosophical implications:\\nCrevier (1993, pp.\\xa0120–132)\\nMcCorduck (2004, pp.\\xa0211–239)\\nRussell & Norvig (2003, pp.\\xa0950–952)\\nFearn (2007, Chpt. 3)\\n\\n^ Crevier (1993), p.\\xa0125.\\n\\n^ Langley (2011).\\n\\n^ Katz (2012).\\n\\n^ \\nNeats vs. scruffies, the historic debate:\\nMcCorduck (2004, pp.\\xa0421–424, 486–489)\\nCrevier (1993, p.\\xa0168)\\nNilsson (1983, pp.\\xa010–11)\\nA classic example of the \"scruffy\" approach to intelligence:\\nMinsky (1986)\\nA modern example of neat AI and its aspirations:\\nDomingos (2015)\\n\\n^ Russell & Norvig (2003), p.\\xa025-26.\\n\\n^ Pennachin & Goertzel (2007).\\n\\n^ a b Roberts (2016).\\n\\n^ a b Russell & Norvig (2003), p.\\xa0947.\\n\\n^ Chalmers (1995).\\n\\n^ Dennett (1991).\\n\\n^ Horst (2005).\\n\\n^ Searle (1999).\\n\\n^ Searle (1980), p.\\xa01.\\n\\n^ \\nSearle\\'s Chinese room argument:\\nSearle (1980). Searle\\'s original presentation of the thought experiment.\\nSearle (1999).\\nDiscussion:\\nRussell & Norvig (2003, pp.\\xa0958–960)\\nMcCorduck (2004, pp.\\xa0443–445)\\nCrevier (1993, pp.\\xa0269–271)\\n\\n^ \\nRobot rights:\\nRussell & Norvig (2003, p.\\xa0964)\\nBBC (2006)\\nMaschafilm (2010) (the film Plug & Pray)\\n\\n^ Evans (2015).\\n\\n^ McCorduck (2004), pp.\\xa019–25.\\n\\n^ Henderson (2007).\\n\\n^ Omohundro (2008).\\n\\n^ Vinge (1993).\\n\\n^ Russell & Norvig (2003), p.\\xa0963.\\n\\n^ \\nTranshumanism:\\nMoravec (1988)\\nKurzweil (2005)\\nRussell & Norvig (2003, p.\\xa0963)\\n\\n^ \\nAI as evolution:\\nEdward Fredkin is quoted in McCorduck (2004, p.\\xa0401)\\nButler (1863)\\nDyson (1998)\\n\\n^ \\nFord & Colvin (2015);\\nMcGaughey (2018)\\n\\n^ IGM Chicago (2017).\\n\\n^ Arntz, Gregory & Zierahn (2016), p.\\xa033.\\n\\n^ \\nLohr (2017);\\nFrey & Osborne (2017);\\nArntz, Gregory & Zierahn (2016, p.\\xa033)\\n\\n^ Morgenstern (2015).\\n\\n^ Mahdawi (2017); Thompson (2014)\\n\\n^ Harari (2018).\\n\\n^ \\nWeaponized AI:\\nRobitzski (2018)\\nSainato (2015)\\n\\n^ Urbina, Fabio; Lentzos, Filippa; Invernizzi, Cédric; Ekins, Sean (7 March 2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189–191. doi:10.1038/s42256-022-00465-9. S2CID\\xa0247302391. Retrieved 15 March 2022.\\n\\n^ CNA (2019).\\n\\n^ Goffrey (2008), p.\\xa017.\\n\\n^ Lipartito (2011, p.\\xa036); Goodman & Flaxman (2017, p.\\xa06)\\n\\n^ Larson & Angwin (2016).\\n\\n^ Cellan-Jones (2014).\\n\\n^ Bostrom (2014); Müller & Bostrom (2014); Bostrom (2015)\\n\\n^ Rubin (2003).\\n\\n^ Müller & Bostrom (2014).\\n\\n^ \\nLeaders\\' concerns about the existential risks of AI:\\nRawlinson (2015)\\nHolley (2015)\\nGibbs (2014)\\nChurm (2019)\\nSainato (2015)\\n\\n^ \\nFunding to mitigate risks of AI:\\nPost (2015)\\nDel Prado (2015)\\nClark (2015a)\\nFastCompany (2015)\\n\\n^ \\nLeaders who argue the benefits of AI outweigh the risks:\\nThibodeau (2019)\\nBhardwaj (2018)\\n\\n^ \\nArguments that AI is not an imminent risk:\\nBrooks (2014)\\nGeist (2015)\\nMadrigal (2015)\\nLee (2014)\\n\\n^ Brooks (2014).\\n\\n^ Yudkowsky (2008).\\n\\n^ a b Anderson & Anderson (2011).\\n\\n^ AAAI (2014).\\n\\n^ Wallach (2010).\\n\\n^ Russell (2019), p.\\xa0173.\\n\\n^ \\nRegulation of AI to mitigate risks:\\nBerryhill et al. (2019)\\nBarfield & Pagallo (2018)\\nIphofen & Kritikos (2019)\\nWirtz, Weyerer & Geyer (2018)\\nBuiten (2019)\\n\\n^ Law Library of Congress (U.S.). Global Legal Research Directorate (2019).\\n\\n^ Kissinger, Henry (1 November 2021). \"The Challenge of Being Human in the Age of AI\". The Wall Street Journal.\\n\\n^ Buttazzo (2001).\\n\\n^ Anderson (2008).\\n\\n^ McCauley (2007).\\n\\n^ Galvan (1997).\\n\\n\\nReferences\\nAI textbooks\\nThese were the four the most widely used AI textbooks in 2008.\\n\\n\\nLuger, George; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (5th\\xa0ed.). Benjamin/Cummings. ISBN\\xa0978-0-8053-4780-7. Archived from the original on 26 July 2020. Retrieved 17 December 2019.\\nNilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN\\xa0978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nRussell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd\\xa0ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN\\xa00-13-790395-2.\\nPoole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN\\xa0978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nLater editions.\\n\\nRussell, Stuart J.; Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd\\xa0ed.). Upper Saddle River, New Jersey: Prentice Hall. ISBN\\xa0978-0-13-604259-4..\\nPoole, David; Mackworth, Alan (2017). Artificial Intelligence: Foundations of Computational Agents (2nd\\xa0ed.). Cambridge University Press. ISBN\\xa0978-1-107-19539-4.\\nThe two most widely used textbooks in 2021.[1]\\n\\nRussell, Stuart J.; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th\\xa0ed.). Hoboken: Pearson. ISBN\\xa09780134610993. LCCN\\xa020190474.\\nKnight, Kevin; Rich, Elaine (1 January 2010). Artificial Intelligence (3rd\\xa0ed.). Mc Graw Hill India. ISBN\\xa09780070087705.\\n\\nHistory of AI\\n\\nCrevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: BasicBooks. ISBN\\xa00-465-02997-3..\\nMcCorduck, Pamela (2004), Machines Who Think (2nd\\xa0ed.), Natick, MA: A. K. Peters, Ltd., ISBN\\xa01-56881-205-1.\\nNewquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN\\xa0978-0-672-30412-5.\\nNilsson, Nils (2009). The Quest for Artificial Intelligence: A History of Ideas and Achievements. New York: Cambridge University Press. ISBN\\xa0978-0-521-12293-1.\\n\\nOther sources\\nWerbos, P. J. (1988), \"Generalization of backpropagation with application to a recurrent gas market model\", Neural Networks, 1 (4): 339–356, doi:10.1016/0893-6080(88)90007-X\\nGers, Felix A.; Schraudolph, Nicol N.; Schraudolph, Jürgen (2002). \"Learning Precise Timing with LSTM Recurrent Networks\" (PDF). Journal of Machine Learning Research. 3: 115–143. Retrieved 13 June 2017.\\nDeng, L.; Yu, D. (2014). \"Deep Learning: Methods and Applications\" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 1–199. doi:10.1561/2000000039. Archived (PDF) from the original on 14 March 2016. Retrieved 18 October 2014.\\nSchulz, Hannes; Behnke, Sven (1 November 2012). \"Deep Learning\". KI - Künstliche Intelligenz. 26 (4): 357–363. doi:10.1007/s13218-012-0198-z. ISSN\\xa01610-1987. S2CID\\xa0220523562.\\nFukushima, K. (2007). \"Neocognitron\". Scholarpedia. 2 (1): 1717. Bibcode:2007SchpJ...2.1717F. doi:10.4249/scholarpedia.1717. was introduced by Kunihiko Fukushima in 1980.\\nHabibi, Aghdam, Hamed (30 May 2017). Guide to convolutional neural networks\\xa0: a practical application to traffic-sign detection and classification. Heravi, Elnaz Jahani. Cham, Switzerland. ISBN\\xa09783319575490. OCLC\\xa0987790957.\\nCiresan, D.; Meier, U.; Schmidhuber, J. (2012). \"Multi-column deep neural networks for image classification\". 2012 IEEE Conference on Computer Vision and Pattern Recognition. pp.\\xa03642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN\\xa0978-1-4673-1228-8. S2CID\\xa02161592.\\n\"From not working to neural networking\". The Economist. 2016. Archived from the original on 31 December 2016. Retrieved 26 April 2018.\\nThompson, Derek (23 January 2014). \"What Jobs Will the Robots Take?\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.\\nScassellati, Brian (2002). \"Theory of mind for a humanoid robot\". Autonomous Robots. 12 (1): 13–24. doi:10.1023/A:1013298507114. S2CID\\xa01979315.\\nSample, Ian (14 March 2017). \"Google\\'s DeepMind makes AI program that can learn like a human\". The Guardian. Archived from the original on 26 April 2018. Retrieved 26 April 2018.\\nHeath, Nick (11 December 2020). \"What is AI? Everything you need to know about Artificial Intelligence\". ZDNet. Retrieved 1 March 2021.\\nBowling, Michael; Burch, Neil; Johanson, Michael; Tammelin, Oskari (9 January 2015). \"Heads-up limit hold\\'em poker is solved\". Science. 347 (6218): 145–149. Bibcode:2015Sci...347..145B. doi:10.1126/science.1259433. ISSN\\xa00036-8075. PMID\\xa025574016. S2CID\\xa03796371.\\nSolly, Meilan (15 July 2019). \"This Poker-Playing A.I. Knows When to Hold \\'Em and When to Fold \\'Em\". Smithsonian.\\n\"Artificial intelligence: Google\\'s AlphaGo beats Go master Lee Se-dol\". BBC News. 12 March 2016. Archived from the original on 26 August 2016. Retrieved 1 October 2016.\\nRowinski, Dan (15 January 2013). \"Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]\". ReadWrite. Archived from the original on 22 December 2015.\\nMarkoff, John (16 February 2011). \"Computer Wins on \\'Jeopardy!\\': Trivial, It\\'s Not\". The New York Times. Archived from the original on 22 October 2014. Retrieved 25 October 2014.\\nAnadiotis, George (1 October 2020). \"The state of AI in 2020: Democratization, industrialization, and the way to artificial general intelligence\". ZDNet. Retrieved 1 March 2021.\\nGoertzel, Ben; Lian, Ruiting; Arel, Itamar; de Garis, Hugo; Chen, Shuo (December 2010). \"A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures\". Neurocomputing. 74 (1–3): 30–49. doi:10.1016/j.neucom.2010.08.012.\\nRobinson, A. J.; Fallside, F. (1987), \"The utility driven dynamic error propagation network.\", Technical Report CUED/F-INFENG/TR.1, Cambridge University Engineering Department\\nHochreiter, Sepp (1991). Untersuchungen zu dynamischen neuronalen Netzen (PDF) (diploma thesis). Munich: Institut f. Informatik, Technische Univ. Archived from the original (PDF) on 6 March 2015. Retrieved 16 April 2016.\\nWilliams, R. J.; Zipser, D. (1994), \"Gradient-based learning algorithms for recurrent networks and their computational complexity\", Back-propagation: Theory, Architectures and Applications, Hillsdale, NJ: Erlbaum\\nHochreiter, Sepp; Schmidhuber, Jürgen (1997), \"Long Short-Term Memory\", Neural Computation, 9 (8): 1735–1780, doi:10.1162/neco.1997.9.8.1735, PMID\\xa09377276, S2CID\\xa01915014\\nGoodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016), Deep Learning, MIT Press., archived from the original on 16 April 2016, retrieved 12 November 2017\\nHinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups\". IEEE Signal Processing Magazine. 29 (6): 82–97. Bibcode:2012ISPM...29...82H. doi:10.1109/msp.2012.2205597. S2CID\\xa0206485943.\\nSchmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\". Neural Networks. 61: 85–117. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. PMID\\xa025462637. S2CID\\xa011715509.\\nLinnainmaa, Seppo (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors (Thesis) (in Finnish). Univ. Helsinki, 6–7.|\\nGriewank, Andreas (2012). \"Who Invented the Reverse Mode of Differentiation? Optimization Stories\". Documenta Matematica, Extra Volume ISMP: 389–400.\\nWerbos, Paul (1974). Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences (Ph.D. thesis). Harvard University.\\nWerbos, Paul (1982). \"Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences\" (PDF). System Modeling and Optimization. Applications of advances in nonlinear sensitivity analysis. Berlin, Heidelberg: Springer. Archived from the original (PDF) on 14 April 2016. Retrieved 16 April 2016.\\n\"What is \\'fuzzy logic\\'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?\". Scientific American. 21 October 1999. Retrieved 5 May 2018.\\nMerkle, Daniel; Middendorf, Martin (2013). \"Swarm Intelligence\".  In Burke, Edmund K.; Kendall, Graham (eds.). Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques. Springer Science & Business Media. ISBN\\xa0978-1-4614-6940-7.\\nvan der Walt, Christiaan; Bernard, Etienne (2006). \"Data characteristics that determine classifier performance\" (PDF). Archived from the original (PDF) on 25 March 2009. Retrieved 5 August 2009.\\nHutter, Marcus (2005). Universal Artificial Intelligence. Berlin: Springer. ISBN\\xa0978-3-540-22139-5.\\nHowe, J. (November 1994). \"Artificial Intelligence at Edinburgh University: a Perspective\". Archived from the original on 15 May 2007. Retrieved 30 August 2007.\\nGalvan, Jill (1 January 1997). \"Entering the Posthuman Collective in Philip K. Dick\\'s \"Do Androids Dream of Electric Sheep?\"\". Science Fiction Studies. 24 (3): 413–429. JSTOR\\xa04240644.\\nMcCauley, Lee (2007). \"AI armageddon and the three laws of robotics\". Ethics and Information Technology. 9 (2): 153–164. CiteSeerX\\xa010.1.1.85.8904. doi:10.1007/s10676-007-9138-2. S2CID\\xa037272949.\\nButtazzo, G. (July 2001). \"Artificial consciousness: Utopia or real possibility?\". Computer. 34 (7): 24–30. doi:10.1109/2.933500.\\nAnderson, Susan Leigh (2008). \"Asimov\\'s \"three laws of robotics\" and machine metaethics\". AI & Society. 22 (4): 477–493. doi:10.1007/s00146-007-0094-5. S2CID\\xa01809459.\\nYudkowsky, E (2008), \"Artificial Intelligence as a Positive and Negative Factor in Global Risk\" (PDF), Global Catastrophic Risks, Oxford University Press, 2008, Bibcode:2008gcr..book..303Y\\nMcGaughey, E (2018), Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy, p.\\xa0SSRN part 2(3), SSRN\\xa03044448, archived from the original on 24 May 2018, retrieved 12 January 2018\\nIGM Chicago (30 June 2017). \"Robots and Artificial Intelligence\". www.igmchicago.org. Archived from the original on 1 May 2019. Retrieved 3 July 2019.\\nLohr, Steve (2017). \"Robots Will Take Jobs, but Not as Fast as Some Fear, New Report Says\". The New York Times. Archived from the original on 14 January 2018. Retrieved 13 January 2018.\\nFrey, Carl Benedikt; Osborne, Michael A (1 January 2017). \"The future of employment: How susceptible are jobs to computerisation?\". Technological Forecasting and Social Change. 114: 254–280. CiteSeerX\\xa010.1.1.395.416. doi:10.1016/j.techfore.2016.08.019. ISSN\\xa00040-1625.\\nArntz, Melanie; Gregory, Terry; Zierahn, Ulrich (2016), \"The risk of automation for jobs in OECD countries: A comparative analysis\", OECD Social, Employment, and Migration Working Papers 189\\nMorgenstern, Michael (9 May 2015). \"Automation and anxiety\". The Economist. Archived from the original on 12 January 2018. Retrieved 13 January 2018.\\nMahdawi, Arwa (26 June 2017). \"What jobs will still be around in 20 years? Read this to prepare your future\". The Guardian. Archived from the original on 14 January 2018. Retrieved 13 January 2018.\\nRubin, Charles (Spring 2003). \"Artificial Intelligence and Human Nature\". The New Atlantis. 1: 88–100. Archived from the original on 11 June 2012.\\nBostrom, Nick (2014). Superintelligence: Paths, Dangers, Strategies. Oxford University Press.\\nBrooks, Rodney (10 November 2014). \"artificial intelligence is a tool, not a threat\". Archived from the original on 12 November 2014.\\nSainato, Michael (19 August 2015). \"Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence\". Observer. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nHarari, Yuval Noah (October 2018). \"Why Technology Favors Tyranny\". The Atlantic.\\nRobitzski, Dan (5 September 2018). \"Five experts share what scares them the most about AI\". Archived from the original on 8 December 2019. Retrieved 8 December 2019.\\nGoffrey, Andrew (2008). \"Algorithm\".  In Fuller, Matthew (ed.). Software studies: a lexicon. Cambridge, Mass.: MIT Press. pp.\\xa015–20. ISBN\\xa0978-1-4356-4787-9.\\nLipartito, Kenneth (6 January 2011), The Narrative and the Algorithm: Genres of Credit Reporting from the Nineteenth Century to Today (PDF) (Unpublished manuscript), doi:10.2139/ssrn.1736283, S2CID\\xa0166742927\\nGoodman, Bryce; Flaxman, Seth (2017). \"EU regulations on algorithmic decision-making and a \"right to explanation\"\". AI Magazine. 38 (3): 50. arXiv:1606.08813. doi:10.1609/aimag.v38i3.2741. S2CID\\xa07373959.\\nCNA (12 January 2019). \"Commentary: Bad news. Artificial intelligence is biased\". CNA. Archived from the original on 12 January 2019. Retrieved 19 June 2020.\\nLarson, Jeff; Angwin, Julia (23 May 2016). \"How We Analyzed the COMPAS Recidivism Algorithm\". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020.\\nMüller, Vincent C.; Bostrom, Nick (2014). \"Future Progress in Artificial Intelligence: A Poll Among Experts\" (PDF). AI Matters. 1 (1): 9–11. doi:10.1145/2639475.2639478. S2CID\\xa08510016. Archived (PDF) from the original on 15 January 2016.\\nCellan-Jones, Rory (2 December 2014). \"Stephen Hawking warns artificial intelligence could end mankind\". BBC News. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nRawlinson, Kevin (29 January 2015). \"Microsoft\\'s Bill Gates insists AI is a threat\". BBC News. Archived from the original on 29 January 2015. Retrieved 30 January 2015.\\nHolley, Peter (28 January 2015). \"Bill Gates on dangers of artificial intelligence: \\'I don\\'t understand why some people are not concerned\\'\". The Washington Post. ISSN\\xa00190-8286. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nGibbs, Samuel (27 October 2014). \"Elon Musk: artificial intelligence is our biggest existential threat\". The Guardian. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nChurm, Philip Andrew (14 May 2019). \"Yuval Noah Harari talks politics, technology and migration\". euronews. Archived from the original on 14 May 2019. Retrieved 15 November 2020.\\nBostrom, Nick (2015). \"What happens when our computers get smarter than we are?\". TED (conference). Archived from the original on 25 July 2020. Retrieved 30 January 2020.\\nPost, Washington (2015). \"Tech titans like Elon Musk are spending $1 billion to save you from terminators\". Chicago Tribune. Archived from the original on 7 June 2016.\\nDel Prado, Guia Marie (9 October 2015). \"The mysterious artificial intelligence company Elon Musk invested in is developing game-changing smart computers\". Tech Insider. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nFastCompany (15 January 2015). \"Elon Musk Is Donating $10M Of His Own Money To Artificial Intelligence Research\". Fast Company. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nThibodeau, Patrick (25 March 2019). \"Oracle CEO Mark Hurd sees no reason to fear ERP AI\". SearchERP. Archived from the original on 6 May 2019. Retrieved 6 May 2019.\\nBhardwaj, Prachi (24 May 2018). \"Mark Zuckerberg responds to Elon Musk\\'s paranoia about AI: \\'AI is going to... help keep our communities safe.\\'\". Business Insider. Archived from the original on 6 May 2019. Retrieved 6 May 2019.\\nGeist, Edward Moore (9 August 2015). \"Is artificial intelligence really an existential threat to humanity?\". Bulletin of the Atomic Scientists. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nMadrigal, Alexis C. (27 February 2015). \"The case against killer robots, from a guy actually working on artificial intelligence\". Fusion.net. Archived from the original on 4 February 2016. Retrieved 31 January 2016.\\nLee, Timothy B. (22 August 2014). \"Will artificial intelligence destroy humanity? Here are 5 reasons not to worry\". Vox. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nLaw Library of Congress (U.S.). Global Legal Research Directorate, issuing body. (2019). Regulation of artificial intelligence in selected jurisdictions. LCCN\\xa02019668143. OCLC\\xa01110727808.\\nUNESCO Science Report: the Race Against Time for Smarter Development. Paris: UNESCO. 11 June 2021. ISBN\\xa0978-92-3-100450-6.\\nBerryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF). Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 20 December 2019. Retrieved 9 August 2020.\\nBarfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence. Cheltenham, UK. ISBN\\xa0978-1-78643-904-8. OCLC\\xa01039480085.\\nIphofen, Ron; Kritikos, Mihalis (3 January 2019). \"Regulating artificial intelligence and robotics: ethics by design in a digital society\". Contemporary Social Science. 16 (2): 170–184. doi:10.1080/21582041.2018.1563803. ISSN\\xa02158-2041. S2CID\\xa059298502.\\nWirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (24 July 2018). \"Artificial Intelligence and the Public Sector – Applications and Challenges\". International Journal of Public Administration. 42 (7): 596–615. doi:10.1080/01900692.2018.1498103. ISSN\\xa00190-0692. S2CID\\xa0158829602. Archived from the original on 18 August 2020. Retrieved 22 August 2020.\\nBuiten, Miriam C (2019). \"Towards Intelligent Regulation of Artificial Intelligence\". European Journal of Risk Regulation. 10 (1): 41–59. doi:10.1017/err.2019.8. ISSN\\xa01867-299X.\\nWallach, Wendell (2010). Moral Machines. Oxford University Press.\\nBrown, Eileen (5 November 2019). \"Half of Americans do not believe deepfake news could target them online\". ZDNet. Archived from the original on 6 November 2019. Retrieved 3 December 2019.\\nFrangoul, Anmar (14 June 2019). \"A Californian business is using A.I. to change the way we think about energy storage\". CNBC. Archived from the original on 25 July 2020. Retrieved 5 November 2019.\\n\"The Economist Explains: Why firms are piling into artificial intelligence\". The Economist. 31 March 2016. Archived from the original on 8 May 2016. Retrieved 19 May 2016.\\nLohr, Steve (28 February 2016). \"The Promise of Artificial Intelligence Unfolds in Small Steps\". The New York Times. Archived from the original on 29 February 2016. Retrieved 29 February 2016.\\nSmith, Mark (22 July 2016). \"So you think you chose to read this article?\". BBC News. Archived from the original on 25 July 2016.\\nAletras, N.; Tsarapatsanis, D.; Preotiuc-Pietro, D.; Lampos, V. (2016). \"Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective\". PeerJ Computer Science. 2: e93. doi:10.7717/peerj-cs.93.\\nCadena, Cesar; Carlone, Luca; Carrillo, Henry; Latif, Yasir; Scaramuzza, Davide; Neira, Jose; Reid, Ian; Leonard, John J. (December 2016). \"Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age\". IEEE Transactions on Robotics. 32 (6): 1309–1332. arXiv:1606.05830. Bibcode:2016arXiv160605830C. doi:10.1109/TRO.2016.2624754. S2CID\\xa02596787.\\nCambria, Erik; White, Bebo (May 2014). \"Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]\". IEEE Computational Intelligence Magazine. 9 (2): 48–57. doi:10.1109/MCI.2014.2307227. S2CID\\xa0206451986.\\nVincent, James (7 November 2019). \"OpenAI has published the text-generating AI it said was too dangerous to share\". The Verge. Archived from the original on 11 June 2020. Retrieved 11 June 2020.\\nJordan, M. I.; Mitchell, T. M. (16 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID\\xa026185243. S2CID\\xa0677218.\\nMaschafilm (2010). \"Content: Plug & Pray Film – Artificial Intelligence – Robots -\". plugandpray-film.de. Archived from the original on 12 February 2016.\\nEvans, Woody (2015). \"Posthuman Rights: Dimensions of Transhuman Worlds\". Teknokultura. 12 (2). doi:10.5209/rev_TK.2015.v12.n2.49072.\\nWaddell, Kaveh (2018). \"Chatbots Have Entered the Uncanny Valley\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.\\nPoria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). \"A review of affective computing: From unimodal analysis to multimodal fusion\". Information Fusion. 37: 98–125. doi:10.1016/j.inffus.2017.02.003. hdl:1893/25490.\\n\"Robots could demand legal rights\". BBC News. 21 December 2006. Archived from the original on 15 October 2019. Retrieved 3 February 2011.\\nHorst, Steven (2005). \"The Computational Theory of Mind\". The Stanford Encyclopedia of Philosophy.\\nOmohundro, Steve (2008). The Nature of Self-Improving Artificial Intelligence. presented and distributed at the 2007 Singularity Summit, San Francisco, CA.\\nFord, Martin; Colvin, Geoff (6 September 2015). \"Will robots create more jobs than they destroy?\". The Guardian. Archived from the original on 16 June 2018. Retrieved 13 January 2018.\\nWhite Paper: On Artificial Intelligence – A European approach to excellence and trust (PDF). Brussels: European Commission. 2020. Archived (PDF) from the original on 20 February 2020. Retrieved 20 February 2020.\\nAnderson, Michael; Anderson, Susan Leigh (2011). Machine Ethics. Cambridge University Press.\\n\"Machine Ethics\". aaai.org. Archived from the original on 29 November 2014.\\nRussell, Stuart (8 October 2019). Human Compatible: Artificial Intelligence and the Problem of Control. United States: Viking. ISBN\\xa0978-0-525-55861-3. OCLC\\xa01083694322.\\n\"AI set to exceed human brain power\". CNN. 9 August 2006. Archived from the original on 19 February 2008.\\n\"Robots could demand legal rights\". BBC News. 21 December 2006. Archived from the original on 15 October 2019. Retrieved 3 February 2011.\\n\"Kismet\". MIT Artificial Intelligence Laboratory, Humanoid Robotics Group. Archived from the original on 17 October 2014. Retrieved 25 October 2014.\\nSmoliar, Stephen W.; Zhang, HongJiang (1994). \"Content based video indexing and retrieval\". IEEE Multimedia. 1 (2): 62–72. doi:10.1109/93.311653. S2CID\\xa032710913.\\nNeumann, Bernd; Möller, Ralf (January 2008). \"On scene interpretation with description logics\". Image and Vision Computing. 26 (1): 82–101. doi:10.1016/j.imavis.2007.08.013.\\nKuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006). \"Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations\". Journal of the American Medical Informatics Association. 13 (4): 369–371. doi:10.1197/jamia.M2055. PMC\\xa01513681. PMID\\xa016622160.\\nMcGarry, Ken (1 December 2005). \"A survey of interestingness measures for knowledge discovery\". The Knowledge Engineering Review. 20 (1): 39–61. doi:10.1017/S0269888905000408. S2CID\\xa014987656.\\nBertini, M; Del Bimbo, A; Torniai, C (2006). \"Automatic annotation and semantic retrieval of video sequences using multimedia ontologies\". MM \\'06 Proceedings of the 14th ACM international conference on Multimedia. 14th ACM international conference on Multimedia. Santa Barbara: ACM. pp.\\xa0679–682.\\nKahneman, Daniel (25 October 2011). Thinking, Fast and Slow. Macmillan. ISBN\\xa0978-1-4299-6935-2. Retrieved 8 April 2012.\\nTuring, Alan (1948), \"Machine Intelligence\",  in Copeland, B. Jack (ed.), The Essential Turing: The ideas that gave birth to the computer age, Oxford: Oxford University Press, p.\\xa0412, ISBN\\xa0978-0-19-825080-7\\nDomingos, Pedro (22 September 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN\\xa0978-0465065707.\\nMinsky, Marvin (1986), The Society of Mind, Simon and Schuster\\nPinker, Steven (4 September 2007) [1994], The Language Instinct, Perennial Modern Classics, Harper, ISBN\\xa0978-0-06-133646-1\\nChalmers, David (1995). \"Facing up to the problem of consciousness\". Journal of Consciousness Studies. 2 (3): 200–219. Archived from the original on 8 March 2005. Retrieved 11 October 2018.\\nRoberts, Jacob (2016). \"Thinking Machines: The Search for Artificial Intelligence\". Distillations. Vol.\\xa02, no.\\xa02. pp.\\xa014–23. Archived from the original on 19 August 2018. Retrieved 20 March 2018.\\nPennachin, C.; Goertzel, B. (2007). \"Contemporary Approaches to Artificial General Intelligence\". Artificial General Intelligence. Cognitive Technologies. Berlin, Heidelberg: Springer. doi:10.1007/978-3-540-68677-4_1. ISBN\\xa0978-3-540-23733-4.\\n\"Ask the AI experts: What\\'s driving today\\'s progress in AI?\". McKinsey & Company. Archived from the original on 13 April 2018. Retrieved 13 April 2018.\\n\"Reshaping Business With Artificial Intelligence\". MIT Sloan Management Review. Archived from the original on 19 May 2018. Retrieved 2 May 2018.\\nLorica, Ben (18 December 2017). \"The state of AI adoption\". O\\'Reilly Media. Archived from the original on 2 May 2018. Retrieved 2 May 2018.\\n\"AlphaGo – Google DeepMind\". Archived from the original on 20 October 2021.\\nAsada, M.; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). \"Cognitive developmental robotics: a survey\". IEEE Transactions on Autonomous Mental Development. 1 (1): 12–34. doi:10.1109/tamd.2009.2021702. S2CID\\xa010168773.\\nAshok83 (10 September 2019). \"How AI Is Getting Groundbreaking Changes In Talent Management And HR Tech\". Hackernoon. Archived from the original on 11 September 2019. Retrieved 14 February 2020.\\nBerlinski, David (2000). The Advent of the Algorithm. Harcourt Books. ISBN\\xa0978-0-15-601391-8. OCLC\\xa046890682. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nBrooks, Rodney (1990). \"Elephants Don\\'t Play Chess\" (PDF). Robotics and Autonomous Systems. 6 (1–2): 3–15. CiteSeerX\\xa010.1.1.588.7539. doi:10.1016/S0921-8890(05)80025-9. Archived (PDF) from the original on 9 August 2007.\\nButler, Samuel (13 June 1863). \"Darwin among the Machines\". Letters to the Editor. The Press. Christchurch, New Zealand. Archived from the original on 19 September 2008. Retrieved 16 October 2014 – via Victoria University of Wellington.\\nClark, Jack (2015a). \"Musk-Backed Group Probes Risks Behind Artificial Intelligence\". Bloomberg.com. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nClark, Jack (2015b). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg.com. Archived from the original on 23 November 2016. Retrieved 23 November 2016.\\nDennett, Daniel (1991). Consciousness Explained. The Penguin Press. ISBN\\xa0978-0-7139-9037-9.\\nDreyfus, Hubert (1972). What Computers Can\\'t Do. New York: MIT Press. ISBN\\xa0978-0-06-011082-6.\\nDreyfus, Hubert; Dreyfus, Stuart (1986). Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer. Oxford, UK: Blackwell. ISBN\\xa0978-0-02-908060-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nDyson, George (1998). Darwin among the Machines. Allan Lane Science. ISBN\\xa0978-0-7382-0030-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nEdelson, Edward (1991). The Nervous System. New York: Chelsea House. ISBN\\xa0978-0-7910-0464-7. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nFearn, Nicholas (2007). The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World\\'s Greatest Thinkers. New York: Grove Press. ISBN\\xa0978-0-8021-1839-4.\\nHaugeland, John (1985). Artificial Intelligence: The Very Idea. Cambridge, Mass.: MIT Press. ISBN\\xa0978-0-262-08153-5.\\nHawkins, Jeff; Blakeslee, Sandra (2005). On Intelligence. New York: Owl Books. ISBN\\xa0978-0-8050-7853-4.\\nHenderson, Mark (24 April 2007). \"Human rights for robots? We\\'re getting carried away\". The Times Online. London. Archived from the original on 31 May 2014. Retrieved 31 May 2014.\\nKahneman, Daniel; Slovic, D.; Tversky, Amos (1982). Judgment under uncertainty: Heuristics and biases. Science. Vol.\\xa0185. New York: Cambridge University Press. pp.\\xa01124–1131. doi:10.1126/science.185.4157.1124. ISBN\\xa0978-0-521-28414-1. PMID\\xa017835457. S2CID\\xa0143452957.\\nKatz, Yarden (1 November 2012). \"Noam Chomsky on Where Artificial Intelligence Went Wrong\". The Atlantic. Archived from the original on 28 February 2019. Retrieved 26 October 2014.\\nKurzweil, Ray (2005). The Singularity is Near. Penguin Books. ISBN\\xa0978-0-670-03384-3.\\nLangley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275–279. doi:10.1007/s10994-011-5242-y.\\nLegg, Shane; Hutter, Marcus (15 June 2007). A Collection of Definitions of Intelligence (Technical report). IDSIA. arXiv:0706.3639. Bibcode:2007arXiv0706.3639L. 07-07.\\nLenat, Douglas; Guha, R. V. (1989). Building Large Knowledge-Based Systems. Addison-Wesley. ISBN\\xa0978-0-201-51752-1.\\nLighthill, James (1973). \"Artificial Intelligence: A General Survey\". Artificial Intelligence: a paper symposium. Science Research Council.\\nLombardo, P; Boehm, I; Nairz, K (2020). \"RadioComics – Santa Claus and the future of radiology\". Eur J Radiol. 122 (1): 108771. doi:10.1016/j.ejrad.2019.108771. PMID\\xa031835078.\\nLungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). \"Developmental robotics: a survey\". Connection Science. 15 (4): 151–190. CiteSeerX\\xa010.1.1.83.7615. doi:10.1080/09540090310001655110. S2CID\\xa01452734.\\nMaker, Meg Houston (2006). \"AI@50: AI Past, Present, Future\". Dartmouth College. Archived from the original on 3 January 2007. Retrieved 16 October 2008.\\nMcCarthy, John; Minsky, Marvin; Rochester, Nathan; Shannon, Claude (1955). \"A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence\". Archived from the original on 26 August 2007. Retrieved 30 August 2007.\\nMinsky, Marvin (1967). Computation: Finite and Infinite Machines. Englewood Cliffs, N.J.: Prentice-Hall. ISBN\\xa0978-0-13-165449-5. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nMoravec, Hans (1988). Mind Children. Harvard University Press. ISBN\\xa0978-0-674-57616-2. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nNRC (United States National Research Council) (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academy Press.\\nNewell, Allen; Simon, H. A. (1976). \"Computer Science as Empirical Inquiry: Symbols and Search\". Communications of the ACM. 19 (3): 113–126. doi:10.1145/360018.360022..\\nNilsson, Nils (1983). \"Artificial Intelligence Prepares for 2001\" (PDF). AI Magazine. 1 (1). Archived (PDF) from the original on 17 August 2020. Retrieved 22 August 2020. Presidential Address to the Association for the Advancement of Artificial Intelligence.\\nOudeyer, P-Y. (2010). \"On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development\" (PDF). IEEE Transactions on Autonomous Mental Development. 2 (1): 2–16. doi:10.1109/tamd.2009.2039057. S2CID\\xa06362217. Archived (PDF) from the original on 3 October 2018. Retrieved 4 June 2013.\\nSchank, Roger C. (1991). \"Where\\'s the AI\". AI magazine. Vol.\\xa012, no.\\xa04.\\nSearle, John (1980). \"Minds, Brains and Programs\" (PDF). Behavioral and Brain Sciences. 3 (3): 417–457. doi:10.1017/S0140525X00005756. S2CID\\xa055303721. Archived (PDF) from the original on 17 March 2019. Retrieved 22 August 2020.\\nSearle, John (1999). Mind, language and society. New York: Basic Books. ISBN\\xa0978-0-465-04521-1. OCLC\\xa0231867665. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nSimon, H. A. (1965). The Shape of Automation for Men and Management. New York: Harper & Row. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nSolomonoff, Ray (1956). An Inductive Inference Machine (PDF). Dartmouth Summer Research Conference on Artificial Intelligence. Archived (PDF) from the original on 26 April 2011. Retrieved 22 March 2011 – via std.com, pdf scanned copy of the original. Later published asSolomonoff, Ray (1957). \"An Inductive Inference Machine\". IRE Convention Record. Vol.\\xa0Section on Information Theory, part 2. pp.\\xa056–62.\\nSpadafora, Anthony (21 October 2016). \"Stephen Hawking believes AI could be mankind\\'s last accomplishment\". BetaNews. Archived from the original on 28 August 2017.\\nTao, Jianhua; Tan, Tieniu (2005). Affective Computing and Intelligent Interaction. Affective Computing: A Review. Vol.\\xa0LNCS 3784. Springer. pp.\\xa0981–995. doi:10.1007/11573548.\\nTecuci, Gheorghe (March–April 2012). \"Artificial Intelligence\". Wiley Interdisciplinary Reviews: Computational Statistics. 4 (2): 168–180. doi:10.1002/wics.200. S2CID\\xa0196141190.\\nThro, Ellen (1993). Robotics: The Marriage of Computers and Machines. New York: Facts on File. ISBN\\xa0978-0-8160-2628-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nTuring, Alan (October 1950), \"Computing Machinery and Intelligence\", Mind, LIX (236): 433–460, doi:10.1093/mind/LIX.236.433, ISSN\\xa00026-4423.\\nVinge, Vernor (1993). \"The Coming Technological Singularity: How to Survive in the Post-Human Era\". Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace: 11. Bibcode:1993vise.nasa...11V. Archived from the original on 1 January 2007. Retrieved 14 November 2011.\\nWason, P. C.; Shapiro, D. (1966). \"Reasoning\".  In Foss, B. M. (ed.). New horizons in psychology. Harmondsworth: Penguin. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nWeng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001). \"Autonomous mental development by robots and animals\" (PDF). Science. 291 (5504): 599–600. doi:10.1126/science.291.5504.599. PMID\\xa011229402. S2CID\\xa054131797. Archived (PDF) from the original on 4 September 2013. Retrieved 4 June 2013 – via msu.edu.\\nFurther reading\\n\\nDH Author, \"Why Are There Still So Many Jobs? The History and Future of Workplace Automation\" (2015) 29(3) Journal of Economic Perspectives 3.\\nBoden, Margaret, Mind As Machine, Oxford University Press, 2006.\\nCukier, Kenneth, \"Ready for Robots?  How to Think about the Future of AI\", Foreign Affairs, vol. 98, no. 4 (July/August 2019), pp.\\xa0192–98.  George Dyson, historian of computing, writes (in what might be called \"Dyson\\'s Law\") that \"Any system simple enough to be understandable will not be complicated enough to behave intelligently, while any system complicated enough to behave intelligently will be too complicated to understand.\" (p.\\xa0197.)  Computer scientist Alex Pentland writes:  \"Current AI machine-learning algorithms are, at their core, dead simple stupid.  They work, but they work by brute force.\" (p.\\xa0198.)\\nDomingos, Pedro, \"Our Digital Doubles:  AI will serve our species, not control it\", Scientific American, vol. 319, no. 3 (September 2018), pp.\\xa088–93.\\nGopnik, Alison, \"Making AI More Human:  Artificial intelligence has staged a revival by starting to incorporate what we know about how children learn\", Scientific American, vol. 316, no. 6 (June 2017), pp.\\xa060–65.\\nHalpern, Sue, \"The Human Costs of AI\" (review of Kate Crawford, Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence, Yale University Press, 2021, 327 pp.; Simon Chesterman, We, the Robots?: Regulating Artificial Intelligence and the Limits of the Law, Cambridge University Press, 2021, 289 pp.; Keven Roose, Futureproof: 9 Rules for Humans in the Age of Automation, Random House, 217 pp.; Erik J. Larson, The Myth of Artificial Intelligence: Why Computers Can\\'t Think the Way We Do, Belknap Press / Harvard University Press, 312 pp.), The New York Review of Books, vol. LXVIII, no. 16 (21 October 2021), pp.\\xa029–31. \"AI training models can replicate entrenched social and cultural biases. [...] Machines only know what they know from the data they have been given. [p. 30.] [A]rtificial general intelligence–machine-based intelligence that matches our own–is beyond the capacity of algorithmic machine learning... \\'Your brain is one piece in a broader system which includes your body, your environment, other humans, and culture as a whole.\\' [E]ven machines that master the tasks they are trained to perform can\\'t jump domains. AIVA, for example, can\\'t drive a car even though it can write music (and wouldn\\'t even be able to do that without Bach and Beethoven [and other composers on which AIVA is trained]).\" (p.\\xa031.)\\nJohnston, John (2008) The Allure of Machinic Life: Cybernetics, Artificial Life, and the New AI, MIT Press.\\nKoch, Christof, \"Proust among the Machines\", Scientific American, vol. 321, no. 6 (December 2019), pp.\\xa046–49. Christof Koch doubts the possibility of \"intelligent\" machines attaining consciousness, because \"[e]ven the most sophisticated brain simulations are unlikely to produce conscious feelings.\" (p.\\xa048.) According to Koch, \"Whether machines can become sentient [is important] for ethical reasons. If computers experience life through their own senses, they cease to be purely a means to an end determined by their usefulness to... humans. Per GNW [the Global Neuronal Workspace theory], they turn from mere objects into subjects... with a point of view.... Once computers\\' cognitive abilities rival those of humanity, their impulse to push for legal and political rights will become irresistible—the right not to be deleted, not to have their memories wiped clean, not to suffer pain and degradation. The alternative, embodied by IIT [Integrated Information Theory], is that computers will remain only supersophisticated machinery, ghostlike empty shells, devoid of what we value most: the feeling of life itself.\" (p.\\xa049.)\\nMarcus, Gary, \"Am I Human?: Researchers need new ways to distinguish artificial intelligence from the natural kind\", Scientific American, vol. 316, no. 3 (March 2017), pp.\\xa058–63.  A stumbling block to AI has been an incapacity for reliable disambiguation.  An example is the \"pronoun disambiguation problem\":  a machine has no way of determining to whom or what a pronoun in a sentence refers. (p.\\xa061.)\\nE McGaughey, \\'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy\\' (2018) SSRN, part 2(3) Archived 24 May 2018 at the Wayback Machine.\\nGeorge Musser, \"Artificial Imagination:  How machines could learn creativity and common sense, among other human qualities\", Scientific American, vol. 320, no. 5 (May 2019), pp.\\xa058–63.\\nMyers, Courtney Boyd ed. (2009). \"The AI Report\" Archived 29 July 2017 at the Wayback Machine. Forbes June 2009\\nRaphael, Bertram (1976). The Thinking Computer. W.H. Freeman and Co. ISBN\\xa0978-0716707233. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nScharre, Paul, \"Killer Apps:  The Real Dangers of an AI Arms Race\", Foreign Affairs, vol. 98, no. 3 (May/June 2019), pp.\\xa0135–44.  \"Today\\'s AI technologies are powerful but unreliable.  Rules-based systems cannot deal with circumstances their programmers did not anticipate.  Learning systems are limited by the data on which they were trained.  AI failures have already led to tragedy.  Advanced autopilot features in cars, although they perform well in some circumstances, have driven cars without warning into trucks, concrete barriers, and parked cars.  In the wrong situation, AI systems go from supersmart to superdumb in an instant.  When an enemy is trying to manipulate and hack an AI system, the risks are even greater.\"  (p.\\xa0140.)\\nSerenko, Alexander (2010). \"The development of an AI journal ranking based on the revealed preference approach\" (PDF). Journal of Informetrics. 4 (4): 447–59. doi:10.1016/j.joi.2010.04.001. Archived (PDF) from the original on 4 October 2013. Retrieved 24 August 2013.\\nSerenko, Alexander; Michael Dohan (2011). \"Comparing the expert survey and citation impact journal ranking methods: Example from the field of Artificial Intelligence\" (PDF). Journal of Informetrics. 5 (4): 629–49. doi:10.1016/j.joi.2011.06.002. Archived (PDF) from the original on 4 October 2013. Retrieved 12 September 2013.\\nTom Simonite (29 December 2014). \"2014 in Computing: Breakthroughs in Artificial Intelligence\". MIT Technology Review.\\nSun, R. & Bookman, L. (eds.), Computational Architectures: Integrating Neural and Symbolic Processes. Kluwer Academic Publishers, Needham, MA. 1994.\\nTaylor, Paul, \"Insanely Complicated, Hopelessly Inadequate\" (review of Brian Cantwell Smith, The Promise of Artificial Intelligence: Reckoning and Judgment, MIT, 2019, ISBN\\xa0978-0262043045, 157 pp.; Gary Marcus and Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust, Ballantine, 2019, ISBN\\xa0978-1524748258, 304 pp.; Judea Pearl and Dana Mackenzie, The Book of Why: The New Science of Cause and Effect, Penguin, 2019, ISBN\\xa0978-0141982410, 418 pp.), London Review of Books, vol. 43, no. 2 (21 January 2021), pp.\\xa037–39. Paul Taylor writes (p.\\xa039): \"Perhaps there is a limit to what a computer can do without knowing that it is manipulating imperfect representations of an external reality.\"\\nTooze, Adam, \"Democracy and Its Discontents\", The New York Review of Books, vol. LXVI, no. 10 (6 June 2019), pp.\\xa052–53, 56–57.  \"Democracy has no clear answer for the mindless operation of bureaucratic and technological power.  We may indeed be witnessing its extension in the form of artificial intelligence and robotics.  Likewise, after decades of dire warning, the environmental problem remains fundamentally unaddressed.... Bureaucratic overreach and environmental catastrophe are precisely the kinds of slow-moving existential challenges that democracies deal with very badly.... Finally, there is the threat du jour:  corporations and the technologies they promote.\"  (pp.\\xa056–57.)\\n\\nExternal links\\nArtificial intelligenceat Wikipedia\\'s sister projectsDefinitions from WiktionaryMedia from CommonsQuotations from WikiquoteTextbooks from WikibooksResources from WikiversityData from Wikidata\\n\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.\\nThomason, Richmond. \"Logic and Artificial Intelligence\".  In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\\nArtificial Intelligence. BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, Dec. 8, 2005).\\nArticles related to Artificial intelligence\\nvteJohn McCarthy\\nArtificial intelligence\\nCircumscription\\nDartmouth workshop\\nFrame problem\\nGarbage collection\\nLisp\\nMcCarthy Formalism\\nMcCarthy 91 function\\nSituation calculus\\nSpace fountain\\n\\nvtePhilosophy of mindPhilosophers\\nAnscombe\\nAustin\\nAquinas\\nBain\\nBergson\\nBhattacharya\\nBlock\\nBrentano\\nBroad\\nBurge\\nChalmers\\nChurchland\\nDennett\\nDharmakirti\\nDavidson\\nDescartes\\nGoldman\\nHeidegger\\nHusserl\\nFeyerabend\\nFodor\\nJames\\nKierkegaard\\nLeibniz\\nLewis\\nMcDowell\\nMerleau-Ponty\\nMinsky\\nMoore\\nNagel\\nParfit\\nPutnam\\nPopper\\nRorty\\nRyle\\nSearle\\nSpinoza\\nTuring\\nVasubandhu\\nWittgenstein\\nZhuangzi\\nmore...\\nTheories\\nBehaviorism\\nBiological naturalism\\nDualism\\nEliminative materialism\\nEmergent materialism\\nEpiphenomenalism\\nFunctionalism\\nIdealism\\nInteractionism\\nMaterialism\\nMonism\\nNaïve realism\\nNeurophenomenology\\nNeutral monism\\nOccasionalism\\nParallelism\\nPhenomenalism\\nPhenomenology\\nPhysicalism\\nidentity theory\\nProperty dualism\\nRepresentational\\nSolipsism\\nSubstance dualism\\nConcepts\\nAbstract object\\nArtificial intelligence\\nChinese room\\nCognition\\nCognitive closure\\nConcept\\nConcept and object\\nConsciousness\\nHard problem of consciousness\\nHypostatic abstraction\\nIdea\\nIdentity\\nIngenuity\\nIntelligence\\nIntentionality\\nIntrospection\\nIntuition\\nLanguage of thought\\nMaterialism\\nMental event\\nMental image\\nMental process\\nMental property\\nMental representation\\nMind\\nMind–body problem\\nNew mysterianism\\nPain\\nProblem of other minds\\nPropositional attitude\\nQualia\\nTabula rasa\\nUnderstanding\\nZombie\\nmore...\\nRelated\\nMetaphysics\\nPhilosophy of artificial intelligence\\xa0/ information\\xa0/ perception\\xa0/ self\\n\\nCategory\\nPhilosophers category\\nProject\\nTask Force\\n\\nvtePhilosophy of scienceConcepts\\nAnalysis\\nAnalytic–synthetic distinction\\nA priori and a posteriori\\nCausality\\nCommensurability\\nConsilience\\nConstruct\\nCreative synthesis\\nDemarcation problem\\nEmpirical evidence\\nExplanatory power\\nFact\\nFalsifiability\\nFeminist method\\nFunctional contextualism\\nIgnoramus et ignorabimus\\nInductive reasoning\\nIntertheoretic reduction\\nInquiry\\nNature\\nObjectivity\\nObservation\\nParadigm\\nProblem of induction\\nScientific law\\nScientific method\\nScientific pluralism\\nScientific revolution\\nScientific theory\\nTestability\\nTheory choice\\nTheory-ladenness\\nUnderdetermination\\nUnity of science\\nMetatheoryof science\\nCoherentism\\nConfirmation holism\\nConstructive empiricism\\nConstructive realism\\nConstructivist epistemology\\nContextualism\\nConventionalism\\nDeductive-nomological model\\nHypothetico-deductive model\\nInductionism\\nEpistemological anarchism\\nEvolutionism\\nFallibilism\\nFoundationalism\\nInstrumentalism\\nPragmatism\\nModel-dependent realism\\nNaturalism\\nPhysicalism\\nPositivism\\xa0/ Reductionism\\xa0/ Determinism\\nRationalism\\xa0/ Empiricism\\nReceived view\\xa0/ Semantic view of theories\\nScientific realism\\xa0/ Anti-realism\\nScientific essentialism\\nScientific formalism\\nScientific skepticism\\nScientism\\nStructuralism\\nUniformitarianism\\nVitalism\\nPhilosophy of\\nPhysics\\nthermal and statistical\\nMotion\\nChemistry\\nBiology\\nGeography\\nSocial science\\nTechnology\\nEngineering\\nArtificial intelligence\\nComputer science\\nInformation\\nMind\\nPsychiatry\\nPsychology\\nPerception\\nSpace and time\\nRelated topics\\nAlchemy\\nCriticism of science\\nDescriptive science\\nEpistemology\\nFaith and rationality\\nHard and soft science\\nHistory and philosophy of science\\nHistory of science\\nHistory of evolutionary thought\\nLogic\\nMetaphysics\\nNormative science\\nPseudoscience\\nRelationship between religion and science\\nRhetoric of science\\nScience studies\\nSociology of scientific knowledge\\nSociology of scientific ignorance\\nPhilosophers of science by eraAncient\\nPlato\\nAristotle\\nStoicism\\nEpicureans\\nEpicurus\\nMedieval\\nAverroes\\nAvicenna\\nRoger Bacon\\nWilliam of Ockham\\nHugh of Saint Victor\\nDominicus Gundissalinus\\nRobert Kilwardby\\nEarly modern\\nFrancis Bacon\\nThomas Hobbes\\nRené Descartes\\nGalileo Galilei\\nPierre Gassendi\\nIsaac Newton\\nDavid Hume\\nLate modern\\nImmanuel Kant\\nFriedrich Schelling\\nWilliam Whewell\\nAuguste Comte\\nJohn Stuart Mill\\nHerbert Spencer\\nWilhelm Wundt\\nCharles Sanders Peirce\\nWilhelm Windelband\\nHenri Poincaré\\nPierre Duhem\\nRudolf Steiner\\nKarl Pearson\\nContemporary\\nAlfred North Whitehead\\nBertrand Russell\\nAlbert Einstein\\nOtto Neurath\\nC. D. Broad\\nMichael Polanyi\\nHans Reichenbach\\nRudolf Carnap\\nKarl Popper\\nCarl Gustav Hempel\\nW. V. O. Quine\\nThomas Kuhn\\nImre Lakatos\\nPaul Feyerabend\\nJürgen Habermas\\nIan Hacking\\nBas van Fraassen\\nLarry Laudan\\nDaniel Dennett\\n\\nCategory\\n\\xa0Philosophy portal\\n\\xa0Science portal\\n\\nvteEvolutionary computationMain Topics\\nConvergence (evolutionary computing)\\nEvolutionary algorithm\\nEvolutionary data mining\\nEvolutionary multimodal optimization\\nHuman-based evolutionary computation\\nInteractive evolutionary computation\\nAlgorithms\\nCellular evolutionary algorithm\\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES)\\nDifferential evolution\\nEvolutionary programming\\nGenetic algorithm\\nGenetic programming\\nGene expression programming\\nEvolution strategy\\nNatural evolution strategy\\nNeuroevolution\\nLearning classifier system\\nRelated techniques\\nSwarm intelligence\\nAnt colony optimization\\nBees algorithm\\nCuckoo search\\nParticle swarm optimization\\nBacterial Colony Optimization\\nMetaheuristic methods\\nFirefly algorithm\\nHarmony search\\nGaussian adaptation\\nMemetic algorithm\\nRelated topics\\nArtificial development\\nArtificial intelligence\\nArtificial life\\nDigital organism\\nEvolutionary robotics\\nFitness function\\nFitness landscape\\nFitness approximation\\nGenetic operators\\nInteractive evolutionary computation\\nNo free lunch in search and optimization\\nMachine learning\\nMating pool\\nProgram synthesis\\nJournals\\nEvolutionary Computation (journal)\\n\\nvteDifferentiable computingGeneral\\nDifferentiable programming\\nNeural Turing machine\\nDifferentiable neural computer\\nAutomatic differentiation\\nNeuromorphic engineering\\nCable theory\\nPattern recognition\\nComputational learning theory\\nTensor calculus\\nConcepts\\nGradient descent\\nSGD\\nClustering\\nRegression\\nOverfitting\\nAdversary\\nAttention\\nConvolution\\nLoss functions\\nBackpropagation\\nNormalization\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nRegularization\\nDatasets\\nAugmentation\\nProgramming languages\\nPython\\nJulia\\nApplication\\nMachine learning\\nArtificial neural network\\nDeep learning\\nScientific computing\\nArtificial Intelligence\\nHardware\\nIPU\\nTPU\\nVPU\\nMemristor\\nSpiNNaker\\nSoftware library\\nTensorFlow\\nPyTorch\\nKeras\\nTheano\\nImplementationAudio-visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nSpeech recognition\\nFacial recognition\\nAlphaFold\\nDALL-E\\nVerbal\\nWord2vec\\nTransformer\\nBERT\\nNMT\\nProject Debater\\nWatson\\nGPT-2\\nGPT-3\\nDecisional\\nAlphaGo\\nAlphaZero\\nQ-learning\\nSARSA\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nRobot control\\nPeople\\nAlex Graves\\nIan Goodfellow\\nYoshua Bengio\\nGeoffrey Hinton\\nYann LeCun\\nAndrew Ng\\nDemis Hassabis\\nDavid Silver\\nFei-Fei Li\\nOrganizations\\nDeepMind\\nOpenAI\\nMIT CSAIL\\nMila\\nGoogle Brain\\nFAIR\\n\\n Portals\\nComputer programming\\nTechnology\\n Category\\nArtificial neural networks\\nMachine learning\\n\\nvteComputable knowledgeTopics andconcepts\\nAlphabet of human thought\\nAuthority control\\nAutomated reasoning\\nCommonsense knowledge\\nCommonsense reasoning\\nComputability\\nDiscovery system\\nFormal system\\nInference engine\\nKnowledge base\\nPersonal knowledge base\\nKnowledge-based systems\\nKnowledge engineering\\nKnowledge extraction\\nKnowledge graph\\nKnowledge representation\\nKnowledge retrieval\\nLibrary classification\\nLogic programming\\nOntology\\nQuestion answering\\nSemantic reasoner\\nProposals andimplementations\\nAntikythera mechanism\\xa0(ca.\\xa0100\\xa0BCE)\\nZairja\\xa0(ca.\\xa01000\\xa0CE)\\nArs Magna\\xa0(1300)\\nAn Essay Towards a Real Character, and a Philosophical Language\\xa0(1688)\\nCalculus ratiocinator and characteristica universalis\\xa0(1700)\\nDewey Decimal Classification\\xa0(1876)\\nBegriffsschrift\\xa0(1879)\\nMundaneum\\xa0(1910)\\nLogical atomism\\xa0(1918)\\nTractatus Logico-Philosophicus\\xa0(1921)\\nHilbert\\'s program\\xa0(1920s)\\nIncompleteness theorem\\xa0(1931)\\nWorld Brain\\xa0(1938)\\nMemex\\xa0(1945)\\nGeneral Problem Solver\\xa0(1959)\\nProlog\\xa0(1972)\\nCyc\\xa0(1984)\\nSemantic Web\\xa0(2001)\\nWikipedia\\xa0(2001)\\nEvi\\xa0(2007)\\nWolfram Alpha\\xa0(2009)\\nWatson\\xa0(2011)\\nSiri\\xa0(2011)\\nGoogle Knowledge Graph\\xa0(2012)\\nWikidata\\xa0(2012)\\nCortana\\xa0(2014)\\nViv\\xa0(2016)\\nIn fiction\\nThe Engine (Gulliver\\'s Travels, 1726)\\nJoe (\"A Logic Named Joe\", 1946)\\nThe Librarian (Snow Crash, 1992)\\nDr. Know (A.I. (film), 2001)\\nWaterhouse (The Baroque Cycle, 2003)\\nSee also: Logic machines in fiction and List of fictional computers\\n\\n\\nvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware\\nPrinted circuit board\\nPeripheral\\nIntegrated circuit\\nVery Large Scale Integration\\nSystems on Chip (SoCs)\\nEnergy consumption (Green computing)\\nElectronic design automation\\nHardware acceleration\\nComputer systems organization\\nComputer architecture\\nEmbedded system\\nReal-time computing\\nDependability\\nNetworks\\nNetwork architecture\\nNetwork protocol\\nNetwork components\\nNetwork scheduler\\nNetwork performance evaluation\\nNetwork service\\nSoftware organization\\nInterpreter\\nMiddleware\\nVirtual machine\\nOperating system\\nSoftware quality\\nSoftware notations and tools\\nProgramming paradigm\\nProgramming language\\nCompiler\\nDomain-specific language\\nModeling language\\nSoftware framework\\nIntegrated development environment\\nSoftware configuration management\\nSoftware library\\nSoftware repository\\nSoftware development\\nControl variable\\nSoftware development process\\nRequirements analysis\\nSoftware design\\nSoftware construction\\nSoftware deployment\\nSoftware maintenance\\nProgramming team\\nOpen-source model\\nTheory of computation\\nModel of computation\\nFormal language\\nAutomata theory\\nComputability theory\\nComputational complexity theory\\nLogic\\nSemantics\\nAlgorithms\\nAlgorithm design\\nAnalysis of algorithms\\nAlgorithmic efficiency\\nRandomized algorithm\\nComputational geometry\\nMathematics of computing\\nDiscrete mathematics\\nProbability\\nStatistics\\nMathematical software\\nInformation theory\\nMathematical analysis\\nNumerical analysis\\nTheoretical computer science\\nInformation systems\\nDatabase management system\\nInformation storage systems\\nEnterprise information system\\nSocial information systems\\nGeographic information system\\nDecision support system\\nProcess control system\\nMultimedia information system\\nData mining\\nDigital library\\nComputing platform\\nDigital marketing\\nWorld Wide Web\\nInformation retrieval\\nSecurity\\nCryptography\\nFormal methods\\nSecurity services\\nIntrusion detection system\\nHardware security\\nNetwork security\\nInformation security\\nApplication security\\nHuman–computer interaction\\nInteraction design\\nSocial computing\\nUbiquitous computing\\nVisualization\\nAccessibility\\nConcurrency\\nConcurrent computing\\nParallel computing\\nDistributed computing\\nMultithreading\\nMultiprocessing\\nArtificial intelligence\\nNatural language processing\\nKnowledge representation and reasoning\\nComputer vision\\nAutomated planning and scheduling\\nSearch methodology\\nControl method\\nPhilosophy of artificial intelligence\\nDistributed artificial intelligence\\nMachine learning\\nSupervised learning\\nUnsupervised learning\\nReinforcement learning\\nMulti-task learning\\nCross-validation\\nGraphics\\nAnimation\\nRendering\\nImage manipulation\\nGraphics processing unit\\nMixed reality\\nVirtual reality\\nImage compression\\nSolid modeling\\nApplied computing\\nE-commerce\\nEnterprise software\\nComputational mathematics\\nComputational physics\\nComputational chemistry\\nComputational biology\\nComputational social science\\nComputational engineering\\nComputational healthcare\\nDigital art\\nElectronic publishing\\nCyberwarfare\\nElectronic voting\\nVideo games\\nWord processing\\nOperations research\\nEducational technology\\nDocument management\\n\\n Category\\n Outline\\nWikiProject\\n Commons\\n\\nvteEmerging technologiesFieldsInformation andcommunications\\nAmbient intelligence\\nInternet of things\\nArtificial intelligence\\nApplications of artificial intelligence\\nProgress in artificial intelligence\\nMachine translation\\nMobile translation\\nMachine vision\\nSemantic Web\\nSpeech recognition\\nAtomtronics\\nCarbon nanotube field-effect transistor\\nCybermethodology\\nFourth-generation optical discs\\n3D optical data storage\\nHolographic data storage\\nGPGPU\\nMemory\\nCBRAM\\nFRAM\\nMillipede\\nMRAM\\nNRAM\\nPRAM\\nRacetrack memory\\nRRAM\\nSONOS\\nECRAM\\nUltraRAM\\nOptical computing\\nRFID\\nChipless RFID\\nSoftware-defined radio\\nThree-dimensional integrated circuit\\nTopics\\nCollingridge dilemma\\nDifferential technological development\\nDisruptive innovation\\nEphemeralization\\nEthics\\nBioethics\\nCyberethics\\nNeuroethics\\nRobot ethics\\nExploratory engineering\\nFictional technology\\nProactionary principle\\nTechnological change\\nTechnological unemployment\\nTechnological convergence\\nTechnological evolution\\nTechnological paradigm\\nTechnology forecasting\\nAccelerating change\\nHorizon scanning\\nMoore\\'s law\\nTechnological singularity\\nTechnology scouting\\nTechnology readiness level\\nTechnology roadmap\\nTranshumanism\\n\\n Category\\n List\\n\\nvteRoboticsMain articles\\nOutline\\nGlossary\\nIndexc\\nHistory\\nGeography\\nHall of Fame\\nEthics\\nLaws\\nCompetitions\\nAI competitions\\nTypes\\nAnthropomorphic\\nHumanoid\\nAndroid\\nCyborg\\nClaytronics\\nCompanion\\nAnimatronic\\nAudio-Animatronics\\nIndustrial\\nArticulated\\narm\\nDomestic\\nEducational\\nEntertainment\\nJuggling\\nMilitary\\nMedical\\nService\\nDisability\\nAgricultural\\nFood service\\nRetail\\nBEAM robotics\\nSoft robotics\\nClassifications\\nBiorobotics\\nUnmanned vehicle\\naerial\\nground\\nMobile robot\\nMicrobotics\\nNanorobotics\\nRobotic spacecraft\\nSpace probe\\nSwarm\\nUnderwater\\nremotely-operated\\nLocomotion\\nTracks\\nWalking\\nHexapod\\nClimbing\\nElectric unicycle\\nRobot navigation\\nResearch\\nEvolutionary\\nKits\\nSimulator\\nSuite\\nOpen-source\\nSoftware\\nAdaptable\\nDevelopmental\\nParadigms\\nUbiquitous\\nRelated\\nCritique of work\\nPowered exoskeleton\\nTechnological unemployment\\nTerrainability\\nFictional robots\\n\\n Category\\n Outline\\n\\nvteExistential risk from artificial intelligenceConcepts\\nAccelerating change\\nAI box\\nAI takeover\\nControl problem\\nExistential risk from artificial general intelligence\\nFriendly artificial intelligence\\nInstrumental convergence\\nIntelligence explosion\\nMachine ethics\\nSuperintelligence\\nTechnological singularity\\nOrganizations\\nAllen Institute for AI\\nCenter for Applied Rationality\\nCenter for Human-Compatible Artificial Intelligence\\nCentre for the Study of Existential Risk\\nDeepMind\\nFoundational Questions Institute\\nFuture of Humanity Institute\\nFuture of Life Institute\\nHumanity+\\nInstitute for Ethics and Emerging Technologies\\nLeverhulme Centre for the Future of Intelligence\\nMachine Intelligence Research Institute\\nOpenAI\\nPeople\\nScott Alexander\\nNick Bostrom\\nEric Drexler\\nSam Harris\\nStephen Hawking\\nBill Hibbard\\nBill Joy\\nElon Musk\\nSteve Omohundro\\nHuw Price\\nMartin Rees\\nStuart J. Russell\\nJaan Tallinn\\nMax Tegmark\\nFrank Wilczek\\nRoman Yampolskiy\\nAndrew Yang\\nEliezer Yudkowsky\\nOther\\nArtificial intelligence as a global catastrophic risk\\nControversies and dangers of artificial general intelligence\\nEthics of artificial intelligence\\nSuffering risks\\nHuman Compatible\\nOpen Letter on Artificial Intelligence\\nOur Final Invention\\nThe Precipice\\nSuperintelligence: Paths, Dangers, Strategies\\nDo You Trust This Computer?\\n Category\\nvteSubfields of and cyberneticians involved in cyberneticsSubfields\\nArtificial intelligence\\nBiological cybernetics\\nBiomedical cybernetics\\nBiorobotics\\nBiosemiotics\\nNeurocybernetics\\nCatastrophe theory\\nComputational neuroscience\\nConnectionism\\nControl theory\\nCybernetics in the Soviet Union\\nDecision theory\\nEmergence\\nEngineering cybernetics\\nHomeostasis\\nInformation theory\\nManagement cybernetics\\nMedical cybernetics\\nSecond-order cybernetics\\nSemiotics\\nSociocybernetics\\nPolycontexturality\\nSynergetics\\nCyberneticians\\nAlexander Lerner\\nAlexey Lyapunov\\nAlfred Radcliffe-Brown\\nAllenna Leonard\\nAnthony Wilden\\nBuckminster Fuller\\nCharles François\\nGenevieve Bell\\nMargaret Boden\\nClaude Bernard\\nCliff Joslyn\\nErich von Holst\\nErnst von Glasersfeld\\nFrancis Heylighen\\nFrancisco Varela\\nFrederic Vester\\nCharles Geoffrey Vickers\\nGordon Pask\\nGordon S. Brown\\nGregory Bateson\\nHeinz von Foerster\\nHumberto Maturana\\nI. A. Richards\\nIgor Aleksander\\nJacque Fresco\\nJakob von Uexküll\\nJason Jixuan Hu\\nJay Wright Forrester\\nJennifer Wilby\\nJohn N. Warfield\\nKevin Warwick\\nLudwig von Bertalanffy\\nMaleyka Abbaszadeh\\nManfred Clynes\\nMargaret Mead\\nMarian Mazur\\nN. Katherine Hayles\\nNatalia Bekhtereva\\nNiklas Luhmann\\nNorbert Wiener\\nPyotr Grigorenko\\nQian Xuesen\\nRanulph Glanville\\nRobert Trappl\\nSergei P. Kurdyumov\\nAnthony Stafford Beer\\nStuart Kauffman\\nStuart Umpleby\\nTalcott Parsons\\nUlla Mitzdorf\\nValentin Turchin\\nValentin Braitenberg\\nWilliam Ross Ashby\\nWalter Bradford Cannon\\nWalter Pitts\\nWarren McCulloch\\nWilliam Grey Walter\\n\\nvteGlossaries of science and engineering\\nAerospace engineering\\nAgriculture\\nArchaeology\\nArchitecture\\nArtificial intelligence\\nAstronomy\\nBiology\\nBotany\\nCalculus\\nChemistry\\nCivil engineering\\nClinical research\\nComputer hardware\\nComputer science\\nEcology\\nEconomics\\nElectrical and electronics engineering\\nEngineering\\nA–L\\nM–Z\\nEntomology\\nEnvironmental science\\nEvolutionary biology\\nGenetics\\nGeography\\nArabic toponyms\\nGeology\\nIchthyology\\nMachine vision\\nMathematics\\nMechanical engineering\\nMedicine\\nMeteorology\\nNanotechnology\\nOrnithology\\nPhysics\\nProbability and statistics\\nPsychiatry\\nRobotics\\nScientific naming\\nStructural engineering\\nVirology\\n\\nAuthority control: National libraries \\nSpain\\nFrance (data)\\nGermany\\nIsrael\\nUnited States\\nJapan\\n\\nSources\\n\\xa0This article incorporates text from a free content work.  Licensed under C-BY-SA 3.0 IGO Text taken from UNESCO Science Report: the Race Against Time for Smarter Development.,  Schneegans, S., T. Straza and J. Lewis (eds), UNESCO. To learn how to add open license text to Wikipedia articles, please see this how-to page. For information on reusing text from Wikipedia, please see the terms of use.\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=1083723544\"',\n",
       "  'Distributed data store for digital transactions\\nFor other uses, see Block chain (disambiguation).\\n\\n\\n Bitcoin blockchain structure[further explanation needed]\\nA blockchain is a growing list of records, called blocks, that are securely linked together using cryptography.[1][2][3][4] Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data (generally represented as a Merkle tree, where data nodes are represented by leafs). The timestamp proves that the transaction data existed when the block was published to get into its hash. As blocks each contain information about the block previous to it, they form a chain, with each additional block reinforcing the ones before it. Therefore, blockchains are resistant to modification of their data because once recorded, the data in any given block cannot be altered retroactively without altering all subsequent blocks.\\nBlockchains are typically managed by a peer-to-peer network for use as a publicly distributed ledger, where nodes collectively adhere to a protocol to communicate and validate new blocks. Although blockchain records are not unalterable as forks are possible, blockchains may be considered secure by design and exemplify a distributed computing system with high Byzantine fault tolerance.[5]\\nThe blockchain was popularized by a person (or group of people) using the name Satoshi Nakamoto in 2008 to serve as the public transaction ledger of the cryptocurrency bitcoin, based on work by Stuart Haber, W. Scott Stornetta, and Dave Bayer.[3][6] The identity of Satoshi Nakamoto remains unknown to date. The implementation of the blockchain within bitcoin made it the first digital currency to solve the double-spending problem without the need of a trusted authority or central server. The bitcoin design has inspired other applications[3][2] and blockchains that are readable by the public and are widely used by cryptocurrencies. The blockchain is considered a type of payment rail.[7]\\nPrivate blockchains have been proposed for business use. Computerworld called the marketing of such privatized blockchains without a proper security model \"snake oil\";[8] however, others have argued that permissioned blockchains, if carefully designed, may be more decentralized and therefore more secure in practice than permissionless ones.[4][9]\\n\\nContents\\n\\n1 History\\n2 Structure\\n\\n2.1 Blocks\\n\\n2.1.1 Block time\\n2.1.2 Hard forks\\n\\n\\n2.2 Decentralization\\n2.3 Openness\\n\\n2.3.1 Permissionlessness\\n2.3.2 Permissioned (private) blockchain\\n2.3.3 Disadvantages of private blockchain\\n2.3.4 Blockchain analysis\\n\\n\\n2.4 Standardisation\\n\\n\\n3 Types\\n\\n3.1 Public blockchains\\n3.2 Private blockchains\\n3.3 Hybrid blockchains\\n3.4 Sidechains\\n\\n\\n4 Uses\\n\\n4.1 Cryptocurrencies\\n4.2 Smart contracts\\n4.3 Financial services\\n4.4 Games\\n4.5 Supply chain\\n4.6 Domain names\\n4.7 Other uses\\n\\n\\n5 Blockchain interoperability\\n6 Energy consumption concerns\\n7 Academic research\\n\\n7.1 Adoption decision\\n7.2 Collaboration\\n7.3 Blockchain and internal audit\\n7.4 Journals\\n\\n\\n8 See also\\n9 References\\n10 Further reading\\n11 External links\\n\\n\\n\\nHistory\\n Bitcoin, Ethereum and Litecoin transactions per day (January 2011 – January 2021)\\nCryptographer David Chaum first proposed a blockchain-like protocol in his 1982 dissertation \"Computer Systems Established, Maintained, and Trusted by Mutually Suspicious Groups.\"[10] Further work on a cryptographically secured chain of blocks was described in 1991 by Stuart Haber and W. Scott Stornetta.[4][11] They wanted to implement a system wherein document timestamps could not be tampered with. In 1992, Haber, Stornetta, and Dave Bayer incorporated Merkle trees into the design, which improved its efficiency by allowing several document certificates to be collected into one block.[4][12] Under their company Surety, their document certificate hashes have been published in The New York Times every week since 1995.[6]\\nThe first decentralized blockchain was conceptualized by a person (or group of people) known as Satoshi Nakamoto in 2008. Nakamoto improved the design in an important way using a Hashcash-like method to timestamp blocks without requiring them to be signed by a trusted party and introducing a difficulty parameter to stabilize the rate at which blocks are added to the chain.[4] The design was implemented the following year by Nakamoto as a core component of the cryptocurrency bitcoin, where it serves as the public ledger for all transactions on the network.[3]\\nIn August 2014, the bitcoin blockchain file size, containing records of all transactions that have occurred on the network, reached 20\\xa0GB (gigabytes).[13] In January 2015, the size had grown to almost 30\\xa0GB, and from January 2016 to January 2017, the bitcoin blockchain grew from 50\\xa0GB to 100\\xa0GB in size.  The ledger size had exceeded 200 GB by early 2020.[14]\\nThe words block and chain were used separately in Satoshi Nakamoto\\'s original paper, but were eventually popularized as a single word, blockchain, by 2016.[citation needed]\\nAccording to Accenture, an application of the diffusion of innovations theory suggests that blockchains attained a 13.5% adoption rate within financial services in 2016, therefore reaching the early adopters\\' phase.[15] Industry trade groups joined to create the Global Blockchain Forum in 2016, an initiative of the Chamber of Digital Commerce.\\nIn May 2018, Gartner found that only 1% of CIOs indicated any kind of blockchain adoption within their organisations, and only 8% of CIOs were in the short-term \"planning or [looking at] active experimentation with blockchain\".[16] For the year 2019 Gartner reported 5% of CIOs believed blockchain technology was a \\'game-changer\\' for their business.[17]\\n\\nStructure\\n Blockchain formation. The main chain (black) consists of the longest series of blocks from the genesis block (green) to the current block. Orphan blocks (purple) exist outside of the main chain.\\nA blockchain is a decentralized, distributed, and oftentimes public, digital ledger consisting of records called blocks that are used to record transactions across many computers so that any involved block cannot be altered retroactively, without the alteration of all subsequent blocks.[3][18] This allows the participants to verify and audit transactions independently and relatively inexpensively.[19] A blockchain database is managed autonomously using a peer-to-peer network and a distributed timestamping server. They are authenticated by mass collaboration powered by collective self-interests.[20] Such a design facilitates robust workflow where participants\\' uncertainty regarding data security is marginal. The use of a blockchain removes the characteristic of infinite reproducibility from a digital asset. It confirms that each unit of value was transferred only once, solving the long-standing problem of double-spending. A blockchain has been described as a value-exchange protocol.[21] A blockchain can maintain title rights because, when properly set up to detail the exchange agreement, it provides a record that compels offer and acceptance.\\nLogically, a blockchain can be seen as consisting of several layers:[22]\\n\\ninfrastructure (hardware)\\nnetworking (node discovery, information propagation[23] and verification)\\nconsensus (proof of work, proof of stake)\\ndata (blocks, transactions)\\napplication (smart contracts/decentralized applications, if applicable)\\nBlocks\\nBlocks hold batches of valid transactions that are hashed and encoded into a Merkle tree.[3] Each block includes the cryptographic hash of the prior block in the blockchain, linking the two. The linked blocks form a chain.[3] This iterative process confirms the integrity of the previous block, all the way back to the initial block, which is known as the genesis block.[24] To assure the integrity of a block and the data contained in it, the block is usually digitally signed.[25]\\nSometimes separate blocks can be produced concurrently, creating a temporary fork. In addition to a secure hash-based history, any blockchain has a specified algorithm for scoring different versions of the history so that one with a higher score can be selected over others. Blocks not selected for inclusion in the chain are called orphan blocks.[24] Peers supporting the database have different versions of the history from time to time. They keep only the highest-scoring version of the database known to them. Whenever a peer receives a higher-scoring version (usually the old version with a single new block added) they extend or overwrite their own database and retransmit the improvement to their peers. There is never an absolute guarantee that any particular entry will remain in the best version of history forever. Blockchains are typically built to add the score of new blocks onto old blocks and are given incentives to extend with new blocks rather than overwrite old blocks. Therefore, the probability of an entry becoming superseded decreases exponentially[26] as more blocks are built on top of it, eventually becoming very low.[3][27]:\\u200ach. 08\\u200a[28] For example, bitcoin uses a proof-of-work system, where the chain with the most cumulative proof-of-work is considered the valid one by the network. There are a number of methods that can be used to demonstrate a sufficient level of computation. Within a blockchain the computation is carried out redundantly rather than in the traditional segregated and parallel manner.[29]\\n\\nBlock time\\nThe block time is the average time it takes for the network to generate one extra block in the blockchain. Some blockchains create a new block as frequently as every five seconds.[30] By the time of block completion, the included data becomes verifiable. In cryptocurrency, this is practically when the transaction takes place, so a shorter block time means faster transactions. The block time for Ethereum is set to between 14 and 15 seconds, while for bitcoin it is on average 10 minutes.[31]\\n\\nHard forks\\nThis section is an excerpt from Fork (blockchain) § Hard fork.[edit]\\nA hard fork is a rule change such that the software validating according to the old rules will see the blocks produced according to the new rules as invalid. In case of a hard fork, all nodes meant to work in accordance with the new rules need to upgrade their software. If one group of nodes continues to use the old software while the other nodes use the new software, a permanent split can occur. \\nFor example, Ethereum was hard-forked in 2016 to \"make whole\" the investors in The DAO, which had been hacked by exploiting a vulnerability in its code. In this case, the fork resulted in a split creating Ethereum and Ethereum Classic chains. In 2014 the Nxt community was asked to consider a hard fork that would have led to a rollback of the blockchain records to mitigate the effects of a theft of 50 million NXT from a major cryptocurrency exchange. The hard fork proposal was rejected, and some of the funds were recovered after negotiations and ransom payment. Alternatively, to prevent a permanent split, a majority of nodes using the new software may return to the old rules, as was the case of bitcoin split on 12 March 2013.[32]\\n\\nA more recent hard-fork example is of Bitcoin in 2017, which resulted in a split creating Bitcoin Cash.[33] The network split was mainly due to a disagreement in how to increase the transactions per second to accommodate for demand.[34]\\nDecentralization\\nBy storing data across its peer-to-peer network, the blockchain eliminates a number of risks that come with data being held centrally.[3] The decentralized blockchain may use ad hoc message passing and distributed networking. One risk of a lack of decentralization is a so-called \"51% attack\" where a central entity can gain control of more than half of a network and can manipulate that specific blockchain record at will, allowing double-spending.[35]\\nPeer-to-peer blockchain networks lack centralized points of vulnerability that computer crackers can exploit; likewise, it has no central point of failure. Blockchain security methods include the use of public-key cryptography.[36]:\\u200a5\\u200a A public key (a long, random-looking string of numbers) is an address on the blockchain. Value tokens sent across the network are recorded as belonging to that address. A private key is like a password that gives its owner access to their digital assets or the means to otherwise interact with the various capabilities that blockchains now support. Data stored on the blockchain is generally considered incorruptible.[3]\\nEvery node in a decentralized system has a copy of the blockchain. Data quality is maintained by massive database replication[37] and computational trust. No centralized \"official\" copy exists and no user is \"trusted\" more than any other.[36] Transactions are broadcast to the network using the software. Messages are delivered on a best-effort basis. Mining nodes validate transactions,[24] add them to the block they are building, and then broadcast the completed block to other nodes.[27]:\\u200ach. 08\\u200a Blockchains use various time-stamping schemes, such as proof-of-work, to serialize changes.[38] Alternative consensus methods include proof-of-stake.[24] The growth of a decentralized blockchain is accompanied by the risk of centralization because the computer resources required to process larger amounts of data become more expensive.[39]\\n\\nOpenness\\nOpen blockchains are more user-friendly than some traditional ownership records, which, while open to the public, still require physical access to view. Because all early blockchains were permissionless, controversy has arisen over the blockchain definition. An issue in this ongoing debate is whether a private system with verifiers tasked and authorized (permissioned) by a central authority should be considered a blockchain.[40][41][42][43][44] Proponents of permissioned or private chains argue that the term \"blockchain\" may be applied to any data structure that batches data into time-stamped blocks. These blockchains serve as a distributed version of multiversion concurrency control (MVCC) in databases.[45] Just as MVCC prevents two transactions from concurrently modifying a single object in a database, blockchains prevent two transactions from spending the same single output in a blockchain.[46]:\\u200a30–31\\u200a Opponents say that permissioned systems resemble traditional corporate databases, not supporting decentralized data verification, and that such systems are not hardened against operator tampering and revision.[40][42] Nikolai Hampton of Computerworld said that \"many in-house blockchain solutions will be nothing more than cumbersome databases,\" and \"without a clear security model, proprietary blockchains should be eyed with suspicion.\"[8][47]\\n\\nPermissionlessness\\nAn advantage to an open, permissionless, or public, blockchain network is that guarding against bad actors is not required and no access control is needed.[26] This means that applications can be added to the network without the approval or trust of others, using the blockchain as a transport layer.[26]\\nBitcoin and other cryptocurrencies currently secure their blockchain by requiring new entries to include proof of work. To prolong the blockchain, bitcoin uses Hashcash puzzles. While Hashcash was designed in 1997 by Adam Back, the original idea was first proposed by Cynthia Dwork and Moni Naor and Eli Ponyatovski in their 1992 paper \"Pricing via Processing or Combatting Junk Mail\".\\nIn 2016, venture capital investment for blockchain-related projects was weakening in the USA but increasing in China.[48] Bitcoin and many other cryptocurrencies use open (public) blockchains. As of April\\xa02018[update], bitcoin has the highest market capitalization.\\n\\nPermissioned (private) blockchain\\nSee also: Distributed ledger\\nPermissioned blockchains use an access control layer to govern who has access to the network.[49] In contrast to public blockchain networks, validators on private blockchain networks are vetted by the network owner. They do not rely on anonymous nodes to validate transactions nor do they benefit from the network effect.[citation needed] Permissioned blockchains can also go by the name of \\'consortium\\' blockchains.[citation needed] It has been argued that permissioned blockchains can guarantee a certain level of decentralization, if carefully designed, as opposed to permissionless blockchains, which are often centralized in practice.[9]\\n\\nDisadvantages of private blockchain\\nNikolai Hampton pointed out in Computerworld that \"There is also no need for a \\'51 percent\\' attack on a private blockchain, as the private blockchain (most likely) already controls 100 percent of all block creation resources. If you could attack or damage the blockchain creation tools on a private corporate server, you could effectively control 100 percent of their network and alter transactions however you wished.\"[8] This has a set of particularly profound adverse implications during a financial crisis or debt crisis like the financial crisis of 2007–08, where politically powerful actors may make decisions that favor some groups at the expense of others,[50] and \"the bitcoin blockchain is protected by the massive group mining effort. It\\'s unlikely that any private blockchain will try to protect records using gigawatts of computing power — it\\'s time-consuming and expensive.\"[8] He also said, \"Within a private blockchain there is also no \\'race\\'; there\\'s no incentive to use more power or discover blocks faster than competitors. This means that many in-house blockchain solutions will be nothing more than cumbersome databases.\"[8]\\n\\nBlockchain analysis\\nThe analysis of public blockchains has become increasingly important with the popularity of bitcoin, Ethereum, litecoin and other cryptocurrencies.[51] A blockchain, if it is public, provides anyone who wants access to observe and analyse the chain data, given one has the know-how. The process of understanding and accessing the flow of crypto has been an issue for many cryptocurrencies, crypto exchanges and banks.[52][53] The reason for this is accusations of blockchain-enabled cryptocurrencies enabling illicit dark market trade of drugs, weapons, money laundering, etc.[54] A common belief has been that cryptocurrency is private and untraceable, thus leading many actors to use it for illegal purposes. This is changing and now specialised tech companies provide blockchain tracking services, making crypto exchanges, law-enforcement and banks more aware of what is happening with crypto funds and fiat-crypto exchanges. The development, some argue, has led criminals to prioritise the use of new cryptos such as Monero.[55][56][57] The question is about the public accessibility of blockchain data and the personal privacy of the very same data. It is a key debate in cryptocurrency and ultimately in the blockchain.[58]\\n\\nStandardisation\\nIn April 2016, Standards Australia submitted a proposal to the International Organization for Standardization to consider developing standards to support blockchain technology. This proposal resulted in the creation of ISO Technical Committee 307, Blockchain and Distributed Ledger Technologies.[59] The technical committee has working groups relating to blockchain terminology, reference architecture, security and privacy, identity, smart contracts, governance and interoperability for blockchain and DLT, as well as standards specific to industry sectors and generic government requirements.[60][non-primary source needed] More than 50 countries are participating in the standardization process together with external liaisons such as the Society for Worldwide Interbank Financial Telecommunication (SWIFT), the European Commission, the International Federation of Surveyors, the International Telecommunication Union (ITU) and the United Nations Economic Commission for Europe (UNECE).[60]\\nMany other national standards bodies and open standards bodies are also working on blockchain standards.[61]  These include the National Institute of Standards and Technology[62] (NIST), the European Committee for Electrotechnical Standardization[63] (CENELEC), the Institute of Electrical and Electronics Engineers[64] (IEEE), the Organization for the Advancement of Structured Information Standards (OASIS), and some individual participants in the  Internet Engineering Task Force[65] (IETF).\\n\\nTypes\\nCurrently, there are at least four types of blockchain networks — public blockchains, private blockchains, consortium blockchains and hybrid blockchains.\\n\\nPublic blockchains\\nA public blockchain has absolutely no access restrictions. Anyone with an Internet connection can send transactions to it as well as become a validator (i.e., participate in the execution of a consensus protocol).[66][self-published source?] Usually, such networks offer economic incentives for those who secure them and utilize some type of a Proof of Stake or Proof of Work algorithm.\\nSome of the largest, most known public blockchains are the bitcoin blockchain and the Ethereum blockchain.\\n\\nPrivate blockchains\\nA private blockchain is permissioned.[49] One cannot join it unless invited by the network administrators. Participant and validator access is restricted. To distinguish between open blockchains and other peer-to-peer decentralized database applications that are not open ad-hoc compute clusters, the terminology Distributed Ledger (DLT) is normally used for private blockchains.\\n\\nHybrid blockchains\\nA hybrid blockchain has a combination of centralized and decentralized features.[67] The exact workings of the chain can vary based on which portions of centralization and decentralization are used.\\n\\nSidechains\\nA sidechain is a designation for a blockchain ledger that runs in parallel to a primary blockchain.[68][69] Entries from the primary blockchain (where said entries typically represent digital assets) can be linked to and from the sidechain; this allows the sidechain to otherwise operate independently of the primary blockchain (e.g., by using an alternate means of record keeping, alternate consensus algorithm, etc.).[70][better\\xa0source\\xa0needed]\\n\\nUses\\n Bitcoin\\'s transactions are recorded on a publicly viewable blockchain.\\nBlockchain technology can be integrated into multiple areas. The primary use of blockchains is as a distributed ledger for cryptocurrencies such as bitcoin; there were also a few other operational products that had matured from proof of concept by late 2016.[48] As of 2016, some businesses have been testing the technology and conducting low-level implementation to gauge blockchain\\'s effects on organizational efficiency in their back office.[71]\\nIn 2019, it was estimated that around $2.9 billion were invested in blockchain technology, which represents an 89% increase from the year prior. Additionally, the International Data Corp has estimated that corporate investment into blockchain technology will reach $12.4 billion by 2022.[72] Furthermore, According to PricewaterhouseCoopers (PwC), the second-largest professional services network in the world, blockchain technology has the potential to generate an annual business value of more than $3 trillion by 2030. PwC\\'s estimate is further augmented by a 2018 study that they have conducted, in which PwC surveyed 600 business executives and determined that 84% have at least some exposure to utilizing blockchain technology, which indicts a significant demand and interest in blockchain technology.[73]\\nIndividual use of blockchain technology has also greatly increased since 2016. According to statistics in 2020, there were more than 40 million blockchain wallets in 2020 in comparison to around 10 million blockchain wallets in 2016.[74]\\n\\nCryptocurrencies\\nMain article: Cryptocurrency\\nMost cryptocurrencies use blockchain technology to record transactions. For example, the bitcoin network and Ethereum network are both based on blockchain. On 8 May 2018 Facebook confirmed that it would open a new blockchain group[75] which would be headed by David Marcus, who previously was in charge of Messenger. Facebook\\'s planned cryptocurrency platform, Libra (now known as Diem), was formally announced on June 18, 2019.[76][77]\\nThe criminal enterprise Silk Road, which operated on Tor, utilized cryptocurrency for payments, some of which the US federal government has seized through research on the blockchain and forfeiture.[78]\\nGovernments have mixed policies on the legality of their citizens or banks\\nowning cryptocurrencies. China implements blockchain technology in several industries including a national digital currency which launched in 2020.[79] To strengthen their respective currencies, Western governments including the European Union and the United States have initiated similar projects.[80]\\n\\nSmart contracts\\nMain article: Smart contract\\nBlockchain-based smart contracts are proposed contracts that can be partially or fully executed or enforced without human interaction.[81] One of the main objectives of a smart contract is automated escrow. A key feature of smart contracts is that they do not need a trusted third party (such as a trustee) to act as an intermediary between contracting entities -the blockchain network executes the contract on its own. This may reduce friction between entities when transferring value and could subsequently open the door to a higher level of transaction automation.[82] An IMF staff discussion from 2018 reported that smart contracts based on blockchain technology might reduce moral hazards and optimize the use of contracts in general. But \"no viable smart contract systems have yet emerged.\" Due to the lack of widespread use their legal status was unclear.[83][84]\\n\\nFinancial services\\nAccording to Reason, many banks have expressed interest in implementing distributed ledgers for use in banking and are cooperating with companies creating private blockchains,[85][86][87] and according to a September 2016 IBM study, this is occurring faster than expected.[88]\\nBanks are interested in this technology not least because it has the potential to speed up back office settlement systems.[89] Moreover, as the blockchain industry has reached early maturity institutional appreciation has grown that it is, practically speaking, the infrastructure of a whole new financial industry, with all the implications which that entails.[90]\\nBanks such as UBS are opening new research labs dedicated to blockchain technology in order to explore how blockchain can be used in financial services to increase efficiency and reduce costs.[91][92]\\nBerenberg, a German bank, believes that blockchain is an \"overhyped technology\" that has had a large number of \"proofs of concept\", but still has major challenges, and very few success stories.[93]\\nThe blockchain has also given rise to initial coin offerings (ICOs) as well as a new category of digital asset called security token offerings (STOs), also sometimes referred to as digital security offerings (DSOs).[94] STO/DSOs may be conducted privately or on public, regulated stock exchange and are used to tokenize traditional assets such as company shares as well as more innovative ones like intellectual property, real estate,[95] art, or individual products. A number of companies are active in this space providing services for compliant tokenization, private STOs, and public STOs.\\n\\nGames\\nMain article: Blockchain game\\nBlockchain technology, such as cryptocurrencies and non-fungible tokens (NFTs), has been used in video games for monetization. Many live-service games offer in-game customization options, such as character skins or other in-game items, which the players can earn and trade with other players using in-game currency. Some games also allow for trading of virtual items using real-world currency, but this may be illegal in some countries where video games are seen as akin to gambling, and has led to gray market issues such as skin gambling, and thus publishers typically have shied away from allowing players to earn real-world funds from games.[96] Blockchain games typically allow players to trade these in-game items for cryptocurrency, which can then be exchanged for money.[97]\\nThe first known game to use blockchain technologies was CryptoKitties, launched in November 2017, where the player would purchase NFTs with Ethereum cryptocurrency, each NFT consisting of a virtual pet that the player could breed with others to create offspring with combined traits as new NFTs.[98][97] The game made headlines in December 2017 when one virtual pet sold for more than US$100,000.[99] CryptoKitties also illustrated scalability problems for games on Ethereum when it created significant congestion on the Ethereum network in early 2018 with approximately 30% of all Ethereum transactions[clarification needed] being for the game.[100][101]\\nBy the early 2020s, there had not been a breakout success in video games using blockchain, as these games tend to focus on using blockchain for speculation instead of more traditional forms of gameplay, which offers limited appeal to most players. Such games also represent a high risk to investors as their revenues can be difficult to predict.[97] However, limited successes of some games, such as Axie Infinity during the COVID-19 pandemic, and corporate plans towards metaverse content, refueled interest in the area of GameFi, a term describing the intersection of video games and financing typically backed by blockchain currency, in the second half of 2021.[102] Several major publishers, including Ubisoft, Electronic Arts, and Take Two Interactive, have stated that blockchain and NFT-based games are under serious consideration for their companies in the future.[103]\\nIn October 2021, Valve Corporation banned blockchain games, including those using cryptocurrency and NFTs, from being hosted on its Steam digital storefront service, which is widely used for personal computer gaming, claiming that this was an extension of their policy banning games that offered in-game items with real-world value. Valve\\'s prior history with gambling, specifically skin gambling, was speculated to be a factor in the decision to ban blockchain games.[104] Journalists and players responded positively to Valve\\'s decision as blockchain and NFT games have a reputation for scams and fraud among most PC gamers,[96][104] Epic Games, which runs the Epic Games Store in competition to Steam, said that they would be open to accepted blockchain games, in the wake of Valve\\'s refusal.[105]\\n\\nSupply chain\\nThere have been several different efforts to employ blockchains in supply chain management.\\n\\nPrecious commodities mining — Blockchain technology has been used for tracking the origins of gemstones and other precious commodities. In 2016, The Wall Street Journal reported that the blockchain technology company, Everledger was partnering with IBM\\'s blockchain-based tracking service to trace the origin of diamonds to ensure that they were ethically mined.[106] As of 2019, the Diamond Trading Company (DTC) has been involved in building a diamond trading supply chain product called Tracr.[107]\\nFood supply — As of 2018, Walmart and IBM were running a trial to use a blockchain-backed system for supply chain monitoring for lettuce and spinach — all nodes of the blockchain were administered by Walmart and were located on the IBM cloud.[108] In 2021, scientists from Nosh Technologies and the University of Essex developed a blockchain-based approach named FoodSQRBlock using QR code and cloud computing to digitize food supply chain data to improve traceability of food by the farmers and consumers.[109][110] Nosh Technologies also developed a blockchain-based multi-layered framework named SmartNoshWaste using reinforcement learning-based machine learning to reduce waste in the food supply chain.[111][112]\\nDomain names\\nThere are several different efforts to offer domain name services via the blockchain. These domain names can be controlled by the use of a private key, which purports to allow for uncensorable websites. This would also bypass a registrar\\'s ability to suppress domains used for fraud, abuse, or illegal content.[113]\\nNamecoin is a cryptocurrency that supports the \".bit\" top-level domain (TLD). Namecoin was forked from bitcoin in 2011. The .bit TLD is not sanctioned by ICANN, instead requiring an alternative DNS root.[113] As of 2015, it was used by 28 websites, out of 120,000 registered names.[114] Namecoin was dropped by OpenNIC in 2019, due to malware and potential other legal issues.[115] Other blockchain alternatives to ICANN include The Handshake Network,[114] EmerDNS, and Unstoppable Domains.[113]\\nSpecific TLDs include \".eth\", \".luxe\", and \".kred\", which are associated with the Ethereum blockchain through the Ethereum Name Service (ENS). The .kred TLD also acts as an alternative to conventional cryptocurrency wallet addresses, as a convenience for transferring cryptocurrency.[116]\\n\\nOther uses\\nBlockchain technology can be used to create a permanent, public, transparent ledger system for compiling data on sales, tracking digital use and payments to content creators, such as wireless users[117] or musicians.[118] The Gartner 2019 CIO Survey reported 2% of higher education respondents had launched blockchain projects and another 18% were planning academic projects in the next 24 months.[119] In 2017, IBM partnered with ASCAP and PRS for Music to adopt blockchain technology in music distribution.[120] Imogen Heap\\'s Mycelia service has also been proposed as a blockchain-based alternative \"that gives artists more control over how their songs and associated data circulate among fans and other musicians.\"[121][122]\\nNew distribution methods are available for the insurance industry such as peer-to-peer insurance, parametric insurance and microinsurance following the adoption of blockchain.[123][124] The sharing economy and IoT are also set to benefit from blockchains because they involve many collaborating peers.[125] The use of blockchain in libraries is being studied with a grant from the U.S. Institute of Museum and Library Services.[126]\\nOther blockchain designs include Hyperledger, a collaborative effort from the Linux Foundation to support blockchain-based distributed ledgers, with projects under this initiative including Hyperledger Burrow (by Monax) and Hyperledger Fabric (spearheaded by IBM).[127][128][129] Another is Quorum, a permissionable private blockchain by JPMorgan Chase with private storage, used for contract applications.[130]\\nBlockchain is also being used in peer-to-peer energy trading.[131][132][133]\\nBlockchain could be used in detecting counterfeits by associating unique identifiers to products, documents and shipments, and storing records associated with transactions that cannot be forged or altered.[134][135] It is however argued that blockchain technology needs to be supplemented with technologies that provide a strong binding between physical objects and blockchain systems.[136] The EUIPO established an Anti-Counterfeiting Blockathon Forum, with the objective of \"defining, piloting and implementing\" an anti-counterfeiting infrastructure at the European level.[137][138] The Dutch Standardisation organisation NEN uses blockchain together with QR Codes to authenticate certificates.[139]\\n\\nBlockchain interoperability\\nWith the increasing number of blockchain systems appearing, even only those that support cryptocurrencies, blockchain interoperability is becoming a topic of major importance. The objective is to support transferring assets from one blockchain system to another blockchain system. Wegner[140] stated that \"interoperability is the ability of two or more software components to cooperate despite differences in language, interface, and execution platform\". The objective of blockchain interoperability is therefore to support such cooperation among blockchain systems, despite those kinds of differences.\\nThere are already several blockchain interoperability solutions available.[141] They can be classified into three categories: cryptocurrency interoperability approaches, blockchain engines, and blockchain connectors.\\nSeveral individual IETF participants produced the draft of a blockchain interoperability architecture.[142]\\n\\nEnergy consumption concerns\\nBlockchain mining — the peer-to-peer computer computations by which transactions are validated and verified — requires a significant amount of energy. In June 2018 the Bank for International Settlements criticized the use of public proof-of-work blockchains for their high energy consumption.[143][144][145] In 2021, a study by Cambridge University determined that Bitcoin (at 121 terawatt-hours per year) used more electricity than Argentina (at 121TWh) and the Netherlands (109TWh).[146] According to Digiconomist, one bitcoin transaction required 708 kilowatt-hours of electrical energy, the amount an average U.S. household consumed in 24 days.[147]\\nIn February 2021, U.S. Treasury secretary Janet Yellen called Bitcoin \"an extremely inefficient way to conduct transactions\", saying \"the amount of energy consumed in processing those transactions is staggering.\"[148] In March 2021, Bill Gates stated that \"Bitcoin uses more electricity per transaction than any other method known to mankind\", adding \"It\\'s not a great climate thing.\"[149]\\nNicholas Weaver, of the International Computer Science Institute at the University of California, Berkeley, examined blockchain\\'s online security, and the energy efficiency of proof-of-work public blockchains, and in both cases found it grossly inadequate.[150][151] The 31TWh–45TWh of electricity used for bitcoin in 2018 produced 17–22.9 million tonnes of CO2.[152][153] By 2022, the University of Cambridge and Digiconomist estimated that the two largest proof-of-work blockchains, Bitcoin and Ethereum, together used twice as much electricity in one year as the whole of Sweden, leading to the release of up to 120 million tonnes of CO2 each year.[154]\\nInside the cryptocurrency industry, concern about high energy consumption has led some companies to consider moving from the proof of work blockchain model to the less energy-intensive proof of stake model.[155] Academics and researchers have estimated that Bitcoin consumes 100,000 times as much energy as proof-of-stake networks.[156][157]\\n\\nAcademic research\\n Blockchain panel discussion at the first IEEE Computer Society TechIgnite conference\\nIn October 2014, the MIT Bitcoin Club, with funding from MIT alumni, provided undergraduate students at the Massachusetts Institute of Technology access to $100 of bitcoin. The adoption rates, as studied by Catalini and Tucker (2016), revealed that when people who typically adopt technologies early are given delayed access, they tend to reject the technology.[158] Many universities have founded departments focusing on crypto and blockchain, including MIT, in 2017. In the same year, Edinburgh became \"one of the first big European universities to launch a blockchain course\", according to the Financial Times.[159]\\n\\nAdoption decision\\nMotivations for adopting blockchain technology (an aspect of innovation adoptation) have been investigated by researchers. For example, Janssen, et al. provided a framework for analysis,[160] and Koens & Poll pointed out that adoption could be heavily driven by non-technical factors.[161] Based on behavioral models, Li[162] has discussed the differences between adoption at the individual level and organizational levels.\\n\\nCollaboration\\nScholars in business and management have started studying the role of blockchains to support collaboration.[163][164] It has been argued that blockchains can foster both cooperation (i.e., prevention of opportunistic behavior) and coordination (i.e., communication and information sharing). Thanks to reliability, transparency, traceability of records, and information immutability, blockchains facilitate collaboration in a way that differs both from the traditional use of contracts and from relational norms. Contrary to contracts, blockchains do not directly rely on the legal system to enforce agreements.[165] In addition, contrary to the use of relational norms, blockchains do not require a trust or direct connections between collaborators.\\n\\nBlockchain and internal audit\\nExternal video Blockchain Basics & Cryptography, Gary Gensler, Massachusetts Institute of Technology, 0:30[166]\\nThe need for internal audits to provide effective oversight of organizational efficiency will require a change in the way that  information  is accessed in new formats.[167] Blockchain adoption requires a framework to identify the risk of exposure associated with transactions using blockchain. The Institute of Internal Auditors has identified the need for internal auditors to address this transformational technology.  New methods are required to develop audit plans that identify threats and risks. The Internal Audit Foundation study, Blockchain and Internal Audit, assesses these factors.[168] The American Institute of Certified Public Accountants has outlined new roles for auditors as a result of blockchain.[169]\\n\\nJournals\\nMain article: Ledger (journal)\\nIn September 2015, the first peer-reviewed academic journal dedicated to cryptocurrency and blockchain technology research, Ledger, was announced. The inaugural issue was published in December 2016.[170] The journal covers aspects of mathematics, computer science, engineering, law, economics and philosophy that relate to cryptocurrencies such as bitcoin.[171][172]\\nThe journal encourages authors to digitally sign a file hash of submitted papers, which are then timestamped into the bitcoin blockchain. Authors are also asked to include a personal bitcoin address on the first page of their papers for non-repudiation purposes.[173]\\n\\nSee also\\n\\n\\nEconomics portal\\nVersion control – a record of all changes (mostly of software project) in a form of a graph\\nChangelog – a record of all notable changes made to a project\\nChecklist – an informational aid used to reduce failure\\nEconomics of digitization\\nPrivacy and blockchain\\nReferences\\n\\n\\n^ Morris, David Z. (15 May 2016). \"Leaderless, Blockchain-Based Venture Capital Fund Raises $100 Million, And Counting\". Fortune. Archived from the original on 21 May 2016. Retrieved 23 May 2016.\\n\\n^ a b Popper, Nathan (21 May 2016). \"A Venture Fund With Plenty of Virtual Capital, but No Capitalist\". The New York Times. Archived from the original on 22 May 2016. Retrieved 23 May 2016.\\n\\n^ a b c d e f g h i j \"Blockchains: The great chain of being sure about things\". The Economist. 31 October 2015. Archived from the original on 3 July 2016. Retrieved 18 June 2016. The technology behind bitcoin lets people who do not know or trust each other build a dependable ledger. This has implications far beyond the crypto currency.\\n\\n^ a b c d e Narayanan, Arvind; Bonneau, Joseph; Felten, Edward; Miller, Andrew; Goldfeder, Steven (2016). Bitcoin and cryptocurrency technologies: a comprehensive introduction. Princeton: Princeton University Press. ISBN\\xa0978-0-691-17169-2.\\n\\n^ Iansiti, Marco; Lakhani, Karim R. (January 2017). \"The Truth About Blockchain\". Harvard Business Review. Harvard University. Archived from the original on 18 January 2017. Retrieved 17 January 2017. The technology at the heart of bitcoin and other virtual currencies, blockchain is an open, distributed ledger that can record transactions between two parties efficiently and in a verifiable and permanent way.\\n\\n^ a b \"The World\\'s Oldest Blockchain Has Been Hiding in the New York Times Since 1995\". www.vice.com. Retrieved 9 October 2021.\\n\\n^ \"Blockchain may finally disrupt payments from Micropayments to credit cards to SWIFT\". dailyfintech.com. 10 February 2018. Archived from the original on 27 September 2018. Retrieved 18 November 2018.\\n\\n^ a b c d e Hampton, Nikolai (5 September 2016). \"Understanding the blockchain hype: Why much of it is nothing more than snake oil and spin\". Computerworld. Archived from the original on 6 September 2016. Retrieved 5 September 2016.\\n\\n^ a b Bakos, Yannis; Halaburda, Hanna; Mueller-Bloch, Christoph (February 2021). \"When Permissioned Blockchains Deliver More Decentralization Than Permissionless\". Communications of the ACM. 64 (2): 20–22. doi:10.1145/3442371. S2CID\\xa0231704491.\\n\\n^ Sherman, Alan T.; Javani, Farid; Zhang, Haibin; Golaszewski, Enis (January 2019). \"On the Origins and Variations of Blockchain Technologies\". IEEE Security Privacy. 17 (1): 72–77. arXiv:1810.06130. doi:10.1109/MSEC.2019.2893730. ISSN\\xa01558-4046. S2CID\\xa053114747.\\n\\n^ Haber, Stuart; Stornetta, W. Scott (January 1991). \"How to time-stamp a digital document\". Journal of Cryptology. 3 (2): 99–111. CiteSeerX\\xa010.1.1.46.8740. doi:10.1007/bf00196791. S2CID\\xa014363020.\\n\\n^ Bayer, Dave; Haber, Stuart; Stornetta, W. Scott (March 1992). Improving the Efficiency and Reliability of Digital Time-Stamping. Sequences. Vol.\\xa02. pp.\\xa0329–334. CiteSeerX\\xa010.1.1.71.4891. doi:10.1007/978-1-4613-9323-8_24. ISBN\\xa0978-1-4613-9325-2.\\n\\n^ Nian, Lam Pak; Chuen, David LEE Kuo (2015). \"A Light Touch of Regulation for Virtual Currencies\".  In Chuen, David LEE Kuo (ed.). Handbook of Digital Currency: Bitcoin, Innovation, Financial Instruments, and Big Data. Academic Press. p.\\xa0319. ISBN\\xa0978-0-12-802351-8.\\n\\n^ \"Blockchain Size\". Archived from the original on 19 May 2020. Retrieved 25 February 2020.\\n\\n^ \"The future of blockchain in 8 charts\". Raconteur. 27 June 2016. Archived from the original on 2 December 2016. Retrieved 3 December 2016.\\n\\n^ \"Hype Killer - Only 1% of Companies Are Using Blockchain, Gartner Reports | Artificial Lawyer\". Artificial Lawyer. 4 May 2018. Archived from the original on 22 May 2018. Retrieved 22 May 2018.\\n\\n^ Kasey Panetta. (31 October 2018). \"Digital Business: CIO Agenda 2019: Exploit Transformational Technologies.\" Gartner website Retrieved 27 March 2021.\\n\\n^ Armstrong, Stephen (7 November 2016). \"Move over Bitcoin, the blockchain is only just getting started\". Wired. Archived from the original on 8 November 2016. Retrieved 9 November 2016.\\n\\n^ Catalini, Christian; Gans, Joshua S. (23 November 2016). \"Some Simple Economics of the Blockchain\" (PDF). SSRN. doi:10.2139/ssrn.2874598. hdl:1721.1/130500. S2CID\\xa046904163. SSRN\\xa02874598. Archived (PDF) from the original on 6 March 2020. Retrieved 16 September 2019.\\n\\n^ Tapscott, Don; Tapscott, Alex (8 May 2016). \"Here\\'s Why Blockchains Will Change the World\". Fortune. Archived from the original on 13 November 2016. Retrieved 16 November 2016.\\n\\n^ Bheemaiah, Kariappa (January 2015). \"Block Chain 2.0: The Renaissance of Money\". Wired. Archived from the original on 14 November 2016. Retrieved 13 November 2016.\\n\\n^ Chen, Huashan; Pendleton, Marcus; Njilla, Laurent; Xu, Shouhuai (12 June 2020). \"A Survey on Ethereum Systems Security: Vulnerabilities, Attacks, and Defenses\". ACM Computing Surveys. 53 (3): 3–4. arXiv:1908.04507. doi:10.1145/3391195. ISSN\\xa00360-0300. S2CID\\xa0199551841.\\n\\n^ Shishir, Bhatia (2 February 2006). Structured Information Flow (SIF) Framework for Automating End-to-End Information Flow for Large Organizations (Thesis). Virginia Tech.\\n\\n^ a b c d Bhaskar, Nirupama Devi; Chuen, David LEE Kuo (2015). \"Bitcoin Mining Technology\". Handbook of Digital Currency. pp.\\xa045–65. doi:10.1016/B978-0-12-802117-0.00003-5. ISBN\\xa0978-0-12-802117-0.\\n\\n^ Knirsch, Unterweger & Engel 2019, p.\\xa02.\\n\\n^ a b c Antonopoulos, Andreas (20 February 2014). \"Bitcoin security model: trust by computation\". Radar. O\\'Reilly. Archived from the original on 31 October 2016. Retrieved 19 November 2016.\\n\\n^ a b Antonopoulos, Andreas M. (2014). Mastering Bitcoin. Unlocking Digital Cryptocurrencies. Sebastopol, CA: O\\'Reilly Media. ISBN\\xa0978-1449374037. Archived from the original on 1 December 2016. Retrieved 3 November 2015.\\n\\n^ Nakamoto, Satoshi (October 2008). \"Bitcoin: A Peer-to-Peer Electronic Cash System\" (PDF). bitcoin.org. Archived (PDF) from the original on 20 March 2014. Retrieved 28 April 2014.\\n\\n^ \"Permissioned Blockchains\". Explainer. Monax. Archived from the original on 20 November 2016. Retrieved 20 November 2016.\\n\\n^ Strydom, Moses; Buckley, Sheryl (July 2019). AI and Big Data\\'s Potential for Disruptive Innovation. IGI Global. ISBN\\xa0978-1-5225-9687-5.\\n\\n^ Kumar, Randhir; Tripathi, Rakesh (November 2019). \"Implementation of Distributed File Storage and Access Framework using IPFS and Blockchain\". 2019 Fifth International Conference on Image Information Processing (ICIIP). IEEE: 246–251. doi:10.1109/iciip47207.2019.8985677. ISBN\\xa0978-1-7281-0899-5. S2CID\\xa0211119043.\\n\\n^ Lee, Timothy (12 March 2013). \"Major glitch in Bitcoin network sparks sell-off; price temporarily falls 23%\". Arstechnica. Archived from the original on 22 April 2013. Retrieved 25 February 2018.\\n\\n^ Smith, Oli (21 January 2018). \"Bitcoin price RIVAL: Cryptocurrency \\'faster than bitcoin\\' will CHALLENGE market leaders\". Express. Retrieved 6 April 2021.\\n\\n^ \"Bitcoin split in two, here\\'s what that means\". CNN. 1 August 2017. Retrieved 7 April 2021.\\n\\n^ \"Bitcoin Spinoff Hacked in Rare \\'51% Attack\\'\". Fortune. Retrieved 28 April 2021.\\n\\n^ a b Brito, Jerry; Castillo, Andrea (2013). Bitcoin: A Primer for Policymakers (PDF) (Report). Fairfax, VA: Mercatus Center, George Mason University. Archived (PDF) from the original on 21 September 2013. Retrieved 22 October 2013.\\n\\n^ Raval, Siraj (2016). Decentralized Applications: Harnessing Bitcoin\\'s Blockchain Technology. O\\'Reilly Media, Inc. pp.\\xa01–2. ISBN\\xa0978-1-4919-2452-5.\\n\\n^ Kopfstein, Janus (12 December 2013). \"The Mission to Decentralize the Internet\". The New Yorker. Archived from the original on 31 December 2014. Retrieved 30 December 2014. The network\\'s \\'nodes\\' — users running the bitcoin software on their computers — collectively check the integrity of other nodes to ensure that no one spends the same coins twice. All transactions are published on a shared public ledger, called the \\'block chain.\\'\\n\\n^ Gervais, Arthur; Karame, Ghassan O.; Capkun, Vedran; Capkun, Srdjan. \"Is Bitcoin a Decentralized Currency?\". InfoQ. InfoQ & IEEE computer society. Archived from the original on 10 October 2016. Retrieved 11 October 2016.\\n\\n^ a b Voorhees, Erik (30 October 2015). \"It\\'s All About the Blockchain\". Money and State. Archived from the original on 1 November 2015. Retrieved 2 November 2015.\\n\\n^ Reutzel, Bailey (13 July 2015). \"A Very Public Conflict Over Private Blockchains\". PaymentsSource. New York, NY: SourceMedia, Inc. Archived from the original on 21 April 2016. Retrieved 18 June 2016.\\n\\n^ a b Casey, Michael J. (15 April 2015). \"Moneybeat/BitBeat: Blockchains Without Coins Stir Tensions in Bitcoin Community\". The Wall Street Journal. Archived from the original on 10 June 2016. Retrieved 18 June 2016.\\n\\n^ \"The \\'Blockchain Technology\\' Bandwagon Has A Lesson Left To Learn\". dinbits.com. 3 November 2015. Archived from the original on 29 June 2016. Retrieved 18 June 2016.\\n\\n^ DeRose, Chris (26 June 2015). \"Why the Bitcoin Blockchain Beats Out Competitors\". American Banker. Archived from the original on 30 March 2016. Retrieved 18 June 2016.\\n\\n^ Greenspan, Gideon (19 July 2015). \"Ending the bitcoin vs blockchain debate\". multichain.com. Archived from the original on 8 June 2016. Retrieved 18 June 2016.\\n\\n^ Tapscott, Don; Tapscott, Alex (May 2016). The Blockchain Revolution: How the Technology Behind Bitcoin is Changing Money, Business, and the World. ISBN\\xa0978-0-670-06997-2.\\n\\n^ Barry, Levine (11 June 2018). \"A new report bursts the blockchain bubble\". MarTech. Archived from the original on 13 July 2018. Retrieved 13 July 2018.\\n\\n^ a b Ovenden, James. \"Blockchain Top Trends In 2017\". The Innovation Enterprise. Archived from the original on 30 November 2016. Retrieved 4 December 2016.\\n\\n^ a b Bob Marvin (30 August 2017). \"Blockchain: The Invisible Technology That\\'s Changing the World\". PC MAG Australia. ZiffDavis, LLC. Archived from the original on 25 September 2017. Retrieved 25 September 2017.\\n\\n^ O\\'Keeffe, M.; Terzi, A. (7 July 2015). \"The political economy of financial crisis policy\". Bruegel. Archived from the original on 19 May 2018. Retrieved 8 May 2018.\\n\\n^ Dr Garrick Hileman & Michel Rauchs (2017). \"GLOBAL CRYPTOCURRENCY BENCHMARKING STUDY\" (PDF). Cambridge Centre for Alternative Finance. University of Cambridge Judge Business School. Archived (PDF) from the original on 15 May 2019. Retrieved 15 May 2019 – via crowdfundinsider.\\n\\n^ Raymaekers, Wim (March 2015). \"Cryptocurrency Bitcoin: Disruption, challenges and opportunities\". Journal of Payments Strategy & Systems. 9 (1): 30–46. Archived from the original on 15 May 2019. Retrieved 15 May 2019.\\n\\n^ \"Why Crypto Companies Still Can\\'t Open Checking Accounts\". 3 March 2019. Archived from the original on 4 June 2019. Retrieved 4 June 2019.\\n\\n^ Christian Brenig, Rafael Accorsi & Günter Müller (Spring 2015). \"Economic Analysis of Cryptocurrency Backed Money Laundering\". Association for Information Systems AIS Electronic Library (AISeL). Archived from the original on 28 August 2019. Retrieved 15 May 2019.\\n\\n^ Greenberg, Andy (25 January 2017). \"Monero, the Drug Dealer\\'s Cryptocurrency of Choice, Is on Fire\". Wired. ISSN\\xa01059-1028. Archived from the original on 10 December 2018. Retrieved 15 May 2019.\\n\\n^ Orcutt, Mike. \"It\\'s getting harder to hide money in Bitcoin\". MIT Technology Review. Retrieved 15 May 2019.\\n\\n^ \"Explainer: \\'Privacy coin\\' Monero offers near total anonymity\". Reuters. 15 May 2019. Archived from the original on 15 May 2019. Retrieved 15 May 2019.\\n\\n^ \"An Untraceable Currency? Bitcoin Privacy Concerns - FinTech Weekly\". FinTech Magazine Article. 7 April 2018. Archived from the original on 15 May 2019. Retrieved 15 May 2019.\\n\\n^ \"Blockchain\". standards.org.au. Standards Australia. Retrieved 21 June 2021.\\n\\n^ a b \"ISO/TC 307 Blockchain and distributed ledger technologies\". iso.org. ISO. Retrieved 21 June 2021.\\n\\n^ Deshmukh, Sumedha; Boulais, Océane; Koens, Tommy. \"Global Standards Mapping Initiative: An overview of blockchain technical standards\" (PDF). weforum.org. World Economic Forum. Retrieved 23 June 2021.\\n\\n^ \"Blockchain Overview\". NIST. 25 September 2019. Retrieved 21 June 2021.\\n\\n^ \"CEN and CENELEC publish a White Paper on standards in Blockchain & Distributed Ledger Technologies\". cencenelec.eu. CENELEC. Retrieved 21 June 2021.\\n\\n^ \"Standards\". ieee.org. IEEE Blockchain. Retrieved 21 June 2021.\\n\\n^ Hardjono, Thomas. \"An Interoperability Architecture for Blockchain/DLT Gateways\". ietf.org. IETF. Retrieved 21 June 2021.\\n\\n^ \"How Companies Can Leverage Private Blockchains to Improve Efficiency and Streamline Business Processes\". Perfectial.\\n\\n^ [Distributed Ledger Technology: Hybrid Approach, Front-to-Back Designing and Changing Trade Processing Infrastructure, By Martin Walker, First published:, 24 OCT 2018 ISBN\\xa0978-1-78272-389-9]\\n\\n^ Siraj Raval (18 July 2016). Decentralized Applications: Harnessing Bitcoin\\'s Blockchain Technology. \"O\\'Reilly Media, Inc.\". pp.\\xa022–. ISBN\\xa0978-1-4919-2452-5.\\n\\n^ Niaz Chowdhury (16 August 2019). Inside Blockchain, Bitcoin, and Cryptocurrencies. CRC Press. pp.\\xa022–. ISBN\\xa0978-1-00-050770-6.\\n\\n^ U.S. Patent 10,438,290\\n\\n^ Katie Martin (27 September 2016). \"CLS dips into blockchain to net new currencies\". Financial Times. Archived from the original on 9 November 2016. Retrieved 7 November 2016.\\n\\n^ Michael Castillo (16 April 2019). \"blockchain 50: Billion Dollar Babies\". Financial Website. SourceMedia. Retrieved 1 February 2021.\\n\\n^ Steve Davies (2018). \"PwC\\'s Global Blockchain Survey\". Financial Website. SourceMedia. Retrieved 1 February 2021.\\n\\n^ Shanhong Liu (13 March 2020). \"Blockchain - Statistics & Facts\". Statistics Website. SourceMedia. Retrieved 17 February 2021.\\n\\n^ Wagner, Kurt (8 May 2018). \"Facebook is making its biggest executive shuffle in company history\". Recode. Archived from the original on 22 July 2018. Retrieved 25 September 2018.\\n\\n^ Isaac, Mike; Popper, Nathaniel (18 June 2019). \"Facebook Plans Global Financial System Based on Cryptocurrency\". The New York Times. Archived from the original on 19 May 2020. Retrieved 18 June 2019.\\n\\n^ Constine, Josh (18 June 2019). \"Facebook announces Libra cryptocurrency: All you need to know\". TechCrunch. Archived from the original on 19 June 2019. Retrieved 19 June 2019.\\n\\n^ KPIX-TV. (5 November 2020). \"Silk Road: Feds Seize $1 Billion In Bitcoins Linked To Infamous Silk Road Dark Web Case; \\'Where Did The Money Go\\'\". KPIX website Retrieved 28 March 2021.\\n\\n^ Aditi Kumar and Eric Rosenbach. (20 May 2020). \"Could China\\'s Digital Currency Unseat the Dollar?: American Economic and Geopolitical Power Is at Stake\". Foreign Affairs website Retrieved 31 March 2021.\\n\\n^ Staff. (16 February 2021). \"The Economist Explains: What is the fuss over central-bank digital currencies?\" The Economist website Retrieved 1 April 2021.\\n\\n^ Franco, Pedro (2014). Understanding Bitcoin: Cryptography, Engineering and Economics. John Wiley & Sons. p.\\xa09. ISBN\\xa0978-1-119-01916-9. Archived from the original on 14 February 2017. Retrieved 4 January 2017 – via Google Books.\\n\\n^ Casey, Michael, 1967- (16 July 2018). The impact of blockchain technology on finance\\xa0: a catalyst for change. London, UK. ISBN\\xa0978-1-912179-15-2. OCLC\\xa01059331326.{{cite book}}:  CS1 maint: multiple names: authors list (link)\\n\\n^ Governatori, Guido; Idelberger, Florian; Milosevic, Zoran; Riveret, Regis; Sartor, Giovanni; Xu, Xiwei (2018). \"On legal contracts, imperative and declarative smart contracts, and blockchain systems\". Artificial Intelligence and Law. 26 (4): 33. doi:10.1007/s10506-018-9223-3. S2CID\\xa03663005.\\n\\n^ Virtual Currencies and Beyond: Initial Considerations (PDF). IMF Discussion Note. International Monetary Fund. 2016. p.\\xa023. ISBN\\xa0978-1-5135-5297-2. Archived (PDF) from the original on 14 April 2018. Retrieved 19 April 2018.\\n\\n^ Epstein, Jim (6 May 2016). \"Is Blockchain Technology a Trojan Horse Behind Wall Street\\'s Walled Garden?\". Reason. Archived from the original on 8 July 2016. Retrieved 29 June 2016. mainstream misgivings about working with a system that\\'s open for anyone to use. Many banks are partnering with companies building so-called private blockchains that mimic some aspects of Bitcoin\\'s architecture except they\\'re designed to be closed off and accessible only to chosen parties. ... [but some believe] that open and permission-less blockchains will ultimately prevail even in the banking sector simply because they\\'re more efficient.\\n\\n^ Redrup, Yolanda (29 June 2016). \"ANZ backs private blockchain, but won\\'t go public\". Australia Financial Review. Archived from the original on 3 July 2016. Retrieved 7 July 2016. Blockchain networks can be either public or private. Public blockchains have many users and there are no controls over who can read, upload or delete the data and there are an unknown number of pseudonymous participants. In comparison, private blockchains also have multiple data sets, but there are controls in place over who can edit data and there are a known number of participants.\\n\\n^ Shah, Rakesh (1 March 2018). \"How Can The Banking Sector Leverage Blockchain Technology?\". PostBox Communications. PostBox Communications Blog. Archived from the original on 17 March 2018. Banks preferably have a notable interest in utilizing Blockchain Technology because it is a great source to avoid fraudulent transactions. Blockchain is considered hassle free, because of the extra level of security it offers.\\n\\n^ Kelly, Jemima (28 September 2016). \"Banks adopting blockchain \\'dramatically faster\\' than expected: IBM\". Reuters. Archived from the original on 28 September 2016. Retrieved 28 September 2016.\\n\\n^ Arnold, Martin (23 September 2013). \"IBM in blockchain project with China UnionPay\". Financial Times. Archived from the original on 9 November 2016. Retrieved 7 November 2016.\\n\\n^ Ravichandran, Arvind; Fargo, Christopher; Kappos, David; Portilla, David; Buretta, John; Ngo, Minh Van; Rosenthal-Larrea, Sasha (28 January 2022). \"Blockchain in the Banking Sector: A Review of the Landscape and Opportunities\".\\n\\n^ \"UBS leads team of banks working on blockchain settlement system\". Reuters. 24 August 2016. Archived from the original on 19 May 2017. Retrieved 13 May 2017.\\n\\n^ \"Cryptocurrency Blockchain\". capgemini.com. Archived from the original on 5 December 2016. Retrieved 13 May 2017.\\n\\n^ Kelly, Jemima (31 October 2017). \"Top banks and R3 build blockchain-based payments system\". Reuters. Archived from the original on 10 July 2018. Retrieved 9 July 2018.\\n\\n^ \"Archived copy\" (PDF). Archived (PDF) from the original on 23 June 2019. Retrieved 26 September 2019.{{cite web}}:  CS1 maint: archived copy as title (link)\\n\\n^ Hammerberg, Jeff (7 November 2021). \"Potential impact of blockchain on real estate\". Washington Blade.\\n\\n^ a b Clark, Mitchell (15 October 2021). \"Valve bans blockchain games and NFTs on Steam, Epic will try to make it work\". The Verge. Retrieved 8 November 2021.\\n\\n^ a b c Mozuch, Mo (29 April 2021). \"Blockchain Games Twist The Fundamentals Of Online Gaming\". Inverse. Retrieved 4 November 2021.\\n\\n^ \"Internet firms try their luck at blockchain games\". Asia Times. 22 February 2018. Retrieved 28 February 2018.\\n\\n^ Evelyn Cheng (6 December 2017). \"Meet CryptoKitties, the $100,000 digital beanie babies epitomizing the cryptocurrency mania\". CNBC. Archived from the original on 20 November 2018. Retrieved 28 February 2018.\\n\\n^ Laignee Barron (13 February 2018). \"CryptoKitties is Going Mobile. Can Ethereum Handle the Traffic?\". Fortune. Archived from the original on 28 October 2018. Retrieved 30 September 2018.\\n\\n^ \"CryptoKitties craze slows down transactions on Ethereum\". 12 May 2017. Archived from the original on 12 January 2018.\\n\\n^ Wells, Charlie; Egkolfopoulou, Misrylena (30 October 2021). \"Into the Metaverse: Where Crypto, Gaming and Capitalism Collide\". Bloomberg News. Retrieved 11 November 2021.\\n\\n^ Orland, Kyle (4 November 2021). \"Big-name publishers see NFTs as a big part of gaming\\'s future\". Ars Technica. Retrieved 4 November 2021.\\n\\n^ a b Knoop, Joseph (15 October 2021). \"Steam bans all games with NFTs or cryptocurrency\". PC Gamer. Retrieved 8 November 2021.\\n\\n^ Clark, Mitchell (15 October 2021). \"Epic says it\\'s \\'open\\' to blockchain games after Steam bans them\". The Verge. Retrieved 11 November 2021.\\n\\n^ Nash, Kim S. (14 July 2016). \"IBM Pushes Blockchain into the Supply Chain\". The Wall Street Journal. Archived from the original on 18 July 2016. Retrieved 24 July 2016.\\n\\n^ Gstettner, Stefan (30 July 2019). \"How Blockchain Will Redefine Supply Chain Management\". Knowledge@Wharton. The Wharton School of the University of Pennsylvania. Retrieved 28 August 2020.\\n\\n^ Corkery, Michael; Popper, Nathaniel (24 September 2018). \"From Farm to Blockchain: Walmart Tracks Its Lettuce\". The New York Times. Archived from the original on 5 December 2018. Retrieved 5 December 2018.\\n\\n^ Dey, Somdip; Saha, Suman; Singh, Amit Kumar; McDonald-Maier, Klaus (22 March 2021). \"FoodSQRBlock: Digitizing Food Production and the Supply Chain with Blockchain and QR Code in the Cloud\". Sustainability. 13 (6): 3486. doi:10.3390/su13063486.\\n\\n^ \"Food Waste Startup Uses AI And Blockchain To Fight Food Waste\". Outlook (Indian magazine). Retrieved 7 February 2022.\\n\\n^ Dey, Somdip; Saha, Suman; Singh, Amit Kumar; McDonald-Maier, Klaus (12 February 2022). \"SmartNoshWaste: Using Blockchain, Machine Learning, Cloud Computing and QR Code to Reduce Food Waste in Decentralized Web 3.0 Enabled Smart Cities\". Smart Cities. 5 (1): 162–176. doi:10.3390/smartcities5010011. ISSN\\xa02624-6511.\\n\\n^ Stanly, John. \"This Founder Started a Tech Business To Reduce Food Waste And Improve Sustainability For a Better Future\". Entrepreneur. Retrieved 7 March 2022.\\n\\n^ a b c Sanders, James; August 28 (28 August 2019). \"Blockchain-based Unstoppable Domains is a rehash of a failed idea\". TechRepublic. Archived from the original on 19 November 2019. Retrieved 16 April 2020.\\n\\n^ a b Orcutt, Mike (4 June 2019). \"The ambitious plan to reinvent how websites get their names\". MIT Technology Review. Retrieved 17 May 2021.\\n\\n^ Cimpanu, Catalin (17 July 2019). \"OpenNIC drops support for .bit domain names after rampant malware abuse\". ZDNet. Retrieved 17 May 2021.\\n\\n^ \".Kred launches as dual DNS and ENS domain\". Domain Name Wire | Domain Name News. 6 March 2020. Archived from the original on 8 March 2020. Retrieved 16 April 2020.\\n\\n^ K. Kotobi, and S. G. Bilen, \"Secure Blockchains for Dynamic Spectrum Access\\xa0: A Decentralized Database in Moving Cognitive Radio Networks Enhances Security and User Access\", IEEE Vehicular Technology Magazine, 2018.\\n\\n^ \"Blockchain Could Be Music\\'s Next Disruptor\". 22 September 2016. Archived from the original on 23 September 2016.\\n\\n^ Susan Moore. (16 October 2019). \"Digital Business: 4 Ways Blockchain Will Transform Higher Education\". Gartner website Retrieved 27 March 2021.\\n\\n^ \"ASCAP, PRS and SACEM Join Forces for Blockchain Copyright System\". Music Business Worldwide. 9 April 2017. Archived from the original on 10 April 2017.\\n\\n^ Burchardi, K.; Harle, N. (20 January 2018). \"The blockchain will disrupt the music business and beyond\". Wired UK. Archived from the original on 8 May 2018. Retrieved 8 May 2018.\\n\\n^ Bartlett, Jamie (6 September 2015). \"Imogen Heap: saviour of the music industry?\". The Guardian. Archived from the original on 22 April 2016. Retrieved 18 June 2016.\\n\\n^ Wang, Kevin; Safavi, Ali (29 October 2016). \"Blockchain is empowering the future of insurance\". Tech Crunch. AOL Inc. Archived from the original on 7 November 2016. Retrieved 7 November 2016.\\n\\n^ Gatteschi, Valentina; Lamberti, Fabrizio; Demartini, Claudio; Pranteda, Chiara; Santamaría, Víctor (20 February 2018). \"Blockchain and Smart Contracts for Insurance: Is the Technology Mature Enough?\". Future Internet. 10 (2): 20. doi:10.3390/fi10020020.\\n\\n^ \"Blockchain reaction: Tech companies plan for critical mass\" (PDF). Ernst & Young. p.\\xa05. Archived (PDF) from the original on 14 November 2016. Retrieved 13 November 2016.\\n\\n^ Carrie Smith. Blockchain Reaction: How library professionals are approaching blockchain technology and its potential impact. Archived 12 September 2019 at the Wayback Machine American Libraries March 2019.\\n\\n^ \"IBM Blockchain based on Hyperledger Fabric from the Linux Foundation\". IBM.com. 9 January 2018. Archived from the original on 7 December 2017. Retrieved 18 January 2018.\\n\\n^ Hyperledger (22 January 2019). \"Announcing Hyperledger Grid, a new project to help build and deliver supply chain solutions!\". Archived from the original on 4 February 2019. Retrieved 8 March 2019.\\n\\n^ Mearian, Lucas (23 January 2019). \"Grid, a new project from the Linux Foundation, will offer developers tools to create supply chain-specific applications running atop distributed ledger technology\". Computerworld. Archived from the original on 3 February 2019. Retrieved 8 March 2019.\\n\\n^ \"Why J.P. Morgan Chase Is Building a Blockchain on Ethereum\". Fortune. Archived from the original on 2 February 2017. Retrieved 24 January 2017.\\n\\n^ Andoni, Merlinda; Robu, Valentin; Flynn, David; Abram, Simone; Geach, Dale; Jenkins, David; McCallum, Peter; Peacock, Andrew (2019). \"Blockchain technology in the energy sector: A systematic review of challenges and opportunities\". Renewable and Sustainable Energy Reviews. 100: 143–174. doi:10.1016/j.rser.2018.10.014. S2CID\\xa0116422191. Archived from the original on 22 June 2020. Retrieved 7 June 2020.\\n\\n^ \"This Blockchain-Based Energy Platform Is Building A Peer-To-Peer Grid\". 16 October 2017. Archived from the original on 7 June 2020. Retrieved 7 June 2020.\\n\\n^ \"Blockchain-based microgrid gives power to consumers in New York\". Archived from the original on 22 March 2016. Retrieved 7 June 2020.\\n\\n^ Ma, Jinhua; Lin, Shih-Ya; Chen, Xin; Sun, Hung-Min; Chen, Yeh-Cheng; Wang, Huaxiong (2020). \"A Blockchain-Based Application System for Product Anti-Counterfeiting\". IEEE Access. 8: 77642–77652. doi:10.1109/ACCESS.2020.2972026. ISSN\\xa02169-3536. S2CID\\xa0214205788.\\n\\n^ Alzahrani, Naif; Bulusu, Nirupama (15 June 2018). \"Block-Supply Chain: A New Anti-Counterfeiting Supply Chain Using NFC and Blockchain\". Proceedings of the 1st Workshop on Cryptocurrencies and Blockchains for Distributed Systems. CryBlock\\'18. Munich, Germany: Association for Computing Machinery: 30–35. doi:10.1145/3211933.3211939. ISBN\\xa0978-1-4503-5838-5. S2CID\\xa0169188795.\\n\\n^ Balagurusamy, V. S. K.; Cabral, C.; Coomaraswamy, S.; Delamarche, E.; Dillenberger, D. N.; Dittmann, G.; Friedman, D.; Gökçe, O.; Hinds, N.; Jelitto, J.; Kind, A. (1 March 2019). \"Crypto anchors\". IBM Journal of Research and Development. 63 (2/3): 4:1–4:12. doi:10.1147/JRD.2019.2900651. ISSN\\xa00018-8646. S2CID\\xa0201109790.\\n\\n^ Brett, Charles (18 April 2018). \"EUIPO Blockathon Challenge 2018 -\". Enterprise Times. Retrieved 1 September 2020.\\n\\n^ \"EUIPO Anti-Counterfeiting Blockathon Forum\".\\n\\n^ \"PT Industrieel Management\". PT Industrieel Management. Retrieved 1 September 2020.\\n\\n^ Wegner, Peter (March 1996). \"Interoperability\". ACM Computing Surveys. 28: 285–287. doi:10.1145/234313.234424. Retrieved 24 October 2020.\\n\\n^ Belchior, Rafael; Vasconcelos, André; Guerreiro, Sérgio; Correia, Miguel (May 2020). \"A Survey on Blockchain Interoperability: Past, Present, and Future Trends\". arXiv:2005.14282 [cs.DC].\\n\\n^ Hardjono, T.; Hargreaves, M.; Smith, N. (2 October 2020). An Interoperability Architecture for Blockchain Gateways (Technical report). IETF. draft-hardjono-blockchain-interop-arch-00.\\n\\n^ Hyun Song Shin (June 2018). \"Chapter V. Cryptocurrencies: looking beyond the hype\" (PDF). BIS 2018 Annual Economic Report. Bank for International Settlements. Archived (PDF) from the original on 18 June 2018. Retrieved 19 June 2018. Put in the simplest terms, the quest for decentralised trust has quickly become an environmental disaster.\\n\\n^ Janda, Michael (18 June 2018). \"Cryptocurrencies like bitcoin cannot replace money, says Bank for International Settlements\". ABC (Australia). Archived from the original on 18 June 2018. Retrieved 18 June 2018.\\n\\n^ Hiltzik, Michael (18 June 2018). \"Is this scathing report the death knell for bitcoin?\". Los Angeles Times. Archived from the original on 18 June 2018. Retrieved 19 June 2018.\\n\\n^ Criddle, Christina (February 20, 2021) \"Bitcoin consumes \\'more electricity than Argentina\\'.\" BBC News. (Retrieved April 26, 2021.)\\n\\n^ Ponciano, Jonathan (March 9, 2021) \"Bill Gates Sounds Alarm On Bitcoin\\'s Energy Consumption–Here\\'s Why Crypto Is Bad For Climate Change.\" Forbes.com. (Retrieved April 26, 2021.)\\n\\n^ Rowlatt, Justin (February 27, 2021) \"How Bitcoin\\'s vast energy use could burst its bubble.\" BBC News. (Retrieved April 26, 2021.)\\n\\n^ Sorkin, Andrew et al. (March 9, 2021) \"Why Bill Gates Is Worried About Bitcoin.\" New York Times. (Retrieved April 25, 2021.)\\n\\n^ Illing, Sean (11 April 2018). \"Why Bitcoin is bullshit, explained by an expert\". Vox. Archived from the original on 17 July 2018. Retrieved 17 July 2018.\\n\\n^ Weaver, Nicholas. \"Blockchains and Cryptocurrencies: Burn It With Fire\". YouTube video. Berkeley School of Information. Archived from the original on 19 February 2019. Retrieved 17 July 2018.\\n\\n^ Köhler, Susanne; Pizzol, Massimo (20 November 2019). \"Life Cycle Assessment of Bitcoin Mining\". Environmental Science & Technology. 53 (23): 13598–13606. Bibcode:2019EnST...5313598K. doi:10.1021/acs.est.9b05687. PMID\\xa031746188.\\n\\n^ Stoll, Christian; Klaaßen, Lena; Gallersdörfer, Ulrich (2019). \"The Carbon Footprint of Bitcoin\". Joule. 3 (7): 1647–1661. doi:10.1016/j.joule.2019.05.012.\\n\\n^ Business Standard (2022) “US lawmakers begin probe into Bitcoin miners\\' high energy use”, 29 January. https://www.business-standard.com/article/international/us-lawmakers-begin-probe-into-bitcoin-miners-high-energy-use-122012900282_1.html#:~:text=Eight%20US%20lawmakers%20have%20come,being%20felt%20across%20the%20globe.\\n\\n^ Cuen, Leigh (March 21, 2021) \"The debate about cryptocurrency and data consumption.\" TechCrunch. (Retrieved April 26, 2021.)\\n\\n^ Joanna Ossinger (2022) \"Polkadot Has Least Carbon Footprint, Crypto Researcher Says\", 2 February. Bloomberg. https://www.bloomberg.com/news/articles/2022-02-02/polkadot-has-smallest-carbon-footprint-crypto-researcher-says\\n\\n^ Jonathan Spencer Jones (2021) \"Proof-of-stake blockchains – not all are equal\", 13 September. Smart Energy International. https://www.smart-energy.com/industry-sectors/new-technology/proof-of-stake-blockchains-not-all-are-equal/\\n\\n^ Catalini, Christian; Tucker, Catherine E. (11 August 2016). \"Seeding the S-Curve? The Role of Early Adopters in Diffusion\" (PDF). SSRN. doi:10.2139/ssrn.2822729. S2CID\\xa0157317501. SSRN\\xa02822729.\\n\\n^ Arnold, M. (2017) “Universities add blockchain to course list”, Financial Times: Masters in Finance, https://www.ft.com/content/f736b04e-3708-11e7-99bd-13beb0903fa3 Retrieved 26 January 2022.\\n\\n^ Janssen, Marijn; Weerakkody, Vishanth; Ismagilova, Elvira; Sivarajah, Uthayasankar; Irani, Zahir (2020). \"A framework for analysing blockchain technology adoption: Integrating institutional, market and technical factors\". International Journal of Information Management. Elsevier. 50: 302–309. doi:10.1016/j.ijinfomgt.2019.08.012.\\n\\n^ Koens, Tommy; Poll, Erik (2019), \"The Drivers Behind Blockchain Adoption: The Rationality of Irrational Choices\", Euro-Par 2018: Parallel Processing Workshops, Lecture Notes in Computer Science, vol.\\xa011339, pp.\\xa0535–546, doi:10.1007/978-3-030-10549-5_42, ISBN\\xa0978-3-030-10548-8, S2CID\\xa057662305\\n\\n^ Li, Jerry (2020), \"Blockchain technology adoption: Examining the Fundamental Drivers\", Proceedings of the 2nd International Conference on Management Science and Industrial Engineering, ACM Publication, April 2020, pp. 253–260. https://dl.acm.org/doi/abs/10.1145/3396743.3396750 Archived 5 June 2020 at the Wayback Machine\\n\\n^ Hsieh, Ying-Ying; Vergne, Jean-Philippe; Anderson, Philip; Lakhani, Karim; Reitzig, Markus (12 February 2019). \"Correction to: Bitcoin and the rise of decentralized autonomous organizations\". Journal of Organization Design. 8 (1): 3. doi:10.1186/s41469-019-0041-1. ISSN\\xa02245-408X.\\n\\n^ Felin, Teppo; Lakhani, Karim (2018). \"What Problems Will You Solve With Blockchain?\". MIT Sloan Management Review.\\n\\n^ Beck, Roman; Mueller-Bloch, Christoph; King, John Leslie (2018). \"Governance in the Blockchain Economy: A Framework and Research Agenda\". Journal of the Association for Information Systems: 1020–1034. doi:10.17705/1jais.00518.\\n\\n^ Popper, Nathaniel (27 June 2018). \"What is the Blockchain? Explaining the Tech Behind Cryptocurrencies (Published 2018)\". The New York Times.\\n\\n^ Hugh Rooney, Brian Aiken, & Megan Rooney. (2017). Q&A. Is Internal Audit Ready for Blockchain? Technology Innovation Management Review, (10), 41.\\n\\n^ Richard C. Kloch, Jr Simon J. Little, Blockchain and Internal Audit Internal Audit Foundation, 2019 ISBN\\xa0978-1-63454-065-0\\n\\n^ Alexander, A. (2019). The audit, transformed: New advancements in technology are reshaping this core service. Accounting Today, 33(1)\\n\\n^ Extance, Andy (30 September 2015). \"The future of cryptocurrencies: Bitcoin and beyond\". Nature. 526 (7571): 21–23. Bibcode:2015Natur.526...21E. doi:10.1038/526021a. ISSN\\xa00028-0836. OCLC\\xa0421716612. PMID\\xa026432223.\\n\\n^ Ledger (eJournal / eMagazine, 2015). OCLC. OCLC\\xa0910895894.\\n\\n^ Hertig, Alyssa (15 September 2015). \"Introducing Ledger, the First Bitcoin-Only Academic Journal\". Motherboard. Archived from the original on 10 January 2017. Retrieved 10 January 2017.\\n\\n^ Rizun, Peter R.; Wilmer, Christopher E.; Burley, Richard Ford; Miller, Andrew (2015). \"How to Write and Format an Article for Ledger\" (PDF). Ledger. 1 (1): 1–12. doi:10.5195/LEDGER.2015.1 (inactive 28 February 2022). ISSN\\xa02379-5980. OCLC\\xa0910895894. Archived (PDF) from the original on 22 September 2015. Retrieved 11 January 2017.{{cite journal}}:  CS1 maint: DOI inactive as of February 2022 (link) \\n\\n\\nFurther reading\\nCrosby, Michael; Nachiappan; Pattanayak, Pradhan; Verma, Sanjeev; Kalyanaraman, Vignesh (16 October 2015). BlockChain Technology: Beyond Bitcoin (PDF) (Report). Sutardja Center for Entrepreneurship & Technology Technical Report. University of California, Berkeley. Retrieved 19 March 2017.\\nJaikaran, Chris (28 February 2018). Blockchain: Background and Policy Issues. Washington, DC: Congressional Research Service. Retrieved 2 December 2018.\\nKakavand, Hossein; De Sevres, Nicolette Kost; Chilton, Bart (12 October 2016). The Blockchain Revolution: An Analysis of Regulation and Technology Related to Distributed Ledger Technologies (Report). Luther Systems & DLA Piper. SSRN\\xa02849251.\\nMazonka, Oleg (29 December 2016). \"Blockchain: Simple Explanation\" (PDF). Journal of Reference.\\nTapscott, Don; Tapscott, Alex (2016). Blockchain Revolution: How the Technology Behind Bitcoin Is Changing Money, Business and the World. London: Portfolio Penguin. ISBN\\xa0978-0-241-23785-4. OCLC\\xa0971395169.\\nSaito, Kenji; Yamada, Hiroyuki (June 2016). What\\'s So Different about Blockchain? Blockchain is a Probabilistic State Machine. IEEE 36th International Conference on Distributed Computing Systems Workshops. International Conference on Distributed Computing Systems Workshops (Icdcs). Nara, Nara, Japan: IEEE. pp.\\xa0168–75. doi:10.1109/ICDCSW.2016.28. ISBN\\xa0978-1-5090-3686-8. ISSN\\xa02332-5666.\\nRaval, Siraj (2016). Decentralized Applications: Harnessing Bitcoin\\'s Blockchain Technology. Oreilly. ISBN\\xa09781491924549.\\nBashir, Imran (2017). Mastering Blockchain. Packt Publishing, Ltd. ISBN\\xa0978-1-78712-544-5. OCLC\\xa0967373845.\\nKnirsch, Fabian; Unterweger, Andread; Engel, Dominik (2019). \"Implementing a blockchain from scratch: why, how, and what we learned\". EURASIP Journal on Information Security. 2019. doi:10.1186/s13635-019-0085-3. S2CID\\xa084837476.\\nD. Puthal, N. Malik, S. P. Mohanty, E. Kougianos, and G. Das, \"Everything you Wanted to Know about the Blockchain\", IEEE Consumer Electronics Magazine, Volume 7, Issue 4, July 2018, pp.\\xa006–14.\\nDavid L. Portilla, David J. Kappos, Minh Van Ngo, Sasha Rosenthal-Larrea, John D. Buretta and Christopher K. Fargo, Cravath, Swaine & Moore LLP, \"Blockchain in the Banking Sector: A Review of the Landscape and Opportunities\" , Harvard Law School of Corporate Governance, posted on Friday, January 28, 2022\\nExternal links\\n\\n\\n\\nWikiversity has learning resources about Blockchain\\n\\n Media related to Blockchain at Wikimedia Commons\\nAuthority control National libraries\\nFrance (data)\\nIsrael\\nUnited States\\nOther\\nFaceted Application of Subject Terminology\\n\\nvteCryptocurrenciesTechnology\\nBlockchain\\nCryptocurrency tumbler\\nCryptocurrency wallet\\nCryptographic hash function\\nDecentralized exchange\\nDecentralized finance\\nDistributed ledger\\nFork\\nLightning Network\\nMetaMask\\nNon-fungible token\\nSmart contract\\nWeb3\\nConsensus mechanisms\\nProof of authority\\nProof of personhood\\nProof of space\\nProof of stake\\nProof of work\\nProof of work currenciesSHA-256-based\\nBitcoin\\nBitcoin Cash\\nCounterparty\\nLBRY\\nMazaCoin\\nNamecoin\\nPeercoin\\nTitcoin\\nEthash-based\\nEthereum\\nEthereum Classic\\nScrypt-based\\nAuroracoin\\nBitconnect\\nCoinye\\nDogecoin\\nLitecoin\\nEquihash-based\\nBitcoin Gold\\nZcash\\nRandomX-based\\nMonero\\nX11-based\\nDash\\nPetro\\nOther\\nAmbaCoin\\nFiro\\nIOTA\\nPrimecoin\\nVerge\\nVertcoin\\nProof of stake currencies\\nAlgorand\\nAvalanche\\nCardano\\nEOS.IO\\nGridcoin\\nKin\\nNxt\\nPeercoin\\nPolkadot\\nSolana\\nSteem/HIVE\\nTezos\\nTRON\\nERC-20 tokens\\nAugur\\nAventus\\nBancor\\nBasic Attention Token\\nChainlink\\nKin\\nKodakCoin\\nMinds\\nShiba Inu\\nThe DAO\\nTRON\\nStablecoins\\nDai\\nDiem\\nTether\\nUSD Coin\\nOther currencies\\nChia\\nFilecoin\\nHBAR (Hashgraph)\\nMobileCoin\\nNano\\nNEO\\nRipple\\nSafeMoon\\nSafuu\\nStellar\\nWhopperCoin\\nCryptocurrency exchanges\\nAbra\\nBinance\\nBitfinex\\nbitFlyer\\nBitkub\\nBitpanda\\nBithumb\\nBitMEX\\nBitso\\nBitstamp\\nBitrue\\nBTCC\\nBUX\\nCircle\\nCoinbase\\nCoincheck\\nCrypto.com\\neToro\\nFTX\\nGemini\\nHuobi\\nItBit (Paxos)\\nKraken\\nLocalBitcoins\\nNewton\\nOKEx\\nShapeShift\\nUniswap\\nUpbit\\nZaif (Tech Bureau)\\nDefunct\\nBTC-e\\nMt. Gox\\nQuadrigaCX\\n\\nRelated topics\\nAirdrop\\nBitLicense\\nBlockchain game\\nComplementary currency\\nCrypto-anarchism\\nCryptocurrency bubble\\nCryptocurrency scams\\nDigital currency\\nDecentralized autonomous organization\\nDecentralized application\\nDistributed ledger technology law\\nDouble-spending\\nEnvironmental impact\\nHyperledger\\nInitial coin offering\\nInitial exchange offering\\nInitiative Q\\nList of cryptocurrencies\\nToken money\\nVirtual currency\\n\\n Category\\n Commons\\n List\\n\\nvteBitcoin\\nHistory\\nEconomics\\nLegal status\\nPeople\\nGavin Andresen\\nAndreas Antonopoulos\\nBrian Armstrong\\nAdam Back\\nWences Casares\\nTim Draper\\nHal Finney\\nMark Karpelès\\nSatoshi Nakamoto\\nCharlie Shrem\\nNick Szabo\\nAmir Taaki\\nRoss Ulbricht\\nRoger Ver\\nCody Wilson\\nCameron Winklevoss\\nTyler Winklevoss\\nCraig Wright\\nJihan Wu\\nLists\\nList of bitcoin companies\\nList of bitcoin forks\\nList of bitcoin organizations\\nList of people in blockchain technology\\nTechnologies\\nBitcoin network\\nBlockchain\\nCryptocurrency\\nCryptocurrency wallet\\nBitcoin ATM\\nECDSA\\nLightning Network\\nP2P\\nProof of work\\nSegWit\\nSHA-2\\nForksClient\\nBitcoin Unlimited\\nCurrency\\nBitcoin Cash\\nBitcoin Gold\\nHistory\\nBitcoin scalability problem\\nHistory of bitcoin\\n2018 cryptocurrency crash\\n2018 Bitcoin bomb threats\\n2020 Twitter account hijacking\\nMovies\\nThe Rise and Rise of Bitcoin (2014 film)\\nDeep Web (2015 film)\\nLegal entities(not exchanges)\\nBitcoin Foundation\\nBitcoin Magazine\\nBitGo\\nBitmain\\nBitwala\\nCanaan Creative\\nCoinDesk\\nGhash.io\\nLegal status and politics\\nBitcoin Law\\nAnti-bitcoin law protests\\n\\n Category\\n Commons\\n Money Portal\\n\\nvteDatabase management systemsTypes\\nObject-oriented\\ncomparison\\nRelational\\nlist\\ncomparison\\nKey–value\\nColumn-oriented\\nlist\\nDocument-oriented\\nWide-column store\\nGraph\\nNoSQL\\nNewSQL\\nIn-memory\\nlist\\nMulti-model\\ncomparison\\nCloud\\nConcepts\\nDatabase\\nACID\\nArmstrong\\'s axioms\\nCodd\\'s 12 rules\\nCAP theorem\\nCRUD\\nNull\\nCandidate key\\nForeign key\\nSuperkey\\nSurrogate key\\nUnique key\\nObjects\\nRelation\\ntable\\ncolumn\\nrow\\nView\\nTransaction\\nTransaction log\\nTrigger\\nIndex\\nStored procedure\\nCursor\\nPartition\\nComponents\\nConcurrency control\\nData dictionary\\nJDBC\\nXQJ\\nODBC\\nQuery language\\nQuery optimizer\\nQuery rewriting system\\nQuery plan\\nFunctions\\nAdministration\\nQuery optimization\\nReplication\\nSharding\\nRelated topics\\nDatabase models\\nDatabase normalization\\nDatabase storage\\nDistributed database\\nFederated database system\\nReferential integrity\\nRelational algebra\\nRelational calculus\\nRelational model\\nObject–relational database\\nTransaction processing\\n\\n Category\\n Outline\\n WikiProject\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Blockchain&oldid=1084175210\"',\n",
       "  'Not to be confused with Web of Things.\\nInternet-like structure connecting everyday physical objects\\n\\nThe Internet of things (IoT) describes physical objects (or groups of such objects)  with sensors, processing ability, software, and other technologies that connect and exchange data with other devices and systems over the Internet or other communications networks.[1][2][3][4] Internet of things has been considered a misnomer because devices do not need to be connected to the public internet, they only need to be connected to a network and be individually addressable.[5][6]\\nThe field has evolved due to the convergence of multiple technologies, including ubiquitous computing, commodity sensors, increasingly powerful embedded systems, and machine learning.[7]  Traditional fields of embedded systems, wireless sensor networks, control systems, automation (including home and building automation), independently and collectively enable the Internet of things.[8]  In the consumer market, IoT technology is most synonymous with products pertaining to the concept of the \"smart home\", including devices and appliances (such as lighting fixtures, thermostats, home security systems, cameras, and other home appliances) that support one or more common ecosystems, and can be controlled via devices associated with that ecosystem, such as smartphones and smart speakers. IoT is also used in healthcare systems.[9]\\nThere are a number of concerns about the risks in the growth of IoT technologies and products, especially in the areas of privacy and security, and consequently, industry and governmental moves to address these concerns have begun, including the development of international and local standards, guidelines, and regulatory frameworks.[10]\\n\\nContents\\n\\n1 History\\n2 Applications\\n\\n2.1 Consumer applications\\n\\n2.1.1 Smart home\\n2.1.2 Elder care\\n\\n\\n2.2 Organizational applications\\n\\n2.2.1 Medical and healthcare\\n2.2.2 Transportation\\n2.2.3 V2X communications\\n2.2.4 Building and home automation\\n\\n\\n2.3 Industrial applications\\n\\n2.3.1 Manufacturing\\n2.3.2 Agriculture\\n2.3.3 Maritime\\n\\n\\n2.4 Infrastructure applications\\n\\n2.4.1 Metropolitan scale deployments\\n2.4.2 Energy management\\n2.4.3 Environmental monitoring\\n\\n\\n2.5 Military applications\\n\\n2.5.1 Internet of Battlefield Things\\n2.5.2 Ocean of Things\\n\\n\\n2.6 Product digitalization\\n\\n\\n3 Trends and characteristics\\n\\n3.1 Intelligence\\n3.2 Architecture\\n\\n3.2.1 Network architecture\\n\\n3.2.1.1 Decentralized IoT\\n\\n\\n\\n\\n3.3 Complexity\\n3.4 Size considerations\\n3.5 Space considerations\\n3.6 A solution to \"basket of remotes\"\\n3.7 Social Internet of things\\n\\n3.7.1 Social Network for IoT Devices (Not Human)\\n3.7.2 How SIoT different from IoT?\\n3.7.3 How SIoT Works?\\n3.7.4 Social IoT Examples\\n3.7.5 Social IoT Challenges\\n\\n\\n\\n\\n4 Enabling technologies for IoT\\n\\n4.1 Addressability\\n4.2 Application Layer\\n4.3 Short-range wireless\\n4.4 Medium-range wireless\\n4.5 Long-range wireless\\n4.6 Wired\\n4.7 Standards and standards organizations\\n\\n\\n5 Politics and civic engagement\\n6 Government regulation on IoT\\n7 Criticism, problems and controversies\\n\\n7.1 Platform fragmentation\\n7.2 Privacy, autonomy, and control\\n7.3 Data storage\\n7.4 Security\\n7.5 Safety\\n7.6 Design\\n7.7 Environmental sustainability impact\\n7.8 Intentional obsolescence of devices\\n7.9 Confusing terminology\\n\\n\\n8 IoT adoption barriers\\n\\n8.1 Lack of interoperability and unclear value propositions\\n8.2 Privacy and security concerns\\n8.3 Traditional governance structure\\n8.4 Business planning and project management\\n\\n\\n9 See also\\n10 References\\n11 Bibliography\\n\\n\\nHistory[edit]\\nThe main concept of a network of smart devices was discussed as early as 1982, with a modified Coca-Cola vending machine at Carnegie Mellon University becoming the first ARPANET-connected appliance,[11] able to report its inventory and whether newly loaded drinks were cold or not.[12] Mark Weiser\\'s 1991 paper on ubiquitous computing, \"The Computer of the 21st Century\", as well as academic venues such as UbiComp and PerCom produced the contemporary vision of the IOT.[13][14] In 1994, Reza Raji described the concept in IEEE Spectrum as \"[moving] small packets of data to a large set of nodes, so as to integrate and automate everything from home appliances to entire factories\".[15] Between 1993 and 1997, several companies proposed solutions like Microsoft\\'s at Work or Novell\\'s NEST. The field gained momentum when Bill Joy envisioned device-to-device communication as a part of his \"Six Webs\" framework, presented at the World Economic Forum at Davos in 1999.[16]\\nThe concept of the \"Internet of things\" and the term itself, first appeared in a speech by Peter T. Lewis, to the Congressional Black Caucus Foundation 15th Annual Legislative Weekend in Washington, D.C, published in September 1985.[17] According to Lewis, \"The Internet of Things, or IoT, is the integration of people, processes and technology with connectable devices and sensors to enable remote monitoring, status, manipulation and evaluation of trends of such devices.\"\\nThe term \"Internet of things\" was coined independently by Kevin Ashton of Procter & Gamble, later MIT\\'s Auto-ID Center, in 1999,[18] though he prefers the phrase \"Internet for things\".[19] At that point, he viewed radio-frequency identification (RFID) as essential to the Internet of things,[20] which would allow computers to manage all individual things.[21][22][23] The main theme of the Internet of things is to embed short-range mobile transceivers in various gadgets and daily necessities to enable new forms of communication between people and things, and between things themselves.[24]\\nDefining the Internet of things as \"simply the point in time when more \\'things or objects\\' were connected to the Internet than people\", Cisco Systems estimated that the IoT was \"born\" between 2008 and 2009, with the things/people ratio growing from 0.08 in 2003 to 1.84 in 2010.[25]\\n\\nApplications[edit]\\nThe extensive set of applications for IoT devices[26] is often divided into consumer, commercial, industrial, and infrastructure spaces.[27][28]\\n\\nConsumer applications[edit]\\nA growing portion of IoT devices are created for consumer use, including connected vehicles, home automation, wearable technology, connected health, and appliances with remote monitoring capabilities.[29]\\n\\nSmart home[edit]\\nIoT devices are a part of the larger concept of home automation, which can include lighting, heating and air conditioning, media and security systems and camera systems.[30][31] Long-term benefits could include energy savings by automatically ensuring lights and electronics are turned off or by making the residents in the home aware of usage.[32]\\n\\n A smart toilet seat that measures blood pressure, weight, pulse and oxygen levels.\\nA smart home or automated home could be based on a platform or hubs that control smart devices and appliances.[33] For instance, using Apple\\'s HomeKit, manufacturers can have their home products and accessories controlled by an application in iOS devices such as the iPhone and the Apple Watch.[34][35] This could be a dedicated app or iOS native applications such as Siri.[36] This can be demonstrated in the case of Lenovo\\'s Smart Home Essentials, which is a line of smart home devices that are controlled through Apple\\'s Home app or Siri without the need for a Wi-Fi bridge.[36] There are also dedicated smart home hubs that are offered as standalone platforms to connect different smart home products and these include the Amazon Echo, Google Home, Apple\\'s HomePod, and Samsung\\'s SmartThings Hub.[37] In addition to the commercial systems, there are many non-proprietary, open source ecosystems; including Home Assistant, OpenHAB and Domoticz.[38][39]\\n\\nElder care[edit]\\nOne key application of a smart home is to provide assistance to elderly individuals and to those with disabilities. These home systems use assistive technology to accommodate an owner\\'s specific disabilities.[40] Voice control can assist users with sight and mobility limitations while alert systems can be connected directly to cochlear implants worn by hearing-impaired users.[41] They can also be equipped with additional safety features. These features can include sensors that monitor for medical emergencies such as falls or seizures.[42] Smart home technology applied in this way can provide users with more freedom and a higher quality of life.[40]\\nThe term \"Enterprise IoT\" refers to devices used in business and corporate settings. By 2019, it is estimated that the EIoT will account for 9.1 billion devices.[27]\\n\\nOrganizational applications[edit]\\nMedical and healthcare[edit]\\nThe Internet of Medical Things (IoMT) is an application of the IoT for medical and health related purposes, data collection and analysis for research, and monitoring.[43][44][45][46][47] The IoMT has been referenced as \"Smart Healthcare\",[48] as the technology for creating a digitized healthcare system, connecting available medical resources and healthcare services.[49][50]\\nIoT devices can be used to enable remote health monitoring and emergency notification systems. These health monitoring devices can range from blood pressure and heart rate monitors to advanced devices capable of monitoring specialized implants, such as pacemakers, Fitbit electronic wristbands, or advanced hearing aids.[51] Some hospitals have begun implementing \"smart beds\" that can detect when they are occupied and when a patient is attempting to get up. It can also adjust itself to ensure appropriate pressure and support is applied to the patient without the manual interaction of nurses.[43] A 2015 Goldman Sachs report indicated that healthcare IoT devices \"can save the United States more than $300 billion in annual healthcare expenditures by increasing revenue and decreasing cost.\"[52] Moreover, the use of mobile devices to support medical follow-up led to the creation of \\'m-health\\', used analyzed health statistics.\"[53]\\nSpecialized sensors can also be equipped within living spaces to monitor the health and general well-being of senior citizens, while also ensuring that proper treatment is being administered and assisting people to regain lost mobility via therapy as well.[54] These sensors create a network of intelligent sensors that are able to collect, process, transfer, and analyze valuable information in different environments, such as connecting in-home monitoring devices to hospital-based systems.[48] Other consumer devices to encourage healthy living, such as connected scales or wearable heart monitors, are also a possibility with the IoT.[55] End-to-end health monitoring IoT platforms are also available for antenatal and chronic patients, helping one manage health vitals and recurring medication requirements.[56]\\nAdvances in plastic and fabric electronics fabrication methods have enabled ultra-low cost, use-and-throw\\xa0IoMT sensors. These sensors, along with the required RFID electronics, can be fabricated on paper or e-textiles for wireless powered disposable sensing devices.[57] Applications have been established for point-of-care medical diagnostics, where portability and low system-complexity is essential.[58]\\nAs of 2018[update] IoMT was not only being applied in the clinical laboratory industry,[45] but also in the healthcare and health insurance industries. IoMT in the healthcare industry is now permitting doctors, patients, and others, such as guardians of patients, nurses, families, and similar, to be part of a system, where patient records are saved in a database, allowing doctors and the rest of the medical staff to have access to patient information.[59] Moreover, IoT-based systems are patient-centered, which involves being flexible to the patient\\'s medical conditions.[citation needed] IoMT in the insurance industry provides access to better and new types of dynamic information. This includes sensor-based solutions such as biosensors, wearables, connected health devices, and mobile apps to track customer behavior. This can lead to more accurate underwriting and new pricing models.[60]\\nThe application of the IoT in healthcare plays a fundamental role in managing chronic diseases and in disease prevention and control. Remote monitoring is made possible through the connection of powerful wireless solutions. The connectivity enables health practitioners to capture patient\\'s data and applying complex algorithms in health data analysis.[61]\\n\\nTransportation[edit]\\n Digital variable speed-limit sign\\nThe IoT can assist in the integration of communications, control, and information processing across various transportation systems. Application of the IoT extends to all aspects of transportation systems (i.e. the vehicle,[62] the infrastructure, and the driver or user). Dynamic interaction between these components of a transport system enables inter- and intra-vehicular communication,[63] smart traffic control, smart parking, electronic toll collection systems, logistics and fleet management, vehicle control, safety, and road assistance.[51][64]\\n\\nV2X communications[edit]\\nMain article: V2X\\nIn vehicular communication systems, vehicle-to-everything communication (V2X), consists of three main components: vehicle to vehicle communication (V2V), vehicle to infrastructure communication (V2I) and vehicle to pedestrian communications (V2P). V2X is the first step to autonomous driving and connected road infrastructure.[citation needed]\\n\\nBuilding and home automation[edit]\\nIoT devices can be used to monitor and control the mechanical, electrical and electronic systems used in various types of buildings (e.g., public and private, industrial, institutions, or residential)[51] in home automation and building automation systems. In this context, three main areas are being covered in literature:[65]\\n\\nThe integration of the Internet with building energy management systems in order to create energy-efficient and IOT-driven \"smart buildings\".[65]\\nThe possible means of real-time monitoring for reducing energy consumption[32] and monitoring occupant behaviors.[65]\\nThe integration of smart devices in the built environment and how they might be used in future applications.[65]\\nIndustrial applications[edit]\\nMain article: Industrial internet of things\\nAlso known as IIoT, industrial IoT devices acquire and analyze data from connected equipment, operational technology (OT), locations, and people. Combined with operational technology (OT) monitoring devices, IIoT helps regulate and monitor industrial systems. Also, the same implementation can be carried out for automated record updates of asset placement in industrial storage units as the size of the assets can vary from a small screw to the whole motor spare part, and misplacement of such assets can cause a loss of manpower time and money.\\n\\nManufacturing[edit]\\nThe IoT can connect various manufacturing devices equipped with sensing, identification, processing, communication, actuation, and networking capabilities.[66] Network control and management of manufacturing equipment, asset and situation management, or manufacturing process control allow IoT to be used for industrial applications and smart manufacturing.[67] IoT intelligent systems enable rapid manufacturing and optimization of new products, and rapid response to product demands.[51]\\nDigital control systems to automate process controls, operator tools and service information systems to optimize plant safety and security are within the purview of the IIoT.[68] IoT can also be applied to asset management via predictive maintenance, statistical evaluation, and measurements to maximize reliability.[69] Industrial management systems can be integrated with smart grids, enabling energy optimization. Measurements, automated controls, plant optimization, health and safety management, and other functions are provided by networked sensors.[51]\\nIn addition to general manufacturing, IoT is also used for processes in the industrialization of construction.[70]\\n\\nAgriculture[edit]\\nThere are numerous IoT applications in farming[71] such as collecting data on temperature, rainfall, humidity, wind speed, pest infestation, and soil content. This data can be used to automate farming techniques, take informed decisions to improve quality and quantity, minimize risk and waste, and reduce the effort required to manage crops. For example, farmers can now monitor soil temperature and moisture from afar, and even apply IoT-acquired data to precision fertilization programs.[72] The overall goal is that data from sensors, coupled with the farmer\\'s knowledge and intuition about his or her farm, can help increase farm productivity, and also help reduce costs.\\nIn August 2018, Toyota Tsusho began a partnership with Microsoft to create fish farming tools using the Microsoft Azure application suite for IoT technologies related to water management. Developed in part by researchers from Kindai University, the water pump mechanisms use artificial intelligence to count the number of fish on a conveyor belt, analyze the number of fish, and deduce the effectiveness of water flow from the data the fish provide.[73] The FarmBeats project[74] from Microsoft Research that uses TV white space to connect farms is also a part of the Azure Marketplace now.[75]\\n\\nMaritime[edit]\\nIoT devices are in use monitoring the environments and systems of boats and yachts.[76] Many pleasure boats are left unattended for days in summer, and months in winter so such devices provide valuable early alerts of boat flooding, fire, and deep discharge of batteries. The use of global internet data networks such as Sigfox, combined with long-life batteries, and microelectronics allows the engine rooms, bilge, and batteries to be constantly monitored and reported to a connected Android & Apple applications for example.\\n\\nInfrastructure applications[edit]\\nMonitoring and controlling operations of sustainable urban and rural infrastructures like bridges, railway tracks and on- and offshore wind-farms is a key application of the IoT.[68] The IoT infrastructure can be used for monitoring any events or changes in structural conditions that can compromise safety and increase risk. The IoT can benefit the construction industry by cost-saving, time reduction, better quality workday, paperless workflow and increase in productivity. It can help in taking faster decisions and save money with Real-Time Data Analytics. It can also be used for scheduling repair and maintenance activities in an efficient manner, by coordinating tasks between different service providers and users of these facilities.[51] IoT devices can also be used to control critical infrastructure like bridges to provide access to ships. Usage of IoT devices for monitoring and operating infrastructure is likely to improve incident management and emergency response coordination, and quality of service, up-times and reduce costs of operation in all infrastructure related areas.[77] Even areas such as waste management can benefit[78] from automation and optimization that could be brought in by the IoT.[citation needed]\\n\\nMetropolitan scale deployments[edit]\\nThere are several planned or ongoing large-scale deployments of the IoT, to enable better management of cities and systems. For example, Songdo, South Korea, the first of its kind fully equipped and wired smart city, is gradually being built, with approximately 70 percent of the business district completed as of June\\xa02018[update]. Much of the city is planned to be wired and automated, with little or no human intervention.[79]\\nAnother application is currently undergoing a project in Santander, Spain. For this deployment, two approaches have been adopted. This city of 180,000 inhabitants has already seen 18,000 downloads of its city smartphone app. The app is connected to 10,000 sensors that enable services like parking search, environmental monitoring, digital city agenda, and more. City context information is used in this deployment so as to benefit merchants through a spark deals mechanism based on city behavior that aims at maximizing the impact of each notification.[80]\\nOther examples of large-scale deployments underway include the Sino-Singapore Guangzhou Knowledge City;[81] work on improving air and water quality, reducing noise pollution, and increasing transportation efficiency in San Jose, California;[82] and smart traffic management in western Singapore.[83] Using its RPMA (Random Phase Multiple Access) technology, San Diego-based Ingenu has built a nationwide public network[84] for low-bandwidth data transmissions using the same unlicensed 2.4 gigahertz spectrum as Wi-Fi. Ingenu\\'s \"Machine Network\" covers more than a third of the US population across 35 major cities including San Diego and Dallas.[85] French company, Sigfox, commenced building an Ultra Narrowband wireless data network in the San Francisco Bay Area in 2014, the first business to achieve such a deployment in the U.S.[86][87] It subsequently announced it would set up a total of 4000 base stations to cover a total of 30 cities in the U.S. by the end of 2016, making it the largest IoT network coverage provider in the country thus far.[88][89] Cisco also participates in smart cities projects. Cisco has started deploying technologies for Smart Wi-Fi, Smart Safety & Security, Smart Lighting, Smart Parking, Smart Transports, Smart Bus Stops, Smart Kiosks, Remote Expert for Government Services (REGS) and Smart Education in the five km area in the city of Vijaywada, India.[90]\\nAnother example of a large deployment is the one completed by New York Waterways in New York City to connect all the city\\'s vessels and be able to monitor them live 24/7. The network was designed and engineered by Fluidmesh Networks, a Chicago-based company developing wireless networks for critical applications. The NYWW network is currently providing coverage on the Hudson River, East River, and Upper New York Bay. With the wireless network in place, NY Waterway is able to take control of its fleet and passengers in a way that was not previously possible. New applications can include security, energy and fleet management, digital signage, public Wi-Fi, paperless ticketing and others.[91]\\n\\nEnergy management[edit]\\nSignificant numbers of energy-consuming devices (e.g. lamps, household appliances, motors, pumps, etc.) already integrate Internet connectivity, which can allow them to communicate with utilities not only to balance power generation but also helps optimize the energy consumption as a whole.[51] These devices allow for remote control by users, or central management via a cloud-based interface, and enable functions like scheduling (e.g., remotely powering on or off heating systems, controlling ovens, changing lighting conditions etc.).[51] The smart grid is a utility-side IoT application; systems gather and act on energy and power-related information to improve the efficiency of the production and distribution of electricity.[92] Using advanced metering infrastructure (AMI) Internet-connected devices, electric utilities not only collect data from end-users, but also manage distribution automation devices like transformers.[51]\\n\\nEnvironmental monitoring[edit]\\nEnvironmental monitoring applications of the IoT typically use sensors to assist in environmental protection[93] by monitoring air or water quality,[94] atmospheric or soil conditions,[95] and can even include areas like monitoring the movements of wildlife and their habitats.[96] Development of resource-constrained devices connected to the Internet also means that other applications like earthquake or tsunami early-warning systems can also be used by emergency services to provide more effective aid. IoT devices in this application typically span a large geographic area and can also be mobile.[51] It has been argued that the standardization that IoT brings to wireless sensing will revolutionize this area.[97]\\nLiving Lab\\nAnother example of integrating the IoT is Living Lab which integrates and combines research and innovation processes, establishing within a public-private-people-partnership.[98] There are currently 320 Living Labs that use the IoT to collaborate and share knowledge between stakeholders to co-create innovative and technological products. For companies to implement and develop IoT services for smart cities, they need to have incentives. The governments play key roles in smart city projects as changes in policies will help cities to implement the IoT which provides effectiveness, efficiency, and accuracy of the resources that are being used. For instance, the government provides tax incentives and cheap rent, improves public transports, and offers an environment where start-up companies, creative industries, and multinationals may co-create, share a common infrastructure and labor markets, and take advantage of locally embedded technologies, production process, and transaction costs.[98] The relationship between the technology developers and governments who manage the city\\'s assets, is key to provide open access to resources to users in an efficient way.\\n\\nMilitary applications[edit]\\nMain article: Internet of Military Things\\nThe Internet of Military Things (IoMT) is the application of IoT technologies in the military domain for the purposes of reconnaissance, surveillance, and other combat-related objectives. It is heavily influenced by the future prospects of warfare in an urban environment and involves the use of sensors, munitions, vehicles, robots, human-wearable biometrics, and other smart technology that is relevant on the battlefield.[99]\\n\\nInternet of Battlefield Things[edit]\\nThe Internet of Battlefield Things (IoBT) is a project initiated and executed by the U.S. Army Research Laboratory (ARL) that focuses on the basic science related to the IoT that enhance the capabilities of Army soldiers.[100] In 2017, ARL launched the Internet of Battlefield Things Collaborative Research Alliance (IoBT-CRA), establishing a working collaboration between industry, university, and Army researchers to advance the theoretical foundations of IoT technologies and their applications to Army operations.[101][102]\\n\\nOcean of Things[edit]\\nThe Ocean of Things project is a DARPA-led program designed to establish an Internet of things across large ocean areas for the purposes of collecting, monitoring, and analyzing environmental and vessel activity data. The project entails the deployment of about 50,000 floats that house a passive sensor suite that autonomously detect and track military and commercial vessels as part of a cloud-based network.[103]\\n\\nProduct digitalization[edit]\\nThere are several applications of smart or active packaging in which a QR code or NFC tag is affixed on a product or its packaging. The tag itself is passive, however, it contains a unique identifier (typically a URL) which enables a user to access digital content about the product via a smartphone.[104] Strictly speaking, such passive items are not part of the Internet of things, but they can be seen as enablers of digital interactions.[105] The term \"Internet of Packaging\" has been coined to describe applications in which unique identifiers are used, to automate supply chains, and are scanned on large scale by consumers to access digital content.[106] Authentication of the unique identifiers, and thereby of the product itself, is possible via a copy-sensitive digital watermark or copy detection pattern for scanning when scanning a QR code,[107] while NFC tags can encrypt communication.[108]\\n\\nTrends and characteristics[edit]\\nThe IoT\\'s major significant trend in recent years is the explosive growth of devices connected and controlled by the Internet.[109] The wide range of applications for IoT technology mean that the specifics can be very different from one device to the next but there are basic characteristics shared by most.\\nThe IoT creates opportunities for more direct integration of the physical world into computer-based systems, resulting in efficiency improvements, economic benefits, and reduced human exertions.[110][111][112][113]\\nThe number of IoT devices increased 31% year-over-year to 8.4 billion in the year 2017[114] and it is estimated that there will be 30 billion devices by 2020.[109] The global market value of the IoT is projected to reach $7.1 trillion by 2020.[115]\\n\\nIntelligence[edit]\\nAmbient intelligence and autonomous control are not part of the original concept of the Internet of things. Ambient intelligence and autonomous control do not necessarily require Internet structures, either. However, there is a shift in research (by companies such as Intel) to integrate the concepts of the IoT and autonomous control, with initial outcomes towards this direction considering objects as the driving force for autonomous IoT.[116] A promising approach in this context is deep reinforcement learning where most of IoT systems provide a dynamic and interactive environment.[117] Training an agent (i.e., IoT device) to behave smartly in such an environment cannot be addressed by conventional machine learning algorithms such as supervised learning. By reinforcement learning approach, a learning agent can sense the environment\\'s state (e.g., sensing home temperature), perform actions (e.g., turn HVAC on or off) and learn through the maximizing accumulated rewards it receives in long term.\\nIoT intelligence can be offered at three levels: IoT devices, Edge/Fog nodes, and Cloud computing.[118] The need for intelligent control and decision at each level depends on the time sensitiveness of the IoT application. For example, an autonomous vehicle\\'s camera needs to make real-time obstacle detection to avoid an accident. This fast decision making would not be possible through transferring data from the vehicle to cloud instances and return the predictions back to the vehicle. Instead, all the operation should be performed locally in the vehicle. Integrating advanced machine learning algorithms including deep learning into IoT devices is an active research area to make smart objects closer to reality. Moreover, it is possible to get the most value out of IoT deployments through analyzing IoT data, extracting hidden information, and predicting control decisions. A wide variety of machine learning techniques have been used in IoT domain ranging from traditional methods such as regression, support vector machine, and random forest to advanced ones such as convolutional neural networks, LSTM, and variational autoencoder.[119][118]\\nIn the future, the Internet of things may be a non-deterministic and open network in which auto-organized or intelligent entities (web services, SOA components) and virtual objects (avatars) will be interoperable and able to act independently (pursuing their own objectives or shared ones) depending on the context, circumstances or environments. Autonomous behavior through the collection and reasoning of context information as well as the object\\'s ability to detect changes in the environment (faults affecting sensors) and introduce suitable mitigation measures constitutes a major research trend,[120] clearly needed to provide credibility to the IoT technology. Modern IoT products and solutions in the marketplace use a variety of different technologies to support such context-aware automation, but more sophisticated forms of intelligence are requested to permit sensor units and intelligent cyber-physical systems to be deployed in real environments.[121]\\n\\nArchitecture[edit]\\nThis section needs attention from an expert in technology. The specific problem is: The information is partially outdated, unclear, and uncited. Requires more details, but not so technical that others won\\'t understand it.. WikiProject Technology may be able to help recruit an expert. (July 2018)\\nIoT system architecture, in its simplistic view, consists of three tiers: Tier 1: Devices, Tier 2: the Edge Gateway, and Tier 3: the Cloud.[122] Devices include networked things, such as the sensors and actuators found in IoT equipment, particularly those that use protocols such as Modbus, Bluetooth, Zigbee, or proprietary protocols, to connect to an Edge Gateway.[122] The Edge Gateway layer consists of sensor data aggregation systems called Edge Gateways that provide functionality, such as pre-processing of the data, securing connectivity to cloud, using systems such as WebSockets, the event hub, and, even in some cases, edge analytics or fog computing.[122] Edge Gateway layer is also required to give a common view of the devices to the upper layers to facilitate in easier management. The final tier includes the cloud application built for IoT using the microservices architecture, which are usually polyglot and inherently secure in nature using HTTPS/OAuth. It includes various database systems that store sensor data, such as time series databases or asset stores using backend data storage systems (e.g. Cassandra, PostgreSQL).[122] The cloud tier in most cloud-based IoT system features event queuing and messaging system that handles communication that transpires in all tiers.[123] Some experts classified the three-tiers in the IoT system as edge, platform, and enterprise and these are connected by proximity network, access network, and service network, respectively.[124]\\nBuilding on the Internet of things, the web of things is an architecture for the application layer of the Internet of things looking at the convergence of data from IoT devices into Web applications to create innovative use-cases. In order to program and control the flow of information in the Internet of things, a predicted architectural direction is being called BPM Everywhere which is a blending of traditional process management with process mining and special capabilities to automate the control of large numbers of coordinated devices.[citation needed]\\n\\nNetwork architecture[edit]\\nThe Internet of things requires huge scalability in the network space to handle the surge of devices.[125] IETF 6LoWPAN would be used to connect devices to IP networks. With billions of devices[126] being added to the Internet space, IPv6 will play a major role in handling the network layer scalability. IETF\\'s Constrained Application Protocol, ZeroMQ, and MQTT would provide lightweight data transport.\\nFog computing is a viable alternative to prevent such a large burst of data flow through the Internet.[127] The edge devices\\' computation power to analyse and process data is extremely limited. Limited processing power is a key attribute of IoT devices as their purpose is to supply data about physical objects while remaining autonomous. Heavy processing requirements use more battery power harming IoT\\'s ability to operate. Scalability is easy because IoT devices simply supply data through the internet to a server with sufficient processing power.[128]\\n\\nDecentralized IoT[edit]\\nDecentralized Internet of things, or decentralized IoT, is a modified IoT. It utilizes Fog Computing to handle and balance requests of connected IoT devices in order to reduce loading on the cloud servers, and improve responsiveness for latency-sensitive IoT applications like vital signs monitoring of patients, vehicle-to-vehicle communication of autonomous driving, and critical failure detection of industrial devices.[129]\\nConventional IoT is connected via a mesh network and led by a major head node (centralized controller).[130] The head node decides how a data is created, stored, and transmitted.[131] In contrast, decentralized IoT attempts to divide IoT systems into smaller divisions.[132] The head node authorizes partial decision making power to lower level sub-nodes under mutual agreed policy.[133] Performance is improved, especially for huge IoT systems with millions of nodes.[134]\\nDecentralized IoT attempts to address the limited bandwidth and hashing capacity of battery-powered or wireless IoT devices via lightweight blockchain.[135][136][137]\\nCyberattack identification can be done through early detection and mitigation at the edge nodes with traffic monitoring and evaluation.[138]\\n\\nComplexity[edit]\\nIn semi-open or closed loops (i.e. value chains, whenever a global finality can be settled) the IoT will often be considered and studied as a complex system[139] due to the huge number of different links, interactions between autonomous actors, and its capacity to integrate new actors. At the overall stage (full open loop) it will likely be seen as a chaotic environment (since systems always have finality).\\nAs a practical approach, not all elements in the Internet of things run in a global, public space. Subsystems are often implemented to mitigate the risks of privacy, control and reliability. For example, domestic robotics (domotics) running inside a smart home might only share data within and be available via a local network.[140] Managing and controlling a high dynamic ad hoc IoT things/devices network is a tough task with the traditional networks architecture, Software Defined Networking (SDN) provides the agile dynamic solution that can cope with the special requirements of the diversity of innovative IoT applications.[141][142]\\n\\nSize considerations[edit]\\nThe Internet of things would encode 50 to 100 trillion objects, and be able to follow the movement of those objects. Human beings in surveyed urban environments are each surrounded by 1000 to 5000 trackable objects.[143] In 2015 there were 83 million smart devices in people\\'s homes. This number is expected to grow to 193 million devices by 2020.[31][144]\\nThe figure of online capable devices grew 31% from 2016 to 2017 to reach 8.4 billion.[114]\\n\\nSpace considerations[edit]\\nIn the Internet of things, the precise geographic location of a thing—and also the precise geographic dimensions of a thing—will be critical.[145] Therefore, facts about a thing, such as its location in time and space, have been less critical to track because the person processing the information can decide whether or not that information was important to the action being taken, and if so, add the missing information (or decide to not take the action). (Note that some things in the Internet of things will be sensors, and sensor location is usually important.[146]) The GeoWeb and Digital Earth are promising applications that become possible when things can become organized and connected by location. However, the challenges that remain include the constraints of variable spatial scales, the need to handle massive amounts of data, and an indexing for fast search and neighbour operations. In the Internet of things, if things are able to take actions on their own initiative, this human-centric mediation role is eliminated. Thus, the time-space context that we as humans take for granted must be given a central role in this information ecosystem. Just as standards play a key role in the Internet and the Web, geo-spatial standards will play a key role in the Internet of things.[147][148]\\n\\nA solution to \"basket of remotes\"[edit]\\nMany IoT devices have the potential to take a piece of this market. Jean-Louis Gassée (Apple initial alumni team, and BeOS co-founder) has addressed this topic in an article on Monday Note,[149] where he predicts that the most likely problem will be what he calls the \"basket of remotes\" problem, where we\\'ll have hundreds of applications to interface with hundreds of devices that don\\'t share protocols for speaking with one another.[149] For improved user interaction, some technology leaders are joining forces to create standards for communication between devices to solve this problem. Others are turning to the concept of predictive interaction of devices, \"where collected data is used to predict and trigger actions on the specific devices\" while making them work together.[150]\\n\\nSocial Internet of things[edit]\\nSocial Internet of things (SIoT) is a new kind of IoT that focuses the importance of social interaction and relationship between IoT devices.[151] SIoT is a pattern of how cross-domain IoT devices enabling application to application communication and collaboration without human intervention in order to serve their owners with autonomous services,[152] and this only can be realized when gained low-level architecture support from both IoT software and hardware engineering.[153]\\n\\nSocial Network for IoT Devices (Not Human)[edit]\\nIoT defines a device with an identity like a citizen in a community, and connect them to the internet to provide services to its users.[154] SIoT defines a social network for IoT devices only to interact with each other for different goals that to serve human.[155]\\n\\nHow SIoT different from IoT?[edit]\\nSIoT is different from the original IoT in terms of the collaboration characteristics. IoT is passive, it was set to serve for dedicated purposes with existing IoT devices in predetermined system. SIoT is active, it was programmed and managed by AI to serve for unplanned purposes with mix and match of potential IoT devices from different systems that benefit its users.[156]\\n\\nHow SIoT Works?[edit]\\nIoT devices built-in with sociability will broadcast their abilities or functionalities, and at the same time discovers, navigates and groups with other IoT devices in the same or nearby network for useful service compositions in order to help its users proactively in every day\\'s life especially during emergency.[157]\\n\\nSocial IoT Examples[edit]\\nIoT-based smart home technology monitors health data of patients or aging adults by analyzing their physiological parameters and prompt the nearby health facilities when emergency medical services needed.[158] In case emergency, automatically, ambulance of a nearest available hospital will be called with pickup location provided, ward assigned, patient\\'s health data will be transmitted to the emergency department, and display on the doctor\\'s computer immediately for further action.[159]\\nIoT sensors on the vehicles, road and traffic lights monitor the conditions of the vehicles and drivers and alert when attention needed and also coordinate themselves automatically to ensure autonomous driving is working normally. Unfortunately if an accident happens, IoT camera will inform the nearest hospital and police station for help.[160]\\nSocial IoT Challenges[edit]\\nInternet of things is multifaceted and complicated.[161] One of the main factors that hindering people from adopting and use Internet of things (IoT) based products and services is its complexity.[162] Installation and setup is a challenge to people, therefore, there is a need for IoT devices to mix match and configure themselves automatically to provide different services at different situation.[163]\\nSystem security always a concern for any technology, and it is more crucial for SIoT as not only security of oneself need to be considered but also the mutual trust mechanism between collaborative IoT devices from time to time, from place to place.[153]\\nAnother critical challenge for SIoT is the accuracy and reliability of the sensors. At most of the circumstances, IoT sensors would need to respond in nanoseconds to avoid accidents, injury, and loss of life.[153]\\nEnabling technologies for IoT[edit]\\nThere are many technologies that enable the IoT. Crucial to the field is the network used to communicate between devices of an IoT installation, a role that several wireless or wired technologies may fulfill:[164][165][166]\\n\\nAddressability[edit]\\nThe original idea of the Auto-ID Center is based on RFID-tags and distinct identification through the Electronic Product Code. This has evolved into objects having an IP address or URI.[167] An alternative view, from the world of the Semantic Web[168] focuses instead on making all things (not just those electronic, smart, or RFID-enabled) addressable by the existing naming protocols, such as URI. The objects themselves do not converse, but they may now be referred to by other agents, such as powerful centralised servers acting for their human owners.[169] Integration with the Internet implies that devices will use an IP address as a distinct identifier. Due to the limited address space of IPv4 (which allows for 4.3 billion different addresses), objects in the IoT will have to use the next generation of the Internet protocol (IPv6) to scale to the extremely large address space required.[170][171][172]\\nInternet-of-things devices additionally will benefit from the stateless address auto-configuration present in IPv6,[173] as it reduces the configuration overhead on the hosts,[171] and the IETF 6LoWPAN header compression. To a large extent, the future of the Internet of things will not be possible without the support of IPv6; and consequently, the global adoption of IPv6 in the coming years will be critical for the successful development of the IoT in the future.[172]\\n\\nApplication Layer[edit]\\nADRC[174] defines an application layer protocol and supporting framework for implementing IoT applications.\\nShort-range wireless[edit]\\nBluetooth mesh networking – Specification providing a mesh networking variant to Bluetooth low energy (BLE) with an increased number of nodes and standardized application layer (Models).\\nLight-Fidelity (Li-Fi) – Wireless communication technology similar to the Wi-Fi standard, but using visible light communication for increased bandwidth.\\nNear-field communication (NFC) – Communication protocols enabling two electronic devices to communicate within a 4\\xa0cm range.\\nRadio-frequency identification (RFID) – Technology using electromagnetic fields to read data stored in tags embedded in other items.\\nWi-Fi – Technology for local area networking based on the IEEE 802.11 standard, where devices may communicate through a shared access point or directly between individual devices.\\nZigBee – Communication protocols for personal area networking based on the IEEE 802.15.4 standard, providing low power consumption, low data rate, low cost, and high throughput.\\nZ-Wave – Wireless communications protocol used primarily for home automation and security applications\\nMedium-range wireless[edit]\\nLTE-Advanced – High-speed communication specification for mobile networks. Provides enhancements to the LTE standard with extended coverage, higher throughput, and lower latency.\\n5G - 5G wireless networks can be used to achieve the high communication requirements of the IoT and connect a large number of IoT devices, even when they are on the move.[175]\\nLong-range wireless[edit]\\nLow-power wide-area networking (LPWAN) – Wireless networks designed to allow long-range communication at a low data rate, reducing power and cost for transmission. Available LPWAN technologies and protocols: LoRaWan, Sigfox, NB-IoT, Weightless, RPMA.\\nVery small aperture terminal (VSAT) – Satellite communication technology using small dish antennas for narrowband and broadband data.\\nWired[edit]\\nEthernet – General purpose networking standard using twisted pair and fiber optic links in conjunction with hubs or switches.\\nPower-line communication (PLC) – Communication technology using electrical wiring to carry power and data. Specifications such as HomePlug or G.hn utilize PLC for networking IoT devices.\\nStandards and standards organizations[edit]\\nThis is a list of technical standards for the IoT, most of which are open standards, and the standards organizations that aspire to successfully setting them.[176][177]\\n\\n\\n\\nShort name\\n\\nLong name\\n\\nStandards under development\\n\\nOther notes\\n\\n\\nAuto-ID Labs\\nAuto Identification Center\\nNetworked RFID (radiofrequency identification) and emerging sensing technologies\\n\\n\\n\\nConnected Home over IP\\nProject Connected Home over IP\\nConnected Home over IP (or Project Connected Home over IP) is an open-sourced, royalty-free home automation connectivity standard project which features compatibility among different smart home and Internet of things (IoT) products and software\\nThe Connected Home over IP project group was launched and introduced by Amazon, Apple, Google,[178] Comcast and the Zigbee Alliance on December 18, 2019.[179] The project is backed by big companies and by being based on proven Internet design principles and protocols it aims to unify the currently fragmented systems.[180]\\n\\n\\nEPCglobal\\nElectronic Product code Technology\\nStandards for adoption of EPC (Electronic Product Code) technology\\n\\n\\n\\nFDA\\nU.S. Food and Drug Administration\\nUDI (Unique Device Identification) system for distinct identifiers for medical devices\\n\\n\\n\\nGS1\\nGlobal Standards One\\nStandards for UIDs (\"unique\" identifiers) and RFID of fast-moving consumer goods (consumer packaged goods), health care supplies, and other things\\nThe GS1 digital link standard,[181] first released in August 2018, allows the use QR Codes, GS1 Datamatrix, RFID and NFC to enable various types of business-to-business, as well as business-to-consumers interactions.\\n\\n\\nParent organization comprises member organizations such as GS1 US\\n\\n\\nIEEE\\nInstitute of Electrical and Electronics Engineers\\nUnderlying communication technology standards such as IEEE 802.15.4, IEEE P1451-99[182] (IoT Harmonization), and IEEE P1931.1 (ROOF Computing).\\n\\n\\n\\nIETF\\nInternet Engineering Task Force\\nStandards that comprise TCP/IP (the Internet protocol suite)\\n\\n\\n\\nMTConnect Institute\\n—\\nMTConnect is a manufacturing industry standard for data exchange with machine tools and related industrial equipment. It is important to the IIoT subset of the IoT.\\n\\n\\n\\nO-DF\\nOpen Data Format\\nO-DF is a standard published by the Internet of Things Work Group of The Open Group in 2014, which specifies a generic information model structure that is meant to be applicable for describing any \"Thing\", as well as for publishing, updating and querying information when used together with O-MI (Open Messaging Interface).\\n\\n\\n\\nO-MI\\nOpen Messaging Interface\\nO-MI is a standard published by the Internet of Things Work Group of The Open Group in 2014, which specifies a limited set of key operations needed in IoT systems, notably different kinds of subscription mechanisms based on the Observer pattern.\\n\\n\\n\\nOCF\\nOpen Connectivity Foundation\\nStandards for simple devices using CoAP (Constrained Application Protocol)\\nOCF (Open Connectivity Foundation) supersedes OIC (Open Interconnect Consortium)\\n\\n\\nOMA\\n\\nOpen Mobile Alliance\\n\\nOMA DM and OMA LWM2M for IoT device management, as well as GotAPI, which provides a secure framework for IoT applications\\n\\n\\n\\n\\nXSF\\nXMPP Standards Foundation\\nProtocol extensions of XMPP (Extensible Messaging and Presence Protocol), the open standard of instant messaging\\n\\n\\n\\nW3C\\n\\nWorld Wide Web Consortium\\n\\nStandards for bringing interoperability between different IoT protocols and platforms such as Thing Description, Discovery , Scripting API and Architecture that explains how they work together.\\n\\nHomepage of the Web of Things activity at the W3C at https://www.w3.org/WoT/\\n\\n\\nPolitics and civic engagement[edit]\\nSome scholars and activists argue that the IoT can be used to create new models of civic engagement if device networks can be open to user control and inter-operable platforms. Philip N. Howard, a professor and author, writes that political life in both democracies and authoritarian regimes will be shaped by the way the IoT will be used for civic engagement. For that to happen, he argues that any connected device should be able to divulge a list of the \"ultimate beneficiaries\" of its sensor data and that individual citizens should be able to add new organisations to the beneficiary list. In addition, he argues that civil society groups need to start developing their IoT strategy for making use of data and engaging with the public.[183]\\n\\nGovernment regulation on IoT[edit]\\nOne of the key drivers of the IoT is data. The success of the idea of connecting devices to make them more efficient is dependent upon access to and storage & processing of data. For this purpose, companies working on the IoT collect data from multiple sources and store it in their cloud network for further processing. This leaves the door wide open for privacy and security dangers and single point vulnerability of multiple systems.[184] The other issues pertain to consumer choice and ownership of data[185] and how it is used. Though still in their infancy, regulations and governance regarding these issues of privacy, security, and data ownership continue to develop.[186][187][188] IoT regulation depends on the country. Some examples of legislation that is relevant to privacy and data collection are: the US Privacy Act of 1974, OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data of 1980, and the EU Directive 95/46/EC of 1995.[189]\\nCurrent regulatory environment:\\nA report published by the Federal Trade Commission (FTC) in January 2015 made the following three recommendations:[190]\\n\\nData security – At the time of designing IoT companies should ensure that data collection, storage and processing would be secure at all times. Companies should adopt a \"defense in depth\" approach and encrypt data at each stage.[191]\\nData consent – users should have a choice as to what data they share with IoT companies and the users must be informed if their data gets exposed.\\nData minimisation – IoT companies should collect only the data they need and retain the collected information only for a limited time.\\nHowever, the FTC stopped at just making recommendations for now. According to an FTC analysis, the existing framework, consisting of the FTC Act, the Fair Credit Reporting Act, and the Children\\'s Online Privacy Protection Act, along with developing consumer education and business guidance, participation in multi-stakeholder efforts and advocacy to other agencies at the federal, state and local level, is sufficient to protect consumer rights.[192]\\nA resolution passed by the Senate in March 2015, is already being considered by the Congress.[193] This resolution recognized the need for formulating a National Policy on IoT and the matter of privacy, security and spectrum. Furthermore, to provide an impetus to the IoT ecosystem, in March 2016, a bipartisan group of four Senators proposed a bill, The Developing Innovation and Growing the Internet of Things (DIGIT) Act, to direct the Federal Communications Commission to assess the need for more spectrum to connect IoT devices.\\nApproved on 28 September 2018, California Senate Bill No. 327[194] goes into effect on 1 January 2020. The bill requires \"a manufacturer of a connected device, as those terms are defined, to equip the device with a reasonable security feature or features that are appropriate to the nature and function of the device, appropriate to the information it may collect, contain, or transmit, and designed to protect the device and any information contained therein from unauthorized access, destruction, use, modification, or disclosure,\"\\nSeveral standards for the IoT industry are actually being established relating to automobiles because most concerns arising from use of connected cars apply to healthcare devices as well. In fact, the National Highway Traffic Safety Administration (NHTSA) is preparing cybersecurity guidelines and a database of best practices to make automotive computer systems more secure.[195]\\nA recent report from the World Bank examines the challenges and opportunities in government adoption of IoT.[196] These include –\\n\\nStill early days for the IoT in government\\xa0\\nUnderdeveloped policy and regulatory frameworks\\xa0\\nUnclear business models, despite strong value proposition\\xa0\\nClear institutional and capacity gap in government AND the private sector\\xa0\\nInconsistent data valuation and management\\xa0\\nInfrastructure a major barrier\\xa0\\nGovernment as an enabler\\xa0\\nMost successful pilots share common characteristics (public-private partnership, local, leadership)\\nIn early December 2021, the U.K. government introduced the Product Security and Telecommunications Infrastructure bill (PST), an effort to legislate IoT distributors, manufacturers, and importers to meet certain cybersecurity standards. The bill also seeks to improve the security credentials of consumer IoT devices.[197]\\n\\nCriticism, problems and controversies[edit]\\nPlatform fragmentation[edit]\\nThe IoT suffers from platform fragmentation, lack of interoperability and common technical standards[198][199][200][201][202][203][204][excessive citations] a situation where the variety of IoT devices, in terms of both hardware variations and differences in the software running on them, makes the task of developing applications that work consistently between different inconsistent technology ecosystems hard.[1] For example, wireless connectivity for IoT devices can be done using Bluetooth, Zigbee, Z-Wave, LoRa, NB-IoT, Cat M1 as well as completely custom proprietary radios – each with its own advantages and disadvantages; and unique support ecosystem.[205]\\nThe IoT\\'s amorphous computing nature is also a problem for security, since patches to bugs found in the core operating system often do not reach users of older and lower-price devices.[206][207][208] One set of researchers say that the failure of vendors to support older devices with patches and updates leaves more than 87% of active Android devices vulnerable.[209][210]\\n\\nPrivacy, autonomy, and control[edit]\\nPhilip N. Howard, a professor and author, writes that the Internet of things offers immense potential for empowering citizens, making government transparent, and broadening information access. Howard cautions, however, that privacy threats are enormous, as is the potential for social control and political manipulation.[211]\\nConcerns about privacy have led many to consider the possibility that big data infrastructures such as the Internet of things and data mining are inherently incompatible with privacy.[212] Key challenges of increased digitalization in the water, transport or energy sector are related to privacy and cybersecurity which necessitate an adequate response from research and policymakers alike.[213]\\nWriter Adam Greenfield claims that IoT technologies are not only an invasion of public space but are also being used to perpetuate normative behavior, citing an instance of billboards with hidden cameras that tracked the demographics of passersby who stopped to read the advertisement.\\nThe Internet of Things Council compared the increased prevalence of digital surveillance due to the Internet of things to the conceptual panopticon described by Jeremy Bentham in the 18th Century.[214] The assertion was defended by the works of French philosophers Michel Foucault and Gilles Deleuze. In Discipline and Punish: The Birth of the Prison Foucault asserts that the panopticon was a central element of the discipline society developed during the Industrial Era.[215] Foucault also argued that the discipline systems established in factories and school reflected Bentham\\'s vision of panopticism.[215] In his 1992 paper \"Postscripts on the Societies of Control,\" Deleuze wrote that the discipline society had transitioned into a control society, with the computer replacing the panopticon as an instrument of discipline and control while still maintaining the qualities similar to that of panopticism.[216]\\nPeter-Paul Verbeek, a professor of philosophy of technology at the University of Twente, Netherlands, writes that technology already influences our moral decision making, which in turn affects human agency, privacy and autonomy. He cautions against viewing technology merely as a human tool and advocates instead to consider it as an active agent.[217]\\nJustin Brookman, of the Center for Democracy and Technology, expressed concern regarding the impact of the IoT on consumer privacy, saying that \"There are some people in the commercial space who say, \\'Oh, big data – well, let\\'s collect everything, keep it around forever, we\\'ll pay for somebody to think about security later.\\' The question is whether we want to have some sort of policy framework in place to limit that.\"[218]\\nTim O\\'Reilly believes that the way companies sell the IoT devices on consumers are misplaced, disputing the notion that the IoT is about gaining efficiency from putting all kinds of devices online and postulating that the \"IoT is really about human augmentation. The applications are profoundly different when you have sensors and data driving the decision-making.\"[219]\\nEditorials at WIRED have also expressed concern, one stating \"What you\\'re about to lose is your privacy. Actually, it\\'s worse than that. You aren\\'t just going to lose your privacy, you\\'re going to have to watch the very concept of privacy be rewritten under your nose.\"[220]\\nThe American Civil Liberties Union (ACLU) expressed concern regarding the ability of IoT to erode people\\'s control over their own lives. The ACLU wrote that \"There\\'s simply no way to forecast how these immense powers – disproportionately accumulating in the hands of corporations seeking financial advantage and governments craving ever more control – will be used. Chances are big data and the Internet of Things will make it harder for us to control our own lives, as we grow increasingly transparent to powerful corporations and government institutions that are becoming more opaque to us.\"[221]\\nIn response to rising concerns about privacy and smart technology, in 2007 the British Government stated it would follow formal Privacy by Design principles when implementing their smart metering program. The program would lead to replacement of traditional power meters with smart power meters, which could track and manage energy usage more accurately.[222] However the British Computer Society is doubtful these principles were ever actually implemented.[223] In 2009 the Dutch Parliament rejected a similar smart metering program, basing their decision on privacy concerns. The Dutch program later revised and passed in 2011.[223]\\n\\nData storage[edit]\\nA challenge for producers of IoT applications is to clean, process and interpret the vast amount of data which is gathered by the sensors. There is a solution proposed for the analytics of the information referred to as Wireless Sensor Networks.[224] These networks share data among sensor nodes that are sent to a distributed system for the analytics of the sensory data.[225]\\nAnother challenge is the storage of this bulk data. Depending on the application, there could be high data acquisition requirements, which in turn lead to high storage requirements. Currently the Internet is already responsible for 5% of the total energy generated,[224] and a \"daunting challenge to power\" IoT devices to collect and even store data still remains.[226]\\n\\nSecurity[edit]\\nSecurity is the biggest concern in adopting Internet of things technology,[227] with concerns that rapid development is happening without appropriate consideration of the profound security challenges involved[228] and the regulatory changes that might be necessary.[229][230]\\nMost of the technical security concerns are similar to those of conventional servers, workstations and smartphones.[231] These concerns include using weak authentication, forgetting to change default credentials, unencrypted messages sent between devices, SQL injections, Man-in-the-middle attacks, and poor handling of security updates.[232][233] However, many IoT devices have severe operational limitations on the computational power available to them. These constraints often make them unable to directly use basic security measures such as implementing firewalls or using strong cryptosystems to encrypt their communications with other devices[234] - and the low price and consumer focus of many devices makes a robust security patching system uncommon.[235]\\nRather than conventional security vulnerabilities, fault injection attacks are on the rise and targeting IoT devices. A fault injection attack is a physical attack on a device to purposefully introduce faults in the system to change the intended behavior. Faults might happen unintentionally by environmental noises and electromagnetic fields. There are ideas stemmed from control-flow integrity (CFI) to prevent fault injection attacks and system recovery to a healthy state before the fault.[236]\\nInternet of things devices also have access to new areas of data, and can often control physical devices,[237] so that even by 2014 it was possible to say that many Internet-connected appliances could already \"spy on people in their own homes\" including televisions, kitchen appliances,[238] cameras, and thermostats.[239] Computer-controlled devices in automobiles such as brakes, engine, locks, hood and trunk releases, horn, heat, and dashboard have been shown to be vulnerable to attackers who have access to the on-board network. In some cases, vehicle computer systems are Internet-connected, allowing them to be exploited remotely.[240] By 2008 security researchers had shown the ability to remotely control pacemakers without authority. Later hackers demonstrated remote control of insulin pumps[241] and implantable cardioverter defibrillators.[242]\\nPoorly secured Internet-accessible IoT devices can also be subverted to attack others. In 2016, a distributed denial of service attack powered by Internet of things devices running the Mirai malware took down a DNS provider and major web sites.[243] The Mirai Botnet had infected roughly 65,000 IoT devices within the first 20 hours.[244] Eventually the infections increased to around 200,000 to 300,000 infections.[244] Brazil, Colombia and Vietnam made up of 41.5% of the infections.[244] The Mirai Botnet had singled out specific IoT devices that consisted of DVRs, IP cameras, routers and printers.[244] Top vendors that contained the most infected devices were identified as Dahua, Huawei, ZTE, Cisco, ZyXEL and MikroTik.[244] In May 2017, Junade Ali, a Computer Scientist at Cloudflare noted that native DDoS vulnerabilities exist in IoT devices due to a poor implementation of the Publish–subscribe pattern.[245][246] These sorts of attacks have caused security experts to view IoT as a real threat to Internet services.[247]\\nThe U.S. National Intelligence Council in an unclassified report maintains that it would be hard to deny \"access to networks of sensors and remotely-controlled objects by enemies of the United States, criminals, and mischief makers... An open market for aggregated sensor data could serve the interests of commerce and security no less than it helps criminals and spies identify vulnerable targets. Thus, massively parallel sensor fusion may undermine social cohesion, if it proves to be fundamentally incompatible with Fourth-Amendment guarantees against unreasonable search.\"[248] In general, the intelligence community views the Internet of things as a rich source of data.[249]\\nOn 31 January 2019, the Washington Post wrote an article regarding the security and ethical challenges that can occur with IoT doorbells and cameras: \"Last month, Ring got caught allowing its team in Ukraine to view and annotate certain user videos; the company says it only looks at publicly shared videos and those from Ring owners who provide consent. Just last week, a California family\\'s Nest camera let a hacker take over and broadcast fake audio warnings about a missile attack, not to mention peer in on them, when they used a weak password\"[250]\\nThere have been a range of responses to concerns over security. The Internet of Things Security Foundation (IoTSF) was launched on 23 September 2015 with a mission to secure the Internet of things by promoting knowledge and best practice. Its founding board is made from technology providers and telecommunications companies. In addition, large IT companies are continually developing innovative solutions to ensure the security of IoT devices. In 2017, Mozilla launched Project Things, which allows to route IoT devices through a safe Web of Things gateway.[251] As per the estimates from KBV Research,[252] the overall IoT security market[253] would grow at 27.9% rate during 2016–2022 as a result of growing infrastructural concerns and diversified usage of Internet of things.[254][255]\\nGovernmental regulation is argued by some to be necessary to secure IoT devices and the wider Internet – as market incentives to secure IoT devices is insufficient.[256][229][230] It was found that due to the nature of most of the IoT development boards, they generate predictable and weak keys which make it easy to be utilized by Man-in-the-middle attack. However, various hardening approaches were proposed by many researchers to resolve the issue of SSH weak implementation and weak keys.[257]\\n\\nSafety[edit]\\nIoT systems are typically controlled by event-driven smart apps that take as input either sensed data, user inputs, or other external triggers (from the Internet) and command one or more actuators towards providing different forms of automation.[258] Examples of sensors include smoke detectors, motion sensors, and contact sensors. Examples of actuators include smart locks, smart power outlets, and door controls. Popular control platforms on which third-party developers can build smart apps that interact wirelessly with these sensors and actuators include Samsung\\'s SmartThings,[259] Apple\\'s HomeKit,[260] and Amazon\\'s Alexa,[261] among others.\\nA problem specific to IoT systems is that buggy apps, unforeseen bad app interactions, or device/communication failures, can cause unsafe and dangerous physical states, e.g., \"unlock the entrance door when no one is at home\" or \"turn off the heater when the temperature is below 0 degrees Celsius and people are sleeping at night\".[258] Detecting flaws that lead to such states, requires a holistic view of installed apps, component devices, their configurations, and more importantly, how they interact. Recently, researchers from the University of California Riverside have proposed IotSan, a novel practical system that uses model checking as a building block to reveal \"interaction-level\" flaws by identifying events that can lead the system to unsafe states.[258] They have evaluated IotSan on the Samsung SmartThings platform. From 76 manually configured systems, IotSan detects 147 vulnerabilities (i.e., violations of safe physical states/properties).\\n\\nDesign[edit]\\nGiven widespread recognition of the evolving nature of the design and management of the Internet of things, sustainable and secure deployment of IoT solutions must design for \"anarchic scalability.\"[262] Application of the concept of anarchic scalability can be extended to physical systems (i.e. controlled real-world objects), by virtue of those systems being designed to account for uncertain management futures. This hard anarchic scalability thus provides a pathway forward to fully realize the potential of Internet-of-things solutions by selectively constraining physical systems to allow for all management regimes without risking physical failure.[262]\\nBrown University computer scientist Michael Littman has argued that successful execution of the Internet of things requires consideration of the interface\\'s usability as well as the technology itself. These interfaces need to be not only more user-friendly but also better integrated: \"If users need to learn different interfaces for their vacuums, their locks, their sprinklers, their lights, and their coffeemakers, it\\'s tough to say that their lives have been made any easier.\"[263]\\n\\nEnvironmental sustainability impact[edit]\\nA concern regarding Internet-of-things technologies pertains to the environmental impacts of the manufacture, use, and eventual disposal of all these semiconductor-rich devices.[264] Modern electronics are replete with a wide variety of heavy metals and rare-earth metals, as well as highly toxic synthetic chemicals. This makes them extremely difficult to properly recycle. Electronic components are often incinerated or placed in regular landfills. Furthermore, the human and environmental cost of mining the rare-earth metals that are integral to modern electronic components continues to grow. This leads to societal questions concerning the environmental impacts of IoT devices over their lifetime.[265]\\n\\nIntentional obsolescence of devices[edit]\\nThe Electronic Frontier Foundation has raised concerns that companies can use the technologies necessary to support connected devices to intentionally disable or \"brick\" their customers\\' devices via a remote software update or by disabling a service necessary to the operation of the device. In one example, home automation devices sold with the promise of a \"Lifetime Subscription\" were rendered useless after Nest Labs acquired Revolv and made the decision to shut down the central servers the Revolv devices had used to operate.[266] As Nest is a company owned by Alphabet (Google\\'s parent company), the EFF argues this sets a \"terrible precedent for a company with ambitions to sell self-driving cars, medical devices, and other high-end gadgets that may be essential to a person\\'s livelihood or physical safety.\"[267]\\nOwners should be free to point their devices to a different server or collaborate on improved software. But such action violates the United States DMCA section 1201, which only has an exemption for \"local use\". This forces tinkerers who want to keep using their own equipment into a legal grey area. EFF thinks buyers should refuse electronics and software that prioritize the manufacturer\\'s wishes above their own.[267]\\nExamples of post-sale manipulations include Google Nest Revolv, disabled privacy settings on Android, Sony disabling Linux on PlayStation 3, enforced EULA on Wii U.[267]\\n\\nConfusing terminology[edit]\\nKevin Lonergan at Information Age, a business technology magazine, has referred to the terms surrounding the IoT as a \"terminology zoo\".[268] The lack of clear terminology is not \"useful from a practical point of view\" and a \"source of confusion for the end user\".[268] A company operating in the IoT space could be working in anything related to sensor technology, networking, embedded systems, or analytics.[268] According to Lonergan, the term IoT was coined before smart phones, tablets, and devices as we know them today existed, and there is a long list of terms with varying degrees of overlap and technological convergence: Internet of things, Internet of everything (IoE), Internet of goods (supply chain), industrial Internet, pervasive computing, pervasive sensing, ubiquitous computing, cyber-physical systems (CPS), wireless sensor networks (WSN), smart objects, digital twin, cyberobjects or avatars,[139] cooperating objects, machine to machine (M2M), ambient intelligence (AmI), Operational technology (OT), and information technology (IT).[268] Regarding IIoT, an industrial sub-field of IoT, the Industrial Internet Consortium\\'s Vocabulary Task Group has created a \"common and reusable vocabulary of terms\"[269] to ensure \"consistent terminology\"[269][270] across publications issued by the Industrial Internet Consortium. IoT One has created an IoT Terms Database including a New Term Alert[271] to be notified when a new term is published. As of March\\xa02020[update], this database aggregates 807 IoT-related terms, while keeping material \"transparent and comprehensive.\"[272][273]\\n\\nIoT adoption barriers[edit]\\n GE Digital CEO William Ruh speaking about GE\\'s attempts to gain a foothold in the market for IoT services at the first IEEE Computer Society TechIgnite conference\\nLack of interoperability and unclear value propositions[edit]\\nDespite a shared belief in the potential of the IoT, industry leaders and consumers are facing barriers to adopt IoT technology more widely. Mike Farley argued in Forbes that while IoT solutions appeal to early adopters, they either lack interoperability or a clear use case for end-users.[274] A study by Ericsson regarding the adoption of IoT among Danish companies suggests that many struggle \"to pinpoint exactly where the value of IoT lies for them\".[275]\\n\\nPrivacy and security concerns[edit]\\nAs for IoT, especially in regards to consumer IoT, information about a user\\'s daily routine is collected so that the “things” around the user can cooperate to provide better services that fulfill personal preference.[276] When the collected information which describes a user in detail travels through multiple hops in a network, due to a diverse integration of services, devices and network, the information stored on a device is vulnerable to privacy violation by compromising nodes existing in an IoT network.[277]\\nFor example, on 21 October 2016, a multiple distributed denial of service (DDoS) attacks systems operated by domain name system provider Dyn, which caused the inaccessibility of several websites, such as GitHub, Twitter, and others. This attack is executed through a botnet consisting of a large number of IoT devices including IP cameras, gateways, and even baby monitors.[278]\\nFundamentally there are 4 security objectives that the IoT system requires: (1) data confidentiality: unauthorized parties cannot have access to the transmitted and stored data; (2) data integrity: intentional and unintentional corruption of transmitted and stored data must be detected; (3) non-repudiation: the sender cannot deny having sent a given message; (4) data availability: the transmitted and stored data should be available to authorized parties even with the denial-of-service (DOS) attacks.[279]\\nInformation privacy regulations also require organizations to practice \"reasonable security\". California\\'s SB-327 Information privacy: connected devices \"would require a manufacturer of a connected device, as those terms are defined, to equip the device with a reasonable security feature or features that are appropriate to the nature and function of the device, appropriate to the information it may collect, contain, or transmit, and designed to protect the device and any information contained therein from unauthorized access, destruction, use, modification, or disclosure, as specified.\"[280] As each organization\\'s environment is unique, it can prove challenging to demonstrate what \"reasonable security\" is and what potential risks could be involved for the business. Oregon\\'s HB 2395 also \"requires [a] person that manufactures, sells or offers to sell connected device] manufacturer to equip connected device with reasonable security features that protect connected device and information that connected device collects, contains, stores or transmits] stores from access, destruction, modification, use or disclosure that consumer does not authorize.\"[281]\\nAccording to antivirus provider Kaspersky, there were 639 million data breaches of IoT devices in 2020 and 1.5 billion breaches in the first six months of 2021.[197]\\n\\nTraditional governance structure[edit]\\n Town of Internet of Things in Hangzhou, China\\nA study issued by Ericsson regarding the adoption of Internet of things among Danish companies identified a \"clash between IoT and companies\\' traditional governance structures, as IoT still presents both uncertainties and a lack of historical precedence.\"[275] Among the respondents interviewed, 60 percent stated that they \"do not believe they have the organizational capabilities, and three of four do not believe they have the processes needed, to capture the IoT opportunity.\"[275] This has led to a need to understand organizational culture in order to facilitate organizational design processes and to test new innovation management practices. A lack of digital leadership in the age of digital transformation has also stifled innovation and IoT adoption to a degree that many companies, in the face of uncertainty, \"were waiting for the market dynamics to play out\",[275] or further action in regards to IoT \"was pending competitor moves, customer pull, or regulatory requirements.\"[275] Some of these companies risk being \"kodaked\" – \"Kodak was a market leader until digital disruption eclipsed film photography with digital photos\" – failing to \"see the disruptive forces affecting their industry\"[282] and \"to truly embrace the new business models the disruptive change opens up.\"[282] Scott Anthony has written in Harvard Business Review that Kodak \"created a digital camera, invested in the technology, and even understood that photos would be shared online\"[282] but ultimately failed to realize that \"online photo sharing was the new business, not just a way to expand the printing business.\"[282]\\n\\nBusiness planning and project management[edit]\\nAccording to 2018 study, 70–75% of IoT deployments were stuck in the pilot or prototype stage, unable to reach scale due in part to a lack of business planning.[283][page\\xa0needed][284]\\nEven though scientists, engineers, and managers across the world are continuously working to create and exploit the benefits of IoT products, there are some flaws in the governance, management and implementation of such projects. Despite tremendous forward momentum in the field of information and other underlying technologies, IoT still remains a complex area and the problem of how IoT projects are managed still needs to be addressed.\\xa0IoT projects must be run differently than simple and traditional IT, manufacturing or construction projects. Because IoT projects have longer project timelines, a lack of skilled resources and several security/legal issues, there is a need for new and specifically designed project processes. The following management techniques should improve the success rate of IoT projects:[285]\\n\\nA separate research and development phase\\xa0\\nA Proof-of-Concept/Prototype before the actual project begins\\xa0\\nProject managers with interdisciplinary technical knowledge\\xa0\\nUniversally defined business and technical jargon\\nSee also[edit]\\n\\n5G\\nArtificial intelligence of things\\nAutomotive security\\nBig Data\\nCloud manufacturing\\nCyber-physical system\\nData Distribution Service\\nDigital object memory\\nDigital twin\\nEdge computing\\nFour-dimensional product\\nHome automation\\nIndoor positioning system\\nIndustry 4.0\\nInternet of Military Things\\nIoT Cloud\\nIoT Simulation\\nOpen Interconnect Consortium\\nOpenWSN\\nQuantified self\\nResponsive computer-aided design\\nSmart grid\\nWeb of things\\nThread (network protocol)\\nMatter (standard)\\n\\nReferences[edit]\\n\\n\\n^ a b Gillis, Alexander (2021). \"What is internet of things (IoT)?\". IOT Agenda. Retrieved 17 August 2021.\\n\\n^ Brown, Eric (20 September 2016). \"21 Open Source Projects for IoT\". Linux.com. Retrieved 23 October 2016.\\n\\n^ \"Internet of Things Global Standards Initiative\". ITU. Retrieved 26 June 2015.\\n\\n^ Hendricks, Drew. \"The Trouble with the Internet of Things\". London Datastore. Greater London Authority. Retrieved 10 August 2015.\\n\\n^ Internet of things and big data analytics toward next-generation intelligence. Nilanjan Dey, Aboul Ella Hassanien, Chintan Bhatt, Amira Ashour, Suresh Chandra Satapathy. Cham, Switzerland. 2018. p.\\xa0440. ISBN\\xa0978-3-319-60435-0. OCLC\\xa01001327784.{{cite book}}:  CS1 maint: others (link)\\n\\n^ \"Forecast: The Internet of Things, Worldwide, 2013\". Gartner. Retrieved 3 March 2022.\\n\\n^ Hu, J.; Niu, H.; Carrasco, J.; Lennox, B.; Arvin, F., \"Fault-tolerant cooperative navigation of networked UAV swarms for forest fire monitoring\" Aerospace Science and Technology, 2022.\\n\\n^ Hu, J.; Lennox, B.; Arvin, F., \"Robust formation control for networked robotic systems using Negative Imaginary dynamics\" Automatica, 2022.\\n\\n^ Laplante, Phillip A.; Kassab, Mohamad; Laplante, Nancy L.; Voas, Jeffrey M. (2018). \"Building Caring Healthcare Systems in the Internet of Things\". IEEE Systems Journal. 12 (3): 3030–3037. Bibcode:2018ISysJ..12.3030L. doi:10.1109/JSYST.2017.2662602. ISSN\\xa01932-8184. PMC\\xa06506834. PMID\\xa031080541.\\n\\n^ \"The New York City Internet of Things Strategy\". www1.nyc.gov. Retrieved 6 September 2021.\\n\\n^ \"The \"Only\" Coke Machine on the Internet\". Carnegie Mellon University. Retrieved 10 November 2014.\\n\\n^ \"Internet of Things Done Wrong Stifles Innovation\". InformationWeek. 7 July 2014. Retrieved 10 November 2014.\\n\\n^ Mattern, Friedemann; Floerkemeier, Christian (2010). \"From the Internet of Computer to the Internet of Things\" (PDF). Informatik-Spektrum. 33 (2): 107–121. Bibcode:2009InfSp..32..496H. doi:10.1007/s00287-010-0417-7. hdl:20.500.11850/159645. S2CID\\xa029563772. Retrieved 3 February 2014.\\n\\n^ Weiser, Mark (1991). \"The Computer for the 21st Century\" (PDF). Scientific American. 265 (3): 94–104. Bibcode:1991SciAm.265c..94W. doi:10.1038/scientificamerican0991-94. Archived from the original (PDF) on 11 March 2015. Retrieved 5 November 2014.\\n\\n^ Raji, R.S. (1994). \"Smart networks for control\". IEEE Spectrum. 31 (6): 49–55. doi:10.1109/6.284793. S2CID\\xa042364553.\\n\\n^ Pontin, Jason (29 September 2005). \"ETC: Bill Joy\\'s Six Webs\". MIT Technology Review. Retrieved 17 November 2013.\\n\\n^ \"CORRECTING THE IOT HISTORY\". CHETAN SHARMA. 14 March 2016. Retrieved 1 June 2021.\\n\\n^ Ashton, K. (22 June 2009). \"That \\'Internet of Things\\' Thing\". Retrieved 9 May 2017.\\n\\n^ \"Peter Day\\'s World of Business\". BBC World Service. BBC. Retrieved 4 October 2016.\\n\\n^ Magrassi, P. (2 May 2002). \"Why a Universal RFID Infrastructure Would Be a Good Thing\". Gartner research report G00106518.\\n\\n^ Magrassi, P.; Berg, T (12 August 2002). \"A World of Smart Objects\". Gartner research report R-17-2243. Archived from the original on 3 October 2003.\\n\\n^ Commission of the European Communities (18 June 2009). \"Internet of Things – An action plan for Europe\" (PDF). COM(2009) 278 final.\\n\\n^ Wood, Alex (31 March 2015). \"The internet of things is revolutionizing our lives, but standards are a must\". The Guardian.\\n\\n^ Stallings, William (2016). Foundations of modern networking\\xa0: SDN, NFV, QoE, IoT, and Cloud. Florence Agboma, Sofiene Jelassi. Indianapolis, Indiana. ISBN\\xa0978-0-13-417547-8. OCLC\\xa0927715441.\\n\\n^ Dave Evans (April 2011). \"The Internet of Things: How the Next Evolution of the Internet Is Changing Everything\" (PDF). CISCO White Paper.\\n\\n^ Vongsingthong, S.; Smanchat, S. (2014). \"Internet of Things: A review of applications & technologies\" (PDF). Suranaree Journal of Science and Technology.\\n\\n^ a b \"The Enterprise Internet of Things Market\". Business Insider. 25 February 2015. Retrieved 26 June 2015.\\n\\n^ Perera, C.; Liu, C. H.; Jayawardena, S. (December 2015). \"The Emerging Internet of Things Marketplace From an Industrial Perspective: A Survey\". IEEE Transactions on Emerging Topics in Computing. 3 (4): 585–598. arXiv:1502.00134. Bibcode:2015arXiv150200134P. doi:10.1109/TETC.2015.2390034. ISSN\\xa02168-6750. S2CID\\xa07329149.\\n\\n^ \"How IoT\\'s are Changing the Fundamentals of \"Retailing\"\". Trak.in – Indian Business of Tech, Mobile & Startups. 30 August 2016. Retrieved 2 June 2017.\\n\\n^ Kang, Won Min; Moon, Seo Yeon; Park, Jong Hyuk (5 March 2017). \"An enhanced security framework for home appliances in smart home\". Human-centric Computing and Information Sciences. 7 (6). doi:10.1186/s13673-017-0087-4.\\n\\n^ a b \"How IoT & smart home automation will change the way we live\". Business Insider. Retrieved 10 November 2017.\\n\\n^ a b Jussi Karlgren; Lennart Fahlén; Anders Wallberg; Pär Hansson; Olov Ståhl; Jonas Söderberg; Karl-Petter Åkesson (2008). Socially Intelligent Interfaces for Increased Energy Awareness in the Home. The Internet of Things. Lecture Notes in Computer Science. Vol.\\xa04952. Springer. pp.\\xa0263–275. arXiv:2106.15297. doi:10.1007/978-3-540-78731-0_17. ISBN\\xa0978-3-540-78730-3. S2CID\\xa030983428.\\n\\n^ Greengard, Samuel (2015). The Internet of Things. Cambridge, MA: MIT Press. p.\\xa090. ISBN\\xa09780262527736.\\n\\n^ \"HomeKit – Apple Developer\". developer.apple.com. Retrieved 19 September 2018.\\n\\n^ Wollerton, Megan (3 June 2018). \"Here\\'s everything you need to know about Apple HomeKit\". CNET. Retrieved 19 September 2018.\\n\\n^ a b Lovejoy, Ben (31 August 2018). \"HomeKit devices getting more affordable as Lenovo announces Smart Home Essentials line\". 9to5Mac. Retrieved 19 September 2018.\\n\\n^ Prospero, Mike (12 September 2018). \"Best Smart Home Hubs of 2018\". Tom\\'s Guide. Retrieved 19 September 2018.\\n\\n^ Chinchilla, Chris (26 November 2018). \"What Smart Home IoT Platform Should You Use?\". Hacker Noon. Retrieved 13 May 2019.\\n\\n^ Baker, Jason (14 December 2017). \"6 open source home automation tools\". opensource.com. Retrieved 13 May 2019.\\n\\n^ a b Demiris, G; Hensel, K (2008). \"Technologies for an Aging Society: A Systematic Review of \\'Smart Home\\' Applications\". IMIA Yearbook of Medical Informatics 2008. 17: 33–40. doi:10.1055/s-0038-1638580. PMID\\xa018660873. S2CID\\xa07244183.\\n\\n^ Aburukba, Raafat; Al-Ali, A. R.; Kandil, Nourhan; AbuDamis, Diala (10 May 2016). Configurable ZigBee-based control system for people with multiple disabilities in smart homes. pp.\\xa01–5. doi:10.1109/ICCSII.2016.7462435. ISBN\\xa0978-1-4673-8743-9. S2CID\\xa016754386.\\n\\n^ Mulvenna, Maurice; Hutton, Anton; Martin, Suzanne; Todd, Stephen; Bond, Raymond; Moorhead, Anne (14 December 2017). \"Views of Caregivers on the Ethics of Assistive Technology Used for Home Surveillance of People Living with Dementia\". Neuroethics. 10 (2): 255–266. doi:10.1007/s12152-017-9305-z. PMC\\xa05486509. PMID\\xa028725288.\\n\\n^ a b da Costa, CA; Pasluosta, CF; Eskofier, B; da Silva, DB; da Rosa Righi, R (July 2018). \"Internet of Health Things: Toward intelligent vital signs monitoring in hospital wards\". Artificial Intelligence in Medicine. 89: 61–69. doi:10.1016/j.artmed.2018.05.005. PMID\\xa029871778. S2CID\\xa046941758.\\n\\n^ Engineer, A; Sternberg, EM; Najafi, B (21 August 2018). \"Designing Interiors to Mitigate Physical and Cognitive Deficits Related to Aging and to Promote Longevity in Older Adults: A Review\". Gerontology. 64 (6): 612–622. doi:10.1159/000491488. PMID\\xa030130764. S2CID\\xa052056959. \\n\\n^ a b Kricka, LJ (2019). \"History of disruptions in laboratory medicine: what have we learned from predictions?\". Clinical Chemistry and Laboratory Medicine. 57 (3): 308–311. doi:10.1515/cclm-2018-0518. PMID\\xa029927745. S2CID\\xa049354315.\\n\\n^ Gatouillat, Arthur; Badr, Youakim; Massot, Bertrand; Sejdic, Ervin (2018). \"Internet of Medical Things: A Review of Recent Contributions Dealing with Cyber-Physical Systems in Medicine\" (PDF). IEEE Internet of Things Journal. 5 (5): 3810–3822. doi:10.1109/jiot.2018.2849014. ISSN\\xa02327-4662. S2CID\\xa053440449.\\n\\n^ Topol, Eric (2016). The Patient Will See You Now: The Future of Medicine Is in Your Hands. Basic Books. ISBN\\xa0978-0465040025.\\n\\n^ a b Dey, Nilanjan; Hassanien, Aboul Ella; Bhatt, Chintan; Ashour, Amira S.; Satapathy, Suresh Chandra (2018). Internet of things and big data analytics toward next-generation intelligence (PDF). Springer International Publishing. ISBN\\xa0978-3-319-60434-3. Retrieved 14 October 2018.\\n\\n^ Pratap Singh, R.; Javaid, M.; Haleem, A.; Vaishya, R.; Ali, S. (2020). \"Internet of Medical Things (IoMT) for orthopaedic in COVID-19 pandemic: Roles, challenges, and applications\". Journal of Clinical Orthopaedics and Trauma. 11 (4): 713–717. doi:10.1016/j.jcot.2020.05.011. PMC\\xa07227564. PMID\\xa032425428.\\n\\n^ \"Deloitte Centre for Health Solutions\" (PDF). Deloitte.\\n\\n^ a b c d e f g h i j Ersue, M.; Romascanu, D.; Schoenwaelder, J.; Sehgal, A. (4 July 2014). \"Management of Networks with Constrained Devices: Use Cases\". IETF Internet Draft.\\n\\n^ \"Goldman Sachs Report: How the Internet of Things Can Save the American Healthcare System $305 Billion Annually\". Engage Mobile Blog. Engage Mobile Solutions, LLC. 23 June 2016. Retrieved 26 July 2018.\\n\\n^ World Health Organization. \"mHealth. New horizons for health through mobile technologies\" (PDF). World Health Organization. Retrieved 3 January 2020.\\n\\n^ Istepanian, R.; Hu, S.; Philip, N.; Sungoor, A. (2011). \"The potential of Internet of m-health Things \"m-IoT\" for non-invasive glucose level sensing\". 2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference. Vol.\\xa02011. pp.\\xa05264–6. doi:10.1109/IEMBS.2011.6091302. ISBN\\xa0978-1-4577-1589-1. PMID\\xa022255525. S2CID\\xa0995488.\\n\\n^ Swan, Melanie (8 November 2012). \"Sensor Mania! The Internet of Things, Wearable Computing, Objective Metrics, and the Quantified Self 2.0\". Journal of Sensor and Actuator Networks. 1 (3): 217–253. doi:10.3390/jsan1030217.\\n\\n^ Taiwan Information Strategy, Internet and E-commerce Development Handbook - Strategic Information, Regulations, Contacts. IBP, Inc. USA. 2016. p.\\xa079. ISBN\\xa0978-1514521021.\\n\\n^ Grell, Max; Dincer, Can; Le, Thao; Lauri, Alberto; Nunez Bajo, Estefania; Kasimatis, Michael; Barandun, Giandrin; Maier, Stefan A.; Cass, Anthony E. G. (2019). \"Autocatalytic Metallization of Fabrics Using Si Ink, for Biosensors, Batteries and Energy Harvesting\". Advanced Functional Materials. 29 (1): 1804798. doi:10.1002/adfm.201804798. ISSN\\xa01616-301X. PMC\\xa07384005. PMID\\xa032733177.\\n\\n^ Dincer, Can; Bruch, Richard; Kling, André; Dittrich, Petra S.; Urban, Gerald A. (1 August 2017). \"Multiplexed Point-of-Care Testing – xPOCT\". Trends in Biotechnology. 35 (8): 728–742. doi:10.1016/j.tibtech.2017.03.013. ISSN\\xa00167-7799. PMC\\xa05538621. PMID\\xa028456344.\\n\\n^ \"What is HIE? | HealthIT.gov\". www.healthit.gov. Retrieved 21 January 2020.\\n\\n^ Amiot, Emmanuel. \"The Internet of Things. Disrupting Traditional Business Models\" (PDF). Oliver Wyman. Retrieved 14 October 2018.\\n\\n^ Vermesan, Ovidiu, and Peter Friess, eds. Internet of things: converging technologies for smart environments and integrated ecosystems. River Publisher, 2013. https://www.researchgate.net/publication/272943881\\n\\n^ Mahmud, Khizir; Town, Graham E.; Morsalin, Sayidul; Hossain, M.J. (February 2018). \"Integration of electric vehicles and management in the internet of energy\". Renewable and Sustainable Energy Reviews. 82: 4179–4203. doi:10.1016/j.rser.2017.11.004.\\n\\n^ Xie, Xiao-Feng; Wang, Zun-Jing (2017). \"Integrated in-vehicle decision support system for driving at signalized intersections: A prototype of smart IoT in transportation\". Transportation Research Board (TRB) Annual Meeting, Washington, DC, USA.\\n\\n^ \"Key Applications of the Smart IoT to Transform Transportation\". 20 September 2016.\\n\\n^ a b c d Haase, Jan; Alahmad, Mahmoud; Nishi, Hiroaki; Ploennigs, Joern; Tsang, Kim Fung (2016). \"The IOT mediated built environment: A brief survey\". 2016 IEEE 14th International Conference on Industrial Informatics (INDIN). pp.\\xa01065–1068. doi:10.1109/INDIN.2016.7819322. ISBN\\xa0978-1-5090-2870-2. S2CID\\xa05554635.\\n\\n^ Yang, Chen; Shen, Weiming; Wang, Xianbin (January 2018). \"The Internet of Things in Manufacturing: Key Issues and Potential Applications\". IEEE Systems, Man, and Cybernetics Magazine. 4 (1): 6–15. doi:10.1109/MSMC.2017.2702391. S2CID\\xa042651835.\\n\\n^ Severi, S.; Abreu, G.; Sottile, F.; Pastrone, C.; Spirito, M.; Berens, F. (23–26 June 2014). \"M2M Technologies: Enablers for a Pervasive Internet of Things\". The European Conference on Networks and Communications (EUCNC2014).\\n\\n^ a b Gubbi, Jayavardhana; Buyya, Rajkumar; Marusic, Slaven; Palaniswami, Marimuthu (24 February 2013). \"Internet of Things (IoT): A vision, architectural elements, and future directions\". Future Generation Computer Systems. 29 (7): 1645–1660. arXiv:1207.0203. doi:10.1016/j.future.2013.01.010. S2CID\\xa0204982032.\\n\\n^ Tan, Lu; Wang, Neng (20–22 August 2010). Future Internet: The Internet of Things. 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE). Vol.\\xa05. pp.\\xa0376–380. doi:10.1109/ICACTE.2010.5579543. ISBN\\xa0978-1-4244-6539-2. S2CID\\xa040587.\\n\\n^ \"Industrialized Construction in Academia\" (PDF). Autodesk.\\n\\n^ Meola, A. (20 December 2016). \"Why IoT, big data & smart farming are the future of agriculture\". Business Insider. Insider, Inc. Retrieved 26 July 2018.\\n\\n^ Zhang, Q. (2015). Precision Agriculture Technology for Crop Farming. CRC Press. pp.\\xa0249–58. ISBN\\xa09781482251081.\\n\\n^ \"Google goes bilingual, Facebook fleshes out translation and TensorFlow is dope ~ And, Microsoft is assisting fish farmers in Japan\". The Register.\\n\\n^ Vasisht, Deepak; Kapetanovic, Zerina; Won, Jongho; Jin, Xinxin; Chandra, Ranveer; Sinha, Sudipta; Kapoor, Ashish; Sudarshan, Madhusudhan; Stratman, Sean (2017). FarmBeats: An IoT Platform for Data-Driven Agriculture. pp.\\xa0515–529. ISBN\\xa0978-1-931971-37-9.\\n\\n^ \"FarmBeats: AI, Edge & IoT for Agriculture\". Microsoft Research. Retrieved 28 June 2021.\\n\\n^ \"Monitoring apps: How the Internet of Things can turn your boat into a smart boat\". Yachting World. 9 March 2020.\\n\\n^ Chui, Michael; Löffler, Markus; Roberts, Roger. \"The Internet of Things\". McKinsey Quarterly. McKinsey & Company. Retrieved 10 July 2014.\\n\\n^ \"Smart Trash\". Postscapes. Retrieved 10 July 2014.\\n\\n^ Poon, L. (22 June 2018). \"Sleepy in Songdo, Korea\\'s Smartest City\". CityLab. Atlantic Monthly Group. Retrieved 26 July 2018.\\n\\n^ Rico, Juan (22–24 April 2014). \"Going beyond monitoring and actuating in large scale smart cities\". NFC & Proximity Solutions – WIMA Monaco.\\n\\n^ \"A vision for a city today, a city of vision tomorrow\". Sino-Singapore Guangzhou Knowledge City. Retrieved 11 July 2014.\\n\\n^ \"San Jose Implements Intel Technology for a Smarter City\". Intel Newsroom. Retrieved 11 July 2014.\\n\\n^ \"Western Singapore becomes test-bed for smart city solutions\". Coconuts Singapore. 19 June 2014. Retrieved 11 July 2014.\\n\\n^ Higginbotham, Stacey. \"A group of wireless execs aim to build a nationwide network for the Internet of things\". Fortune.com. Retrieved 8 June 2019.\\n\\n^ Freeman, Mike (9 September 2015). \"On-Ramp Wireless becomes Ingenu, launches nationwide IoT network\". SanDiegoUnionTribune.com. Retrieved 8 June 2019.\\n\\n^ Lipsky, Jessica. \"IoT Clash Over 900 MHz Options\". EETimes. Retrieved 15 May 2015.\\n\\n^ Alleven, Monica. \"Sigfox launches IoT network in 10 UK cities\". Fierce Wireless Tech. Retrieved 13 May 2015.\\n\\n^ Merritt, Rick. \"13 Views of IoT World\". EETimes. Retrieved 15 May 2015.\\n\\n^ Fitchard, Kevin (20 May 2014). \"Sigfox brings its internet of things network to San Francisco\". Gigaom. Retrieved 15 May 2015.\\n\\n^ Ujaley, Mohd (25 July 2018). \"Cisco To Invest in Fiber Grid, IoT, Smart Cities in Andhra Pradesh\". ProQuest\\xa01774166769.\\n\\n^ \"STE Security Innovation Awards Honorable Mention: The End of the Disconnect\". securityinfowatch.com. Retrieved 12 August 2015.\\n\\n^ Parello, J.; Claise, B.; Schoening, B.; Quittek, J. (28 April 2014). \"Energy Management Framework\". IETF Internet Draft.\\n\\n^ Davies, Nicola. \"How the Internet of Things will enable \\'smart buildings\\'\". Extreme Tech.\\n\\n^ \"Molluscan eye\". Retrieved 26 June 2015.\\n\\n^ Li, Shixing; Wang, Hong; Xu, Tao; Zhou, Guiping (2011). Application Study on Internet of Things in Environment Protection Field (Submitted manuscript). Lecture Notes in Electrical Engineering. Vol.\\xa0133. pp.\\xa099–106. doi:10.1007/978-3-642-25992-0_13. ISBN\\xa0978-3-642-25991-3.\\n\\n^ \"Use case: Sensitive wildlife monitoring\". FIT French Project. Archived from the original on 14 July 2014. Retrieved 10 July 2014.\\n\\n^ Hart, Jane K.; Martinez, Kirk (1 May 2015). \"Toward an environmental Internet of Things\". Earth and Space Science. 2 (5): 194–200. Bibcode:2015E&SS....2..194H. doi:10.1002/2014EA000044.\\n\\n^ a b Scuotto, Veronica; Ferraris, Alberto; Bresciani, Stefano (4 April 2016). \"Internet of Things\". Business Process Management Journal. 22 (2): 357–367. doi:10.1108/bpmj-05-2015-0074. ISSN\\xa01463-7154.\\n\\n^ Cameron, Lori. \"Internet of Things Meets the Military and Battlefield: Connecting Gear and Biometric Wearables for an IoMT and IoBT\". IEEE Computer Society. Retrieved 31 October 2019.\\n\\n^ \"Army Takes on Wicked Problems With the Internet of Battlefield Things\". MeriTalk. 30 January 2018. Retrieved 31 October 2019.\\n\\n^ Gudeman, Kim (6 October 2017). \"Next-Generation Internet of Battle things (IoBT) Aims to Help Keep Troops and Civilians Safe\". ECE Illinois. Retrieved 31 October 2019.\\n\\n^ \"Internet of Battlefield Things (IOBT)\". CCDC Army Research Laboratory. Retrieved 31 October 2019.\\n\\n^ \"DARPA Floats a Proposal for the Ocean of Things\". MeriTalk. 3 January 2018. Retrieved 31 October 2019.\\n\\n^ \"How to make smart packaging even smarter\". Packaging Digest. 4 June 2018. Retrieved 28 April 2020.\\n\\n^ foodnavigator-asia.com. \"Connecting with consumers: The benefits - and dangers - of smart packaging for the F&B industry\". foodnavigator-asia.com. Retrieved 28 April 2020.\\n\\n^ confectionerynews.com. \"Which smart packaging technologies are readily available in 2018\". confectionerynews.com. Retrieved 28 April 2020.\\n\\n^ Chen, Changsheng; Li, Mulin; Ferreira, Anselmo; Huang, Jiwu; Cai, Rizhao (2020). \"A Copy-Proof Scheme Based on the Spectral and Spatial Barcoding Channel Models\". IEEE Transactions on Information Forensics and Security. 15: 1056–1071. doi:10.1109/tifs.2019.2934861. ISSN\\xa01556-6013. S2CID\\xa0201903693.\\n\\n^ \"MIT unveils battery-free crypto tag for anti-counterfeit\". www.securingindustry.com. 26 February 2020. Retrieved 28 April 2020.\\n\\n^ a b Nordrum, Amy (18 August 2016). \"Popular Internet of Things Forecast of 50 Billion Devices by 2020 Is Outdated\". IEEE Spectrum.\\n\\n^ Vermesan, Ovidiu; Friess, Peter (2013). Internet of Things: Converging Technologies for Smart Environments and Integrated Ecosystems (PDF). Aalborg, Denmark: River Publishers. ISBN\\xa0978-87-92982-96-4.\\n\\n^ Santucci, Gérald. \"The Internet of Things: Between the Revolution of the Internet and the Metamorphosis of Objects\" (PDF). European Commission Community Research and Development Information Service. Retrieved 23 October 2016.\\n\\n^ Mattern, Friedemann; Floerkemeier, Christian. \"From the Internet of Computers to the Internet of Things\" (PDF). ETH Zurich. Retrieved 23 October 2016.\\n\\n^ Lindner, Tim (13 July 2015). \"The Supply Chain: Changing at the Speed of Technology\". Connected World. Retrieved 18 September 2015.\\n\\n^ a b Köhn, Rüdiger. \"Online-Kriminalität: Konzerne verbünden sich gegen Hacker\". Faz.net.\\n\\n^ Hsu, Chin-Lung; Lin, Judy Chuan-Chuan (2016). \"An empirical examination of consumer adoption of Internet of Things services: Network externalities and concern for information privacy perspectives\". Computers in Human Behavior. 62: 516–527. doi:10.1016/j.chb.2016.04.023.\\n\\n^ \"Smarter Things: The Autonomous IoT\". GDR Blog. GDR Creative Intelligence. 5 January 2018. Retrieved 26 July 2018.\\n\\n^ Levine, Sergey; Finn, Chelsea; Darrell, Trevor; Abbeel, Pieter (2016). \"End-to-End Training of Deep Visuomotor Policies\" (PDF). The Journal of Machine Learning Research. 17 (1): 1334–1373. arXiv:1504.00702. Bibcode:2015arXiv150400702L.\\n\\n^ a b Mohammadi, Mehdi; Al-Fuqaha, Ala; Sorour, Sameh; Guizani, Mohsen (2018). \"Deep Learning for IoT Big Data and Streaming Analytics: A Survey\". IEEE Communications Surveys & Tutorials. 20 (4): 2923–2960. arXiv:1712.04301. doi:10.1109/COMST.2018.2844341. S2CID\\xa09461213.\\n\\n^ Mahdavinejad, Mohammad Saeid; Rezvan, Mohammadreza; Barekatain, Mohammadamin; Adibi, Peyman; Barnaghi, Payam; Sheth, Amit P. (2018). \"Machine learning for internet of things data analysis: A survey\". Digital Communications and Networks. 4 (3): 161–175. arXiv:1802.06305. Bibcode:2018arXiv180206305S. doi:10.1016/j.dcan.2017.10.002. S2CID\\xa02666574.\\n\\n^ Alippi, C. (2014). Intelligence for Embedded Systems. Springer Verlag. ISBN\\xa0978-3-319-05278-6.\\n\\n^ Delicato, F.C.; Al-Anbuky, A.; Wang, K., eds. (2018). Smart Cyber-Physical Systems: towards Pervasive Intelligence systems. Future Generation Computer Systems. Elsevier. Retrieved 26 July 2018.\\n\\n^ a b c d Traukina, Alena; Thomas, Jayant; Tyagi, Prashant; Reddipalli, Kishore (29 September 2018). Industrial Internet Application Development: Simplify IIoT development using the elasticity of Public Cloud and Native Cloud Services (1st\\xa0ed.). Packt Publishing. p.\\xa018.\\n\\n^ Hassan, Qusay; Khan, Atta; Madani, Sajjad (2018). Internet of Things: Challenges, Advances, and Applications. Boca Raton, Florida: CRC Press. p.\\xa0198. ISBN\\xa09781498778510.\\n\\n^ Chauhuri, Abhik (2018). Internet of Things, for Things, and by Things. Boca Raton, Florida: CRC Press. ISBN\\xa09781138710443.\\n\\n^ Pal, Arpan (May–June 2015). \"Internet of Things: Making the Hype a Reality\" (PDF). IT Pro. 17 (3): 2–4. doi:10.1109/MITP.2015.36. Retrieved 10 April 2016.\\n\\n^ \"Gartner Says 6.4 Billion Connected \"Things\" Will Be in Use in 2016, Up 30 Percent From 2015\". Gartner. 10 November 2015. Archived from the original on 12 November 2015. Retrieved 21 April 2016.\\n\\n^ Reza Arkian, Hamid (2017). \"MIST: Fog-based Data Analytics Scheme with Cost-Efficient Resource Provisioning for IoT Crowdsensing Applications\". Journal of Network and Computer Applications. 82: 152–165. doi:10.1016/j.jnca.2017.01.012.\\n\\n^ \"IoT The outer Edge Computing\". June 2019. Retrieved 3 June 2019. {{cite journal}}: Cite journal requires |journal= (help)\\n\\n^ Cui, Laizhong; Yang, Shu; Chen, Ziteng; Pan, Yi; Ming, Zhong; Xu, Mingwei (May 2020). \"A Decentralized and Trusted Edge Computing Platform for Internet of Things\". IEEE Internet of Things Journal. 7 (5): 3910–3922. doi:10.1109/JIOT.2019.2951619. ISSN\\xa02327-4662. S2CID\\xa0209097962.\\n\\n^ Nguyen, Tien-Dung; Huh, Eui-Nam; Jo, Minho (June 2019). \"Decentralized and Revised Content-Centric Networking-Based Service Deployment and Discovery Platform in Mobile Edge Computing for IoT Devices\". IEEE Internet of Things Journal. 6 (3): 4162–4175. doi:10.1109/JIOT.2018.2875489. ISSN\\xa02327-4662. S2CID\\xa069250756.\\n\\n^ Xiong, Zehui; Zhang, Yang; Luong, Nguyen Cong; Niyato, Dusit; Wang, Ping; Guizani, Nadra (January 2020). \"The Best of Both Worlds: A General Architecture for Data Management in Blockchain-enabled Internet-of-Things\". IEEE Network. 34 (1): 166–173. doi:10.1109/MNET.001.1900095. ISSN\\xa01558-156X. S2CID\\xa0211050783.\\n\\n^ Alhaizaey, Yousef; Singer, Jeremy; Michala, Anna Lito (June 2021). \"Optimizing Task Allocation for Edge Micro-Clusters in Smart Cities\". 2021 IEEE 22nd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM): 341–347. doi:10.1109/WoWMoM51794.2021.00062. ISBN\\xa0978-1-6654-2263-5. S2CID\\xa0235780952.\\n\\n^ Guo, Hongzhi; Liu, Jiajia; Qin, Huiling (January 2018). \"Collaborative Mobile Edge Computation Offloading for IoT over Fiber-Wireless Networks\". IEEE Network. 32 (1): 66–71. doi:10.1109/MNET.2018.1700139. ISSN\\xa01558-156X. S2CID\\xa012479631.\\n\\n^ Messaoud, Seifeddine; Bradai, Abbas; Bukhari, Syed Hashim Raza; Quang, Pham Tran Anh; Ahmed, Olfa Ben; Atri, Mohamed (1 December 2020). \"A survey on machine learning in Internet of Things: Algorithms, strategies, and applications\". Internet of Things. 12: 100314. doi:10.1016/j.iot.2020.100314. ISSN\\xa02542-6605. S2CID\\xa0228876304.\\n\\n^ Cherupally, Sumanth Reddy; Boga, Srinivas; Podili, Prashanth; Kataoka, Kotaro (January 2021). \"Lightweight and Scalable DAG based distributed ledger for verifying IoT data integrity\". 2021 International Conference on Information Networking (ICOIN): 267–272. doi:10.1109/ICOIN50884.2021.9334000. ISBN\\xa0978-1-7281-9101-0. S2CID\\xa0231825899.\\n\\n^ Fan, Xinxin; Chai, Qi; Xu, Lei; Guo, Dong (6 October 2020). \"DIAM-IoT: A Decentralized Identity and Access Management Framework for Internet of Things\". Proceedings of the 2nd ACM International Symposium on Blockchain and Secure Critical Infrastructure. BSCI \\'20. Taipei, Taiwan: Association for Computing Machinery: 186–191. doi:10.1145/3384943.3409436. ISBN\\xa0978-1-4503-7610-5. S2CID\\xa0222142832.\\n\\n^ Durand, Arnaud; Gremaud, Pascal; Pasquier, Jacques (22 October 2017). \"Decentralized web of trust and authentication for the internet of things\". Proceedings of the Seventh International Conference on the Internet of Things. IoT \\'17. Linz, Austria: Association for Computing Machinery: 1–2. doi:10.1145/3131542.3140263. ISBN\\xa0978-1-4503-5318-2. S2CID\\xa03645848.\\n\\n^ Rathore, Shailendra; Wook Kwon, Byung; Park, Jong Hyuk (1 October 2019). \"BlockSecIoTNet: Blockchain-based decentralized security architecture for IoT network\". Journal of Network and Computer Applications. 143: 167–177. doi:10.1016/j.jnca.2019.06.019. ISSN\\xa01084-8045. S2CID\\xa0198365021.\\n\\n^ a b Gautier, Philippe; Gonzalez, Laurent (2011). L\\'Internet des Objets... Internet, mais en mieux (PDF). Foreword by Gérald Santucci (European commission), postword by Daniel Kaplan (FING) and Michel Volle. Paris: AFNOR editions. ISBN\\xa0978-2-12-465316-4.\\n\\n^ Marginean, M.-T.; Lu, C. (2016). \"sDOMO communication protocol for home robotic systems in the context of the internet of things\". Computer Science, Technology And Application. World Scientific. pp.\\xa0151–60. ISBN\\xa09789813200432.\\n\\n^ Montazerolghaem, Ahmadreza (2021). \"Software-defined Internet of Multimedia Things: Energy-efficient and Load-balanced Resource Management\". IEEE Internet of Things Journal. 9 (3): 2432–2442. doi:10.1109/JIOT.2021.3095237. ISSN\\xa02327-4662. S2CID\\xa0237801052.\\n\\n^ Rowayda, A. Sadek (May 2018). \"– An Agile Internet of Things (IoT) based Software Defined Network (SDN) Architecture\" (PDF). Egyptian Computer Science Journal.\\n\\n^ Waldner, Jean-Baptiste (2007). Nanoinformatique et intelligence ambiante. Inventer l\\'Ordinateur du XXIeme Siècle. London: Hermes Science. p.\\xa0254. ISBN\\xa0978-2-7462-1516-0.\\n\\n^ Montazerolghaem, Ahmadreza; Yaghmaee, Mohammad Hossein (April 2020). \"Load-Balanced and QoS-Aware Software-Defined Internet of Things\". IEEE Internet of Things Journal. 7 (4): 3323–3337. doi:10.1109/JIOT.2020.2967081. ISSN\\xa02327-4662. S2CID\\xa0214551067.\\n\\n^ \"OGC SensorThings API standard specification\". OGC. Retrieved 15 February 2016.\\n\\n^ \"OGC Sensor Web Enablement: Overview And High Level Architecture\". OGC. Retrieved 15 February 2016.\\n\\n^ Minteer, A. (2017). \"Chapter 9: Applying Geospatial Analytics to IoT Data\". Analytics for the Internet of Things (IoT). Packt Publishing. pp.\\xa0230–57. ISBN\\xa09781787127579.\\n\\n^ van der Zee, E.; Scholten, H. (2014). \"Spatial Dimensions of Big Data: Application of Geographical Concepts and Spatial Technology to the Internet of Things\".  In Bessis, N.; Dobre, C. (eds.). Big Data and Internet of Things: A Roadmap for Smart Environments. Springer. pp.\\xa0137–68. ISBN\\xa09783319050294.\\n\\n^ a b Gassée, J.-L. (12 January 2014). \"Internet of Things: The \"Basket of Remotes\" Problem\". Monday Note. Retrieved 26 June 2015.\\n\\n^ de Sousa, M. (2015). \"Chapter 10: Integrating with Muzzley\". Internet of Things with Intel Galileo. Packt Publishing. p.\\xa0163. ISBN\\xa09781782174912.\\n\\n^ \"Social IoT\". Enabling the Internet of Things. ieeexplore.ieee.org. 2021. pp.\\xa0195–211. doi:10.1002/9781119701460.ch9. ISBN\\xa09781119701255. S2CID\\xa0240696468. Retrieved 9 July 2021.\\n\\n^ Saleem, Yasir; Crespi, Noel; Pace, Pasquale (April 2018). \"SCDIoT: Social Cross-Domain IoT Enabling Application-to-Application Communications\". 2018 IEEE International Conference on Cloud Engineering (IC2E). Orlando, FL: IEEE: 346–350. doi:10.1109/IC2E.2018.00068. ISBN\\xa0978-1-5386-5008-0. S2CID\\xa021720322.\\n\\n^ a b c Afzal, Bilal; Umair, Muhammad; Asadullah Shah, Ghalib; Ahmed, Ejaz (March 2019). \"Enabling IoT platforms for social IoT applications: Vision, feature mapping, and challenges\". Future Generation Computer Systems. 92: 718–731. doi:10.1016/j.future.2017.12.002. S2CID\\xa057379503.\\n\\n^ Bhatia, Munish; Sood, Sandeep K. (June 2020). \"Quantum Computing-Inspired Network Optimization for IoT Applications\". IEEE Internet of Things Journal. 7 (6): 5590–5598. doi:10.1109/JIOT.2020.2979887. ISSN\\xa02327-4662. S2CID\\xa0215845606.\\n\\n^ Cheng, Wai Khuen; Ileladewa, Adeoye Abiodun; Tan, Teik Boon (January 2019). \"A Personalized Recommendation Framework for Social Internet of Things (SIoT)\". 2019 International Conference on Green and Human Information Technology (ICGHIT): 24–29. doi:10.1109/ICGHIT.2019.00013. ISBN\\xa0978-1-7281-0627-4. S2CID\\xa0204702019.\\n\\n^ Atzori, Luigi; Iera, Antonio; Morabito, Giacomo; Nitti, Michele (14 November 2012). \"The Social Internet of Things (SIoT) – When social networks meet the Internet of Things: Concept, architecture and network characterization\". Computer Networks. 56 (16): 3594–3608. doi:10.1016/j.comnet.2012.07.010. ISSN\\xa01389-1286.\\n\\n^ Khelloufi, Amar; Ning, Huansheng; Dhelim, Sahraoui; Qiu, Tie; Ma, Jianhua; Huang, Runhe; Atzori, Luigi (1 February 2021). \"A Social-Relationships-Based Service Recommendation System for SIoT Devices\". IEEE Internet of Things Journal. 8 (3): 1859–1870. doi:10.1109/JIOT.2020.3016659. ISSN\\xa02327-4662. S2CID\\xa0226476576.\\n\\n^ Miori, Vittorio; Russo, Dario (June 2017). \"Improving life quality for the elderly through the Social Internet of Things (SIoT)\". 2017 Global Internet of Things Summit (GIoTS). Geneva, Switzerland: IEEE: 1–6. doi:10.1109/GIOTS.2017.8016215. ISBN\\xa0978-1-5090-5873-0. S2CID\\xa07475703.\\n\\n^ Udawant, Omkar; Thombare, Nikhil; Chauhan, Devanand; Hadke, Akash; Waghole, Dattatray (December 2017). \"Smart ambulance system using IoT\". 2017 International Conference on Big Data, IoT and Data Science (BID). Pune, India: IEEE: 171–176. doi:10.1109/BID.2017.8336593. ISBN\\xa0978-1-5090-6593-6. S2CID\\xa04865714.\\n\\n^ Saleem, Yasir; Crespi, Noel; Rehmani, Mubashir Husain; Copeland, Rebecca; Hussein, Dina; Bertin, Emmanuel (December 2016). \"Exploitation of social IoT for recommendation services\". 2016 IEEE 3rd World Forum on Internet of Things (WF-IoT). Reston, VA, USA: IEEE: 359–364. doi:10.1109/WF-IoT.2016.7845500. ISBN\\xa0978-1-5090-4130-5. S2CID\\xa0206866361.\\n\\n^ Andrade, Rossana M.C.; Aragão, Belmondo R.; Oliveira, Pedro Almir M.; Maia, Marcio E.F.; Viana, Windson; Nogueira, Tales P. (April 2021). \"Multifaceted infrastructure for self-adaptive IoT systems\". Information and Software Technology. 132: 106505. doi:10.1016/j.infsof.2020.106505. S2CID\\xa0231731945.\\n\\n^ Farahbakhsh, Bahareh; Fanian, Ali; Manshaei, Mohammad Hossein (March 2021). \"TGSM: Towards trustworthy group-based service management for social IoT\". Internet of Things. 13: 100312. doi:10.1016/j.iot.2020.100312. ISSN\\xa02542-6605. S2CID\\xa0228806944.\\n\\n^ Iqbal, Muhammad Azhar; Hussain, Sajjad; Xing, Huanlai; Imran, Muhammad (February 2021). Enabling the Internet of Things: Fundamentals, Design, and Applications (1\\xa0ed.). Wiley. doi:10.1002/9781119701460.ch9. ISBN\\xa0978-1-119-70125-5. S2CID\\xa0240696468.\\n\\n^ Want, Roy; Schilit, Bill N.; Jenson, Scott (2015). \"Enabling the Internet of Things\". Computer. 48: 28–35. doi:10.1109/MC.2015.12. S2CID\\xa017384656.\\n\\n^ \"The Internet of Things: a jumbled mess or a jumbled mess?\". The Register. Retrieved 5 June 2016.\\n\\n^ \"Can we talk? Internet of Things vendors face a communications \\'mess\\'\". Computerworld. 18 April 2014. Retrieved 5 June 2016.\\n\\n^ Hassan, Q.F. (2018). Internet of Things A to Z: Technologies and Applications. John Wiley & Sons. pp.\\xa027–8. ISBN\\xa09781119456759.\\n\\n^ Dan Brickley et al., c. 2001\\n\\n^ Sheng, M.; Qun, Y.; Yao, L.; Benatallah, B. (2017). Managing the Web of Things: Linking the Real World to the Web. Morgan Kaufmann. pp.\\xa0256–8. ISBN\\xa09780128097656.\\n\\n^ Waldner, Jean-Baptiste (2008). Nanocomputers and Swarm Intelligence. London: ISTE. pp.\\xa0227–231. ISBN\\xa0978-1-84704-002-2.\\n\\n^ a b Kushalnagar, N.; Montenegro, G.; Schumacher, C. (August 2007). IPv6 over Low-Power Wireless Personal Area Networks (6LoWPANs): Overview, Assumptions, Problem Statement, and Goals. IETF. doi:10.17487/RFC4919. RFC 4919.\\n\\n^ a b Sun, Charles C. (1 May 2014). \"Stop using Internet Protocol Version 4!\". Computerworld.\\n\\n^ Thomson, S.; Narten, T.; Jinmei, T. (September 2007). IPv6 Stateless Address Autoconfiguration. IETF. doi:10.17487/RFC4862. RFC 4862.\\n\\n^ Xped Limited, ADRC Overview\", from Wikipedia\\n\\n^ Alsulami, M. M.; Akkari, N. (April 2018). \"The role of 5G wireless networks in the internet-of- things (IoT)\". 2018 1st International Conference on Computer Applications Information Security (ICCAIS): 1–8. doi:10.1109/CAIS.2018.8471687. ISBN\\xa0978-1-5386-4427-0. S2CID\\xa052897932.\\n\\n^ Jing, J.; Li, H. (2012). \"Research on the Relevant Standards of Internet of Things\".  In Wang, Y.; Zhang, X. (eds.). Internet of Things: International Workshop, IOT 2012. Springer. pp.\\xa0627–32. ISBN\\xa09783642324277.\\n\\n^ Mahmood, Z. (2018). Connected Environments for the Internet of Things: Challenges and Solutions. Springer. pp.\\xa089–90. ISBN\\xa09783319701028.\\n\\n^ \"Project Connected Home over IP\". Google Developers Blog. Retrieved 16 September 2020.\\n\\n^ Mihalcik, Carrie. \"Apple, Amazon, Google, and others want to create a new standard for smart home tech\". CNET. Retrieved 24 December 2019.\\n\\n^ Strategy, Moor Insights and. \"CHIP Shot: Will Project Connected Home Over IP Get Us Onto The IoT Green?\". Forbes. Retrieved 3 September 2020.\\n\\n^ \"Digital Link - Standards | GS1\". www.gs1.org. 12 November 2018. Retrieved 28 April 2020.\\n\\n^ \"P1451-99 - Standard for Harmonization of Internet of Things (IoT) Devices and Systems\". IEEE. Retrieved 26 July 2021.\\n\\n^ Howard, Philip N. (1 June 2015). \"The Internet of Things is Posed to Change Democracy Itself\". Politico. Retrieved 8 August 2017.\\n\\n^ Thompson, Kirsten; Mattalo, Brandon (24 November 2015). \"The Internet of Things: Guidance, Regulation and the Canadian Approach\". CyberLex. Retrieved 23 October 2016.\\n\\n^ \"The Question of Who Owns the Data Is About to Get a Lot Trickier\". Fortune. 6 April 2016. Retrieved 23 October 2016.\\n\\n^ Weber, R.H.; Weber, R. (2010). Internet of Things: Legal Perspectives. Springer Science & Business Media. pp.\\xa059–64. ISBN\\xa09783642117107.\\n\\n^ Hassan, Q.F. (2018). Internet of Things A to Z: Technologies and Applications. John Wiley & Sons. pp.\\xa041–4. ISBN\\xa09781119456759.\\n\\n^ Hassan, Q.F.; Khan, A. ur R.; Madani, S.A. (2017). Internet of Things: Challenges, Advances, and Applications. CRC Press. pp.\\xa041–2. ISBN\\xa09781498778534.\\n\\n^ Lopez, Javier; Rios, Ruben; Bao, Feng; Wang, Guilin (2017). \"Evolving privacy: From sensors to the Internet of Things\". Future Generation Computer Systems. 75: 46–57. doi:10.1016/j.future.2017.04.045.\\n\\n^ \"The \\'Internet of Things\\': Legal Challenges in an Ultra-connected World\". Mason Hayes & Curran. 22 January 2016. Retrieved 23 October 2016.\\n\\n^ Brown, Ian (2015). \"Regulation and the Internet of Things\" (PDF). Oxford Internet Institute. Retrieved 23 October 2016.\\n\\n^ \"FTC Report on Internet of Things Urges Companies to Adopt Best Practices to Address Consumer Privacy and Security Risks\". Federal Trade Commission. 27 January 2015. Retrieved 23 October 2016.\\n\\n^ Lawson, Stephen (2 March 2016). \"IoT users could win with a new bill in the US Senate\". Tech Barrista. Retrieved 9 December 2019.\\n\\n^ \"California Legislative Information – SB-327 Information privacy: connected devices\".\\n\\n^ Pittman, F. Paul (2 February 2016). \"Legal Developments in Connected Car Arena Provide Glimpse of Privacy and Data Security Regulation in Internet of Things\". Lexology. Retrieved 23 October 2016.\\n\\n^ Rasit, Yuce, Mehmet; Claus, Beisswenger, Stefan; Mangalam, Srikanth; Das, Prasanna, Lal; Martin, Lukac (2 November 2017). \"Internet of things\\xa0: the new government to business platform – a review of opportunities, practices, and challenges\": 1–112. {{cite journal}}: Cite journal requires |journal= (help)\\n\\n^ a b Page, Carly (4 December 2021). \"Is the UK government\\'s new IoT cybersecurity bill fit for purpose?\". TechCrunch. Retrieved 4 December 2021.\\n\\n^ Wieland, Ken (25 February 2016). \"IoT experts fret over fragmentation\". Mobile World.\\n\\n^ Wallace, Michael (19 February 2016). \"Fragmentation is the enemy of the Internet of Things\". Qualcomm.com.\\n\\n^ Bauer, Harald; Patel, Mark; Veira, Jan (October 2015). \"Internet of Things: Opportunities and challenges for semiconductor companies\". McKinsey & Co.\\n\\n^ Ardiri, Aaron (8 July 2014). \"Will fragmentation of standards only hinder the true potential of the IoT industry?\". evothings.com.\\n\\n^ \"IOT Brings Fragmentation in Platform\" (PDF). arm.com.\\n\\n^ Raggett, Dave (27 April 2016). \"Countering Fragmentation with the Web of Things: Interoperability across IoT platforms\" (PDF). W3C.\\n\\n^ Kovach, Steve (30 July 2013). \"Android Fragmentation Report\". Business Insider. Retrieved 19 October 2013.\\n\\n^ \"Ultimate Guide to Internet of Things (IoT) Connectivity\".\\n\\n^ Piedad, Floyd N. \"Will Android fragmentation spoil its IoT appeal?\". TechBeacon.\\n\\n^ Franceschi-Bicchierai, Lorenzo (29 July 2015). \"Goodbye, Android\". Motherboard. Vice.\\n\\n^ Kingsley-Hughes, Adrian. \"The toxic hellstew survival guide\". ZDnet. Retrieved 2 August 2015.\\n\\n^ Tung, Liam (13 October 2015). \"Android security a \\'market for lemons\\' that leaves 87 percent vulnerable\". ZDNet. Retrieved 14 October 2015.\\n\\n^ Thomas, Daniel R.; Beresford, Alastair R.; Rice, Andrew (2015). Proceedings of the 5th Annual ACM CCS Workshop on Security and Privacy in Smartphones and Mobile Devices – SPSM \\'15 (PDF). Computer Laboratory, University of Cambridge. pp.\\xa087–98. doi:10.1145/2808117.2808118. ISBN\\xa09781450338196. S2CID\\xa014832327. Retrieved 14 October 2015.\\n\\n^ Howard, Philip N. (2015). Pax Technica: How the internet of things May Set Us Free, Or Lock Us Up. New Haven, CT: Yale University Press. ISBN\\xa0978-0-30019-947-5.\\n\\n^ McEwan, Adrian (2014). \"Designing the Internet of Things\" (PDF). Retrieved 1 June 2016.\\n\\n^ Moy de Vitry, Matthew; Schneider, Mariane; Wani, Omar; Liliane, Manny; Leitao, João P.; Eggimann, Sven (2019). \"Smart urban water systems: what could possibly go wrong?\". Environmental Research Letters. 14 (8): 081001. Bibcode:2019ERL....14h1001M. doi:10.1088/1748-9326/ab3761.\\n\\n^ \"Panopticon as a metaphor for the internet of things\" (PDF). The Council of the Internet of Things. Retrieved 6 June 2016.\\n\\n^ a b \"Foucault\" (PDF). UCLA.\\n\\n^ \"Deleuze – 1992 – Postscript on the Societies of Control\" (PDF). UCLA.\\n\\n^ Verbeek, Peter-Paul (2011). Moralizing Technology: Understanding and Designing the Morality of Things. Chicago: The University of Chicago Press. ISBN\\xa0978-0-22685-291-1.\\n\\n^ Cardwell, Diane (18 February 2014). \"At Newark Airport, the Lights Are On, and They\\'re Watching You\". The New York Times.\\n\\n^ Hardy, Quentin (4 February 2015). \"Tim O\\'Reilly Explains the Internet of Things\". The New York Times.\\n\\n^ Webb, Geoff (5 February 2015). \"Say Goodbye to Privacy\". WIRED. Retrieved 15 February 2015.\\n\\n^ Crump, Catherine; Harwood, Matthew (25 March 2014). \"The Net Closes Around Us\". TomDispatch.\\n\\n^ Brown, Ian (12 February 2013). \"Britain\\'s Smart Meter Programme: A Case Study in Privacy by Design\". International Review of Law, Computers & Technology. 28 (2): 172–184. doi:10.1080/13600869.2013.801580. S2CID\\xa062756630. SSRN\\xa02215646.\\n\\n^ a b \"The Societal Impact of the Internet of Things\" (PDF). British Computer Society. 14 February 2013. Retrieved 23 October 2016.\\n\\n^ a b Gubbi, Jayavardhana; Buyya, Rajkumar; Marusic, Slaven; Palaniswami, Marimuthu (1 September 2013). \"Internet of Things (IoT): A vision, architectural elements, and future directions\". Future Generation Computer Systems. Including Special sections: Cyber-enabled Distributed Computing for Ubiquitous Cloud and Network Services & Cloud Computing and Scientific Applications – Big Data, Scalable Analytics, and Beyond. 29 (7): 1645–1660. arXiv:1207.0203. doi:10.1016/j.future.2013.01.010. S2CID\\xa0204982032.\\n\\n^ Acharjya, D.P.; Ahmed, N.S.S. (2017). \"Recognizing Attacks in Wireless Sensor Network in View of Internet of Things\".  In Acharjya, D.P.; Geetha, M.K. (eds.). Internet of Things: Novel Advances and Envisioned Applications. Springer. pp.\\xa0149–50. ISBN\\xa09783319534725.\\n\\n^ Hussain, A. (June 2017). \"Energy Consumption of Wireless IoT Nodes\" (PDF). Norwegian University of Science and Technology. Retrieved 26 July 2018.\\n\\n^ \"We Asked Executives About The Internet of Things And Their Answers Reveal That Security Remains A Huge Concern\". Business Insider. Retrieved 26 June 2015.\\n\\n^ Singh, Jatinder; Pasquier, Thomas; Bacon, Jean; Ko, Hajoon; Eyers, David (2015). \"Twenty Cloud Security Considerations for Supporting the Internet of Things\". IEEE Internet of Things Journal. 3 (3): 1. doi:10.1109/JIOT.2015.2460333. S2CID\\xa04732406.\\n\\n^ a b Clearfield, Chris. \"Why The FTC Can\\'t Regulate The Internet of Things\". Forbes. Retrieved 26 June 2015.\\n\\n^ a b Feamster, Nick (18 February 2017). \"Mitigating the Increasing Risks of an Insecure Internet of Things\". Freedom to Tinker. Retrieved 8 August 2017.\\n\\n^ Li, S. (2017). \"Chapter 1: Introduction: Securing the Internet of Things\".  In Li, S.; Xu, L.D. (eds.). Securing the Internet of Things. Syngress. p.\\xa04. ISBN\\xa09780128045053.\\n\\n^ Bastos, D.; Shackleton, M.; El-Moussa, F. (2018). \"Internet of Things: A Survey of Technologies and Security Risks in Smart Home and City Environments\". Living in the Internet of Things: Cybersecurity of the IoT - 2018. pp.\\xa030 (7 pp.). doi:10.1049/cp.2018.0030. ISBN\\xa09781785618437.\\n\\n^ Harbi, Yasmine; Aliouat, Zibouda; Harous, Saad; Bentaleb, Abdelhak; Refoufi, Allaoua (September 2019). \"A Review of Security in Internet of Things\". Wireless Personal Communications. 108 (1): 325–344. doi:10.1007/s11277-019-06405-y. ISSN\\xa00929-6212. S2CID\\xa0150181134.\\n\\n^ Liu, Ximeng; Yang, Yang; Choo, Kim-Kwang Raymond; Wang, Huaqun (24 September 2018). \"Security and Privacy Challenges for Internet-of-Things and Fog Computing\". Wireless Communications and Mobile Computing. 2018: 1–3. doi:10.1155/2018/9373961. ISSN\\xa01530-8669.\\n\\n^ Morrissey, Janet (22 January 2019). \"In the Rush to Join the Smart Home Crowd, Buyers Should Beware\". The New York Times. ISSN\\xa00362-4331. Retrieved 26 February 2020.\\n\\n^ Ahmadi, Mohsen; Kiaei, Pantea; Emamdoost, Navid (2021). SN4KE: Practical Mutation Testing at Binary Level (PDF) (MSc). NDSS Symposium 2021.\\n\\n^ Clearfield, Christopher (26 June 2013). \"Rethinking Security for the Internet of Things\". Harvard Business Review Blog.\\n\\n^ Witkovski, Adriano; Santin, Altair; Abreu, Vilmar; Marynowski, Joao (2014). \"An IdM and Key-Based Authentication Method for Providing Single Sign-On in IoT\". 2015 IEEE Global Communications Conference (GLOBECOM). pp.\\xa01–6. doi:10.1109/GLOCOM.2014.7417597. ISBN\\xa0978-1-4799-5952-5. S2CID\\xa08108114.\\n\\n^ Steinberg, Joseph (27 January 2014). \"These Devices May Be Spying on You (Even in Your Own Home)\". Forbes. Retrieved 27 May 2014.\\n\\n^ Greenberg, Andy (21 July 2015). \"Hackers Remotely Kill a Jeep on the Highway—With Me in It\". Wired. Retrieved 21 July 2015.\\n\\n^ Scientific American, April 2015, p.68.\\n\\n^ Loukas, George (June 2015). Cyber-Physical Attacks A growing invisible threat. Oxford, UK: Butterworh-Heinemann (Elsevier). p.\\xa065. ISBN\\xa09780128012901.\\n\\n^ Woolf, Nicky (26 October 2016). \"DDoS attack that disrupted internet was largest of its kind in history, experts say\". The Guardian.\\n\\n^ a b c d e Antonakakis, Manos; April, Tim; Bailey, Michael; Bernhard, Matt; Bursztein, Elie; Cochran, Jaime; Durumeric, Zakir; Halderman, J. Alex; Invernizzi, Luca (18 August 2017). Understanding the Mirai Botnet (PDF). Usenix. ISBN\\xa0978-1-931971-40-9. Retrieved 13 May 2018.\\n\\n^ \"The \"anti-patterns\" that turned the IoT into the Internet of Shit / Boing Boing\". boingboing.net. 3 May 2017.\\n\\n^ Ali, Junade (2 May 2017). \"IoT Security Anti-Patterns\". Cloudflare Blog.\\n\\n^ Schneier, Bruce (6 October 2016). \"We Need to Save the Internet from the Internet of Things\". Motherboard.\\n\\n^ \"Disruptive Technologies Global Trends 2025\" (PDF). National Intelligence Council (NIC). April 2008. p.\\xa027.\\n\\n^ Ackerman, Spencer (15 March 2012). \"CIA Chief: We\\'ll Spy on You Through Your Dishwasher\". WIRED. Retrieved 26 June 2015.\\n\\n^ https://www.facebook.com/geoffreyfowler. \"The doorbells have eyes: The privacy battle brewing over home security cameras\". Washington Post. Retrieved 3 February 2019. {{cite news}}: |last= has generic name (help); External link in |last= (help)\\n\\n^ \"Building the Web of Things – Mozilla Hacks – the Web developer blog\". Mozilla Hacks – the Web developer blog.\\n\\n^ \"The Step Towards Innovation\".\\n\\n^ \"Global IoT Security Market to reach a market size of $29.2 billion by 2022\".\\n\\n^ Ward, Mark (23 September 2015). \"Smart devices to get security tune-up\". BBC News.\\n\\n^ \"Executive Steering Board\". IoT Security Foundation.\\n\\n^ Schneier, Bruce (1 February 2017). \"Security and the Internet of Things\".\\n\\n^ Alfandi, Omar; Hasan, Musaab; Balbahaith, Zayed (2019), \"Assessment and Hardening of IoT Development Boards\", Lecture Notes in Computer Science, Springer International Publishing, pp.\\xa027–39, doi:10.1007/978-3-030-30523-9_3, ISBN\\xa0978-3-030-30522-2, S2CID\\xa0202550425\\n\\n^ a b c Nguyen, Dang Tu; Song, Chengyu; Qian, Zhiyun; V. Krishnamurthy, Srikanth; J. M. Colbert, Edward; McDaniel, Patrick (2018). IoTSan: Fortifying the Safety of IoT Systems. Proc. of the 14th International Conference on emerging Networking EXperiments and Technologies (CoNEXT \\'18). Heraklion, Greece. arXiv:1810.09551. doi:10.1145/3281411.3281440. arXiv:1810.09551.\\n\\n^ \"SmartThings\". SmartThings.com.\\n\\n^ \"HomeKit – Apple Developer\". developer.apple.com.\\n\\n^ \"Amazon Alexa\". developer.amazon.com.\\n\\n^ a b Fielding, Roy Thomas (2000). \"Architectural Styles and the Design of Network-based Software Architectures\" (PDF). University of California, Irvine.\\n\\n^ Littman, Michael; Kortchmar, Samuel (11 June 2014). \"The Path to a Programmable World\". Footnote. Retrieved 14 June 2014.\\n\\n^ Finley, Klint (6 May 2014). \"The Internet of Things Could Drown Our Environment in Gadgets\". Wired.\\n\\n^ Light, A.; Rowland, C. (2015). \"Chapter 11: Responsible IoT Design\".  In Rowland, C.; Goodman, E.; Charlier, M.;  et\\xa0al. (eds.). Designing Connected Products: UX for the Consumer Internet of Things. O\\'Reilly Media. pp.\\xa0457–64. ISBN\\xa09781449372569.\\n\\n^ Gilbert, Arlo (3 April 2016). \"The time that Tony Fadell sold me a container of hummus\". Retrieved 7 April 2016.\\n\\n^ a b c Walsh, Kit (5 April 2016). \"Nest Reminds Customers That Ownership Isn\\'t What It Used to Be\". Electronic Frontier Foundation. Retrieved 7 April 2016.\\n\\n^ a b c d \"Taming the IoT terminology zoo: what does it all mean?\". Information Age. Vitesse Media Plc. 30 July 2015.\\n\\n^ a b \"Technology Working Group\". The Industrial Internet Consortium. Retrieved 21 March 2017.\\n\\n^ \"Vocabulary Technical Report\". The Industrial Internet Consortium. Retrieved 21 March 2017.\\n\\n^ \"Acceleration Sensing\". IoT One. Retrieved 21 March 2017.\\n\\n^ \"IoT Terms Database\". IoT One. Retrieved 21 March 2017.\\n\\n^ \"Quick Guide\". IoT ONE. Retrieved 26 July 2018.\\n\\n^ \"Why The Consumer Internet of Things Is Stalling\". Forbes. Retrieved 24 March 2017.\\n\\n^ a b c d e \"Every. Thing. Connected. A study of the adoption of \\'Internet of Things\\' among Danish companies\" (PDF). Ericsson. Retrieved 2 May 2020.\\n\\n^ Zhang, Zhi-Kai; Cho, Michael Cheng Yi; Wang, Chia-Wei; Hsu, Chia-Wei; Chen, Chong-Kuan; Shieh, Shiuhpyng (2014). \"IoT Security: Ongoing Challenges and Research Opportunities\". 2014 IEEE 7th International Conference on Service-Oriented Computing and Applications. pp.\\xa0230–234. doi:10.1109/SOCA.2014.58. ISBN\\xa0978-1-4799-6833-6. S2CID\\xa018445510.\\n\\n^ Khan, Minhaj Ahmad; Salah, Khaled (2018). \"IoT security: Review, blockchain solutions, and open challenges\". Future Generation Computer Systems. 82: 395–411. doi:10.1016/j.future.2017.11.022.\\n\\n^ Zhou, Wei; Jia, Yan; Peng, Anni; Zhang, Yuqing; Liu, Peng (2019). \"The Effect of IoT New Features on Security and Privacy: New Threats, Existing Solutions, and Challenges Yet to be Solved\". IEEE Internet of Things Journal. 6 (2): 1606–1616. arXiv:1802.03110. doi:10.1109/JIOT.2018.2847733. S2CID\\xa031057653.\\n\\n^ Supriya, S.; Padaki, Sagar (2016). \"Data Security and Privacy Challenges in Adopting Solutions for IOT\". 2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData). pp.\\xa0410–415. doi:10.1109/iThings-GreenCom-CPSCom-SmartData.2016.97. ISBN\\xa0978-1-5090-5880-8. S2CID\\xa034661195.\\n\\n^ \"California Legislative Information\".\\n\\n^ \"Oregon State Legislature\".\\n\\n^ a b c d Anthony, Scott (15 July 2016). \"Disruptive Innovation: Kodak\\'s Downfall Wasn\\'t About Technology\". Harvard Business Review. Harvard Business Publishing. Retrieved 30 March 2017.\\n\\n^ \"World Economic Forum: The Next Economic Growth Engine – Scaling Fourth Industrial Revolution Technologies in Production\" (PDF). World Economic Forum. January 2018. p.\\xa04.\\n\\n^ at 11:15, Kat Hall 23 May 2017. \"Three-quarters of IoT projects are failing, says Cisco\". www.theregister.co.uk. Retrieved 29 January 2020.\\n\\n^ Prasher, V. S.; Onu, Stephen (15 September 2020). \"The Internet of Things (IoT) upheaval: overcoming management challenges\". The Journal of Modern Project Management. 8 (2). doi:10.19255/JMPM02402 (inactive 28 February 2022). ISSN\\xa02317-3963.{{cite journal}}:  CS1 maint: DOI inactive as of February 2022 (link)\\n\\n\\nBibliography[edit]\\n\\n\\n\\nWikimedia Commons has media related to Internet of things.\\n\\nAcharjya, D.P.; Geetha, M.K., eds. (2017). Internet of Things: Novel Advances and Envisioned Applications. Springer. p.\\xa0311. ISBN\\xa09783319534725.\\nLi, S.; Xu, L.D., eds. (2017). Securing the Internet of Things. Syngress. p.\\xa0154. ISBN\\xa09780128045053.\\nRowland, C.; Goodman, E.; Charlier, M.;  et\\xa0al., eds. (2015). Designing Connected Products: UX for the Consumer Internet of Things. O\\'Reilly Media. p.\\xa0726. ISBN\\xa09781449372569.\\nThomas, Jayant; Traukina, Alena (2018). Industrial Internet Application Development: Simplify IIoT development using the elasticity of Public Cloud and Native Cloud Services. Packt Publishing. p.\\xa025. ISBN\\xa0978-1788298599.\\nStephenson, W. David (2018). The Future Is Smart: how your company can capitalize on the Internet of Things--and win in a connected economy. HarperCollins Leadership. p.\\xa0250. ISBN\\xa09780814439777.\\nvteAmbient intelligenceConcepts\\nContext awareness\\nInternet of things\\nObject hyperlinking\\nProfiling\\nSpime\\nSupranet\\nUbiquitous computing\\nWeb of Things\\nWireless sensor networks\\nTechnologies\\n6LoWPAN\\nANT+\\nDASH7\\nIEEE 802.15.4\\nInternet 0\\nMachine to machine\\nRadio-frequency identification\\nSmartdust\\nXBee\\nPlatforms\\nArduino\\nContiki\\nGadgeteer\\nioBridge\\nNetduino\\nRaspberry Pi\\nTinyOS\\nWiring\\nXively\\nNodeMCU\\nApplications\\nAmbient device\\nCeNSE\\nConnected car\\nHome automation\\nHomeOS\\nInternet refrigerator\\nNabaztag\\nSmart city\\nSmart TV\\nSmarter Planet\\nPioneers\\nKevin Ashton\\nGaetano Borriello\\nAdam Dunkels\\nStefano Marzano\\nDon Norman\\nRoel Pieper\\nJosef Preishuber-Pflügl\\nJohn Seely Brown\\nBruce Sterling\\nMark Weiser\\nOther\\nAmbient Devices\\nAmbieSense\\nEbbits project\\nIPSO Alliance\\n\\nvteEmbedded systemsGeneral terms\\nASIC\\nBoard support package\\nBootloader\\nConsumer electronics\\nCross compiler\\nEmbedded database\\nEmbedded hypervisor\\nEmbedded OS\\nEmbedded software\\nFPGA\\nIoT\\nMemory footprint\\nMicrocontroller\\nSingle-board computer\\nRaspberry Pi\\nSoC\\nFirmware and controls\\nClosed platform\\nCrippleware\\nCustom firmware\\nDefective by Design\\nHacking of consumer electronics\\nHomebrew (video games)\\niOS jailbreaking\\nPlayStation 3 Jailbreak\\nProprietary firmware\\nRooting (Android)\\nVendor lock-in\\nBoot loaders\\nU-Boot\\nBarebox\\nSoftware libraries\\nuClibc\\ndietlibc\\nEmbedded GLIBC\\nlwIP\\nmusl\\nProgramming tools\\nAlmquist shell\\nBitBake\\nBuildroot\\nBusyBox\\nOpenEmbedded\\nStand-alone shell\\nToybox\\nYocto Project\\nOperating systems\\nLinux on embedded systems\\nLinux for mobile devices\\nLight-weight Linux distribution\\nReal-time operating system\\nWindows IoT\\nWin CE\\nProgramming languages\\nAda\\nAssembly language\\nCAPL\\nEmbedded C\\nEmbedded C++\\nEmbedded Java\\nMISRA C\\nMicroPython\\n\\nLightweight browsers\\nList of open-source computing hardware\\nOpen-source robotics\\n\\nvteEmerging technologiesFieldsInformation andcommunications\\nAmbient intelligence\\nInternet of things\\nArtificial intelligence\\nApplications of artificial intelligence\\nProgress in artificial intelligence\\nMachine translation\\nMobile translation\\nMachine vision\\nSemantic Web\\nSpeech recognition\\nAtomtronics\\nCarbon nanotube field-effect transistor\\nCybermethodology\\nFourth-generation optical discs\\n3D optical data storage\\nHolographic data storage\\nGPGPU\\nMemory\\nCBRAM\\nFRAM\\nMillipede\\nMRAM\\nNRAM\\nPRAM\\nRacetrack memory\\nRRAM\\nSONOS\\nECRAM\\nUltraRAM\\nOptical computing\\nRFID\\nChipless RFID\\nSoftware-defined radio\\nThree-dimensional integrated circuit\\nTopics\\nCollingridge dilemma\\nDifferential technological development\\nDisruptive innovation\\nEphemeralization\\nEthics\\nBioethics\\nCyberethics\\nNeuroethics\\nRobot ethics\\nExploratory engineering\\nFictional technology\\nProactionary principle\\nTechnological change\\nTechnological unemployment\\nTechnological convergence\\nTechnological evolution\\nTechnological paradigm\\nTechnology forecasting\\nAccelerating change\\nHorizon scanning\\nMoore\\'s law\\nTechnological singularity\\nTechnology scouting\\nTechnology readiness level\\nTechnology roadmap\\nTranshumanism\\n\\n Category\\n List\\n\\nvteSelf-driving cars and enabling technologiesOverview and context\\nHistory of self-driving cars\\nIntelligent transportation system\\nContext-aware pervasive systems\\nMobile computing\\nSmart, connected products\\nUbiquitous computing\\nAmbient intelligence\\nInternet of things\\nSAE LevelsHuman driver monitors the driving environment(Levels 0,1,2)\\nLane departure warning system\\nAutomatic parking\\nCollision avoidance system\\nCruise control\\nAdaptive cruise control\\nAdvanced driver-assistance systems\\nDriver drowsiness detection\\nIntelligent speed adaptation\\nBlind spot monitor\\nSystem monitors the driving environment(Levels 3,4,5)\\nVehicular ad hoc network (V2V)\\nConnected car\\nAutomotive navigation system\\nVehiclesCars\\nVaMP (1994)\\nSpirit of Berlin (2007)\\nGeneral Motors EN-V (2010)\\nMadeInGermany (2011)\\nWaymo, formerly Google Car (2012)\\nTesla Model S with Autopilot (2015)\\nLUTZ Pathfinder (2015)\\nYandex self-driving car (2017)\\nHonda Legend (2021)\\nBuses and commercial vehicles\\nAutomated guideway transit\\nParkShuttle\\nNavia shuttle\\nNuTonomy taxi\\nFreightliner Inspiration\\nDriverless tractor\\nMobility as a service\\nRegulation\\nLegislation\\nIEEE 802.11p\\n Safe speed automotive common law\\nAutomated lane keeping system (unece regulation 157)\\nRegulation (EU) 2019/2144\\nEnabling technologies\\nRadar\\nLaser\\nLIDAR\\nArtificial neural network\\nComputer stereo vision\\nImage recognition\\nDedicated short-range communications\\nReal-time Control System\\nrFpro\\nEye tracking\\nRadio-frequency identification\\nAutomotive navigation system\\nOrganizations, Projects & PeopleOrganizations, projects and events\\nAmerican Center for Mobility\\nDAVI\\nEuropean Land-Robot Trial\\nNavlab\\nDARPA Grand Challenge\\nVisLab Intercontinental Autonomous Challenge\\nEureka Prometheus Project\\nIEEE Intelligent Transportation Systems Society\\nPeople\\nHarold Goddijn\\nAlberto Broggi\\nAnthony Levandowski\\n\\nAuthority control: National libraries \\nFrance (data)\\nGermany\\nIsrael\\nUnited States\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Internet_of_things&oldid=1084380147\"',\n",
       "  'Form of shared Internet-based computing\\nNot to be confused with Cloud Computing (horse).\\nThis article may be confusing or unclear to readers. In particular, it is a poorly-written and -sourced article full of inaccuracies about a high-profile topic. Please help clarify the article. There is a discussion about this on Talk:Cloud computing §\\xa0Ungrammatical and Uninterpretable Language, Incoherent Scope/Purpose, Full of Misinformation. (March 2021) (Learn how and when to remove this template message)\\n\\n\\n Cloud computing metaphor: the group of networked elements providing services need not be individually addressed or managed by users; instead, the entire provider-managed suite of hardware and software can be thought of as an amorphous cloud.\\nCloud computing[1] is the on-demand availability of computer system resources, especially data storage (cloud storage) and computing power, without direct active management by the user.[2] Large clouds often have functions distributed over multiple locations, each location being a data center. Cloud computing relies on sharing of resources to achieve coherence and typically using a \"pay-as-you-go\" model which can help in reducing capital expenses but may also lead to unexpected operating expenses for unaware users.[3]\\n\\nContents\\n\\n1 Value proposition\\n2 History\\n\\n2.1 Early history\\n2.2 2000s\\n2.3 2010s\\n\\n\\n3 Similar concepts\\n4 Characteristics\\n5 Service models\\n\\n5.1 Infrastructure as a service (IaaS)\\n5.2 Platform as a service (PaaS)\\n5.3 Software as a service (SaaS)\\n5.4 Mobile \"backend\" as a service (MBaaS)\\n5.5 Serverless computing or Function-as-a-Service (FaaS)\\n\\n\\n6 Deployment models\\n\\n6.1 Private cloud\\n6.2 Public cloud\\n6.3 Hybrid cloud\\n6.4 Others\\n\\n6.4.1 Community cloud\\n6.4.2 Distributed cloud\\n6.4.3 Multicloud\\n6.4.4 Poly cloud\\n6.4.5 Big data cloud\\n6.4.6 HPC cloud\\n\\n\\n\\n\\n7 Architecture\\n\\n7.1 Cloud engineering\\n\\n\\n8 Security and privacy\\n9 Limitations and disadvantages\\n10 Emerging trends\\n11 Digital forensics in the cloud\\n12 See also\\n13 References\\n14 Further reading\\n15 External links\\n\\n\\nValue proposition[edit]\\nAdvocates of public and hybrid clouds note that cloud computing allows companies to avoid or minimize up-front IT infrastructure costs. Proponents also claim that cloud computing allows enterprises to get their applications up and running faster, with improved manageability and less maintenance, and that it enables IT teams to more rapidly adjust resources to meet fluctuating and unpredictable demand,[4][5][6] providing burst computing capability: high computing power at certain periods of peak demand.[7]\\n\\nHistory[edit]\\nThis section may be confusing or unclear to readers. Please help clarify the section. There might be a discussion about this on the talk page. (January 2021) (Learn how and when to remove this template message)\\nThe cloud symbol was used to represent networks of computing equipment in the original ARPANET by as early as 1977,[8] and the CSNET by 1981[9]—both predecessors to the Internet itself. The word cloud was used as a metaphor for the Internet and a standardized cloud-like shape was used to denote a network on telephony schematics. With this simplification, the implication is that the specifics of how the endpoints of a network are connected are not relevant to understanding the diagram.[10]\\nThe term cloud was used to refer to platforms for distributed computing as early as 1993, when Apple spin-off General Magic and AT&T used it in describing their (paired) Telescript and PersonaLink technologies.[11]  In Wired\\'s April 1994 feature \"Bill and Andy\\'s Excellent Adventure II\", Andy Hertzfeld commented on Telescript, General Magic\\'s distributed programming language:\\n\\n\"The beauty of Telescript\\xa0... is that now, instead of just having a device to program, we now have the entire Cloud out there, where a single program can go and travel to many different sources of information and create a sort of a virtual service. No one had conceived that before. The example Jim White [the designer of Telescript, X.400 and ASN.1] uses now is a date-arranging service where a software agent goes to the flower store and orders flowers and then goes to the ticket shop and gets the tickets for the show, and everything is communicated to both parties.\"[12]\\nEarly history[edit]\\nDuring the 1960s, the initial concepts of time-sharing became popularized via RJE (Remote Job Entry);[13] this terminology was mostly associated with large vendors such as IBM and DEC.  Full-time-sharing solutions were available by the early 1970s on such platforms as Multics (on GE hardware), Cambridge CTSS, and the earliest UNIX ports (on DEC hardware). Yet, the \"data center\" model where users submitted jobs to operators to run on IBM\\'s mainframes was overwhelmingly predominant.\\nIn the 1990s, telecommunications companies, who previously offered primarily dedicated point-to-point data circuits, began offering virtual private network (VPN) services with comparable quality of service, but at a lower cost. By switching traffic as they saw fit to balance server use, they could use overall network bandwidth more effectively.[citation needed]  They began to use the cloud symbol to denote the demarcation point between what the provider was responsible for and what users were responsible for. Cloud computing extended this boundary to cover all servers as well as the network infrastructure.[14] As computers became more diffused, scientists and technologists explored ways to make large-scale computing power available to more users through time-sharing.[citation needed] They experimented with algorithms to optimize the infrastructure, platform, and applications to prioritize CPUs and increase efficiency for end users.[15]\\nThe use of the cloud metaphor for virtualized services dates at least to General Magic in 1994, where it was used to describe the universe of \"places\" that mobile agents in the Telescript environment could go. As described by \\nAndy Hertzfeld:\\n\\n\"The beauty of Telescript,\" says Andy, \"is that now, instead of just having a device to program, we now have the entire Cloud out there, where a single program can go and travel to many different sources of information and create a sort of a virtual service.\"[16]\\nThe use of the cloud metaphor is credited to General Magic communications employee David Hoffman, based on long-standing use in networking and telecom. In addition to use by General Magic itself, it was also used in promoting AT&T\\'s associated PersonaLink Services.[17]\\n\\n2000s[edit]\\nIn July 2002, Amazon created subsidiary Amazon Web Services, with the goal to \"enable developers to build innovative and entrepreneurial applications on their own.\" In March 2006 Amazon introduced its Simple Storage Service (S3), followed by Elastic Compute Cloud (EC2) in August of the same year.[18][19] These products pioneered the usage of server virtualization to deliver IaaS at a cheaper and on-demand pricing basis.\\nIn April 2008, Google released the beta version of Google App Engine.[20] The App Engine was a PaaS (one of the first of its kind) which provided fully maintained infrastructure and a deployment platform for users to create web applications using common languages/technologies such as Python, Node.js and PHP. The goal was to eliminate the need for some administrative tasks typical of an IaaS model, while creating a platform where users could easily deploy such applications and scale them to demand.[21]\\nIn early 2008, NASA\\'s Nebula,[22] enhanced in the RESERVOIR European Commission-funded project, became the first open-source software for deploying private and hybrid clouds, and for the federation of clouds.[23]\\nBy mid-2008, Gartner saw an opportunity for cloud computing \"to shape the relationship among consumers of IT services, those who use IT services and those who sell them\"[24] and observed that \"organizations are switching from company-owned hardware and software assets to per-use service-based models\" so that the \"projected shift to computing\\xa0... will result in dramatic growth in IT products in some areas and significant reductions in other areas.\"[25]\\nIn 2008, the U.S. National Science Foundation began the Cluster Exploratory program to fund academic research using Google-IBM cluster technology to analyze massive amounts of data.[26]\\nIn 2009, the government of France announced Project Andromède to create a \"sovereign cloud\" or national cloud computing, with the government to spend €285 million.[27][28]  The initiative failed badly and Cloudwatt was shut down on 1 February 2020.[29][30]\\n\\n2010s[edit]\\nIn February 2010, Microsoft released Microsoft Azure, which was announced in October 2008.[31]\\nIn July 2010, Rackspace Hosting and NASA jointly launched an open-source cloud-software initiative known as OpenStack. The OpenStack project intended to help organizations offering cloud-computing services running on standard hardware. The early code came from NASA\\'s Nebula platform as well as from Rackspace\\'s Cloud Files platform. As an open-source offering and along with other open-source solutions such as CloudStack, Ganeti, and OpenNebula, it has attracted attention by several key communities. Several studies aim at comparing these open source offerings based on a set of criteria.[32][33][34][35][36][37][38]\\nOn March 1, 2011, IBM announced the IBM SmartCloud framework to support Smarter Planet.[39] Among the various components of the Smarter Computing foundation, cloud computing is a critical part. On June 7, 2012, Oracle announced the Oracle Cloud.[40] This cloud offering is poised to be the first to provide users with access to an integrated set of IT solutions, including the Applications (SaaS), Platform (PaaS), and Infrastructure (IaaS) layers.[41][42][43]\\nIn May 2012, Google Compute Engine was released in preview, before being rolled out into General Availability in December 2013.[44]\\nIn 2019, Linux was the most common OS used on Microsoft Azure.[45] In December 2019, Amazon announced AWS Outposts, which is a fully managed service that extends AWS infrastructure, AWS services, APIs, and tools to virtually any customer datacenter, co-location space, or on-premises facility for a truly consistent hybrid experience[46]\\n\\nSimilar concepts[edit]\\nThe goal of cloud computing is to allow users to take benefit from all of these technologies, without the need for deep knowledge about or expertise with each one of them. The cloud aims to cut costs and helps the users focus on their core business instead of being impeded by IT obstacles.[47] The main enabling technology for cloud computing is virtualization. Virtualization software separates a physical computing device into one or more \"virtual\" devices, each of which can be easily used and managed to perform computing tasks. With operating system–level virtualization essentially creating a scalable system of multiple independent computing devices, idle computing resources can be allocated and used more efficiently. Virtualization provides the agility required to speed up IT operations and reduces cost by increasing infrastructure utilization. Autonomic computing automates the process through which the user can provision resources on-demand. By minimizing user involvement, automation speeds up the process, reduces labor costs and reduces the possibility of human errors.[47]\\nCloud computing uses concepts from utility computing to provide metrics for the services used. Cloud computing attempts to address QoS (quality of service) and reliability problems of other grid computing models.[47]\\nCloud computing shares characteristics with:\\n\\nClient–server model—Client–server computing refers broadly to any distributed application that distinguishes between service providers (servers) and service requestors (clients).[48]\\nComputer bureau—A service bureau providing computer services, particularly from the 1960s to 1980s.\\nGrid computing—A form of distributed and parallel computing, whereby a \\'super and virtual computer\\' is composed of a cluster of networked, loosely coupled computers acting in concert to perform very large tasks.\\nFog computing—Distributed computing paradigm that provides data, compute, storage and application services closer to the client or near-user edge devices, such as network routers. Furthermore, fog computing handles data at the network level, on smart devices and on the end-user client-side (e.g. mobile devices), instead of sending data to a remote location for processing.\\nMainframe computer—Powerful computers used mainly by large organizations for critical applications, typically bulk data processing such as census; industry and consumer statistics; police and secret intelligence services; enterprise resource planning; and financial transaction processing.\\nUtility computing—The \"packaging of computing resources, such as computation and storage, as a metered service similar to a traditional public utility, such as electricity.\"[49][50]\\nPeer-to-peer—A distributed architecture without the need for central coordination. Participants are both suppliers and consumers of resources (in contrast to the traditional client-server model).\\nGreen computing—Study and practice of environmentally sustainable computing or IT.\\nCloud sandbox—A live, isolated computer environment in which a program, code or file can run without affecting the application in which it runs.\\nCharacteristics[edit]\\nCloud computing exhibits the following key characteristics:\\n\\nAgility for organizations may be improved, as cloud computing may increase users\\' flexibility with re-provisioning, adding, or expanding technological infrastructure resources.\\nCost reductions are claimed by cloud providers. A public-cloud delivery model converts capital expenditures (e.g., buying servers) to operational expenditure.[51] This purportedly lowers barriers to entry, as infrastructure is typically provided by a third party and need not be purchased for one-time or infrequent intensive computing tasks. Pricing on a utility computing basis is \"fine-grained\", with usage-based billing options. As well, less in-house IT skills are required for implementation of projects that use cloud computing.[52] The e-FISCAL project\\'s state-of-the-art repository[53] contains several articles looking into cost aspects in more detail, most of them concluding that costs savings depend on the type of activities supported and the type of infrastructure available in-house.\\nDevice and location independence[54] enable users to access systems using a web browser regardless of their location or what device they use (e.g., PC, mobile phone). As infrastructure is off-site (typically provided by a third-party) and accessed via the Internet, users can connect to it from anywhere.[52]\\nMaintenance of cloud environment is easier because the data is hosted on an outside server maintained by a provider without the need to invest in data center hardware. IT maintenance of cloud computing is managed and updated by the cloud provider\\'s IT maintenance team that reduces cloud computing costs compared with the on-premises data centers.\\nMultitenancy enables sharing of resources and costs across a large pool of users thus allowing for:\\ncentralization of infrastructure in locations with lower costs (such as real estate, electricity, etc.)\\npeak-load capacity increases (users need not engineer and pay for the resources and equipment to meet their highest possible load-levels)\\nutilisation and efficiency improvements for systems that are often only 10–20% utilised.[55][56]\\nPerformance is monitored by IT experts from the service provider, and consistent and loosely coupled architectures are constructed using web services as the system interface.[52][57]\\nProductivity may be increased when multiple users can work on the same data simultaneously, rather than waiting for it to be saved and emailed. Time may be saved as information does not need to be re-entered when fields are matched, nor do users need to install application software upgrades to their computer.[58]\\nAvailability improves with the use of multiple redundant sites, which makes well-designed cloud computing suitable for business continuity and disaster recovery.[59]\\nScalability and elasticity via dynamic (\"on-demand\") provisioning of resources on a fine-grained, self-service basis in near real-time[60][61] (Note, the VM startup time varies by VM type, location, OS and cloud providers[60]), without users having to engineer for peak loads.[62][63][64] This gives the ability to scale up when the usage need increases or down if resources are not being used.[65] The time-efficient benefit of cloud scalability also means faster time to market, more business flexibility, and adaptability, as adding new resources doesn’t take as much time as it used to.[66] Emerging approaches for managing elasticity include the use of machine learning techniques to propose efficient elasticity models.[67]\\nSecurity can improve due to centralization of data, increased security-focused resources, etc., but concerns can persist about loss of control over certain sensitive data, and the lack of security for stored kernels. Security is often as good as or better than other traditional systems, in part because service providers are able to devote resources to solving security issues that many customers cannot afford to tackle or which they lack the technical skills to address.[68] However, the complexity of security is greatly increased when data is distributed over a wider area or over a greater number of devices, as well as in multi-tenant systems shared by unrelated users. In addition, user access to security audit logs may be difficult or impossible. Private cloud installations are in part motivated by users\\' desire to retain control over the infrastructure and avoid losing control of information security.\\nThe National Institute of Standards and Technology\\'s definition of cloud computing identifies \"five essential characteristics\":\\n\\nOn-demand self-service. A consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with each service provider.\\nBroad network access. Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, tablets, laptops, and workstations).\\nResource pooling. The provider\\'s computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand.\\xa0\\nRapid elasticity. Capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand. To the consumer, the capabilities available for provisioning often appear unlimited and can be appropriated in any quantity at any time.\\n\\nMeasured service. Cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.—\\u2009National Institute of Standards and Technology[69]\\nService models[edit]\\n Cloud computing service models arranged as layers in a stack\\nThough service-oriented architecture advocates \"Everything as a service\" (with the acronyms EaaS or XaaS,[70] or simply aas), cloud-computing providers offer their \"services\" according to different models, of which the three standard models per NIST are Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS).[69] These models offer increasing abstraction; they are thus often portrayed as layers in a stack: infrastructure-, platform- and software-as-a-service, but these need not be related. For example, one can provide SaaS implemented on physical machines (bare metal), without using underlying PaaS or IaaS layers, and conversely one can run a program on IaaS and access it directly, without wrapping it as SaaS.\\n\\nInfrastructure as a service (IaaS)[edit]\\nMain article: Infrastructure as a service\\n\"Infrastructure as a service\" (IaaS) refers to online services that provide high-level APIs used to abstract various low-level details of underlying network infrastructure like physical computing resources, location, data partitioning, scaling, security, backup, etc. A hypervisor runs the virtual machines as guests. Pools of hypervisors within the cloud operational system can support large numbers of virtual machines and the ability to scale services up and down according to customers\\' varying requirements. Linux containers run in isolated partitions of a single Linux kernel running directly on the physical hardware. Linux cgroups and namespaces are the underlying Linux kernel technologies used to isolate, secure and manage the containers. Containerisation offers higher performance than virtualization because there is no hypervisor overhead.  IaaS clouds often offer additional resources such as a virtual-machine disk-image library, raw block storage, file or object storage, firewalls, load balancers, IP addresses, virtual local area networks (VLANs), and software bundles.[71]\\nThe NIST\\'s definition of cloud computing describes IaaS as \"where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, and deployed applications; and possibly limited control of select networking components (e.g., host firewalls).\"[69]\\nIaaS-cloud providers supply these resources on-demand from their large pools of equipment installed in data centers. For wide-area connectivity, customers can use either the Internet or carrier clouds (dedicated virtual private networks). To deploy their applications, cloud users install operating-system images and their application software on the cloud infrastructure. In this model, the cloud user patches and maintains the operating systems and the application software. Cloud providers typically bill IaaS services on a utility computing basis: cost reflects the amount of resources allocated and consumed.[citation needed]\\n\\nPlatform as a service (PaaS)[edit]\\nMain article: Platform as a service\\nThe NIST\\'s definition of cloud computing defines Platform as a Service as:[69]\\n\\nThe capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment.\\nPaaS vendors offer a development environment to application developers. The provider typically develops toolkit and standards for development and channels for distribution and payment. In the PaaS models, cloud providers deliver a computing platform, typically including operating system, programming-language execution environment, database, and web server. Application developers develop and run their software on a cloud platform instead of directly buying and managing the underlying hardware and software layers. With some PaaS, the underlying computer and storage resources scale automatically to match application demand so that the cloud user does not have to allocate resources manually.[72][need quotation to verify]\\nSome integration and data management providers also use specialized applications of PaaS as delivery models for data. Examples include iPaaS (Integration Platform as a Service) and dPaaS (Data Platform as a Service). iPaaS enables customers to develop, execute and govern integration flows.[73] Under the iPaaS integration model, customers drive the development and deployment of integrations without installing or managing any hardware or middleware.[74] dPaaS delivers integration—and data-management—products as a fully managed service.[75] Under the dPaaS model, the PaaS provider, not the customer, manages the development and execution of programs by building data applications for the customer. dPaaS users access data through data-visualization tools.[76]\\n\\nSoftware as a service (SaaS)[edit]\\nMain article: Software as a service\\nThe NIST\\'s definition of cloud computing defines Software as a Service as:[69]\\n\\nThe capability provided to the consumer is to use the provider\\'s applications running on a cloud infrastructure. The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings.\\nIn the software as a service (SaaS) model, users gain access to application software and databases. Cloud providers manage the infrastructure and platforms that run the applications. SaaS is sometimes referred to as \"on-demand software\" and is usually priced on a pay-per-use basis or using a subscription fee.[77] In the SaaS model, cloud providers install and operate application software in the cloud and cloud users access the software from cloud clients. Cloud users do not manage the cloud infrastructure and platform where the application runs. This eliminates the need to install and run the application on the cloud user\\'s own computers, which simplifies maintenance and support. Cloud applications differ from other applications in their scalability—which can be achieved by cloning tasks onto multiple virtual machines at run-time to meet changing work demand.[78] Load balancers distribute the work over the set of virtual machines. This process is transparent to the cloud user, who sees only a single access-point. To accommodate a large number of cloud users, cloud applications can be multitenant, meaning that any machine may serve more than one cloud-user organization.\\nThe pricing model for SaaS applications is typically a monthly or yearly flat fee per user,[79] so prices become scalable and adjustable if users are added or removed at any point. It may also be free.[80] Proponents claim that SaaS gives a business the potential to reduce IT operational costs by outsourcing hardware and software maintenance and support to the cloud provider. This enables the business to reallocate IT operations costs away from hardware/software spending and from personnel expenses, towards meeting other goals. In addition, with applications hosted centrally, updates can be released without the need for users to install new software. One drawback of SaaS comes with storing the users\\' data on the cloud provider\\'s server. As a result,[citation needed] there could be unauthorized access to the data.[81] Examples of applications offered as SaaS are games and productivity software like Google Docs and Word Online. SaaS applications may be integrated with cloud storage or File hosting services, which is the case with Google Docs being integrated with Google Drive and Word Online being integrated with Onedrive.[citation needed]\\n\\nMobile \"backend\" as a service (MBaaS)[edit]\\nMain article: Mobile backend as a service\\nIn the mobile \"backend\" as a service (m) model, also known as backend as a service (BaaS), web app and mobile app developers are provided with a way to link their applications to cloud storage and cloud computing services with application programming interfaces (APIs) exposed to their applications and custom software development kits (SDKs). Services include user management, push notifications, integration with social networking services[82] and more. This is a relatively recent model in cloud computing,[83] with most BaaS startups dating from 2011 or later[84][85][86] but trends indicate that these services are gaining significant mainstream traction with enterprise consumers.[87]\\n\\nServerless computing or Function-as-a-Service (FaaS)[edit]\\nMain article: Serverless computing\\nServerless computing is a cloud computing code execution model in which the cloud provider fully manages starting and stopping virtual machines as necessary to serve requests, and requests are billed by an abstract measure of the resources required to satisfy the request, rather than per virtual machine, per hour.[88] Despite the name, it does not actually involve running code without servers.[88] Serverless computing is so named because the business or person that owns the system does not have to purchase, rent or provide servers or virtual machines for the back-end code to run on.\\nFunction as a service (FaaS) is a service-hosted remote procedure call that leverages serverless computing to enable the deployment of individual functions in the cloud that run in response to events.[89] FaaS is considered by some to come under the umbrella of serverless computing, while some others use the terms interchangeably.[90]\\n\\nDeployment models[edit]\\n Cloud computing types\\nPrivate cloud[edit]\\nPrivate cloud is cloud infrastructure operated solely for a single organization, whether managed internally or by a third party, and hosted either internally or externally.[69] Undertaking a private cloud project requires significant engagement to virtualize the business environment, and requires the organization to reevaluate decisions about existing resources. It can improve business, but every step in the project raises security issues that must be addressed to prevent serious vulnerabilities. Self-run data centers[91] are generally capital intensive. They have a significant physical footprint, requiring allocations of space, hardware, and environmental controls. These assets have to be refreshed periodically, resulting in additional capital expenditures. They have attracted criticism because users \"still have to buy, build, and manage them\" and thus do not benefit from less hands-on management,[92] essentially \"[lacking] the economic model that makes cloud computing such an intriguing concept\".[93][94]\\n\\nPublic cloud[edit]\\nFor a comparison of cloud-computing software and providers, see Cloud-computing comparison\\nCloud services are considered \"public\" when they are delivered over the public Internet, and they may be offered as a paid subscription, or free of charge.[95] Architecturally, there are few differences between public- and private-cloud services, but security concerns increase substantially when services (applications, storage, and other resources) are shared by multiple customers. Most public-cloud providers offer direct-connection services that allow customers to securely link their legacy data centers to their cloud-resident applications.[52][96]\\nSeveral factors like the functionality of the solutions, cost, integrational and organizational aspects as well as safety & security are influencing the decision of enterprises and organizations to choose a public cloud or on-premises solution.[97]\\n\\nHybrid cloud[edit]\\nHybrid cloud is a composition of a public cloud and a private environment, such as a private cloud or on-premises resources,[98][99] that remain distinct entities but are bound together, offering the benefits of multiple deployment models. Hybrid cloud can also mean the ability to connect collocation, managed and/or dedicated services with cloud resources.[69] Gartner defines a hybrid cloud service as a cloud computing service that is composed of some combination of private, public and community cloud services, from different service providers.[100] A hybrid cloud service crosses isolation and provider boundaries so that it can\\'t be simply put in one category of private, public, or community cloud service. It allows one to extend either the capacity or the capability of a cloud service, by aggregation, integration or customization with another cloud service.\\nVaried use cases for hybrid cloud composition exist. For example, an organization may store sensitive client data in house on a private cloud application, but interconnect that application to a business intelligence application provided on a public cloud as a software service.[101] This example of hybrid cloud extends the capabilities of the enterprise to deliver a specific business service through the addition of externally available public cloud services. Hybrid cloud adoption depends on a number of factors such as data security and compliance requirements, level of control needed over data, and the applications an organization uses.[102]\\nAnother example of hybrid cloud is one where IT organizations use public cloud computing resources to meet temporary capacity needs that can not be met by the private cloud.[103] This capability enables hybrid clouds to employ cloud bursting for scaling across clouds.[69] Cloud bursting is an application deployment model in which an application runs in a private cloud or data center and \"bursts\" to a public cloud when the demand for computing capacity increases. A primary advantage of cloud bursting and a hybrid cloud model is that an organization pays for extra compute resources only when they are needed.[104] Cloud bursting enables data centers to create an in-house IT infrastructure that supports average workloads, and use cloud resources from public or private clouds, during spikes in processing demands.[105] The specialized model of hybrid cloud, which is built atop heterogeneous hardware, is called \"Cross-platform Hybrid Cloud\". A cross-platform hybrid cloud is usually powered by different CPU architectures, for example, x86-64 and ARM, underneath. Users can transparently deploy and scale applications without knowledge of the cloud\\'s hardware diversity.[106] This kind of cloud emerges from the rise of ARM-based system-on-chip for server-class computing.\\nHybrid cloud infrastructure essentially serves to eliminate limitations inherent to the multi-access relay characteristics of private cloud networking. The advantages include enhanced runtime flexibility and adaptive memory processing unique to virtualized interface models.[107]\\n\\nOthers[edit]\\nCommunity cloud[edit]\\nCommunity cloud shares infrastructure between several organizations from a specific community with common concerns (security, compliance, jurisdiction, etc.), whether managed internally or by a third-party, and either hosted internally or externally. The costs are spread over fewer users than a public cloud (but more than a private cloud), so only some of the cost savings potential of cloud computing are realized.[69]\\n\\nDistributed cloud[edit]\\nA cloud computing platform can be assembled from a distributed set of machines in different locations, connected to a single network or hub service. It is possible to distinguish between two types of distributed clouds: public-resource computing and volunteer cloud.\\n\\nPublic-resource computing—This type of distributed cloud results from an expansive definition of cloud computing, because they are more akin to distributed computing than cloud computing. Nonetheless, it is considered a sub-class of cloud computing.\\nVolunteer cloud—Volunteer cloud computing is characterized as the intersection of public-resource computing and cloud computing, where a cloud computing infrastructure is built using volunteered resources. Many challenges arise from this type of infrastructure, because of the volatility of the resources used to build it and the dynamic environment it operates in. It can also be called peer-to-peer clouds, or ad-hoc clouds. An interesting effort in such direction is Cloud@Home, it aims to implement a cloud computing infrastructure using volunteered resources providing a business-model to incentivize contributions through financial restitution.[108]\\nMulticloud[edit]\\nMain article: Multicloud\\nMulticloud is the use of multiple cloud computing services in a single heterogeneous architecture to reduce reliance on single vendors, increase flexibility through choice, mitigate against disasters, etc. It differs from hybrid cloud in that it refers to multiple cloud services, rather than multiple deployment modes (public, private, legacy).[109][110][111]\\n\\nPoly cloud[edit]\\nPoly cloud refers to the use of multiple public clouds for the purpose of leveraging specific services that each provider offers. It differs from Multi cloud in that it is not designed to increase flexibility or mitigate against failures but is rather used to allow an organization to achieve more that could be done with a single provider.[112]\\n\\nBig data cloud[edit]\\nThe issues of transferring large amounts of data to the cloud as well as data security once the data is in the cloud initially hampered adoption of cloud for big data, but now that much data originates in the cloud and with the advent of bare-metal servers, the cloud has become[113] a solution for use cases including business analytics and geospatial analysis.[114]\\n\\nHPC cloud[edit]\\nHPC cloud refers to the use of cloud computing services and infrastructure to execute high-performance computing (HPC) applications.[115] These applications consume considerable amount of computing power and memory and are traditionally executed on clusters of computers. In 2016 a handful of companies, including R-HPC, Amazon Web Services, Univa, Silicon Graphics International, Sabalcore, Gomput, and Penguin Computing offered a high performance computing cloud. The Penguin On Demand (POD) cloud was one of the first non-virtualized remote HPC services offered on a pay-as-you-go basis.[116][117] Penguin Computing launched its HPC cloud in 2016 as alternative to Amazon\\'s EC2 Elastic Compute Cloud, which uses virtualized computing nodes.[118][119]\\n\\nArchitecture[edit]\\n Cloud computing sample architecture\\nCloud architecture,[120] the systems architecture of the software systems involved in the delivery of cloud computing, typically involves multiple cloud components communicating with each other over a loose coupling mechanism such as a messaging queue. Elastic provision implies intelligence in the use of tight or loose coupling as applied to mechanisms such as these and others.\\n\\nCloud engineering[edit]\\nCloud engineering is the application of engineering disciplines of cloud computing. It brings a systematic approach to the high-level concerns of commercialization, standardization and governance in conceiving, developing, operating and maintaining cloud computing systems. It is a multidisciplinary method encompassing contributions from diverse areas such as systems, software, web, performance, information technology engineering, security, platform, risk, and quality engineering.\\n\\nSecurity and privacy[edit]\\n Cloud suppliers security and privacy agreements must be alligned to the demand(s) requirements\\nMain article: Cloud computing security\\nCloud computing poses privacy concerns because the service provider can access the data that is in the cloud at any time.  It could accidentally or deliberately alter or delete information.[121] Many cloud providers can share information with third parties if necessary for purposes of law and order without a warrant. That is permitted in their privacy policies, which users must agree to before they start using cloud services. Solutions to privacy include policy and legislation as well as end-users\\' choices for how data is stored.[121] Users can encrypt data that is processed or stored within the cloud to prevent unauthorized access.[122][121] Identity management systems can also provide practical solutions to privacy concerns in cloud computing. These systems distinguish between authorized and unauthorized users and determine the amount of data that is accessible to each entity.[123] The systems work by creating and describing identities, recording activities, and getting rid of unused identities.\\nAccording to the Cloud Security Alliance, the top three threats in the cloud are Insecure Interfaces and APIs, Data Loss & Leakage, and Hardware Failure—which accounted for 29%, 25% and 10% of all cloud security outages respectively. Together, these form shared technology vulnerabilities. In a cloud provider platform being shared by different users, there may be a possibility that information belonging to different customers resides on the same data server. Additionally, Eugene Schultz, chief technology officer at Emagined Security, said that hackers are spending substantial time and effort looking for ways to penetrate the cloud. \"There are some real Achilles\\' heels in the cloud infrastructure that are making big holes for the bad guys to get into\". Because data from hundreds or thousands of companies can be stored on large cloud servers, hackers can theoretically gain control of huge stores of information through a single attack—a process he called \"hyperjacking\". Some examples of this include the Dropbox security breach, and iCloud 2014 leak.[124] Dropbox had been breached in October 2014, having over 7 million of its users passwords stolen by hackers in an effort to get monetary value from it by Bitcoins (BTC). By having these passwords, they are able to read private data as well as have this data be indexed by search engines (making the information public).[124]\\nThere is the problem of legal ownership of the data (If a user stores some data in the cloud, can the cloud provider profit from it?). Many Terms of Service agreements are silent on the question of ownership.[125] Physical control of the computer equipment (private cloud) is more secure than having the equipment off-site and under someone else\\'s control (public cloud). This delivers great incentive to public cloud computing service providers to prioritize building and maintaining strong management of secure services.[126] Some small businesses that don\\'t have expertise in IT security could find that it\\'s more secure for them to use a public cloud. There is the risk that end users do not understand the issues involved when signing on to a cloud service (persons sometimes don\\'t read the many pages of the terms of service agreement, and just click \"Accept\" without reading). This is important now that cloud computing is becoming popular and required for some services to work, for example for an intelligent personal assistant (Apple\\'s Siri or Google Now). Fundamentally, private cloud is seen as more secure with higher levels of control for the owner, however public cloud is seen to be more flexible and requires less time and money investment from the user.[127]\\n\\nLimitations and disadvantages[edit]\\nAccording to Bruce Schneier, \"The downside is that you will have limited customization options. Cloud computing is cheaper because of economics of scale, and—like any outsourced task—you tend to get what you want. A restaurant with a limited menu is cheaper than a personal chef who can cook anything you want. Fewer options at a much cheaper price: it\\'s a feature, not a bug.\" He also suggests that \"the cloud provider might not meet your legal needs\" and that businesses need to weigh the benefits of cloud computing against the risks.[128]\\nIn cloud computing, the control of the back end infrastructure is limited to the cloud vendor only. Cloud providers often decide on the management policies, which moderates what the cloud users are able to do with their deployment.[129] Cloud users are also limited to the control and management of their applications, data and services.[130] This includes data caps, which are placed on cloud users by the cloud vendor allocating a certain amount of bandwidth for each customer and are often shared among other cloud users.[130]\\nPrivacy and confidentiality are big concerns in some activities. For instance, sworn translators working under the stipulations of an NDA, might face problems regarding sensitive data that are not encrypted.[131] Due to the use of the internet, confidential information such as employee data and user data can be easily available to third-party organisations and people in Cloud Computing.[132]\\nCloud computing is beneficial to many enterprises; it lowers costs and allows them to focus on competence instead of on matters of IT and infrastructure. Nevertheless, cloud computing has proven to have some limitations and disadvantages, especially for smaller business operations, particularly regarding security and downtime. Technical outages are inevitable and occur sometimes when cloud service providers (CSPs) become overwhelmed in the process of serving their clients. This may result in temporary business suspension. Since this technology\\'s systems rely on the Internet, an individual cannot access their applications, server, or data from the cloud during an outage.[133]\\n\\nEmerging trends[edit]\\nThis section needs expansion. You can help by adding to it.  (September 2021)\\nCloud computing is still a subject of research.[134] A driving factor in the evolution of cloud computing has been chief technology officers seeking to minimize risk of internal outages and mitigate the complexity of housing network and computing hardware in-house.[135] They are also looking to share information to workers located in diverse areas in near and real-time, to enable teams to work seamlessly, no matter where they are located. Since the global pandemic of 2020, it is said that cloud technology jumped ahead in popularity due to the level of security of data and the flexibility of working options for all employees, notably remote workers. For example, Zoom grew over 160% in 2020 alone.[136]\\n\\nDigital forensics in the cloud[edit]\\nThe issue of carrying out investigations where the cloud storage devices cannot be physically accessed has generated a number of changes to the way that digital evidence is located and collected.[137] New process models have been developed to formalize collection.[138]\\nIn some scenarios existing digital forensics tools can be employed to access cloud storage as networked drives (although this is a slow process generating a large amount of internet traffic).[citation needed]\\nAn alternative approach is to deploy a tool that processes in the cloud itself.[139]\\nFor organizations using Office 365 with an \\'E5\\' subscription, there is the option to use Microsoft\\'s built-in e-discovery resources, although these do not provide all the functionality that is typically required for a forensic process.[140]\\n\\nSee also[edit]\\n\\nBlock-level storage\\nCategory:Cloud computing providers\\nCategory:Cloud platforms\\nCommunication protocol\\nCommunications system\\nCloud collaboration\\nCloud native computing\\nCloud computing security\\nCloud computing comparison\\nCloud management\\nCloud research\\nCloud robotics\\nCloud gaming\\nCloud storage\\nCloudlet\\nComputer cluster\\nCooperative storage cloud\\nDew computing\\nData cluster\\nDirectory\\nDistributed data store\\nDistributed database\\nDistributed computing\\nDistributed networking\\nDecentralized computing\\nEdge computing\\nEdge device\\neScience\\nFile system\\nClustered file system\\nDistributed file system\\nDistributed file system for cloud\\nFog computing\\nFog robotics\\nGrid computing\\nIn-memory database\\nIn-memory processing\\nInternet of things\\nMicroservices\\nMobile cloud computing\\nMobile edge computing\\nPeer-to-peer\\nPersonal cloud\\nRobot as a service\\nAs a service\\nService-oriented architecture\\nTime-sharing\\nUbiquitous computing\\nVDI\\nVirtual private cloud\\nWeb computing\\n\\nReferences[edit]\\n\\n\\n^ Ray, Partha Pratim (2018). \"An Introduction to Dew Computing: Definition, Concept and Implications - IEEE Journals & Magazine\". IEEE Access. 6: 723–737. doi:10.1109/ACCESS.2017.2775042. S2CID\\xa03324933.\\n\\n^ Montazerolghaem, Ahmadreza; Yaghmaee, Mohammad Hossein; Leon-Garcia, Alberto (September 2020). \"Green Cloud Multimedia Networking: NFV/SDN Based Energy-Efficient Resource Allocation\". IEEE Transactions on Green Communications and Networking. 4 (3): 873–889. doi:10.1109/TGCN.2020.2982821. ISSN\\xa02473-2400. S2CID\\xa0216188024.\\n\\n^ \"Where\\'s The Rub: Cloud Computing\\'s Hidden Costs\". Forbes. 2014-02-27. Retrieved 2014-07-14.\\n\\n^ \"What is Cloud Computing?\". Amazon Web Services. 2013-03-19. Retrieved 2013-03-20.\\n\\n^ Baburajan, Rajani (2011-08-24). \"The Rising Cloud Storage Market Opportunity Strengthens Vendors\". It.tmcnet.com. Retrieved 2011-12-02.\\n\\n^ Oestreich, Ken (2010-11-15). \"Converged Infrastructure\". CTO Forum. Thectoforum.com. Archived from the original on 2012-01-13. Retrieved 2011-12-02.\\n\\n^ Ted Simpson, Jason Novak, Hands on Virtual Computing,  2017, ISBN\\xa01337515744, p. 451\\n\\n^ \"Internet History of 1970s | Internet History | Computer History Museum\". www.computerhistory.org.\\n\\n^ \"National Science Foundation, \"Diagram of CSNET,\" 1981\".\\n\\n^ \"What Is Cloud Computing?\". PCMAG. Retrieved 2020-02-24.\\n\\n^ AT&T (1993). \"What Is The Cloud?\". YouTube. Archived from the original on 2021-10-27. Retrieved 2017-10-26. You can think of our electronic meeting place as the Cloud. PersonaLink was built from the ground up to give handheld communicators and other devices easy access to a variety of services.  [...]  Telescript is the revolutionary software technology that makes intelligent assistance possible.  Invented by General Magic, AT&T is the first company to harness Telescript, and bring its benefits to people everywhere.  [...]  Very shortly, anyone with a computer, a personal communicator, or television will be able to use intelligent assistance in the Cloud.  And our new meeting place is open, so that anyone, whether individual, entrepreneur, or a multinational company, will be able to offer information, goods, and services.\\n\\n^ Steven Levy (April 1994). \"Bill and Andy\\'s Excellent Adventure II\". Wired.\\n\\n^ White, J.E. \"Network Specifications for Remote Job Entry and Remote Job Output Retrieval at UCSB\". tools.ietf.org. Retrieved 2016-03-21.\\n\\n^ \"July, 1993 meeting report from the IP over ATM working group of the IETF\". CH: Switch. Archived from the original on 2012-07-10. Retrieved 2010-08-22.\\n\\n^ Corbató, Fernando J. \"An Experimental Time-Sharing System\". SJCC Proceedings. MIT. Archived from the original on 6 September 2009. Retrieved 3 July 2012.\\n\\n^ Levy, Steven (April 1994). \"Bill and Andy\\'s Excellent Adventure II\". Wired.\\n\\n^ Levy, Steven (2014-05-23). \"Tech Time Warp of the Week: Watch AT&T Invent Cloud Computing in 1994\". Wired. AT&T and the film\\'s director, David Hoffman, pulled out the cloud metaphor–something that had long been used among networking and telecom types. [...]  \"You can think of our electronic meeting place as the cloud,\" says the film\\'s narrator, [...] David Hoffman, the man who directed the film and shaped all that cloud imagery, was a General Magic employee.\\n\\n^ \"Announcing Amazon Elastic Compute Cloud (Amazon EC2) – beta\". 24 August 2006. Retrieved 31 May 2014.\\n\\n^ Qian, Ling; Lou, Zhigou; Du, Yujian; Gou, Leitao. \"Cloud Computing: An Overview\". researchgate.net. Retrieved 19 April 2021.\\n\\n^ \"Introducing Google App Engine + our new blog\". Google Developer Blog. 2008-04-07. Retrieved 2017-03-07.\\n\\n^ \"App Engine\". cloud.google.com. Retrieved 19 April 2021.\\n\\n^ \"Nebula Cloud Computing Platform: NASA\". Open Government at NASA. 2012-11-20. Retrieved 2020-11-15.\\n\\n^ Rochwerger, B.; Breitgand, D.; Levy, E.; Galis, A.; Nagin, K.; Llorente, I. M.; Montero, R.; Wolfsthal, Y.; Elmroth, E.; Caceres, J.; Ben-Yehuda, M.; Emmerich, W.; Galan, F. (2009). \"The Reservoir model and architecture for open federated cloud computing\". IBM Journal of Research and Development. 53 (4): 4:1–4:11. doi:10.1147/JRD.2009.5429058.\\n\\n^ Keep an eye on cloud computing, Amy Schurr, Network World, 2008-07-08, citing the Gartner report, \"Cloud Computing Confusion Leads to Opportunity\". Retrieved 2009-09-11.\\n\\n^ Gartner (2008-08-18). \"Gartner Says Worldwide IT Spending on Pace to Surpass Trillion in 2008\". Archived from the original on December 4, 2008.\\n\\n^ \"Cluster Exploratory (CluE) nsf08560\". www.nsf.gov.\\n\\n^ \"285 millions d\\'euros pour Andromède, le cloud souverain français - le Monde Informatique\". Archived from the original on 2011-10-23.\\n\\n^ Hicks, Jacqueline. \"\\'Digital colonialism\\': why some countries want to take control of their people\\'s data from Big Tech\". The Conversation.\\n\\n^ \"Orange enterre Cloudwatt, qui fermera ses portes le 31 janvier 2020\". www.nextinpact.com. August 30, 2019.\\n\\n^ \"Cloudwatt\\xa0: Vie et mort du premier \" cloud souverain \" de la France\". 29 August 2019.\\n\\n^ \"Windows Azure General Availability\". The Official Microsoft Blog. Microsoft. 2010-02-01. Archived from the original on 2014-05-11. Retrieved 2015-05-03.\\n\\n^ Milita Datta (August 9, 2016). \"Apache CloudStack vs. OpenStack: Which Is the Best?\". DZone · Cloud Zone.\\n\\n^ \"OpenNebula vs OpenStack\". SoftwareInsider.[dead link]\\n\\n^ Kostantos, Konstantinos, et al. \"OPEN-source IaaS fit for purpose: a comparison between OpenNebula and OpenStack.\" International Journal of Electronic Business Management 11.3 (2013)\\n\\n^ L. Albertson, \"OpenStack vs. Ganeti\", LinuxFest Northwest 2017\\n\\n^ Qevani, Elton, et al. \"What can OpenStack adopt from a Ganeti-based open-source IaaS?.\" Cloud Computing (CLOUD), 2014 IEEE 7th International Conference on. IEEE, 2014\\n\\n^ Von Laszewski, Gregor, et al. \"Comparison of multiple cloud frameworks.\", IEEE 5th International Conference on Cloud Computing (CLOUD), 2012.\\n\\n^ Diaz, Javier et al. \" Abstract Image Management and Universal Image Registration for Cloud and HPC Infrastructures \", IEEE 5th International Conference on Cloud Computing (CLOUD), 2012\\n\\n^ \"Launch of IBM Smarter Computing\". Archived from the original on 20 April 2013. Retrieved 1 March 2011.\\n\\n^ \"Launch of Oracle Cloud\". The Register. Retrieved 28 February 2014.\\n\\n^ \"Oracle Cloud, Enterprise-Grade Cloud Solutions: SaaS, PaaS, and IaaS\". Retrieved 12 October 2014.\\n\\n^ \"Larry Ellison Doesn\\'t Get the Cloud: The Dumbest Idea of 2013\". Forbes.com. Retrieved 12 October 2014.\\n\\n^ \"Oracle Disrupts Cloud Industry with End-to-End Approach\". Forbes.com. Retrieved 12 October 2014.\\n\\n^ \"Google Compute Engine is now Generally Available with expanded OS support, transparent maintenance, and lower prices\". Google Developers Blog. 2013-12-02. Retrieved 2017-03-07.\\n\\n^ Vaughan-Nichols, Steven J. \"Microsoft developer reveals Linux is now more used on Azure than Windows Server\". ZDNet. Retrieved 2019-07-02.\\n\\n^ \"Announcing General Availability of AWS Outposts\". Amazon Web Services, Inc.\\n\\n^ a b c HAMDAQA, Mohammad (2012). Cloud Computing Uncovered: A Research Landscape (PDF). Elsevier Press. pp.\\xa041–85. ISBN\\xa0978-0-12-396535-6.\\n\\n^ \"Distributed Application Architecture\" (PDF). Sun Microsystem. Retrieved 2009-06-16.\\n\\n^ Vaquero, Luis M.; Rodero-Merino, Luis; Caceres, Juan; Lindner, Maik (December 2008). \"It\\'s probable that you\\'ve misunderstood \\'Cloud Computing\\' until now\". Sigcomm Comput. Commun. Rev. TechPluto. 39 (1): 50–55. doi:10.1145/1496091.1496100. S2CID\\xa0207171174.\\n\\n^ Danielson, Krissi (2008-03-26). \"Distinguishing Cloud Computing from Utility Computing\". Ebizq.net. Retrieved 2010-08-22.\\n\\n^ \"Recession Is Good For Cloud Computing – Microsoft Agrees\". CloudAve. 2009-02-12. Retrieved 2010-08-22.\\n\\n^ a b c d \"Defining \\'Cloud Services\\' and \"Cloud Computing\"\". IDC. 2008-09-23. Archived from the original on 2010-07-22. Retrieved 2010-08-22.\\n\\n^ \"State of the Art | e-FISCAL project\". www.efiscal.eu.\\n\\n^ Farber, Dan (2008-06-25). \"The new geek chic: Data centers\". CNET News. Retrieved 2010-08-22.\\n\\n^ \"Jeff Bezos\\' Risky Bet\". Business Week.\\n\\n^ He, Sijin; Guo, L.; Guo, Y.; Ghanem, M. (June 2012). Improving Resource Utilisation in the Cloud Environment Using Multivariate Probabilistic Models. 2012 2012 IEEE 5th International Conference on Cloud Computing (CLOUD). pp.\\xa0574–581. doi:10.1109/CLOUD.2012.66. ISBN\\xa0978-1-4673-2892-0. S2CID\\xa015374752.\\n\\n^ He, Qiang, et al. \"Formulating Cost-Effective Monitoring Strategies for Service-based Systems.\" (2013): 1–1.\\n\\n^ Heather Smith (23 May 2013). Xero For Dummies. John Wiley & Sons. pp.\\xa037–. ISBN\\xa0978-1-118-57252-8.\\n\\n^ King, Rachael (2008-08-04). \"Cloud Computing: Small Companies Take Flight\". Bloomberg BusinessWeek. Retrieved 2010-08-22.\\n\\n^ a b Mao, Ming; M. Humphrey (2012). A Performance Study on the VM Startup Time in the Cloud. Proceedings of 2012 IEEE 5th International Conference on Cloud Computing (Cloud2012). p.\\xa0423. doi:10.1109/CLOUD.2012.103. ISBN\\xa0978-1-4673-2892-0. S2CID\\xa01285357.\\n\\n^ Bruneo, Dario; Distefano, Salvatore; Longo, Francesco; Puliafito, Antonio; Scarpa, Marco (2013). \"Workload-Based Software Rejuvenation in Cloud Systems\". IEEE Transactions on Computers. 62 (6): 1072–1085. doi:10.1109/TC.2013.30. S2CID\\xa023981532.\\n\\n^ Kuperberg, Michael; Herbst, Nikolas; Kistowski, Joakim Von; Reussner, Ralf (2011). \"Defining and Measuring Cloud Elasticity\". KIT Software Quality Departement. doi:10.5445/IR/1000023476. Retrieved 13 August 2011. {{cite journal}}: Cite journal requires |journal= (help)\\n\\n^ \"Economies of Cloud Scale Infrastructure\". Cloud Slam 2011. Archived from the original on 2021-10-27. Retrieved 13 May 2011.\\n\\n^ He, Sijin; L. Guo; Y. Guo; C. Wu; M. Ghanem; R. Han (March 2012). Elastic Application Container: A Lightweight Approach for Cloud Resource Provisioning. 2012 IEEE 26th International Conference on Advanced Information Networking and Applications (AINA). pp.\\xa015–22. doi:10.1109/AINA.2012.74. ISBN\\xa0978-1-4673-0714-7. S2CID\\xa04863927.\\n\\n^ Marston, Sean; Li, Zhi; Bandyopadhyay, Subhajyoti; Zhang, Juheng; Ghalsasi, Anand (2011-04-01). \"Cloud computing – The business perspective\". Decision Support Systems. 51 (1): 176–189. doi:10.1016/j.dss.2010.12.006.\\n\\n^ Why Cloud computing scalability matters for business growth, Symphony Solutions, 2021\\n\\n^ Nouri, Seyed; Han, Li; Srikumar, Venugopal; Wenxia, Guo; MingYun, He; Wenhong, Tian (2019). \"Autonomic decentralized elasticity based on a reinforcement learning controller for cloud applications\". Future Generation Computer Systems. 94: 765–780. doi:10.1016/j.future.2018.11.049. S2CID\\xa059284268.\\n\\n^ Mills, Elinor (2009-01-27). \"Cloud computing security forecast: Clear skies\". CNET News. Retrieved 2019-09-19.\\n\\n^ a b c d e f g h i Peter Mell; Timothy Grance (September 2011). The NIST Definition of Cloud Computing (Technical report). National Institute of Standards and Technology: U.S. Department of Commerce. doi:10.6028/NIST.SP.800-145. Special publication 800-145.\\n\\n^ Duan, Yucong; Fu, Guohua; Zhou, Nianjun; Sun, Xiaobing; Narendra, Nanjangud; Hu, Bo (2015). \"Everything as a Service (XaaS) on the Cloud: Origins, Current and Future Trends\". 2015 IEEE 8th International Conference on Cloud Computing. IEEE. pp.\\xa0621–628. doi:10.1109/CLOUD.2015.88. ISBN\\xa0978-1-4673-7287-9. S2CID\\xa08201466.\\n\\n^ \\nAmies, Alex; Sluiman, Harm; Tong, Qiang Guo; Liu, Guo Ning (July 2012). \"Infrastructure as a Service Cloud Concepts\". Developing and Hosting Applications on the Cloud. IBM Press. ISBN\\xa0978-0-13-306684-5.\\n\\n^ Boniface, M.;  et\\xa0al. (2010). Platform-as-a-Service Architecture for Real-Time Quality of Service Management in Clouds. 5th International Conference on Internet and Web Applications and Services (ICIW). Barcelona, Spain: IEEE. pp.\\xa0155–160. doi:10.1109/ICIW.2010.91.\\n\\n^ \"Integration Platform as a Service (iPaaS)\". Gartner IT Glossary. Gartner.\\n\\n^ Gartner; Massimo Pezzini; Paolo Malinverno; Eric Thoo. \"Gartner Reference Model for Integration PaaS\". Retrieved 16 January 2013.\\n\\n^ Loraine Lawson (3 April 2015). \"IT Business Edge\". Retrieved 6 July 2015.\\n\\n^ Enterprise CIO Forum; Gabriel Lowy. \"The Value of Data Platform-as-a-Service (dPaaS)\". Archived from the original on 19 April 2015. Retrieved 6 July 2015.\\n\\n^ \"Definition of: SaaS\". PC Magazine Encyclopedia. Ziff Davis. Retrieved 14 May 2014.\\n\\n^ Hamdaqa, Mohammad. A Reference Model for Developing Cloud Applications (PDF).\\n\\n^ \\nChou, Timothy. Introduction to Cloud Computing: Business & Technology.\\n\\n^ \"HVD: the cloud\\'s silver lining\" (PDF). Intrinsic Technology. Archived from the original (PDF) on 2 October 2012. Retrieved 30 August 2012.\\n\\n^ Sun, Yunchuan; Zhang, Junsheng; Xiong, Yongping; Zhu, Guangyu (2014-07-01). \"Data Security and Privacy in Cloud Computing\". International Journal of Distributed Sensor Networks. 10 (7): 190903. doi:10.1155/2014/190903. ISSN\\xa01550-1477. S2CID\\xa013213544.\\n\\n^ Carney, Michael (2013-06-24). \"AnyPresence partners with Heroku to beef up its enterprise mBaaS offering\". PandoDaily. Retrieved 24 June 2013.\\n\\n^ Alex Williams (11 October 2012). \"Kii Cloud Opens Doors For Mobile Developer Platform With 25 Million End Users\". TechCrunch. Retrieved 16 October 2012.\\n\\n^ Aaron Tan (30 September 2012). \"FatFractal ups the ante in backend-as-a-service market\". Techgoondu.com. Retrieved 16 October 2012.\\n\\n^ Dan Rowinski (9 November 2011). \"Mobile Backend As A Service Parse Raises $5.5 Million in Series A Funding\". ReadWrite. Retrieved 23 October 2012.\\n\\n^ Pankaj Mishra (7 January 2014). \"MobStac Raises $2 Million in Series B To Help Brands Leverage Mobile Commerce\". TechCrunch. Retrieved 22 May 2014.\\n\\n^ \"built.io Is Building an Enterprise MBaas Platform for IoT\". programmableweb. 2014-03-03. Retrieved 3 March 2014.\\n\\n^ a b Miller, Ron (24 Nov 2015). \"AWS Lambda Makes Serverless Applications A Reality\". TechCrunch. Retrieved 10 July 2016.\\n\\n^ \"bliki: Serverless\". martinfowler.com. Retrieved 2018-05-04.\\n\\n^ Sbarski, Peter (2017-05-04). Serverless Architectures on AWS: With examples using AWS Lambda (1st\\xa0ed.). Manning Publications. ISBN\\xa09781617293825.\\n\\n^ \"Self-Run Private Cloud Computing Solution\\xa0– GovConnection\". govconnection.com. 2014. Retrieved April 15, 2014.\\n\\n^ \"Private Clouds Take Shape – Services – Business services – Informationweek\". 2012-09-09. Archived from the original on 2012-09-09.\\n\\n^ Haff, Gordon (2009-01-27). \"Just don\\'t call them private clouds\". CNET News. Retrieved 2010-08-22.\\n\\n^ \"There\\'s No Such Thing As A Private Cloud – Cloud-computing -\". 2013-01-26. Archived from the original on 2013-01-26.\\n\\n^ Rouse, Margaret. \"What is public cloud?\". Definition from Whatis.com. Retrieved 12 October 2014.\\n\\n^ \"FastConnect | Oracle Cloud Infrastructure\". cloud.oracle.com. Retrieved 2017-11-15.\\n\\n^ Schmidt, Rainer; Möhring, Michael; Keller, Barbara (2017). \"Customer Relationship Management in a Public Cloud environment - Key influencing factors for European enterprises\". HICSS. Proceedings of the 50th Hawaii International Conference on System Sciences (2017). doi:10.24251/HICSS.2017.513. hdl:10125/41673. ISBN\\xa09780998133102.\\n\\n^ \"What is hybrid cloud? - Definition from WhatIs.com\". SearchCloudComputing. Retrieved 2019-08-10.\\n\\n^ Butler, Brandon (2017-10-17). \"What is hybrid cloud computing? The benefits of mixing private and public cloud services\". Network World. Retrieved 2019-08-11.\\n\\n^ \"Mind the Gap: Here Comes Hybrid Cloud – Thomas Bittman\". Thomas Bittman. 24 September 2012. Retrieved 22 April 2015.\\n\\n^ \"Business Intelligence Takes to Cloud for Small Businesses\". CIO.com. 2014-06-04. Retrieved 2014-06-04.\\n\\n^ Désiré Athow (24 August 2014). \"Hybrid cloud: is it right for your business?\". TechRadar. Retrieved 22 April 2015.\\n\\n^ Metzler, Jim; Taylor, Steve. (2010-08-23) \"Cloud computing: Reality vs. fiction\", Network World.\\n\\n^ Rouse, Margaret. \"Definition: Cloudbursting\", May 2011. SearchCloudComputing.com.\\n\\n^ \"How Cloudbursting \"Rightsizes\" the Data Center\". 2012-06-22.\\n\\n^ Kaewkasi, Chanwit (3 May 2015). \"Cross-Platform Hybrid Cloud with Docker\".\\n\\n^ Qiang, Li (2009). \"Adaptive management of virtualized resources in cloud computing using feedback control\". First International Conference on Information Science and Engineering.\\n\\n^ Cunsolo, Vincenzo D.; Distefano, Salvatore; Puliafito, Antonio; Scarpa, Marco (2009). \"Volunteer Computing and Desktop Cloud: The Cloud@Home Paradigm\". 2009 Eighth IEEE International Symposium on Network Computing and Applications. pp.\\xa0134–139. doi:10.1109/NCA.2009.41. S2CID\\xa015848602.\\n\\n^ Rouse, Margaret. \"What is a multi-cloud strategy\". SearchCloudApplications. Retrieved 3 July 2014.\\n\\n^ King, Rachel. \"Pivotal\\'s head of products: We\\'re moving to a multi-cloud world\". ZDnet. Retrieved 3 July 2014.\\n\\n^ Multcloud manage multiple cloud accounts. Retrieved on 06 August 2014\\n\\n^ Gall, Richard (2018-05-16). \"Polycloud: a better alternative to cloud agnosticism\". Packt Hub. Retrieved 2019-11-11.\\n\\n^ Roh, Lucas (31 August 2016). \"Is the Cloud Finally Ready for Big Data?\". dataconomy.com. Retrieved 29 January 2018.\\n\\n^ Yang, C.; Huang, Q.; Li, Z.; Liu, K.; Hu, F. (2017). \"Big Data and cloud computing: innovation opportunities and challenges\". International Journal of Digital Earth. 10 (1): 13–53. Bibcode:2017IJDE...10...13Y. doi:10.1080/17538947.2016.1239771. S2CID\\xa08053067.\\n\\n^ Netto, M.; Calheiros, R.; Rodrigues, E.; Cunha, R.; Buyya, R. (2018). \"HPC Cloud for Scientific and Business Applications: Taxonomy, Vision, and Research Challenges\". ACM Computing Surveys. 51 (1): 8:1–8:29. arXiv:1710.08731. doi:10.1145/3150224. S2CID\\xa03604131.\\n\\n^ Eadline, Douglas. \"Moving HPC to the Cloud\". Admin Magazine. Admin Magazine. Retrieved 30 March 2019.\\n\\n^ \"Penguin Computing On Demand (POD)\". Retrieved 23 January 2018.\\n\\n^ Niccolai, James (11 August 2009). \"Penguin Puts High-performance Computing in the Cloud\". PCWorld. IDG Consumer & SMB. Retrieved 6 June 2016.\\n\\n^ \"HPC in AWS\". Retrieved 23 January 2018.\\n\\n^ \"Building GrepTheWeb in the Cloud, Part 1: Cloud Architectures\". Developer.amazonwebservices.com. Archived from the original on 5 May 2009. Retrieved 22 August 2010.\\n\\n^ a b c Ryan, Mark D. \"Cloud Computing Privacy Concerns on Our Doorstep\". cacm.acm.org.\\n\\n^ Haghighat, Mohammad; Zonouz, Saman; Abdel-Mottaleb, Mohamed (2015). \"CloudID: Trustworthy cloud-based and cross-enterprise biometric identification\". Expert Systems with Applications. 42 (21): 7905–7916. doi:10.1016/j.eswa.2015.06.025.\\n\\n^ Indu, I.; Anand, P.M. Rubesh; Bhaskar, Vidhyacharan (August 1, 2018). \"Identity and access management in cloud environment: Mechanisms and challenges\". Engineering Science and Technology. 21 (4): 574–588. doi:10.1016/j.jestch.2018.05.010 – via www.sciencedirect.com.\\n\\n^ a b \"Google Drive, Dropbox, Box and iCloud Reach the Top 5 Cloud Storage Security Breaches List\". psg.hitachi-solutions.com. Archived from the original on 2015-11-23. Retrieved 2015-11-22.\\n\\n^ Maltais, Michelle (26 April 2012). \"Who owns your stuff in the cloud?\". Los Angeles Times. Retrieved 2012-12-14.\\n\\n^ \"Security of virtualization, cloud computing divides IT and security pros\". Network World. 2010-02-22. Retrieved 2010-08-22.\\n\\n^ \"The Bumpy Road to Private Clouds\". 2010-12-20. Retrieved 8 October 2014.\\n\\n^ \"Should Companies Do Most of Their Computing in the Cloud? (Part 1) – Schneier on Security\". www.schneier.com. Retrieved 2016-02-28.\\n\\n^ \\n\"Disadvantages of Cloud Computing (Part 1) – Limited control and flexibility\". www.cloudacademy.com. Retrieved 2016-11-03.\\n\\n^ a b \\n\"The real limits of cloud computing\". www.itworld.com. 2012-05-14. Retrieved 2016-11-03.\\n\\n^ Karra, Maria. \"Cloud solutions for translation, yes or no?\". IAPTI.org. Retrieved 16 February 2021.\\n\\n^ Pradhan, Sayam (2021). \"Cloud Computing\". Transitioning from Traditional Data Centers to Cloud Computing: Pros and Cons (1\\xa0ed.). India. p.\\xa014. ISBN\\xa09798528758633.\\n\\n^ Seltzer, Larry. \"Your infrastructure\\'s in the cloud and the Internet goes down. Now, what?\". ZDNet. Retrieved 2020-06-01.\\n\\n^ Smith, David Mitchell. \"Hype Cycle for Cloud Computing, 2013\". Gartner. Retrieved 3 July 2014.\\n\\n^ \"The evolution of Cloud Computing\". Archived from the original on 29 March 2017. Retrieved 22 April 2015.\\n\\n^ \"Remote work helps Zoom grow 169% in one year, posting $328.2M in Q1 revenue\". TechCrunch. Retrieved 2021-04-27.\\n\\n^ Ruan, Keyun; Carthy, Joe; Kechadi, Tahar; Crosbie, Mark (2011-01-01). Cloud forensics: An overview.\\n\\n^ R., Adams (2013). The emergence of cloud storage and the need for a new digital forensic process model. researchrepository.murdoch.edu.au. ISBN\\xa09781466626621. Retrieved 2018-03-18.\\n\\n^ Richard, Adams; Graham, Mann; Valerie, Hobbs (2017). \"ISEEK, a tool for high speed, concurrent, distributed forensic data acquisition\". Research Online. doi:10.4225/75/5a838d3b1d27f.\\n\\n^ \"Office 365 Advanced eDiscovery\". Retrieved 2018-03-18.\\n\\n\\nFurther reading[edit]\\nMillard, Christopher (2013). Cloud Computing Law. Oxford University Press. ISBN\\xa0978-0-19-967168-7.\\nWeisser, Alexander (2020). International Taxation of Cloud Computing. Editions Juridiques Libres, ISBN 978-2-88954-030-3.\\nSingh, Jatinder; Powles, Julia; Pasquier, Thomas; Bacon, Jean (July 2015). \"Data Flow Management and Compliance in Cloud Computing\". IEEE Cloud Computing. 2 (4): 24–32. doi:10.1109/MCC.2015.69. S2CID\\xa09812531.\\nArmbrust, Michael; Stoica, Ion; Zaharia, Matei; Fox, Armando; Griffith, Rean; Joseph, Anthony D.; Katz, Randy; Konwinski, Andy; Lee, Gunho; Patterson, David; Rabkin, Ariel (1 April 2010). \"A view of cloud computing\". Communications of the ACM. 53 (4): 50. doi:10.1145/1721654.1721672. S2CID\\xa01673644.\\nHu, Tung-Hui (2015). A Prehistory of the Cloud. MIT Press. ISBN\\xa0978-0-262-02951-3.\\nMell, P. (2011, September 31). The NIST Definition of Cloud Computing. Retrieved November 1, 2015, from National Institute of Standards and Technology website\\nExternal links[edit]\\n Media related to Cloud computing at Wikimedia Commons\\n\\n\\n\\nWikiquote has quotations related to: Cloud computing\\n\\nvteCloud computingAs a service\\nContent as a service\\nData as a service\\nDesktop as a service\\nFunction as a service\\nInfrastructure as a service\\nIntegration platform as a service\\nMobile backend as a service\\nNetwork as a service\\nPlatform as a service\\nSecurity as a service\\nSoftware as a service\\nTechnologies\\nCloud database\\nCloud storage\\nData centers\\nDistributed file system for cloud\\nHardware virtualization\\nInternet\\nNative cloud application\\nNetworking\\nSecurity\\nStructured storage\\nVirtual appliance\\nWeb APIs\\nVirtual private cloud\\nApplications\\nBox\\nDropbox\\nGoogle\\nWorkspace\\nDrive\\nHP Cloud (closed)\\nIBM Cloud\\nMicrosoft\\nOffice 365\\nOneDrive\\nNextcloud\\nOracle Cloud\\nRackspace\\nSalesforce\\nWorkday\\nZoho\\nPlatforms\\nAlibaba Cloud\\nAmazon Web Services\\nAppScale\\nBox\\nBluemix\\nCloudBolt\\nCloud Foundry\\nCocaine (PaaS)\\nCreatio\\nEngine Yard\\nHelion\\nGE Predix\\nGoogle App Engine\\nGreenQloud\\nHeroku\\nIBM Cloud\\nInktank\\nJelastic\\nMicrosoft Azure\\nMindSphere\\nNetlify\\nOracle Cloud\\nOutSystems\\nopenQRM\\nOpenShift\\nPythonAnywhere\\nRightScale\\nScalr\\nForce.com\\nSAP Cloud Platform\\nSplunk\\nVMware vCloud Air\\nWaveMaker\\nInfrastructure\\nAlibaba Cloud\\nAmazon Web Services\\nAbiquo Enterprise Edition\\nCloudStack\\nCitrix Cloud\\nCtrlS\\nDigitalOcean\\nEMC Atmos\\nEucalyptus\\nFujitsu\\nGoogle Cloud Platform\\nGreenButton\\nGreenQloud\\nIBM Cloud\\niland\\nJoyent\\nLinode\\nLunacloud\\nMicrosoft Azure\\nMirantis\\nNetlify\\nNimbula\\nNimbus\\nOpenIO\\nOpenNebula\\nOpenStack\\nOracle Cloud\\nOrionVM\\nRackspace Cloud\\nSafe Swiss Cloud\\nZadara\\nlibvirt\\nlibguestfs\\nOVirt\\nVirtual Machine Manager\\nWakame-vdc\\nVirtual Private Cloud OnDemand\\n\\n Category\\n Commons\\n\\nvteParallel computingGeneral\\nDistributed computing\\nParallel computing\\nMassively parallel\\nCloud computing\\nHigh-performance computing\\nMultiprocessing\\nManycore processor\\nGPGPU\\nComputer network\\nSystolic array\\nLevels\\nBit\\nInstruction\\nThread\\nTask\\nData\\nMemory\\nLoop\\nPipeline\\nMultithreading\\nTemporal\\nSimultaneous (SMT)\\nSpeculative (SpMT)\\nPreemptive\\nCooperative\\nClustered multi-thread (CMT)\\nHardware scout\\nTheory\\nPRAM model\\nPEM model\\nAnalysis of parallel algorithms\\nAmdahl\\'s law\\nGustafson\\'s law\\nCost efficiency\\nKarp–Flatt metric\\nSlowdown\\nSpeedup\\nElements\\nProcess\\nThread\\nFiber\\nInstruction window\\nArray data structure\\nCoordination\\nMultiprocessing\\nMemory coherency\\nCache coherency\\nCache invalidation\\nBarrier\\nSynchronization\\nApplication checkpointing\\nProgramming\\nStream processing\\nDataflow programming\\nModels\\nImplicit parallelism\\nExplicit parallelism\\nConcurrency\\nNon-blocking algorithm\\nHardware\\nFlynn\\'s taxonomy\\nSISD\\nSIMD\\nArray processing (SIMT)\\nPipelined processing\\nAssociative processing\\nMISD\\nMIMD\\nDataflow architecture\\nPipelined processor\\nSuperscalar processor\\nVector processor\\nMultiprocessor\\nsymmetric\\nasymmetric\\nMemory\\nshared\\ndistributed\\ndistributed shared\\nUMA\\nNUMA\\nCOMA\\nMassively parallel computer\\nComputer cluster\\nGrid computer\\nHardware acceleration\\nAPIs\\nAteji PX\\nBoost\\nChapel\\nHPX\\nCharm++\\nCilk\\nCoarray Fortran\\nCUDA\\nDryad\\nC++ AMP\\nGlobal Arrays\\nGPUOpen\\nMPI\\nOpenMP\\nOpenCL\\nOpenHMPP\\nOpenACC\\nParallel Extensions\\nPVM\\nPOSIX Threads\\nRaftLib\\nROCm\\nUPC\\nTBB\\nZPL\\nProblems\\nAutomatic parallelization\\nDeadlock\\nDeterministic algorithm\\nEmbarrassingly parallel\\nParallel slowdown\\nRace condition\\nSoftware lockout\\nScalability\\nStarvation\\n\\n\\xa0Category: Parallel computing\\n\\nAuthority control National libraries\\nSpain\\nFrance (data)\\nGermany\\nIsrael\\nUnited States\\nJapan\\nOther\\nFaceted Application of Subject Terminology\\nSUDOC (France)\\n1\\n2\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Cloud_computing&oldid=1083869818\"',\n",
       "  '\\n\\n\\nLook up Amazon\\xa0or amazon in Wiktionary, the free dictionary.\\n\\nAmazon most often refers to:\\n\\nAmazons, a tribe of woman warriors in Greek mythology\\nAmazon rainforest, a rainforest covering most of the Amazon basin\\nAmazon River, in South America\\nAmazon (company), an American multinational technology company\\nAmazon or Amazone may also refer to:\\n\\nContents\\n\\n1 Places\\n\\n1.1 South America\\n1.2 Elsewhere\\n\\n\\n2 People\\n3 Art and entertainment\\n\\n3.1 Fictional characters\\n3.2 Film and television\\n3.3 Games\\n3.4 Literature\\n3.5 Music\\n\\n\\n4 Military units\\n5 Organizations\\n6 Transportation\\n\\n6.1 Land vehicles\\n6.2 Ships\\n\\n\\n7 Other uses\\n8 See also\\n\\n\\n\\nPlaces[edit]\\nSouth America[edit]\\nAmazon Basin (sedimentary basin), a sedimentary basin at the middle and lower course of the river\\nAmazon basin, the part of South America drained by the river and its tributaries\\nAmazon Reef, at the mouth of the Amazon basin\\nElsewhere[edit]\\n1042 Amazone, an asteroid\\nAmazon Creek, a stream in Oregon, US\\nPeople[edit]\\nAmazon Eve (born 1979), American model, fitness trainer, and actress\\nLesa Lewis (born 1967), American professional bodybuilder nicknamed \"Amazon\"\\nArt and entertainment[edit]\\nFictional characters[edit]\\nAmazon (Amalgam Comics)\\nAmazon, an alias of the Marvel supervillain Man-Killer\\nAmazons (DC Comics), a group of superhuman characters\\nThe Amazon, a Diablo II character\\nThe Amazon, a Pro Wrestling character\\nKamen Rider Amazon, title character in the fourth installment of the Kamen Rider series\\nFilm and television[edit]\\n\\n\\nThe Amazons (1917 film), an American silent tragedy\\nThe Amazon (film), a 1921 German silent film\\nWar Goddess, also known as The Amazons, a 1973 Italian adventure fantasy drama\\nAmazons (1984 film), an American thriller\\nAmazons (1986 film), an Argentine adventure fantasy\\nAmazon (1990 film), a 1990 drama\\nAmazon (1997 film), a short documentary\\nAmazon (1999 TV series), a Canadian drama\\nAmazon (2000 film), a 2000 French film\\nAmazon (2008 TV series), a British documentary series\\nGames[edit]\\nAmazon (chess), a fairy chess piece\\nAmazons (solitaire), a card game\\nAmazon (video game), a 1984 interactive fiction graphic adventure game\\nAmazon: Guardians of Eden, a 1991 video game\\nGame of the Amazons, a board game\\nLiterature[edit]\\nAmazons (novel), a 1980 novel co-written by Don DeLillo, published under the pseudonym Cleo Birdwell\\nAmazons!, a fantasy anthology edited by Jessica Amanda Salmonson\\nSwallows and Amazons series, a series of twelve children\\'s books by Arthur Ransome\\nThe Amazon (novella), by Nikolai Leskov\\nThe Amazons (play), by Arthur Wing Pinero\\nMusic[edit]\\nThe Amazons (band), a British indie band from Reading, Berkshire\\nMilitary units[edit]\\nAmazonian Guard, or \"the Amazons\", a bodyguard unit of Muammar Gaddafi\\nAmazons Company, a Greek ceremonial female battalion\\nDahomey Amazons, a Fon regiment\\nOrganizations[edit]\\nAmazon Bookstore Cooperative, a former feminist bookstore\\nAmazonen-Werke, a German agricultural machinery manufacturer\\nLos Angeles Amazons, an American football team\\nTakembeng, or les Amazones des SDF, a women\\'s social movement in Cameroon\\nTransportation[edit]\\nLand vehicles[edit]\\nAmazon (automobile), a 1920s British cyclecar\\nAmazon, a GWR 3031 Class locomotive operating 1892–1908\\nAmazon, a GWR Iron Duke Class locomotive operating 1851–1877\\nVolvo Amazon, a 1956–1970 mid-size car\\nShips[edit]\\nAmazon (1780 ship), launched in France in 1775 under another name\\nAmazon (brigantine), a Canadian brigantine launched 1861\\nAmazon (yacht), a British screw schooner built 1885\\nAmazon-class frigate, four classes of frigate of the British Royal Navy\\nAmazon-class sloop, of the British Royal Navy\\nFrench submarine Amazone (1916), an Armide-class diesel-electric attack submarine\\nHMS Amazon, nine ships of the Royal Navy\\nRMS Amazon, two ships of the Royal Mail Steam Packet Company\\nSMS Amazone (1843), a 3-masted sail corvette of the Prussian Navy\\nSMS Amazone, a 1900 2,700 ton Gazelle-class light cruiser\\nUSS Amazon (1861), a US Navy bark\\nOther uses[edit]\\nAmazon (color), a variant of jungle green\\nAmazon parrot\\nSee also[edit]\\nAll pages with titles beginning with Amazon\\nAll pages with titles containing Amazon\\nAmason (disambiguation)\\nAmazonas (disambiguation)\\nAmazonia (disambiguation)\\nAmazonian (disambiguation)\\nAmazonka, a 2008 album by Ruslana\\nAmyzon (disambiguation)\\nTopics referred to by the same term\\n\\n This disambiguation page lists  articles associated with the title Amazon.If an internal link led you here, you may wish to change the link to point directly to the intended article. \\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Amazon&oldid=1084465742\"',\n",
       "  'Personal computer for mobile use\\nFor other uses, see Laptop (disambiguation).\\nThis article needs to be updated. Please help update this article to reflect recent events or newly available information. (November 2021)\\n\\n\\n A Chromebook 11 laptop by Acer Inc.\\n A Huawei MateBook series laptop by Huawei\\nA laptop, laptop computer, or notebook computer is a small, portable personal computer (PC) with a screen and alphanumeric keyboard. Laptops typically have a clam shell form factor with the screen mounted on the inside of the upper lid and the keyboard on the inside of the lower lid, although 2-in-1 PCs with a detachable keyboard are often marketed as laptops or as having a laptop mode. Laptops are folded shut for transportation, and thus are suitable for mobile use.[1] Its name comes from lap, as it was deemed practical to be placed on a person\\'s lap when being used. Today, laptops are used in a variety of settings, such as at work, in education, for playing games, web browsing, for personal multimedia, and for general home computer use.\\nAs of 2021, in American English, the terms laptop computer and notebook computer are used interchangeably;[2] in other dialects of English, one or the other may be preferred. Although the terms notebook computers or notebooks originally referred to a specific size of laptop (originally smaller and lighter than mainstream laptops of the time),[3] the terms have come to mean the same thing and notebook no longer refers to any specific size.\\nLaptops combine all the input/output components and capabilities of a desktop computer, including the display screen, small speakers, a keyboard, data storage device, sometimes an optical disc drive, pointing devices (such as a touch pad or pointing stick), with an operating system, a processor and memory into a single unit. Most modern laptops feature integrated webcams and built-in microphones, while many also have touchscreens. Laptops can be powered either from an internal battery or by an external power supply from an AC adapter. Hardware specifications, such as the processor speed and memory capacity, significantly vary between different types, models and price points.\\nDesign elements, form factor and construction can also vary significantly between models depending on the intended use. Examples of specialized models of laptops include rugged notebooks for use in construction or military applications, as well as low production cost laptops such as those from the One Laptop per Child (OLPC) organization, which incorporate features like solar charging and semi-flexible components not found on most laptop computers. Portable computers, which later developed into modern laptops, were originally considered to be a small niche market, mostly for specialized field applications, such as in the military, for accountants, or traveling sales representatives. As portable computers evolved into modern laptops, they became widely used for a variety of purposes.[4]\\n\\nContents\\n\\n1 History\\n2 Etymology\\n3 Types\\n\\n3.1 Smaller and Larger Laptops\\n3.2 Convertible, hybrid, 2-in-1\\n3.3 Rugged laptop\\n\\n\\n4 Hardware\\n\\n4.1 Display\\n\\n4.1.1 Sizes\\n4.1.2 Resolution\\n4.1.3 Refresh rates and 3D\\n\\n\\n4.2 Central processing unit\\n4.3 Graphical processing unit\\n4.4 Memory\\n4.5 Internal storage\\n4.6 Removable media drive\\n4.7 Inputs\\n4.8 Input/output (I/O) ports\\n4.9 Expansion cards\\n4.10 Battery and power supply\\n4.11 Power connectors\\n4.12 Cooling\\n4.13 Docking station\\n4.14 Charging trolleys\\n4.15 Solar panels\\n4.16 Accessories\\n4.17 Modularity\\n4.18 Obsolete features\\n\\n\\n5 Comparison with desktops\\n\\n5.1 Advantages\\n5.2 Disadvantages\\n\\n5.2.1 Performance\\n5.2.2 Upgradeability\\n5.2.3 Ergonomics and health effects\\n\\n5.2.3.1 Wrists\\n5.2.3.2 Neck and spine\\n5.2.3.3 Possible effect on fertility\\n\\n\\n5.2.4 Thighs\\n5.2.5 Durability\\n\\n5.2.5.1 Equipment wear\\n5.2.5.2 Heating and cooling\\n5.2.5.3 Battery life\\n\\n\\n5.2.6 Security and privacy\\n\\n\\n\\n\\n6 Sales\\n\\n6.1 Manufacturers\\n6.2 Market share\\n\\n\\n7 Disposal\\n8 Extreme use\\n9 See also\\n10 Notes\\n11 References\\n\\n\\n\\nHistory[edit]\\nMain article: History of laptops\\n Alan Kay holding the mockup of his Dynabook concept in 2008\\n The Epson HX-20, the first \"laptop computer\", was invented in 1980 and introduced in 1981\\nAs the personal computer (PC) became feasible in 1971, the idea of a portable personal computer soon followed. A \"personal, portable information manipulator\" was imagined by Alan Kay at Xerox PARC in 1968,[5] and described in his 1972 paper as the \"Dynabook\".[6] The IBM Special Computer APL Machine Portable (SCAMP) was demonstrated in 1973.[7] This prototype was based on the IBM PALM processor.[8] The IBM 5100, the first commercially available portable computer, appeared in September 1975, and was based on the SCAMP prototype.[9]\\nAs 8-bit CPU machines became widely accepted, the number of portables increased rapidly. The first \"laptop-sized notebook computer\" was the Epson HX-20,[10][11] invented (patented) by Suwa Seikosha\\'s Yukio Yokozawa in July 1980,[12] introduced at the COMDEX computer show in Las Vegas by Japanese company Seiko Epson in 1981,[13][11] and released in July 1982.[11][14] It had an LCD screen, a rechargeable battery, and a calculator-size printer, in a 1.6\\xa0kg (3.5\\xa0lb) chassis, the size of an A4 notebook.[11] It was described as a \"laptop\" and \"notebook\" computer in its patent.[12]\\nThe portable micro computer Portal of the French company R2E Micral CCMC officially appeared in September 1980 at the Sicob show in Paris. It was a portable microcomputer designed and marketed by the studies and developments department of R2E Micral at the request of the company CCMC specializing in payroll and accounting. It was based on an Intel 8085 processor, 8-bit, clocked at 2\\xa0MHz. It was equipped with a central 64 KB RAM, a keyboard with 58 alphanumeric keys and 11 numeric keys (separate blocks), a 32-character screen, a floppy disk: capacity = 140,000 characters, of a thermal printer: speed = 28 characters / second, an asynchronous channel, asynchronous channel, a 220 V power supply. It weighed 12\\xa0kg and its dimensions were 45\\u2009×\\u200945\\u2009×\\u200915\\xa0cm. It provided total mobility. Its operating system was aptly named Prologue.\\n\\n A Siemens PCD-3Psx laptop, released in 1989\\nThe Osborne 1, released in 1981, was a luggable computer that used the Zilog Z80 and weighed 24.5 pounds (11.1\\xa0kg).[15] It had no battery, a 5\\xa0in (13\\xa0cm) cathode-ray tube (CRT) screen, and dual 5.25\\xa0in (13.3\\xa0cm) single-density floppy drives. Both Tandy/RadioShack and Hewlett Packard (HP) also produced portable computers of varying designs during this period.[16][17] The first laptops using the flip form factor appeared in the early 1980s. The Dulmont Magnum was released in Australia in 1981–82, but was not marketed internationally until 1984–85. The US$8,150 (equivalent to $22,880 in 2021) GRiD Compass 1101, released in 1982, was used at NASA and by the military, among others. The Sharp PC-5000,[18] Ampere[19] and Gavilan SC released in 1983. The Gavilan SC was described as a \"laptop\" by its manufacturer,[20] while the Ampere had a modern clamshell design.[19][21] The Toshiba T1100 won acceptance not only among PC experts but the mass market as a way to have PC portability.[22]\\nFrom 1983 onward, several new input techniques were developed and included in laptops, including the touch pad (Gavilan SC, 1983), the pointing stick (IBM ThinkPad 700, 1992), and handwriting recognition (Linus Write-Top,[23] 1987). Some CPUs, such as the 1990 Intel i386SL, were designed to use minimum power to increase battery life of portable computers and were supported by dynamic power management features such as Intel SpeedStep and AMD PowerNow! in some designs.\\nDisplays reached 640x480 (VGA) resolution by 1988 (Compaq SLT/286), and color screens started becoming a common upgrade in 1991,[24] with increases in resolution and screen size occurring frequently until the introduction of 17\" screen laptops in 2003. Hard drives started to be used in portables, encouraged by the introduction of 3.5\" drives in the late 1980s, and became common in laptops starting with the introduction of 2.5\" and smaller drives around 1990; capacities have typically lagged behind physically larger desktop drives.\\nCommon resolutions of laptop webcams are 720p (HD), and in lower-end laptops 480p.[25] The earliest known laptops with 1080p (Full HD) webcams like the Samsung 700G7C were released in the early 2010s.[26]\\nOptical disc drives became common in full-size laptops around 1997; this initially consisted of CD-ROM drives, which were supplanted by CD-R, DVD, and Blu-ray drives with writing capability over time. Starting around 2011, the trend shifted against internal optical drives, and as of 2021, they have largely disappeared; they are still readily available as external peripherals.\\n\\nEtymology[edit]\\nWhile the terms laptop and notebook are used interchangeably today, there is some question as to the original etymology and specificity of either term. The term laptop appears to have been coined in the early 1980s to describe a mobile computer which could be used on one\\'s lap and to distinguish these devices from earlier and much heavier portable computers (informally called \"luggables\"). The term notebook appears to have gained currency somewhat later as manufacturers started producing even smaller portable devices, further reducing their weight and size and incorporating a display roughly the size of A4 paper;[3] these were marketed as notebooks to distinguish them from bulkier mainstream or desktop replacement laptops.\\n\\nTypes[edit]\\n Compaq Armada laptop from the late 1990s\\n Apple MacBook Air, an \"ultraportable\" laptop weighing under 3.0\\xa0lb (1.36\\xa0kg)\\n Lenovo\\'s IdeaPad laptop\\n Lenovo\\'s ThinkPad business laptop, originally an IBM product\\n Acer Aspire laptop\\n Asus Transformer Pad, a hybrid tablet, powered by Android OS\\n Microsoft Surface Pro 3, 2-in-1 detachable\\n Alienware gaming laptop with backlit keyboard and touch pad\\n Samsung Sens laptop\\n Samsung Notebook 3\\n Panasonic Toughbook CF-M34, a rugged laptop/subnotebook\\nSince the introduction of portable computers during the late 1970s, their form has changed significantly, spawning a variety of visually and technologically differing subclasses. Except where there is a distinct legal trademark around a term (notably, Ultrabook), there are rarely hard distinctions between these classes and their usage has varied over time and between different sources. Since the late 2010s, the use of more specific terms has become less common, with sizes distinguished largely by the size of the screen.\\n\\nSmaller and Larger Laptops[edit]\\nMain articles: Subnotebook and Desktop replacement computer\\nThere were in the past a number of marketing categories for smaller and larger laptop computers; these included \"subnotebook\" models, low cost \"netbooks\", and \"Ultra-mobile PCs\" where the size class overlapped with devices like smartphone and handheld tablets, and \"Desktop replacement\" laptops for machines notably larger and heavier than typical to operate more powerful processors or graphics hardware.[27] All of these terms have fallen out of favor as the size of mainstream laptops has gone down and their capabilities have gone up; except for niche models, laptop sizes tend to be distinguished by the size of the screen, and for more powerful models, by any specialized purpose the machine is intended for, such as a \"gaming laptop\" or a \"mobile workstation\" for professional use.See also: Gaming computer §\\xa0Gaming laptop computers, and Workstation\\nConvertible, hybrid, 2-in-1[edit]\\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (November 2015) (Learn how and when to remove this template message)\\n\\n\\n\\nMain article: 2-in-1 PC\\nThe latest trend of technological convergence in the portable computer industry spawned a broad range of devices, which combined features of several previously separate device types. The hybrids, convertibles, and 2-in-1s emerged as crossover devices, which share traits of both tablets and laptops. All such devices have a touchscreen display designed to allow users to work in a tablet mode, using either multi-touch gestures or a stylus/digital pen.\\nConvertibles are devices with the ability to conceal a hardware keyboard. Keyboards on such devices can be flipped, rotated, or slid behind the back of the chassis, thus transforming from a laptop into a tablet. Hybrids have a keyboard detachment mechanism, and due to this feature, all critical components are situated in the part with the display. 2-in-1s can have a hybrid or a convertible form, often dubbed 2-in-1 detachable and 2-in-1 convertibles respectively, but are distinguished by the ability to run a desktop OS, such as Windows 10. 2-in-1s are often marketed as laptop replacement tablets.[28]\\n2-in-1s are often very thin, around 10 millimetres (0.39\\xa0in), and light devices with a long battery life. 2-in-1s are distinguished from mainstream tablets as they feature an x86-architecture CPU (typically a low- or ultra-low-voltage model), such as the Intel Core i5, run a full-featured desktop OS like Windows 10, and have a number of typical laptop I/O ports, such as USB 3 and Mini DisplayPort.\\n2-in-1s are designed to be used not only as a media consumption device but also as valid desktop or laptop replacements, due to their ability to run desktop applications, such as Adobe Photoshop. It is possible to connect multiple peripheral devices, such as a mouse, keyboard, and several external displays to a modern 2-in-1.\\nMicrosoft Surface Pro-series devices and Surface Book are examples of modern 2-in-1 detachable, whereas Lenovo Yoga-series computers are a variant of 2-in-1 convertibles. While the older Surface RT and Surface 2 have the same chassis design as the Surface Pro, their use of ARM processors and Windows RT do not classify them as 2-in-1s, but as hybrid tablets.[29] Similarly, a number of hybrid laptops run a mobile operating system, such as Android. These include Asus\\'s Transformer Pad devices, examples of hybrids with a detachable keyboard design, which do not fall in the category of 2-in-1s.\\n\\nRugged laptop[edit]\\nMain article: Rugged computer\\nA rugged laptop is designed to reliably operate in harsh usage conditions such as strong vibrations, extreme temperatures, and wet or dusty environments. Rugged laptops are bulkier, heavier, and much more expensive than regular laptops,[30] and thus are seldom seen in regular consumer use.\\n\\nHardware[edit]\\nThis section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (July 2016) (Learn how and when to remove this template message)\\nMain article: Personal computer hardware\\n Miniaturization: a comparison of a desktop computer motherboard (ATX form factor) to a motherboard from a 13\" laptop (2008 unibody MacBook)\\n Inner view of a Sony VAIO laptop\\n A SODIMM memory module\\nThe basic components of laptops function identically to their desktop counterparts. Traditionally they were miniaturized and adapted to mobile use, although desktop systems increasingly use the same smaller, lower-power parts which were originally developed for mobile use. The design restrictions on power, size, and cooling of laptops limit the maximum performance of laptop parts compared to that of desktop components, although that difference has increasingly narrowed.[31]\\nIn general, laptop components are not intended to be replaceable or upgradable by the end-user, except for components that can be detached; in the past, batteries and optical drives were commonly exchangeable. This restriction is one of the major differences between laptops and desktop computers, because the large \"tower\" cases used in desktop computers are designed so that new motherboards, hard disks, sound cards, RAM, and other components can be added. Memory and storage can often be upgraded with some disassembly, but with the most compact laptops, there may be no upgradeable components at all.[32]\\nIntel, Asus, Compal, Quanta, and some other laptop manufacturers have created the Common Building Block standard for laptop parts to address some of the inefficiencies caused by the lack of standards and inability to upgrade components.[33]\\nThe following sections summarizes the differences and distinguishing features of laptop components in comparison to desktop personal computer parts.[34]\\n\\nDisplay[edit]\\nInternally, a display is usually an LCD panel, although occasionally OLEDs are used. These interface to the laptop using the LVDS or embedded DisplayPort protocol, while externally, it can be a glossy screen or a matte (anti-glare) screen. As of 2021, mainstream consumer laptops tend to come with either 13\" or 15\"-16\" screens; 14\" models are more popular among business machines. Larger and smaller models are available, but less common – there is no clear dividing line in minimum or maximum size. Machines small enough to be handheld (screens in the 6–8\" range) can be marketed either as very small laptops or \"handheld PCs,\" while the distinction between the largest laptops and \"All-in-One\" desktops is whether they fold for travel.\\n\\nSizes[edit]\\nIn the past, there was a broader range of marketing terms (both formal and informal) to distinguish between different sizes of laptops. These included Netbooks, subnotebooks, Ultra-mobile PC, and Desktop replacement computers; these are sometimes still used informally, although they are essentially dead in terms of manufacturer marketing.\\n\\nResolution[edit]\\nHaving a higher resolution display allows more items to fit onscreen at a time, improving the user\\'s ability to multitask, although at the higher resolutions on smaller screens, the resolution may only serve to display sharper graphics and text rather than increasing the usable area. Since the introduction of the MacBook Pro with Retina display in 2012, there have been an increase in the availability of \"HiDPI\" (or high Pixel density) displays; as of 2021, this is generally considered to be anything higher than 1920 pixels wide. This has increasingly converged around 4K (3840-pixel-wide) resolutions.\\nExternal displays can be connected to most laptops, and models with a Mini DisplayPort can handle up to three.[35]\\n\\nRefresh rates and 3D[edit]\\nThe earliest laptops known to feature a display with doubled 120 Hz of refresh rate and active shutter 3D system were released in 2011 by Dell (M17x) and Samsung (700G7A).[36][37]\\n\\nCentral processing unit[edit]\\nA laptop\\'s central processing unit (CPU) has advanced power-saving features and produces less heat than one intended purely for desktop use. Mainstream laptop CPUs made after 2018 have four processor cores, although some inexpensive models still have 2-core CPUs, and 6-core and 8-core models are also available.\\nFor the low price and mainstream performance, there is no longer a significant performance difference between laptop and desktop CPUs, but at the high end, the fastest desktop CPUs still substantially outperform the fastest laptop processors, at the expense of massively higher power consumption and heat generation; the fastest laptop processors top out at 56 watts of heat, while the fastest desktop processors top out at 150 watts.\\nThere has been a wide range of CPUs designed for laptops available from both Intel, AMD, and other manufacturers. On non-x86 architectures, Motorola and IBM produced the chips for the former PowerPC-based Apple laptops (iBook and PowerBook). Between around 2000 to 2014, most full-size laptops had socketed, replaceable CPUs; on thinner models, the CPU was soldered on the motherboard and was not replaceable or upgradable without replacing the motherboard. Since 2015, Intel has not offered new laptop CPU models with pins to be interchangeable, preferring ball grid array chip packages which have to be soldered;[38]and as of 2021, only a few rare models using desktop parts.\\nIn the past, some laptops have used a desktop processor instead of the laptop version and have had high-performance gains at the cost of greater weight, heat, and limited battery life; this is not unknown as of 2021, but since around 2010, the practice has been restricted to small-volume gaming models. Laptop CPUs are rarely able to be overclocked; most use locked processors. Even on gaming models where unlocked processors are available, the cooling system in most laptops is often very close to its limits and there is rarely headroom for an overclocking–related operating temperature increase.\\n\\nGraphical processing unit[edit]\\nOn most laptops, a graphical processing unit (GPU) is integrated into the CPU to conserve power and space. This was introduced by Intel with the Core i-series of mobile processors in 2010, and similar accelerated processing unit (APU) processors by AMD later that year.\\nBefore that, lower-end machines tended to use graphics processors integrated into the system chipset, while higher-end machines had a separate graphics processor. In the past, laptops lacking a separate graphics processor were limited in their utility for gaming and professional applications involving 3D graphics, but the capabilities of CPU-integrated graphics have converged with the low-end of dedicated graphics processors since the mid-2010s.\\nHigher-end laptops intended for gaming or professional 3D work still come with dedicated and in some cases even dual, graphics processors on the motherboard or as an internal expansion card. Since 2011, these almost always involve switchable graphics so that when there is no demand for the higher performance dedicated graphics processor, the more power-efficient integrated graphics processor will be used. Nvidia Optimus and AMD Hybrid Graphics are examples of this sort of system of switchable graphics.\\n\\nMemory[edit]\\nSince around the year 2000, most laptops have used SO-DIMM RAM,[34] although, as of 2021, an increasing number of models use memory soldered to the motherboard. Before 2000, most laptops used proprietary memory modules if their memory was upgradable.\\nIn the early 2010s, high end laptops such as the 2011 Samsung 700G7A have passed the 10 GB RAM barrier, featuring 16 GB of RAM.[39]\\nWhen upgradeable, memory slots are sometimes accessible from the bottom of the laptop for ease of upgrading; in other cases, accessing them requires significant disassembly. Most laptops have two memory slots, although some will have only one, either for cost savings or because some amount of memory is soldered. Some high-end models have four slots; these are usually mobile engineering workstations, although a few high-end models intended for gaming do as well.\\nAs of 2021, 8 GB RAM is most common, with lower-end models occasionally having 4GB. Higher-end laptops may come with 16 GB of RAM or more.\\n\\nInternal storage[edit]\\nThe earliest laptops most often used floppy disk for storage, although a few used either RAM disks or tape, by the late 1980s hard disk drives had become the standard form of storage.\\nBetween 1990 and 2009, almost all laptops typically had a hard disk drive (HDD) for storage; since then, solid-state drives (SSD) have gradually come to supplant hard drives in all but some inexpensive consumer models. Solid-state drives are faster and more power-efficient, as well as eliminating the hazard of drive and data corruption caused by a laptop\\'s physical impacts, as they use no mechanical parts such as a rotational platter.[40] In many cases, they are more compact as well. Initially, in the late 2000s, SSDs were substantially more expensive than HDDs, but as of 2021 prices on smaller capacity (under 1 terabyte) drives have converged; larger capacity drives remain more expensive than comparable-sized HDDs.\\nSince around 1990, where a hard drive is present it will typically be a 2.5-inch drive; some very compact laptops support even smaller 1.8-inch HDDs, and a very small number used 1\" Microdrives. Some SSDs are built to match the size/shape of a laptop hard drive, but increasingly they have been replaced with smaller mSATA or M.2 cards. SSDs using the newer and much faster NVM Express standard for connecting are only available as cards.\\nAs of 2021, many laptops no longer contain space for a 2.5\" drive, accepting only M.2 cards; a few of the smallest have storage soldered to the motherboard. For those that can, they can typically contain a single 2.5-inch drive, but a small number of laptops with a screen wider than 15 inches can house two drives.\\nA variety of external HDDs or NAS data storage servers with support of RAID technology can be attached to virtually any laptop over such interfaces as USB, FireWire, eSATA, or Thunderbolt, or over a wired or wireless network to further increase space for the storage of data. Many laptops also incorporate a card reader which allows for use of memory cards, such as those used for digital cameras, which are typically SD or microSD cards. This enables users to download digital pictures from an SD card onto a laptop, thus enabling them to delete the SD card\\'s contents to free up space for taking new pictures.\\n\\nRemovable media drive[edit]\\nOptical disc drives capable of playing CD-ROMs, compact discs (CD), DVDs, and in some cases, Blu-ray discs (BD), were nearly universal on full-sized models between the mid-1990s and the early 2010s. As of 2021, drives are uncommon in compact or premium laptops; they remain available in some bulkier models, but the trend towards thinner and lighter machines is gradually eliminating these drives and players – when needed they can be connected via USB instead.\\n\\nInputs[edit]\\n Closeup of a touchpad on an Acer laptop, where buttons and the touch-sensitive surface are shared\\n Closeup of a TrackPoint cursor and UltraNav buttons on a ThinkPad laptop\\n Interfaces on a ThinkPad laptop (2011): Ethernet network port (center), VGA (left), DisplayPort (top right) and USB 2.0 (bottom right). Due to the trend towards very flat laptops and the widespread use of WLAN, the relatively high Ethernet socket is no longer mandatory in today\\'s devices, as is the technically outdated VGA.\\nAn alphanumeric keyboard is used to enter text, data, and other commands (e.g., function keys). A touchpad (also called a trackpad), a pointing stick, or both, are used to control the position of the cursor on the screen, and an integrated keyboard[41] is used for typing. Some touchpads have buttons separate from the touch surface, while others share the surface. A quick double-tap is typically registered as a click, and operating systems may recognize multi-finger touch gestures.\\nAn external keyboard and mouse may be connected using a USB port or wirelessly, via Bluetooth or similar technology. Some laptops have multitouch touchscreen displays, either available as an option or standard. Most laptops have webcams and microphones, which can be used to communicate with other people with both moving images and sound, via web conferencing or video-calling software.\\nLaptops typically have USB ports and a combined headphone/microphone jack, for use with headphones, a combined headset, or an external mic. Many laptops have a card reader for reading digital camera SD cards.\\n\\nInput/output (I/O) ports[edit]\\nOn a typical laptop there are several USB ports; if they use only the older USB connectors instead of USB-C, they will typically have an external monitor port (VGA, DVI, HDMI or Mini DisplayPort or occasionally more than one), an audio in/out port (often in form of a single socket) is common. It is possible to connect up to three external displays to a 2014-era laptop via a single Mini DisplayPort, using multi-stream transport technology.[35]\\nApple, in a 2015 version of its MacBook, transitioned from a number of different I/O ports to a single USB-C port.[42] This port can be used both for charging and connecting a variety of devices through the use of aftermarket adapters. Google, with its updated version of Chromebook Pixel, shows a similar transition trend towards USB-C, although keeping older USB Type-A ports for a better compatibility with older devices.[43] Although being common until the end of the 2000s decade, Ethernet network port are rarely found on modern laptops, due to widespread use of wireless networking, such as Wi-Fi. Legacy ports such as a PS/2 keyboard/mouse port, serial port, parallel port, or FireWire are provided on some models, but they are increasingly rare. On Apple\\'s systems, and on a handful of other laptops, there are also Thunderbolt ports, but Thunderbolt 3 uses USB-C. Laptops typically have a headphone jack, so that the user can connect external headphones or amplified speaker systems for listening to music or other audio.\\n\\nExpansion cards[edit]\\nIn the past, a PC Card (formerly PCMCIA) or ExpressCard slot for expansion was often present on laptops to allow adding and removing functionality, even when the laptop is powered on; these are becoming increasingly rare since the introduction of USB 3.0. Some internal subsystems such as Ethernet, Wi-Fi, or a wireless cellular modem can be implemented as replaceable internal expansion cards, usually accessible under an access cover on the bottom of the laptop. The standard for such cards is PCI Express, which comes in both mini and even smaller M.2 sizes. In newer laptops, it is not uncommon to also see Micro SATA (mSATA) functionality on PCI Express Mini or M.2 card slots allowing the use of those slots for SATA-based solid-state drives.[44]\\n\\nBattery and power supply[edit]\\nMain article: Smart battery\\n Almost all laptops use smart batteries\\nSince the late 1990s, laptops have typically used lithium ion or lithium polymer batteries, These replaced the older nickel metal-hydride typically used in the 1990s, and nickel–cadmium batteries used in most of the earliest laptops. A few of the oldest laptops used non-rechargeable batteries, or lead–acid batteries.\\nBattery life is highly variable by model and workload and can range from one hour to nearly a day. A battery\\'s performance gradually decreases over time; a substantial reduction in capacity is typically evident after one to three years of regular use, depending on the charging and discharging pattern and the design of the battery. Innovations in laptops and batteries have seen situations in which the battery can provide up to 24 hours of continued operation, assuming average power consumption levels. An example is the HP EliteBook 6930p when used with its ultra-capacity battery.[45]\\n\\n A 2011 laptop with extended capacity replacement battery inserted.\\nLaptops with removable batteries may support larger replacement batteries with extended capacity.\\nA laptop\\'s battery is charged using an external power supply, which is plugged into a wall outlet. The power supply outputs a DC voltage typically in the range of 7.2—24 volts. The power supply is usually external and connected to the laptop through a DC connector cable. In most cases, it can charge the battery and power the laptop simultaneously. When the battery is fully charged, the laptop continues to run on power supplied by the external power supply, avoiding battery use. If the used power supply is not strong enough to power computing components and charge the battery simultaneously, the battery may charge in a shorter period of time if the laptop is turned off or sleeping. The charger typically adds about 400 grams (0.88\\xa0lb) to the overall transporting weight of a laptop, although some models are substantially heavier or lighter. Most 2016-era laptops use a smart battery, a rechargeable battery pack with a built-in battery management system (BMS). The smart battery can internally measure voltage and current, and deduce charge level and State of Health (SoH) parameters, indicating the state of the cells.[citation needed]\\n\\nPower connectors[edit]\\n Laptop power supply with cylindrical coaxial DC power connector\\nHistorically, DC connectors, typically cylindrical/barrel-shaped coaxial power connectors have been used in laptops. Some vendors such as Lenovo made intermittent use of a rectangular connector.\\nSome connector heads feature a center pin to allow the end device to determine the power supply type by measuring the resistance between it and the connector\\'s negative pole (outer surface). Vendors may block charging if a power supply is not recognized as original part, which could deny the legitimate use of universal third-party chargers.[46]\\n\\n USB-C connector\\nWith the advent of USB-C, portable electronics made increasing use of it for both power delivery and data transfer. Its support for 20 V (common laptop power supply voltage) and 5 A typically suffices for low to mid-end laptops, but some with higher power demands such as gaming laptops depend on dedicated DC connectors to handle currents beyond 5 A without risking overheating, some even above 10 A. Additionally, dedicated DC connectors are more durable and less prone to wear and tear from frequent reconnection, as their design is less delicate.[47]\\n\\nCooling[edit]\\nWaste heat from the operation is difficult to remove in the compact internal space of a laptop. The earliest laptops used passive cooling; this gave way to heat sinks placed directly on the components to be cooled, but when these hot components are deep inside the device, a large space-wasting air duct is needed to exhaust the heat. Modern laptops instead rely on heat pipes to rapidly move waste heat towards the edges of the device, to allow for a much smaller and compact fan and heat sink cooling system. Waste heat is usually exhausted away from the device operator towards the rear or sides of the device. Multiple air intake paths are used since some intakes can be blocked, such as when the device is placed on a soft conforming surface like a chair cushion. Secondary device temperature monitoring may reduce performance or trigger an emergency shutdown if it is unable to dissipate heat, such as if the laptop were to be left running and placed inside a carrying case. Aftermarket cooling pads with external fans can be used with laptops to reduce operating temperatures.\\n\\nDocking station[edit]\\n Docking station and laptop\\nA docking station (sometimes referred to simply as a dock) is a laptop accessory that contains multiple ports and in some cases expansion slots or bays for fixed or removable drives. A laptop connects and disconnects to a docking station, typically through a single large proprietary connector. A docking station is an especially popular laptop accessory in a corporate computing environment, due to a possibility of a docking station transforming a laptop into a full-featured desktop replacement, yet allowing for its easy release. This ability can be advantageous to \"road warrior\" employees who have to travel frequently for work, and yet who also come into the office. If more ports are needed, or their position on a laptop is inconvenient, one can use a cheaper passive device known as a port replicator. These devices mate to the connectors on the laptop, such as through USB or FireWire.\\n\\nCharging trolleys[edit]\\nLaptop charging trolleys, also known as laptop trolleys or laptop carts, are mobile storage containers to charge multiple laptops, netbooks, and tablet computers at the same time. The trolleys are used in schools that have replaced their traditional static computer labs[48] suites of desktop equipped with \"tower\" computers, but do not have enough plug sockets in an individual classroom to charge all of the devices. The trolleys can be wheeled between rooms and classrooms so that all students and teachers in a particular building can access fully charged IT equipment.[49]\\nLaptop charging trolleys are also used to deter and protect against opportunistic and organized theft. Schools, especially those with open plan designs, are often prime targets for thieves who steal high-value items. Laptops, netbooks, and tablets are among the highest–value portable items in a school. Moreover, laptops can easily be concealed under clothing and stolen from buildings. Many types of laptop–charging trolleys are designed and constructed to protect against theft. They are generally made out of steel, and the laptops remain locked up while not in use. Although the trolleys can be moved between areas from one classroom to another, they can often be mounted or locked to the floor, support pillars, or walls to prevent thieves from stealing the laptops, especially overnight.[48]\\n\\nSolar panels[edit]\\nMain article: Solar notebook\\nIn some laptops, solar panels are able to generate enough solar power for the laptop to operate.[50] The One Laptop Per Child Initiative released the OLPC XO-1 laptop which was tested and successfully operated by use of solar panels.[51] Presently, they are designing an OLPC XO-3 laptop with these features. The OLPC XO-3 can operate with 2 watts of electricity because its renewable energy resources generate a total of 4 watts.[52][53] Samsung has also designed the NC215S solar–powered notebook that will be sold commercially in the U.S. market.[54]\\n\\nAccessories[edit]\\nA common accessory for laptops is a laptop sleeve, laptop skin, or laptop case, which provides a degree of protection from scratches. Sleeves, which are distinguished by being relatively thin and flexible, are most commonly made of neoprene, with sturdier ones made of low-resilience polyurethane. Some laptop sleeves are wrapped in ballistic nylon to provide some measure of waterproofing. Bulkier and sturdier cases can be made of metal with polyurethane padding inside and may have locks for added security. Metal, padded cases also offer protection against impacts and drops. Another common accessory is a laptop cooler, a device that helps lower the internal temperature of the laptop either actively or passively. A common active method involves using electric fans to draw heat away from the laptop, while a passive method might involve propping the laptop up on some type of pad so it can receive more airflow. Some stores sell laptop pads that enable a reclining person on a bed to use a laptop.\\n\\nModularity[edit]\\n Opened bottom covers allow replacement of RAM and storage modules (Lenovo G555)\\nSome of the components of earlier models of laptops can easily be replaced without opening completely its bottom part, such as keyboard, battery, hard disk, memory modules, CPU cooling fan, etc.\\nSome of the components of recent models of laptops reside inside. Replacing most of its components, such as keyboard, battery, hard disk, memory modules, CPU cooling fan, etc., requires removal of its either top or bottom part, removal of the motherboard, and returning them.\\nIn some types, solder and glue are used to mount components such as RAM, storage, and batteries, making repairs additionally difficult.[55][56]\\n\\nObsolete features[edit]\\n A modem PCMCIA card on an old ThinkPad. The card would normally fully insert into the socket.\\nFeatures that certain early models of laptops used to have that are not available in most current laptops include:\\n\\nReset (\"cold restart\") button in a hole (needed a thin metal tool to press)\\nInstant power off button in a hole (needed a thin metal tool to press)\\nIntegrated charger or power adapter inside the laptop\\nFloppy disk drive\\nSerial port\\nParallel port\\nModem\\nShared PS/2 input device port\\nIrDA\\nS-video port[note 1]\\nS/PDIF audio port\\nPC Card / PCMCIA slot\\nExpressCard slot\\nCD/DVD Drives (starting with 2013 models)\\nVGA port (starting with 2013 models)\\nComparison with desktops[edit]\\nAdvantages[edit]\\n A teacher using the laptop as part of a workshop for school children\\n Wikipedia co-founder Jimmy Wales using a laptop on a park bench\\nPortability is usually the first feature mentioned in any comparison of laptops versus desktop PCs.[57] Physical portability allows a laptop to be used in many places—not only at home and the office but also during commuting and flights, in coffee shops, in lecture halls and libraries, at clients\\' locations or a meeting room, etc. Within a home, portability enables laptop users to move their devices from the living room to the dining room to the family room. Portability offers several distinct advantages:\\n\\nProductivity: Using a laptop in places where a desktop PC cannot be used can help employees and students to increase their productivity on work or school tasks, such as an office worker reading their work e-mails during an hour-long commute by train, or a student doing their homework at the university coffee shop during a break between lectures, for example.\\nImmediacy: Carrying a laptop means having instant access to information, including personal and work files. This allows better collaboration between coworkers or students, as a laptop can be flipped open to look at a report, document, spreadsheet, or presentation anytime and anywhere.\\nUp-to-date information: If a person has more than one desktop PC, a problem of synchronization arises: changes made on one computer are not automatically propagated to the others. There are ways to resolve this problem, including physical transfer of updated files (using a USB flash memory stick or CD-ROMs) or using synchronization software over the Internet, such as cloud computing. However, transporting a single laptop to both locations avoids the problem entirely, as the files exist in a single location and are always up-to-date.\\nConnectivity: In the 2010s, a proliferation of Wi-Fi wireless networks and cellular broadband data services (HSDPA, EVDO and others) in many urban centers, combined with near-ubiquitous Wi-Fi support by modern laptops[note 2] meant that a laptop could now have easy Internet and local network connectivity while remaining mobile. Wi-Fi networks and laptop programs are especially widespread at university campuses.[58]\\nOther advantages of laptops:\\n\\nSize: Laptops are smaller than desktop PCs. This is beneficial when space is at a premium, for example in small apartments and student dorms. When not in use, a laptop can be closed and put away in a desk drawer.\\nLow power consumption: Laptops are several times more power-efficient than desktops. A typical laptop uses 20–120 W, compared to 100–800 W for desktops. This could be particularly beneficial for large businesses, which run hundreds of personal computers thus multiplying the potential savings, and homes where there is a computer running 24/7 (such as a home media server, print server, etc.).\\nQuiet: Laptops are typically much quieter than desktops, due both to the components (quieter, slower 2.5-inch hard drives) and to less heat production leading to the use of fewer and slower cooling fans.\\nBattery: a charged laptop can continue to be used in case of a power outage and is not affected by short power interruptions and blackouts. A desktop PC needs an uninterruptible power supply (UPS) to handle short interruptions, blackouts, and spikes; achieving on-battery time of more than 20–30 minutes for a desktop PC requires a large and expensive UPS.[59]\\nAll-in-One: designed to be portable, most 2010-era laptops have all components integrated into the chassis (however, some small laptops may not have an internal CD/CDR/DVD drive, so an external drive needs to be used). For desktops (excluding all-in-ones) this is usually divided into the desktop \"tower\" (the unit with the CPU, hard drive, power supply, etc.), keyboard, mouse, display screen, and optional peripherals such as speakers.\\nDisadvantages[edit]\\nCompared to desktop PCs, laptops have disadvantages in the following areas:\\n\\nPerformance[edit]\\nParts of this article (those related to sub-section) need to be updated. The reason given is: info is since 2008, nearly 13 years old. Please help update this article to reflect recent events or newly available information. (April 2021)\\nWhile the performance of mainstream desktops and laptops are comparable, and the cost of laptops has fallen less rapidly than desktops, laptops remain more expensive than desktop PCs at the same performance level.[60][needs update] The upper limits of performance of laptops remain much lower than the highest-end desktops (especially \"workstation class\" machines with two processor sockets), and \"leading-edge\" features usually appear first in desktops and only then, as the underlying technology matures, are adapted to laptops.\\nFor Internet browsing and typical office applications, where the computer spends the majority of its time waiting for the next user input, even relatively low-end laptops (such as Netbooks) can be fast enough for some users.[61] Most higher-end laptops are sufficiently powerful for high-resolution movie playback, some 3D gaming and video editing and encoding. However, laptop processors can be disadvantaged when dealing with a higher-end database, maths, engineering, financial software, virtualization, etc. This is because laptops use the mobile versions of processors to conserve power, and these lag behind desktop chips when it comes to performance. Some manufacturers work around this performance problem by using desktop CPUs for laptops.[62]\\n\\nUpgradeability[edit]\\nThe upgradeability of laptops is very limited compared to thoroughly standardized desktops. In general, hard drives and memory can be upgraded easily. Optical drives and internal expansion cards may be upgraded if they follow an industry standard, but all other internal components, including the motherboard, CPU, and graphics, are not always intended to be upgradeable. Intel, Asus, Compal, Quanta and some other laptop manufacturers have created the Common Building Block standard for laptop parts to address some of the inefficiencies caused by the lack of standards. The reasons for limited upgradeability are both technical and economic. There is no industry-wide standard form factor for laptops; each major laptop manufacturer pursues its own proprietary design and construction, with the result that laptops are difficult to upgrade and have high repair costs. Moreover, starting with 2013 models, laptops have become increasingly integrated (soldered) with the motherboard for most of its components (CPU, SSD, RAM, keyboard, etc.) to reduce size and upgradeability prospects. Devices such as sound cards, network adapters, hard and optical drives, and numerous other peripherals are available, but these upgrades usually impair the laptop\\'s portability, because they add cables and boxes to the setup and often have to be disconnected and reconnected when the laptop is on the move.[citation needed]\\n\\nErgonomics and health effects[edit]\\nWrists[edit]\\n Laptop cooler (silver) under laptop (white), preventing heating of lap and improving laptop airflow\\nProlonged use of laptops can cause repetitive strain injury because of their small, flat keyboard and trackpad pointing devices.[63] Usage of separate, external ergonomic keyboards and pointing devices is recommended to prevent injury when working for long periods of time; they can be connected to a laptop easily by USB, Bluetooth or via a docking station. Some health standards require ergonomic keyboards at workplaces.\\n\\nNeck and spine[edit]\\nA laptop\\'s integrated screen often requires users to lean over for a better view, which can cause neck or spinal injuries. A larger and higher-quality external screen can be connected to almost any laptop to alleviate this and to provide additional screen space for more productive work. Another solution is to use a computer stand.\\n\\nPossible effect on fertility[edit]\\nA study by State University of New York researchers found that heat generated from laptops can increase the temperature of the lap of male users when balancing the computer on their lap, potentially putting sperm count at risk. The study, which included roughly two dozen men between the ages of 21 and 35, found that the sitting position required to balance a laptop can increase scrotum temperature by as much as 2.1\\xa0°C (4\\xa0°F). However, further research is needed to determine whether this directly affects male sterility.[64] A later 2010 study of 29 males published in Fertility and Sterility found that men who kept their laptops on their laps experienced scrotal hyperthermia (overheating) in which their scrotal temperatures increased by up to 2.0\\xa0°C (4\\xa0°F). The resulting heat increase, which could not be offset by a laptop cushion, may increase male infertility.[65][66][67][68][69]\\nA common practical solution to this problem is to place the laptop on a table or desk or to use a book or pillow between the body and the laptop.[citation needed] Another solution is to obtain a cooling unit for the laptop. These are usually USB powered and consist of a hard thin plastic case housing one, two, or three cooling fans\\xa0– with the entire assembly designed to sit under the laptop in question\\xa0– which results in the laptop remaining cool to the touch, and greatly reduces laptop heat buildup.\\n\\nThighs[edit]\\nHeat generated from using a laptop on the lap can also cause skin discoloration on the thighs known as \"toasted skin syndrome\".[70][71][72][73]\\n\\nDurability[edit]\\n A clogged heat sink on a laptop after 2.5 years of use\\nLaptops are less durable than desktops/PCs. However, the durability of the laptop depends on the user if proper maintenance is done then the laptop can work longer. Laptop keyboard with its keys (except the space bar) removed, revealing crumbs, pet hair, and other detritus to be cleaned away.\\nEquipment wear[edit]\\nBecause of their portability, laptops are subject to more wear and physical damage than desktops. Components such as screen hinges, latches, power jacks, and power cords deteriorate gradually from ordinary use and may have to be replaced. A liquid spill onto the keyboard, a rather minor mishap with a desktop system (given that a basic keyboard costs about US$20), can damage the internals of a laptop and destroy the computer, result in a costly repair or entire replacement of laptops. One study found that a laptop is three times more likely to break during the first year of use than a desktop.[74] To maintain a laptop, it is recommended to clean it every three months for dirt, debris, dust, and food particles. Most cleaning kits consist of a lint-free or microfiber cloth for the LCD screen and keyboard, compressed air for getting dust out of the cooling fan, and a cleaning solution. Harsh chemicals such as bleach should not be used to clean a laptop, as they can damage it.[75]\\n\\nHeating and cooling[edit]\\nLaptops rely on extremely compact cooling systems involving a fan and heat sink that can fail from blockage caused by accumulated airborne dust and debris. Most laptops do not have any type of removable dust collection filter over the air intake for these cooling systems, resulting in a system that gradually conducts more heat and noise as the years pass. In some cases, the laptop starts to overheat even at idle load levels. This dust is usually stuck inside where the fan and heat sink meet, where it can not be removed by a casual cleaning and vacuuming. Most of the time, compressed air can dislodge the dust and debris but may not entirely remove it. After the device is turned on, the loose debris is reaccumulated into the cooling system by the fans. Complete disassembly is usually required to clean the laptop entirely. However, preventative maintenance such as regular cleaning of the heat sink via compressed air can prevent dust build-up on the heat sink. Many laptops are difficult to disassemble by the average user and contain components that are sensitive to electrostatic discharge (ESD).\\n\\nBattery life[edit]\\nBattery life is limited because the capacity drops with time, eventually requiring replacement after as little as a year. A new battery typically stores enough energy to run the laptop for three to five hours, depending on usage, configuration, and power management settings. Yet, as it ages, the battery\\'s energy storage will dissipate progressively until it lasts only a few minutes. The battery is often easily replaceable and a higher capacity model may be obtained for longer charging and discharging time. Some laptops (specifically ultrabooks) do not have the usual removable battery and have to be brought to the service center of their manufacturer or a third-party laptop service center to have their battery replaced. Replacement batteries can also be expensive.\\n\\nSecurity and privacy[edit]\\nMain article: Laptop theft\\nBecause they are valuable, commonly used, portable, and easy to hide in a backpack or other type of travel bag, laptops are often stolen. Every day, over 1,600 laptops go missing from U.S. airports.[76] The cost of stolen business or personal data, and of the resulting problems (identity theft, credit card fraud, breach of privacy), can be many times the value of the stolen laptop itself. Consequently, the physical protection of laptops and the safeguarding of data contained on them are both of great importance. Most laptops have a Kensington security slot, which can be used to tether them to a desk or other immovable object with a security cable and lock. In addition, modern operating systems and third-party software offer disk encryption functionality, which renders the data on the laptop\\'s hard drive unreadable without a key or a passphrase. As of 2015, some laptops also have additional security elements added, including eye recognition software and fingerprint scanning components.[77]\\nSoftware such as LoJack for Laptops, Laptop Cop, and GadgetTrack have been engineered to help people locate and recover their stolen laptops in the event of theft. Setting one\\'s laptop with a password on its firmware (protection against going to firmware setup or booting), internal HDD/SSD (protection against accessing it and loading an operating system on it afterward), and every user account of the operating system are additional security measures that a user should do.[78][79] Fewer than 5% of lost or stolen laptops are recovered by the companies that own them,[80] however, that number may decrease due to a variety of companies and software solutions specializing in laptop recovery. In the 2010s, the common availability of webcams on laptops raised privacy concerns. In Robbins v. Lower Merion School District (Eastern District of Pennsylvania 2010), school-issued laptops loaded with special software enabled staff from two high schools to take secret webcam shots of students at home, via their students\\' laptops.[81][82][83]\\n\\nSales[edit]\\nManufacturers[edit]\\nMajor laptop brands\\nAcer / Gateway / eMachines / Packard Bell: TravelMate, Extensa, Ferrari and Aspire; Easynote; Chromebook\\n\\nApple: MacBook Air and MacBook Pro\\n\\nAsus: TUF, ROG, Pro and ProArt, ZenBook, VivoBook, ExpertBook\\n\\nClevo\\n\\nDell: Alienware, Inspiron, Latitude, Precision,  Vostro and XPS\\n\\nDynabook (former Toshiba): Portege, Tecra, Satellite, Qosmio, Libretto\\n\\nFalcon Northwest: DRX, TLX, I / O\\n\\nFujitsu: Lifebook, Celsius\\n\\nGigabyte: AORUS\\n\\nHCL (India): ME Laptop, ME Netbook, Leaptop and MiLeap\\n\\nHewlett-Packard: Pavilion, Envy, ProBook, EliteBook, ZBook\\n\\nHuawei: Matebook\\n\\nLenovo: ThinkPad, ThinkBook, IdeaPad, Yoga, Legion and the Essential B and G Series\\n\\nLG: Xnote, Gram\\n\\nMedion: Akoya (OEM version of MSI Wind)\\n\\nMSI: E, C, P, G, V, A, X, U series, Modern, Prestige and Wind\\xa0Netbook\\n\\nPanasonic: Toughbook, Satellite, Let\\'s Note (Japan only)\\n\\nSamsung: Sens: N, P, Q, R and X series; Chromebook, ATIV Book\\n\\nTG Sambo (Korea): Averatec, Averatec Buddy\\n\\nVaio (former Sony)\\n\\nXiaomi: Mi, Mi Gaming and Mi RedmiBook laptops\\nvte\\nMain article: List of laptop brands and manufacturers\\nFurther information: Market share of personal computer vendors\\nThere are many laptop brands and manufacturers. Several major brands that offer notebooks in various classes are listed in the adjacent box.\\nThe major brands usually offer good service and support, including well-executed documentation and driver downloads that remain available for many years after a particular laptop model is no longer produced. Capitalizing on service, support, and brand image, laptops from major brands are more expensive than laptops by smaller brands and ODMs. Some brands specialize in a particular class of laptops, such as gaming laptops (Alienware), high-performance laptops (HP Envy), netbooks (EeePC) and laptops for children (OLPC).\\nMany brands, including the major ones, do not design and do not manufacture their laptops. Instead, a small number of Original Design Manufacturers (ODMs) design new models of laptops, and the brands choose the models to be included in their lineup. In 2006, 7 major ODMs manufactured 7 of every 10 laptops in the world, with the largest one (Quanta Computer) having 30% of the world market share.[84] Therefore, identical models are available both from a major label and from a low-profile ODM in-house brand.\\n\\nMarket share[edit]\\nBattery-powered portable computers had just 2% worldwide market share in 1986.[85] However, laptops have become increasingly popular, both for business and personal use.[86] Around 109 million notebook PCs shipped worldwide in 2007, a growth of 33% compared to 2006.[87] In 2008 it was estimated that 145.9\\xa0million notebooks were sold, and that the number would grow in 2009 to 177.7\\xa0million.[88] The third quarter of 2008 was the first time when worldwide notebook PC shipments exceeded desktops, with 38.6\\xa0million units versus 38.5\\xa0million units.[86][89][90][91]\\nMay 2005 was the first time notebooks outsold desktops in the US over the course of a full month; at the time notebooks sold for an average of $1,131 while desktops sold for an average of $696.[92] When looking at operating systems, for Microsoft Windows laptops the average selling price (ASP) showed a decline in 2008/2009, possibly due to low-cost netbooks, drawing an average US$689 at U.S. retail stores in August 2008. In 2009, ASP had further fallen to $602 by January and to $560 in February. While Windows machines ASP fell $129 in these seven months, Apple macOS laptop ASP declined just $12 from $1,524 to $1,512.[93]\\n\\nDisposal[edit]\\nThe list of materials that go into a laptop computer is long, and many of the substances used, such as beryllium (used in beryllium-copper alloy contacts in some connectors and sockets), lead (used in lead-tin solder), chromium, and mercury (used in CCFL LCD backlights) compounds, are toxic or carcinogenic to humans. Although these toxins are relatively harmless when the laptop is in use, concerns that discarded laptops cause a serious health risk and toxic environmental damage, were so strong, that the Waste Electrical and Electronic Equipment Directive (WEEE Directive) in Europe specified that all laptop computers must be recycled by law. Similarly, the U.S. Environmental Protection Agency (EPA) has outlawed landfill dumping or the incinerating of discarded laptop computers.\\nMost laptop computers begin the recycling process with a method known as Demanufacturing, this involves the physical separation of the components of the laptop.[94] These components are then either grouped into materials (e.g. plastic, metal and glass) for recycling or more complex items that require more advanced materials separation (e.g.) circuit boards, hard drives and batteries.\\nCorporate laptop recycling can require an additional process known as data destruction. The data destruction process ensures that all information or data that has been stored on a laptop hard drive can never be retrieved again. Below is an overview of some of the data protection and environmental laws and regulations applicable for laptop recycling data destruction:\\n\\nData Protection Act 1998 (DPA)\\nEU Privacy Directive (Due 2016)\\nFinancial Conduct Authority\\nSarbanes-Oxley Act\\nPCI-DSS Data Security Standard\\nWaste, Electronic & Electrical Equipment Directive (WEEE)\\nBasel Convention\\nBank Secrecy Act (BSA)\\nFACTA Sarbanes-Oxley Act\\nFDA Security Regulations (21 C.F.R. part 11)\\nGramm-Leach-Bliley Act (GLBA)\\nHIPAA (Health Insurance Portability and Accountability Act)\\nNIST SP 800–53\\nAdd NIST SP 800–171\\nIdentity Theft and Assumption Deterrence Act\\nPatriot Act of 2002\\nPCI Data Security Standard\\nUS Safe Harbor Provisions\\nVarious state laws\\nJAN 6/3\\nGramm-leach-Bliley Act\\nDCID\\nExtreme use[edit]\\nSee also: International Space Station §\\xa0Communications and computers\\n ISS laptops in the US lab\\nThe ruggedized Grid Compass computer was used since the early days of the Space Shuttle program. The first commercial laptop used in space was a Macintosh portable in 1991 aboard Space Shuttle mission STS-43.[95][96][97] Apple and other laptop computers continue to be flown aboard crewed spaceflights, though the only long-duration flight certified computer for the International Space Station is the ThinkPad.[98] As of 2011, over 100 ThinkPads were aboard the ISS. Laptops used aboard the International Space Station and other spaceflights are generally the same ones that can be purchased by the general public but needed modifications are made to allow them to be used safely and effectively in a weightless environment such as updating the cooling systems to function without relying on hot air rising and accommodation for the lower cabin air pressure.[99] Laptops operating in harsh usage environments and conditions, such as strong vibrations, extreme temperatures, and wet or dusty conditions differ from those used in space in that they are custom designed for the task and do not use commercial off-the-shelf hardware.\\n\\nSee also[edit]\\n\\nList of computer size categories\\nList of laptop brands and manufacturers\\nNetbook\\nSmartbook\\nChromebook\\nUltrabook\\nSmartphone\\nSubscriber Identity Module\\nMobile broadband\\nMobile Internet device (MID)\\nPersonal digital assistant\\nVIA OpenBook\\nTethering\\nXJACK\\nOpen-source computer hardware\\nNovena\\nPortal laptop computer\\nMobile modem\\nStereoscopy glasses\\n\\nNotes[edit]\\n\\n\\n^ Unconfirmed if this exists in most recent models of laptops.\\n\\n^ Almost all laptops contain a Wi-Fi interface; broadband cellular devices are available widely as extension cards and USB devices, and also as internal cards in select models.\\n\\n\\nReferences[edit]\\n\\n\\n^ Beal, Vangie (September 1996). \"What is Laptop Computer? Webopedia Definition\". www.webopedia.com.\\n\\n^ \"Laptop vs desktop: which should you buy?\". TechRadar. Retrieved 1 August 2021.\\n\\n^ a b Naik, Abhijit. \"Notebook Vs. Laptop\". Buzzle.com. Archived from the original on 14 February 2015. Retrieved 23 September 2014.\\n\\n^ \"U.S. Commercial Channel Computing Device Sales Set to End 2013 with Double-Digit Growth, According to NPD\". NPD Group. Archived from the original on 9 August 2019. Retrieved 23 September 2014.\\n\\n^ John W. Maxwell (2006). Tracing the Dynabook: A Study of Technocultural Transformations (PDF) (PhD). University of British Columbia. Archived from the original (PDF) on 24 January 2007. Retrieved 17 October 2008.\\n\\n^ Alan C. Kay (August 1972). A Personal Computer for Children of All Ages (PDF). Proceedings of the ACM National Conference. Boston: Xerox Palo Alto Research Center. Retrieved 17 October 2008.\\n\\n^ \"IBM Archives: IBM Personal Computer\". www.ibm.com. 23 January 2003. Retrieved 16 May 2021.\\n\\n^ \"IBM Personal Computer\". IBM Inc. 23 January 2003.\\n\\n^ \"IBM 5100 computer\". oldcomputers.net. Retrieved 6 July 2009.\\n\\n^ \"Epson SX-20 Promotional Brochure\" (PDF). Epson America, Inc. 1987. Retrieved 2 November 2008.\\n\\n^ a b c d \"HC-20-Computer Museum\". museum.ipsj.or.jp.\\n\\n^ a b \"portable computer system small\". google.com.\\n\\n^ Epson HX-20, Old Computers\\n\\n^ Michael R. Peres, The Focal Encyclopedia of Photography, page 306, Taylor & Francis\\n\\n^ Osborne 1, Old Computers\\n\\n^ \"Tandy/Radio Shack model 100 portable computer\". oldcomputers.net. Retrieved 6 July 2009.\\n\\n^ \"Hewlett-Packard model 85\". oldcomputers.net. Retrieved 6 July 2009.\\n\\n^ Sharp PC-5000 Archived 4 April 2019 at the Wayback Machine, Old Computers\\n\\n^ a b Bob Armstrong, http://cosy.com/language/cosyhard/cosyhard.htm\\n\\n^ \"Gavilian SC computer\". oldcomputers.net. Retrieved 7 July 2009.\\n\\n^ Japanese PCs (1984) (13:13), Computer Chronicles\\n\\n^ \"Milestones:Toshiba T1100, a Pioneering Contribution to the Development of Laptop PC, 1985 – Engineering and Technology History Wiki\". ethw.org. 3 November 2021.\\n\\n^ \"Linus Write-Top\". Retrieved 18 October 2008.\\n\\n^ \"IBM PS/2 CL57SX | Laptop Pics\". Retrieved 5 December 2020.\\n\\n^ DigitalTrends\\n\\n^ [https://www.cnet.com/reviews/samsung-700g7c-review/ Cnet\\n\\n^ \"Laptop Buying Guide\". Cnet. Retrieved 7 November 2008.\\n\\n^ \"Best 2-in-1 PCs in 2020 for when you need a laptop and tablet in one\". CNet. Retrieved 1 April 2020.\\n\\n^ \"What Is a Hybrid Laptop? | Advantages & Buying Guide | Lenovo US\". www.lenovo.com. Retrieved 1 April 2020.\\n\\n^ \"Rugged Laptop: Choices, Pointers & Specs of Buying Rugged Laptops\". Linux-on-laptops.com. Retrieved 27 November 2008.\\n\\n^ Dé specialist voor smartphone, tablet en laptop reparaties (4 January 2013). \"Laptop reparatie\". Smartrepair Den Bosch, Nijmegen, Tilburg, Almere en Utrecht (in Dutch). www.smart-repair.nl. Retrieved 30 March 2017.\\n\\n^ \"Microsoft Surface Pro 3 Teardown\". iFixit.com. 23 June 2014. Retrieved 1 October 2014.\\n\\n^ \"Common Building Blocks Platform\" (PDF). Intel. Archived from the original (PDF) on 16 May 2006. Retrieved 20 November 2013.\\n\\n^ a b Catherine Roseberry. \"What Makes Laptops Work\\xa0– The Laptop Motherboard\". About.com. Retrieved 15 November 2008.\\n\\n^ a b \"Configuration 3-Displays FAQ\". Intel.com. Retrieved 16 September 2014.\\n\\n^ \"Dell refreshes Alienware M17x, Dell XPS 17 with 120Hz 3D HD screens, Sandy Bridge CPUs\". Engadget. 6 January 2011. Retrieved 28 April 2021.\\n\\n^ \"Samsung 700G7A GAMER\". www.pocket-lint.com. 11 April 2012. Retrieved 28 April 2021.\\n\\n^ btarunr (26 November 2012). \"Is Haswell the Last Interchangeable Intel Client Processor?\". TechPowerUp. Retrieved 30 May 2021.\\n\\n^ Samsung Review Samsung Series 7 Gamer 700G7A Notebook – Florian Glaser (translated by Liala Stieglitz) – November 24th, 2011\\n\\n^ Edwards, Benj (17 January 2012). \"Evolution of the Solid-State Drive\". PCWorld.com. Archived from the original on 1 October 2012. Retrieved 1 October 2014.\\n\\n^ Most keyboards are not illuminated. Some models of laptops feature an illuminated keyboard.\\n\\n^ \"Apple — MacBook — Tech Specs\". apple.com. Retrieved 2 April 2015.\\n\\n^ \"Chromebook Pixel\". google.com. Retrieved 2 April 2015.\\n\\n^ Gabriel Torres (25 November 2004). \"Innovations in Notebook Expansion\". Hardware Secrets, LLC. Archived from the original on 28 April 2005. Retrieved 15 November 2008.\\n\\n^ \"HP EliteBook 6930p Notebook PC specifications – HP Products and Services Products\". HP. 25 May 2009. Archived from the original on 1 June 2012. Retrieved 17 June 2013.\\n\\n^ Hacking Dell Laptops To Use Off-Brand Chargers\\n\\n^ PC Mag – What is USB-C - an explainer – April 28, 2021\\n\\n^ a b Woods, Dough. \"Getting rid of the ICT suite\". Blog. Archived from the original on 6 October 2010.\\n\\n^ Wilce, Hilary (1 December 2000). \"Welcome to Lapland\". TES Magazine. Archived from the original on 26 May 2015. Retrieved 5 June 2012.\\n\\n^ Clarke, Gavin. \"The SOLAR-POWERED Ubuntu laptop\". The Register. Retrieved 7 August 2013.\\n\\n^ Archived at Ghostarchive and the Wayback Machine: OLPC XO laptop powered by a solar panel. 9 January 2012. Retrieved 23 October 2012 – via YouTube.\\n\\n^ Elizabeth Woyke (18 April 2012). \"A Look at OLPC\\'s XO 3.0 Tablet\\'s Solar And Kinetic Chargers\". Forbes. Retrieved 23 October 2012.\\n\\n^ \"One Laptop per Child (OLPC): Frequently Asked Questions\". Laptop.org. Archived from the original on 18 March 2017. Retrieved 23 October 2012.\\n\\n^ \"Samsung\\'s Solar Powered Laptop Will Be First Sun Powered Laptop Sold in US | Inhabitat\\xa0– Sustainable Design Innovation, Eco Architecture, Green Building\". Inhabitat. 21 June 2011. Retrieved 23 October 2012.\\n\\n^ RAM upgrade – Melanie Pinola – March 26th, 2017 – LaptopMag\\n\\n^ DigitalTrends –  MacBook Pro battery replacement: Everything you need to know  –  March 15, 2021 – Tyler Lacoma\\n\\n^ \"Should I buy a laptop or desktop?\". IT Division\\xa0– the University of Wisconsin. 19 March 2008. Retrieved 27 November 2008.\\n\\n^ Josh Fischman (7 August 2008). \"Faster Wi-Fi Predicted for Colleges\". The Chronicle of Higher Education. Retrieved 27 November 2008.\\n\\n^ A sample line of UPS devices and on-battery power: \"Back-UPS RS\". APC. Retrieved 27 November 2008.\\n\\n^ In a comparison between laptops and desktops of equal cost, the desktop\\'s System Benchmark Score was twice that of the laptop. \"What to Buy, a Notebook or Desktop PC?\". Tom\\'s Hardware. 11 June 2008. Retrieved 28 November 2008.[needs update]\\n\\n^ For example, a review of the MSI Wind Netbook says that \"The device is rarely sluggish in general use. It renders Web pages quickly, launches most applications without becoming too bogged down and generally doesn\\'t feel like it\\'s a budget laptop.\" Reid, Rory (7 July 2008). \"MSI Wind Review\". CNET Australia. Archived from the original on 5 December 2008. Retrieved 28 November 2008.\\n\\n^ \"Rock delivers BD / Core i7-equipped Xtreme 790 and Xtreme 840 gaming laptops\". Engadget.\\n\\n^ Toub, Allegra (23 May 2017). \"Take It Easy on Those Keyboards\". Backlight Resumes. Retrieved 23 May 2017.\\n\\n^ \"You Asked: Can Using a Laptop Make You Infertile?\". Time. Retrieved 9 November 2021.\\n\\n^ Yefim Sheynkin; Robert Welliver; Andrew Winer; Farshid Hajimirzaee; Hongshik Ahn; Kyewon Lee (8 November 2010). \"Protection from scrotal hyperthermia in laptop computer users\". Fertility and Sterility. 95 (2): 647–651. doi:10.1016/j.fertnstert.2010.10.013. PMID\\xa021055743.\\n\\n^ Yin, Sara (8 November 2010). \"Study: Laptop Pads Don\\'t Prevent Male Infertility\". PC Magazine. Retrieved 8 November 2010.\\n\\n^ \"Men, your laptop may be roasting your testicles\". The Independent. 8 November 2010. Retrieved 8 November 2010.\\n\\n^ Caulfield, Philip (7 November 2010). \"Study finds men who place laptop computer on lap put testicles at risk of overheating, infertility\". Daily News. Archived from the original on 10 November 2010. Retrieved 8 November 2010.\\n\\n^ Joelving, Frederik (8 November 2010). \"Is your laptop cooking your testicles?\". Reuters. Retrieved 8 November 2010.\\n\\n^ Levinbook, WS.; Mallet J; Grant-Kels JM (October 2007). \"Laptop computer—associated erythema ab igne\". Cutis. Quadrant HealthCom. 80 (4): 319–20. PMID\\xa018038695.\\n\\n^ Diaz, Jesus (7 October 2010). \"What Is Toasted Skin Syndrome?\". Gizmodo. Retrieved 8 November 2010.\\n\\n^ Hendrick, Bill (4 October 2010). \"Laptop Risk: \\'Toasted Skin Syndrome\\'\". WebMD. Retrieved 8 November 2010.\\n\\n^ Tanner, Lindsey (10 April 2010). \"Laptops lead to \\'toasted skin syndrome\\'\". Associated Press. Retrieved 8 November 2010.\\n\\n^ \"Gartner: Notebook PCs still prone to hardware failure\". IDG News Service / ITWorld. 27 June 2006. Retrieved 27 November 2008.\\n\\n^ Geier, Eric (6 August 2012). \"Zen and the Art of Laptop Maintenance\". PC World. Retrieved 25 January 2014.\\n\\n^ [1], Ponemon Institute, Airport Insecurity: The Case of Lost Laptops, June 2008\\n\\n^ \"Secure File Sharing\". Biometric Devices and Laptop Security. Laptop Security Pro. Retrieved 7 February 2015.\\n\\n^ Hoffman, Chris. \"How to Secure Your Computer With a BIOS or UEFI Password\". How-To Geek.\\n\\n^ Hoffman, Chris. \"Hard Disk Passwords Explained: Should You Set One to Secure Your Files?\". How-To Geek.\\n\\n^ [2] Archived 6 June 2013 at the Wayback Machine, Ponemon Institute, The Billion Dollar Lost Laptop Problem, September 2010\\n\\n^ Holmes, Kristin E. (31 August 2010). \"Lower Merion School District ordered to pay plaintiff\\'s lawyer $260,000\". The Philadelphia Inquirer. Retrieved 20 September 2010.\\n\\n^ \"Main Line Media News\". Main Line Media News. 18 September 2010. Archived from the original on 5 March 2016. Retrieved 20 September 2010.\\n\\n^ \"A lawyer in the Lower Merion webcam case wants to be paid now\", Philly.com Archived 1 September 2010 at the Wayback Machine\\n\\n^ \"Identical Laptops, Different Prices: Don\\'t Be Fooled by Branding\". Info-Tech Research Group. 10 October 2006. Retrieved 11 November 2011.\\n\\n^ \"Lap-top computers gain stature as power grows\". Daily News of Los Angeles (CA). 12 April 1987. Retrieved 1 November 2008.\\n\\n^ a b \"The Falling Costs of Mobile Computing\". Falling Costs of Mobile Computing Drive Corporate Adoption. Computer Economics, Inc. December 2005. Retrieved 1 November 2008.\\n\\n^ Worldwide notebook shipments grow 33% on year in 2007, says IDC, 31 January 2008, Yen Ting Chen, DigiTimes, retrieved at 12 September 2011\\n\\n^ Analysis: Did Intel underestimate netbook success?, Accessed at 10 January 2009\\n\\n^ Notebook PC Shipments Exceed Desktops for First Time in Q3, isuppli.com, accessed at 13 January 2009\\n\\n^ Randall Stross (18 April 2008). \"The PC Doesn\\'t Have to Be an Anchor\". The New York Times. Retrieved 20 April 2009.\\n\\n^ \"Intel: laptop/desktop crossover coming sooner than expected\". The Register, UK. Archived from the original on 7 October 2008. Retrieved 10 October 2008.\\n\\n^ Michael Singer. \"PC milestone—notebooks outsell desktops\". 2005.\\n\\n^ \"Netbooks Are Destroying the Laptop Market and Microsoft Needs to Act Now\". eWEEK. 16 April 2009.\\n\\n^ Recycling, Newtech. \"Laptop Disposal Ewaste Recycling and IT asset disposition (ITAD)\". www.newtechrecycling.com. Retrieved 11 June 2018.\\n\\n^ \"Macintosh Portable: Used in Space Shuttle\". Support.apple.com. Retrieved 23 October 2012.\\n\\n^ Linzmayer, Owen W. (2004). Apple confidential 2.0\\xa0: the definitive history of the world\\'s most colorful company ([Rev. 2. ed.].\\xa0ed.). San Francisco, Calif.: No Starch Press. ISBN\\xa01-59327-010-0.\\n\\n^ \"This Week in Apple History\\xa0– August 22–31: \"Welcome, IBM. Seriously\", Too Late to License\". The Mac Observer. 31 October 2004. Retrieved 23 October 2012.\\n\\n^ IBM Archives: IBM ThinkPads in space Archived 20 July 2011 at the Wayback Machine\\n\\n^ \"2001: A Space Laptop – SpaceRef – Your Space Reference\". www.spaceref.com.\\n\\n\\n Media related to Laptops at Wikimedia Commons\\n\\nvteComputer sizesClasses of computersmicrocomputer,personalcomputerstatic\\nAppliances:\\nSmart speaker\\nSmart TV\\nInteractive kiosk\\nArcade cabinet\\nHome console\\nMicroconsole\\nthin client/computer terminal\\nComputers:\\nBy use:\\nHome\\nHome server\\nWorkstation\\nPersonal supercomputer\\nBy size:\\nPortable\\nSmall form factor\\nNettop\\nPlug\\nDesktop\\nDeskside\\nAll-in-One\\nTabletop\\nmobilelaptop\\nDesktop replacement\\n2-in-1\\nSubnotebook\\nNetbook\\nSmartbook\\nUltrabook\\nUltra-mobile PC\\ntablet\\nUltra-mobile PC\\n2-in-1\\nPhablet\\nTabletop\\nhandheld(informationappliance)\\nHandheld PC\\nPalmtop PC\\nPocket computer\\nPersonal digital assistant\\nElectronic organizer\\nMobile phone\\nFeature phone\\nSmartphone\\nRugged Phone\\nPhablet\\nPortable media player\\nE-reader\\nHandheld game console\\nPortable/Mobile data terminal\\ncalculator\\nScientific\\nProgrammable\\nGraphing\\nwearable\\nDigital wristwatch\\nCalculator watch\\nSmartwatch\\nSportwatch\\nSmartband\\nSmartglasses\\nSmart ring\\nmidrange\\nMinicomputer\\nSupermini\\nlarge\\nSuper\\nMainframe\\nMinisuper\\nothers\\nMicrocontroller\\nNanocomputer\\nSingle-board computer\\nSmartdust\\nWireless sensor network\\nServer (size independent)\\n\\n\\xa0Category\\n\\xa0Portal\\n\\nvteElectronicsBranches\\nAnalog electronics\\nDigital electronics\\nElectronic instrumentation\\nElectronics engineering\\nMicroelectronics\\nOptoelectronics\\nPower electronics\\nPrinted electronics\\nSemiconductor\\nSchematic capture\\nThermal management\\nAdvanced topics\\nAtomtronics\\nBioelectronics\\nFailure of electronic components\\nFlexible electronics\\nLow-power electronics\\nMolecular electronics\\nNanoelectronics\\nOrganic electronics\\nPhotonics\\nPiezotronics\\nQuantum electronics\\nSpintronics\\nElectronic equipment\\nAir conditioner\\nCentral heating\\nClothes dryer\\nComputer/Notebook\\nCamera\\nDishwasher\\nFreezer\\nHome robot\\nHome cinema\\nHome theater PC\\nInformation technologies\\nCooker\\nMicrowave oven\\nMobile phone\\nNetworking hardware\\nPortable media player\\nRadio\\nRefrigerator\\nRobotic vacuum cleaner\\nTablet\\nTelephone\\nTelevision\\nWater heater\\nVideo game console\\nWashing machine\\nApplications\\nAudio electronics\\nAutomotive electronics\\nAvionics\\nControl system\\nData acquisition\\ne-book\\ne-health\\nElectronics industry\\nElectronic warfare\\nEmbedded system\\nHome appliance\\nHome automation\\nIntegrated circuit\\nHome appliance\\nConsumer electronics\\nMajor appliance\\nSmall appliance\\nMicrowave technology\\nMilitary electronics\\nMultimedia\\nNuclear electronics\\nOpen hardware\\nRadar and Radionavigation\\nRadio electronics\\nTerahertz technology\\nVideo hardware\\nWired and Wireless Communications\\n\\nAuthority control: National libraries \\nFrance (data)\\nGermany\\nIsrael\\nUnited States\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Laptop&oldid=1083550987\"',\n",
       "  'For information on using Wikipedia on mobile devices, see Help:Mobile access.\\n\\n\\n\\nLook up Mobile, mobile, or -mobile in Wiktionary, the free dictionary.\\n\\nMobile may refer to:\\n\\nContents\\n\\n1 Places\\n2 Arts, entertainment, and media\\n\\n2.1 Music\\n\\n2.1.1 Groups and labels\\n2.1.2 Other uses in music\\n\\n\\n2.2 Other uses in arts, entertainment, and media\\n\\n\\n3 Military and law enforcement\\n4 Science\\n5 Technology\\n6 See also\\n\\n\\n\\nPlaces[edit]\\nMobile, Alabama, a U.S. port city\\nMobile County, Alabama\\nMobile, Arizona, a small town near Phoenix, U.S.\\nMobile, Newfoundland and Labrador\\nArts, entertainment, and media[edit]\\nMusic[edit]\\nGroups and labels[edit]\\nMobile (band), a Canadian rock band\\nThe Mobiles, a 1980s British band\\nOther uses in music[edit]\\nMobile (album), a 1999 album by Brazilian Paulinho Moska\\n\"Mobile\" (song), a 2003 song by Avril Lavigne from Let Go\\n\"Mobile\", a song by Gentle Giant from the album Free Hand\\nOther uses in arts, entertainment, and media[edit]\\nMobile (sculpture), a kinetic sculpture constructed to take advantage of the principle of equilibrium\\nMobile (TV series), a British ITV drama\\n\"Mobile\", a short story by J. G. Ballard, later renamed \"Venus Smiles\"\\nMobile, a feature of the game GunBound\\nMobile Magazine, a publication on portable electronics\\nMilitary and law enforcement[edit]\\nGarde Mobile, historic French military unit\\nMobile Brigade Corps (Brimob), the special police force of Indonesia\\nMobile forces, especially:\\nMotorized infantry\\nMounted infantry\\nOperation Mobile, Canadian Forces operations in the 2011 military intervention in Libya\\nScience[edit]\\nMotility\\nMotion (physics), the ability to move or be moved\\nTechnology[edit]\\nMobile computing, a generic term describing one\\'s ability to use technology in mobile environments\\nMobile device, such as a smartphone, tablet, or computer designed for mobile computing\\nMobile game, a video game played on a mobile phone, smartphone, PDA or handheld computer\\nMobile network operator, a company which provides mobile phone network access and services\\nMobile operating system, the various underlying systems to power and run phones\\nMobile phone, a portable telephone that can make and receive calls\\nMobile radio, wireless communications systems and devices which are based on radio frequencies\\nMobile rig\\nMobile station, user equipment and software needed for communication with a wireless telephone network\\nMobile Web, the World Wide Web as accessed from mobile devices using Mobile Web Browser\\nMobile TV, TV services viewed via a mobile device\\nSee also[edit]\\nMabila, a Native American people of Alabama\\nMauvilla (disambiguation)\\nMavilla (disambiguation)\\nMobil, a major oil company\\nMobile station (disambiguation)\\nMobility (disambiguation)\\nTopics referred to by the same term\\n\\n This disambiguation page lists  articles associated with the title Mobile.If an internal link led you here, you may wish to change the link to point directly to the intended article. \\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Mobile&oldid=1053533393\"',\n",
       "  'Automatic general-purpose device for performing arithmetic or logical operations\\nFor other uses, see Computer (disambiguation).\\n\\n\\nComputers and computing devices from different eras – clockwise from top left:Early vacuum tube computer (ENIAC)Mainframe computer (IBM System 360)Desktop computer (IBM ThinkCentre S50 with monitor)Supercomputer (IBM Summit)Video game console (Nintendo GameCube)Smartphone (LYF Water 2)\\nA computer is a digital electronic machine that can be programmed to carry out sequences of arithmetic or logical operations (computation) automatically. Modern computers can perform generic sets of operations known as programs. These programs enable computers to perform a wide range of tasks. A computer system is a \"complete\" computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for \"full\" operation. This term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.\\nA broad range of industrial and consumer products use computers as control systems. Simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. Computers power the Internet, which links billions of other computers and users.\\nEarly computers were meant to be used only for calculations. Simple manual instruments like the abacus have aided people in doing calculations since ancient times. Early in the Industrial Revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. More sophisticated electrical machines did specialized analog calculations in the early 20th century. The first digital electronic calculating machines were developed during World War II. The first semiconductor transistors in the late 1940s were followed by the silicon-based MOSFET (MOS transistor) and monolithic integrated circuit (IC) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. The speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by Moore\\'s law), leading to the Digital Revolution during the late 20th to early 21st centuries.\\nConventionally, a modern computer consists of at least one processing element, typically a central processing unit (CPU) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. The processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. Peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). Peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.\\n\\nContents\\n\\n1 Etymology\\n2 History\\n\\n2.1 Pre-20th century\\n2.2 First computer\\n2.3 Analog computers\\n2.4 Digital computers\\n\\n2.4.1 Electromechanical\\n2.4.2 Vacuum tubes and digital electronic circuits\\n\\n\\n2.5 Modern computers\\n\\n2.5.1 Concept of modern computer\\n2.5.2 Stored programs\\n2.5.3 Transistors\\n2.5.4 Integrated circuits\\n\\n\\n2.6 Mobile computers\\n\\n\\n3 Types\\n\\n3.1 By architecture\\n3.2 By size, form-factor and purpose\\n\\n\\n4 Hardware\\n\\n4.1 History of computing hardware\\n4.2 Other hardware topics\\n4.3 Input devices\\n4.4 Output devices\\n4.5 Control unit\\n4.6 Central processing unit (CPU)\\n4.7 Arithmetic logic unit (ALU)\\n4.8 Memory\\n4.9 Input/output (I/O)\\n4.10 Multitasking\\n4.11 Multiprocessing\\n\\n\\n5 Software\\n\\n5.1 Languages\\n5.2 Programs\\n\\n5.2.1 Stored program architecture\\n5.2.2 Machine code\\n5.2.3 Programming language\\n\\n5.2.3.1 Low-level languages\\n5.2.3.2 High-level languages\\n\\n\\n5.2.4 Program design\\n5.2.5 Bugs\\n\\n\\n\\n\\n6 Networking and the Internet\\n7 Unconventional computers\\n8 Future\\n\\n8.1 Computer architecture paradigms\\n8.2 Artificial intelligence\\n\\n\\n9 Professions and organizations\\n10 See also\\n11 Notes\\n12 References\\n13 Sources\\n14 External links\\n\\n\\n\\nEtymology\\n A human computer, with microscope and calculator, 1952\\nAccording to the Oxford English Dictionary, the first known use of computer was in a 1613 book called The Yong Mans Gleanings by the English writer Richard Brathwait: \"I haue  [sic] read the truest computer of Times, and the best Arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number.\" This usage of the term referred to a human computer, a person who carried out calculations or computations. The word continued with the same meaning until the middle of the 20th century. During the latter part of this period women were often hired as computers because they could be paid less than their male counterparts.[1] By 1943, most human computers were women.[2]\\nThe Online Etymology Dictionary gives the first attested use of computer in the 1640s, meaning \\'one who calculates\\'; this is an \"agent noun from compute (v.)\". The Online Etymology Dictionary states that the use of the term to mean \"\\'calculating machine\\' (of any type) is from 1897.\"  The Online Etymology Dictionary indicates that the \"modern use\" of the term, to mean \\'programmable digital electronic computer\\' dates from \"1945 under this name; [in a] theoretical [sense] from 1937, as Turing machine\".[3]\\n\\nHistory\\nMain articles: History of computing hardware and History of computing\\nPre-20th century\\n The Ishango bone, a bone tool dating back to prehistoric Africa.\\nDevices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers.[a][4] The use of counting rods is one example.\\n\\n The Chinese suanpan (算盘). The number represented on this abacus is 6,302,715,408.\\nThe abacus was initially used for arithmetic tasks. The Roman abacus was developed from devices used in Babylonia as early as 2400 BC. Since then, many other forms of reckoning boards or tables have been invented. In a medieval European counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.[5]\\n\\n The Antikythera mechanism, dating back to ancient Greece circa 150–100 BC, is an early analog computing device.\\nThe Antikythera mechanism is believed to be the earliest known mechanical analog computer, according to Derek J. de Solla Price.[6] It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to approximately c.\\u2009100 BC. Devices of comparable complexity to the Antikythera mechanism would not reappear until the fourteenth century.[7]\\nMany mechanical aids to calculation and measurement were constructed for astronomical and navigation use. The planisphere was a star chart invented by Abū Rayhān al-Bīrūnī in the early 11th century.[8] The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer[9][10] and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235.[11] Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe,[12] an early fixed-wired knowledge processing machine[13] with a gear train and gear-wheels,[14] c.\\u20091000 AD.\\nThe sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.\\nThe planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.\\n\\n A slide rule.\\nThe slide rule was invented around 1620–1630 by the English clergyman William Oughtred, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Slide rules with special scales are still used for quick performance of routine calculations, such as the E6B circular slide rule used for time and distance calculations on light aircraft.\\nIn the 1770s, Pierre Jaquet-Droz, a Swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. By switching the number and order of its internal wheels different letters, and hence different messages, could be produced. In effect, it could be mechanically \"programmed\" to read instructions. Along with two other complex machines, the doll is at the Musée d\\'Art et d\\'Histoire of Neuchâtel, Switzerland, and still operates.[15]\\nIn 1831–1835, mathematician and engineer Giovanni Plana devised a Perpetual Calendar machine, which, through a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from AD 0 (that is, 1 BC) to AD 4000, keeping track of leap years and varying day length. The tide-predicting machine invented by the Scottish scientist Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.\\nThe differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876, Sir William Thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators.[16] In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.\\n\\nFirst computer\\n A portion of Babbage\\'s Difference engine.\\nCharles Babbage, an English mechanical engineer and polymath, originated the concept of a programmable computer. Considered the \"father of the computer\",[17] he conceptualized and invented the first mechanical computer in the early 19th century. After working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an Analytical Engine, was possible. The input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the Jacquard loom. For output, the machine would have a printer, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. The Engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as Turing-complete.[18][19]\\nThe machine was about a century ahead of its time. All the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. Eventually, the project was dissolved with the decision of the British Government to cease funding. Babbage\\'s failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. Nevertheless, his son, Henry Babbage, completed a simplified version of the analytical engine\\'s computing unit (the mill) in 1888. He gave a successful demonstration of its use in computing tables in 1906.\\n\\nAnalog computers\\nMain article: Analog computer\\n Sir William Thomson\\'s third tide-predicting machine design, 1879–81\\nDuring the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. However, these were not programmable and generally lacked the versatility and accuracy of modern digital computers.[20] The first modern analog computer was a tide-predicting machine, invented by Sir William Thomson (later to become Lord Kelvin) in 1872. The differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by James Thomson, the elder brother of the more famous Sir William Thomson.[16]\\nThe art of mechanical analog computing reached its zenith with the differential analyzer, built by H. L. Hazen and Vannevar Bush at MIT starting in 1927. This built on the mechanical integrators of James Thomson and the torque amplifiers invented by H. W. Nieman. A dozen of these devices were built before their obsolescence became obvious. By the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).\\n\\nDigital computers\\nElectromechanical\\nBy 1938, the United States Navy had developed an electromechanical analog computer small enough to use aboard a submarine. This was the Torpedo Data Computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. During World War II similar devices were developed in other countries as well.\\n\\n Replica of Konrad Zuse\\'s Z3, the first fully automatic, digital (electromechanical) computer.\\nEarly digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. These devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. The Z2, created by German engineer Konrad Zuse in 1939, was one of the earliest examples of an electromechanical relay computer.[21]\\nIn 1941, Zuse followed his earlier machine up with the Z3, the world\\'s first working electromechanical programmable, fully automatic digital computer.[22][23] The Z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 Hz.[24] Program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. It was quite similar to modern machines in some respects, pioneering numerous advances such as floating-point numbers. Rather than the harder-to-implement decimal system (used in Charles Babbage\\'s earlier design), using a binary system meant that Zuse\\'s machines were easier to build and potentially more reliable, given the technologies available at that time.[25] The Z3 was not itself a universal computer but could be extended to be Turing complete.[26][27]\\nZuse\\'s next computer, the Z4, became the world\\'s first commercial computer; after initial delay due to the Second World War, it was completed in 1950 and delivered to the ETH Zurich.[28] The computer was manufactured by Zuse\\'s own company, Zuse KG\\xa0[de], which was founded in 1941 as the first company with the sole purpose of developing computers.[28]\\n\\nVacuum tubes and digital electronic circuits\\n\\nPurely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. The engineer Tommy Flowers, working at the Post Office Research Station in London in the 1930s, began to explore the possible use of electronics for the telephone exchange. Experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes.[20] In the US, John Vincent Atanasoff and Clifford E. Berry of Iowa State University developed and tested the Atanasoff–Berry Computer (ABC) in 1942,[29] the first \"automatic electronic digital computer\".[30] This design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.[31]\\n\\n Colossus, the first electronic digital programmable computing device, was used to break German ciphers during World War II. It is seen here in use at Bletchley Park in 1943.\\nDuring World War II, the British code-breakers at Bletchley Park achieved a number of successes at breaking encrypted German military communications. The German encryption machine, Enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women.[32][33] To crack the more sophisticated German Lorenz SZ 40/42 machine, used for high-level Army communications, Max Newman and his colleagues commissioned Flowers to build the Colossus.[31] He spent eleven months from early February 1943 designing and building the first Colossus.[34] After a functional test in December 1943, Colossus was shipped to Bletchley Park, where it was delivered on 18 January 1944[35] and attacked its first message on 5 February.[31]\\nColossus was the world\\'s first electronic digital programmable computer.[20] It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1,500 thermionic valves (tubes), but Mark II with 2,400 valves, was both five times faster and simpler to operate than Mark I, greatly speeding the decoding process.[36][37]\\n\\n ENIAC was the first electronic, Turing-complete device, and performed ballistics trajectory calculations for the United States Army.\\nThe ENIAC[38] (Electronic Numerical Integrator and Computer) was the first electronic programmable computer built in the U.S. Although the ENIAC was similar to the Colossus, it was much faster, more flexible, and it was Turing-complete. Like the Colossus, a \"program\" on the ENIAC was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were six women, often known collectively as the \"ENIAC girls\".[39][40]\\nIt combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC\\'s development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.[41]\\n\\nModern computers\\nConcept of modern computer\\nThe principle of the modern computer was proposed by Alan Turing in his seminal 1936 paper,[42] On Computable Numbers. Turing proposed a simple device that he called \"Universal Computing machine\" and that is now known as a universal Turing machine. He proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. The fundamental concept of Turing\\'s design is the stored program, where all the instructions for computing are stored in memory. Von Neumann acknowledged that the central concept of the modern computer was due to this paper.[43] Turing machines are to this day a central object of study in theory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to be Turing-complete, which is to say, they have algorithm execution capability equivalent to a universal Turing machine.\\n\\nStored programs\\nMain article: Stored-program computer\\n A section of the Manchester Baby, the first electronic stored-program computer\\nEarly computing machines had fixed programs. Changing its function required the re-wiring and re-structuring of the machine.[31] With the proposal of the stored-program computer this changed. A stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. The theoretical basis for the stored-program computer was laid by Alan Turing in his 1936 paper. In 1945, Turing joined the National Physical Laboratory and began work on developing an electronic stored-program digital computer. His 1945 report \"Proposed Electronic Calculator\" was the first specification for such a device. John von Neumann at the University of Pennsylvania also circulated his First Draft of a Report on the EDVAC in 1945.[20]\\nThe Manchester Baby was the world\\'s first stored-program computer. It was built at the University of Manchester in England by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948.[44] It was designed as a testbed for the Williams tube, the first random-access digital storage device.[45] Although the computer was considered \"small and primitive\" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer.[46] As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the Manchester Mark 1. Grace Hopper was the first person to develop a compiler for programming language.[2]\\nThe Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world\\'s first commercially available general-purpose computer.[47] Built by Ferranti, it was delivered to the University of Manchester in February 1951. At least seven of these later machines were delivered between 1953 and 1957, one of them to Shell labs in Amsterdam.[48] In October 1947, the directors of British catering company J. Lyons & Company decided to take an active role in promoting the commercial development of computers. The LEO I computer became operational in April 1951[49] and ran the world\\'s first regular routine office computer job.\\n\\nTransistors\\nMain articles: Transistor and History of the transistor\\nFurther information: Transistor computer and MOSFET\\n Bipolar junction transistor (BJT)\\nThe concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by Shockley\\'s bipolar junction transistor in 1948.[50][51] From 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the \"second generation\" of computers. Compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. Junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. Transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.[52]\\nAt the University of Manchester, a team under the leadership of Tom Kilburn designed and built a machine using the newly developed transistors instead of valves.[53] Their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in April 1955. However, the machine did make use of valves to generate its 125\\xa0kHz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. That distinction goes to the Harwell CADET of 1955,[54] built by the electronics division of the Atomic Energy Research Establishment at Harwell.[54][55]\\n\\n MOSFET (MOS transistor), showing gate (G), body (B), source (S) and drain (D) terminals. The gate is separated from the body by an insulating layer (pink).\\nThe metal–oxide–silicon field-effect transistor (MOSFET), also known as the MOS transistor, was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959.[56] It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses.[52] With its high scalability,[57] and much lower power consumption and higher density than bipolar junction transistors,[58] the MOSFET made it possible to build high-density integrated circuits.[59][60] In addition to data processing, it also enabled the practical use of MOS transistors as memory cell storage elements, leading to the development of MOS semiconductor memory, which replaced earlier magnetic-core memory in computers. The MOSFET led to the microcomputer revolution,[61] and became the driving force behind the computer revolution.[62][63] The MOSFET is the most widely used transistor in computers,[64][65] and is the fundamental building block of digital electronics.[66]\\n\\nIntegrated circuits\\nMain articles: Integrated circuit and Invention of the integrated circuit\\nFurther information: Planar process and Microprocessor\\nThe next great advance in computing power came with the advent of the integrated circuit (IC).\\nThe idea of the integrated circuit was first conceived by a radar scientist working for the Royal Radar Establishment of the Ministry of Defence, Geoffrey W.A. Dummer. Dummer presented the first public description of an integrated circuit at the Symposium on Progress in Quality Electronic Components in Washington,\\xa0D.C. on 7 May 1952.[67]\\nThe first working ICs were invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor.[68] Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958.[69] In his patent application of 6 February 1959, Kilby described his new device as \"a body of semiconductor material\\xa0... wherein all the components of the electronic circuit are completely integrated\".[70][71] However, Kilby\\'s invention was a hybrid integrated circuit (hybrid IC), rather than a monolithic integrated circuit (IC) chip.[72] Kilby\\'s IC had external wire connections, which made it difficult to mass-produce.[73]\\nNoyce also came up with his own idea of an integrated circuit half a year later than Kilby.[74] Noyce\\'s invention was the first true monolithic IC chip.[75][73] His chip solved many practical problems that Kilby\\'s had not. Produced at Fairchild Semiconductor, it was made of silicon, whereas Kilby\\'s chip was made of germanium. Noyce\\'s monolithic IC was fabricated using the planar process, developed by his colleague Jean Hoerni in early 1959. In turn, the planar process was based on Mohamed M. Atalla\\'s work on semiconductor surface passivation by silicon dioxide in the late 1950s.[76][77][78]\\nModern monolithic ICs are predominantly MOS (metal-oxide-semiconductor) integrated circuits, built from MOSFETs (MOS transistors).[79] The earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962.[80] General Microelectronics later introduced the first commercial MOS IC in 1964,[81] developed by Robert Norman.[80] Following the development of the self-aligned gate (silicon-gate) MOS transistor by Robert Kerwin, Donald Klein and John Sarace at Bell Labs in 1967, the first silicon-gate MOS IC with self-aligned gates was developed by Federico Faggin at Fairchild Semiconductor in 1968.[82] The MOSFET has since become the most critical device component in modern ICs.[83]\\nThe development of the MOS integrated circuit led to the invention of the microprocessor,[84][85] and heralded an explosion in the commercial and personal use of computers. While the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term \"microprocessor\", it is largely undisputed that the first single-chip microprocessor was the Intel 4004,[86] designed and realized by Federico Faggin with his silicon-gate MOS IC technology,[84] along with Ted Hoff, Masatoshi Shima and Stanley Mazor at Intel.[b][88] In the early 1970s, MOS IC technology enabled the integration of more than 10,000 transistors on a single chip.[60]\\nSystem on a Chip (SoCs) are complete computers on a microchip (or chip) the size of a coin.[89] They may or may not have integrated RAM and flash memory. If not integrated, the RAM is usually placed directly above (known as Package on package) or below (on the opposite side of the circuit board) the SoC, and the flash memory is usually placed right next to the SoC, this all done to improve data transfer speeds, as the data signals don\\'t have to travel long distances. Since ENIAC in 1945, computers have advanced enormously, with modern SoCs (Such as the Snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than ENIAC, integrating billions of transistors, and consuming only a few watts of power.\\n\\nMobile computers\\nThe first mobile computers were heavy and ran from mains power. The 50\\xa0lb (23\\xa0kg) IBM 5100 was an early example. Later portables such as the Osborne 1 and Compaq Portable were considerably lighter but still needed to be plugged in. The first laptops, such as the Grid Compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s.[90] The same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.\\nThese smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market.[91] These are powered by System on a Chip (SoCs), which are complete computers on a microchip the size of a coin.[89]\\n\\nTypes\\nSee also: Classes of computers\\nComputers can be classified in a number of different ways, including:\\n\\nBy architecture\\nAnalog computer\\nDigital computer\\nHybrid computer\\nHarvard architecture\\nVon Neumann architecture\\nComplex instruction set computer\\nReduced instruction set computer\\nBy size, form-factor and purpose\\nSupercomputer\\nMainframe computer\\nMinicomputer (term no longer used)\\nServer\\nRackmount server\\nBlade server\\nTower server\\nPersonal computer\\nWorkstation\\nMicrocomputer (term no longer used)\\nHome computer\\nDesktop computer\\nTower desktop\\nSlimline desktop\\nMultimedia computer (non-linear editing system computers, video editing PCs and the like)\\nGaming computer\\nAll-in-one PC\\nNettop (Small form factor PCs, Mini PCs)\\nHome theater PC\\nKeyboard computer\\nPortable computer\\nThin client\\nInternet appliance\\nLaptop\\nDesktop replacement computer\\nGaming laptop\\nRugged laptop\\n2-in-1 PC\\nUltrabook\\nChromebook\\nSubnotebook\\nNetbook\\nMobile computers:\\nTablet computer\\nSmartphone\\nUltra-mobile PC\\nPocket PC\\nPalmtop PC\\nHandheld PC\\nWearable computer\\nSmartwatch\\nSmartglasses\\nSingle-board computer\\nPlug computer\\nStick PC\\nProgrammable logic controller\\nComputer-on-module\\nSystem on module\\nSystem in a package\\nSystem-on-chip (Also known as an Application Processor or AP if it lacks circuitry such as radio circuitry)\\nMicrocontroller\\nHardware\\nMain articles: Computer hardware, Personal computer hardware, Central processing unit, and MicroprocessorPlay media Video demonstrating the standard components of a \"slimline\" computer\\nThe term hardware covers all of those parts of a computer that are tangible physical objects. Circuits, computer chips, graphic cards, sound cards, memory (RAM), motherboard, displays, power supplies, cables, keyboards, printers and \"mice\" input devices are all hardware.\\n\\nHistory of computing hardware\\nMain article: History of computing hardware\\n\\n\\nFirst generation(mechanical/electromechanical)\\nCalculators\\nPascal\\'s calculator, Arithmometer, Difference engine, Quevedo\\'s analytical machines\\n\\n\\nProgrammable devices\\nJacquard loom, Analytical engine, IBM ASCC/Harvard Mark I, Harvard Mark II, IBM SSEC, Z1, Z2, Z3\\n\\n\\nSecond generation(vacuum tubes)\\nCalculators\\nAtanasoff–Berry Computer, IBM 604, UNIVAC 60, UNIVAC 120\\n\\n\\nProgrammable devices\\nColossus, ENIAC, Manchester Baby, EDSAC, Manchester Mark 1, Ferranti Pegasus, Ferranti Mercury, CSIRAC, EDVAC, UNIVAC I, IBM 701, IBM 702, IBM 650, Z22\\n\\n\\nThird generation(discrete transistors and SSI, MSI, LSI integrated circuits)\\nMainframes\\nIBM 7090, IBM 7080, IBM System/360, BUNCH\\n\\n\\nMinicomputer\\nHP 2116A, IBM System/32, IBM System/36, LINC, PDP-8, PDP-11\\n\\n\\nDesktop Computer\\nHP 9100\\n\\n\\nFourth generation(VLSI integrated circuits)\\nMinicomputer\\nVAX, IBM AS/400\\n\\n\\n4-bit microcomputer\\nIntel 4004, Intel 4040\\n\\n\\n8-bit microcomputer\\nIntel 8008, Intel 8080, Motorola 6800, Motorola 6809, MOS Technology 6502, Zilog Z80\\n\\n\\n16-bit microcomputer\\nIntel 8088, Zilog Z8000, WDC 65816/65802\\n\\n\\n32-bit microcomputer\\nIntel 80386, Pentium, Motorola 68000, ARM\\n\\n\\n64-bit microcomputer[c]\\nAlpha, MIPS, PA-RISC, PowerPC, SPARC, x86-64, ARMv8-A\\n\\n\\nEmbedded computer\\nIntel 8048, Intel 8051\\n\\n\\nPersonal computer\\nDesktop computer, Home computer, Laptop computer, Personal digital assistant (PDA), Portable computer, Tablet PC, Wearable computer\\n\\n\\nTheoretical/experimental\\nQuantum computer\\n\\n\\n\\nChemical computer\\n\\n\\n\\nDNA computing\\n\\n\\n\\nOptical computer\\n\\n\\n\\nSpintronics-based computer\\n\\n\\n\\nWetware/Organic computer\\n\\n\\nOther hardware topics\\n\\n\\nPeripheral device (input/output)\\nInput\\nMouse, keyboard, joystick, image scanner, webcam, graphics tablet, microphone\\n\\n\\nOutput\\nMonitor, printer, loudspeaker\\n\\n\\nBoth\\nFloppy disk drive, hard disk drive, optical disc drive, teleprinter\\n\\n\\nComputer buses\\nShort range\\nRS-232, SCSI, PCI, USB\\n\\n\\nLong range (computer networking)\\nEthernet, ATM, FDDI\\n\\nA general-purpose computer has four main components: the arithmetic logic unit (ALU), the control unit, the memory, and the input and output devices (collectively termed I/O). These parts are interconnected by buses, often made of groups of wires. Inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. Each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a \"1\", and when off it represents a \"0\" (in positive logic representation). The circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.\\n\\nInput devices\\nWhen unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. The input devices may be hand-operated or automated. The act of processing is mainly regulated by the CPU. Some examples of input devices are:\\n\\nComputer keyboard\\nDigital camera\\nDigital video\\nGraphics tablet\\nImage scanner\\nJoystick\\nMicrophone\\nMouse\\nOverlay keyboard\\nReal-time clock\\nTrackball\\nTouchscreen\\nLight pen\\nOutput devices\\nThe means through which computer gives output are known as output devices. Some examples of output devices are:\\n\\nComputer monitor\\nPrinter\\nPC speaker\\nProjector\\nSound card\\nVideo card\\nControl unit\\nMain articles: CPU design and Control unit\\n Diagram showing how a particular MIPS architecture instruction would be decoded by the control system\\nThe control unit (often called a control system or central controller) manages the computer\\'s various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer.[d] Control systems in advanced computers may change the order of execution of some instructions to improve performance.\\nA key component common to all CPUs is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.[e]\\nThe control system\\'s function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of CPU:\\n\\nRead the code for the next instruction from the cell indicated by the program counter.\\nDecode the numerical code for the instruction into a set of commands or signals for each of the other systems.\\nIncrement the program counter so it points to the next instruction.\\nRead whatever data the instruction requires from cells in memory (or perhaps from an input device). The location of this required data is typically stored within the instruction code.\\nProvide the necessary data to an ALU or register.\\nIf the instruction requires an ALU or specialized hardware to complete, instruct the hardware to perform the requested operation.\\nWrite the result from the ALU back to a memory location or to a register or perhaps an output device.\\nJump back to step (1).\\nSince the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the ALU. Adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. Instructions that modify the program counter are often known as \"jumps\" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).\\nThe sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex CPU designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.\\n\\nCentral processing unit (CPU)\\nMain articles: Central processing unit and Microprocessor\\nThe control unit, ALU, and registers are collectively known as a central processing unit (CPU). Early CPUs were composed of many separate components. Since the 1970s, CPUs have typically been constructed on a single MOS integrated circuit chip called a microprocessor.\\n\\nArithmetic logic unit (ALU)\\nMain article: Arithmetic logic unit\\nThe ALU is capable of performing two classes of operations: arithmetic and logic.[92] The set of arithmetic operations that a particular ALU supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. Some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. However, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. Therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its ALU does not directly support the operation. An ALU may also compare numbers and return Boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (\"is 64 greater than 65?\"). Logic operations involve Boolean logic: AND, OR, XOR, and NOT. These can be useful for creating complicated conditional statements and processing Boolean logic.\\nSuperscalar computers may contain multiple ALUs, allowing them to process several instructions simultaneously.[93] Graphics processors and computers with SIMD and MIMD features often contain ALUs that can perform arithmetic on vectors and matrices.\\n\\nMemory\\nMain articles: Computer memory and Computer data storage\\n Magnetic-core memory (using magnetic cores) was the computer memory of choice in the 1960s, until it was replaced by semiconductor memory (using MOS memory cells).\\nA computer\\'s memory can be viewed as a list of cells into which numbers can be placed or read. Each cell has a numbered \"address\" and can store a single number. The computer can be instructed to \"put the number 123 into the cell numbered 1357\" or to \"add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595.\" The information stored in memory may represent practically anything. Letters, numbers, even computer instructions can be placed into memory with equal ease. Since the CPU does not differentiate between different types of information, it is the software\\'s responsibility to give significance to what the memory sees as nothing but a series of numbers.\\nIn almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). Each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. To store larger numbers, several consecutive bytes may be used (typically, two, four or eight). When negative numbers are required, they are usually stored in two\\'s complement notation. Other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. A computer can store any kind of information in memory if it can be represented numerically. Modern computers have billions or even trillions of bytes of memory.\\nThe CPU contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. There are typically between two and one hundred registers depending on the type of CPU. Registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. As data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the ALU and control units) greatly increases the computer\\'s speed.\\nComputer main memory comes in two principal varieties:\\n\\nrandom-access memory or RAM\\nread-only memory or ROM\\nRAM can be read and written to anytime the CPU commands it, but ROM is preloaded with data and software that never changes, therefore the CPU can only read from it. ROM is typically used to store the computer\\'s initial start-up instructions. In general, the contents of RAM are erased when the power to the computer is turned off, but ROM retains its data indefinitely. In a PC, the ROM contains a specialized program called the BIOS that orchestrates loading the computer\\'s operating system from the hard disk drive into RAM whenever the computer is turned on or reset. In embedded computers, which frequently do not have disk drives, all of the required software may be stored in ROM. Software stored in ROM is often called firmware, because it is notionally more like hardware than software. Flash memory blurs the distinction between ROM and RAM, as it retains its data when turned off but is also rewritable. It is typically much slower than conventional ROM and RAM however, so its use is restricted to applications where high speed is unnecessary.[f]\\nIn more sophisticated computers there may be one or more RAM cache memories, which are slower than registers but faster than main memory. Generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer\\'s part.\\n\\nInput/output (I/O)\\nMain article: Input/output\\n Hard disk drives are common storage devices used with computers.\\nI/O is the means by which a computer exchanges information with the outside world.[95] Devices that provide input or output to the computer are called peripherals.[96] On a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. Hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. Computer networking is another form of I/O.\\nI/O devices are often complex computers in their own right, with their own CPU and memory. A graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3D graphics.[citation needed] Modern desktop computers contain many smaller computers that assist the main CPU in performing I/O. A 2016-era flat screen display contains its own computer circuitry.\\n\\nMultitasking\\nMain article: Computer multitasking\\nWhile a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. This is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn.[97] One means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. By remembering where it was executing prior to the interrupt, the computer can return to that task later. If several programs are running \"at the same time\". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. Since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. This method of multitasking is sometimes termed \"time-sharing\" since each program is allocated a \"slice\" of time in turn.[98]\\nBefore the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. Seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. If a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a \"time slice\" until the event it is waiting for has occurred. This frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.\\n\\nMultiprocessing\\nMain article: Multiprocessing\\n Cray designed many supercomputers that used multiprocessing heavily.\\nSome computers are designed to distribute their work across several CPUs in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. Multiprocessor and multi-core (multiple CPUs on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.\\nSupercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers.[g] They often feature thousands of CPUs, customized high-speed interconnects, and specialized computing hardware. Such designs tend to be useful for only specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. Supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called \"embarrassingly parallel\" tasks.\\n\\nSoftware\\nMain article: Software\\nSoftware refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. Software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. It is often divided into system software and application software Computer hardware and software require each other and neither can be realistically used on its own. When software is stored in hardware that cannot easily be modified, such as with BIOS ROM in an IBM PC compatible computer, it is sometimes called \"firmware\".\\n\\n\\n\\nOperating system /System Software\\n\\nUnix and BSD\\nUNIX System V, IBM AIX, HP-UX, Solaris (SunOS), IRIX, List of BSD operating systems\\n\\n\\nLinux\\nList of Linux distributions, Comparison of Linux distributions\\n\\n\\nMicrosoft Windows\\nWindows 95, Windows 98, Windows NT, Windows 2000, Windows ME, Windows XP, Windows Vista, Windows 7, Windows 8, Windows 8.1, Windows 10, Windows 11\\n\\n\\nDOS\\n86-DOS (QDOS), IBM PC DOS, MS-DOS, DR-DOS, FreeDOS\\n\\n\\nMacintosh operating systems\\nClassic Mac OS, macOS (previously OS X and Mac OS X)\\n\\n\\nEmbedded and real-time\\nList of embedded operating systems\\n\\n\\nExperimental\\nAmoeba, Oberon–AOS, Bluebottle, A2, Plan 9 from Bell Labs\\n\\n\\nLibrary\\nMultimedia\\nDirectX, OpenGL, OpenAL, Vulkan (API)\\n\\n\\nProgramming library\\nC standard library, Standard Template Library\\n\\n\\nData\\nProtocol\\nTCP/IP, Kermit, FTP, HTTP, SMTP\\n\\n\\nFile format\\nHTML, XML, JPEG, MPEG, PNG\\n\\n\\nUser interface\\nGraphical user interface (WIMP)\\nMicrosoft Windows, GNOME, KDE, QNX Photon, CDE, GEM, Aqua\\n\\n\\nText-based user interface\\nCommand-line interface, Text user interface\\n\\n\\nApplication Software\\n\\nOffice suite\\nWord processing, Desktop publishing, Presentation program, Database management system, Scheduling & Time management, Spreadsheet, Accounting software\\n\\n\\nInternet Access\\nBrowser, Email client, Web server, Mail transfer agent, Instant messaging\\n\\n\\nDesign and manufacturing\\nComputer-aided design, Computer-aided manufacturing, Plant management, Robotic manufacturing, Supply chain management\\n\\n\\nGraphics\\nRaster graphics editor, Vector graphics editor, 3D modeler, Animation editor, 3D computer graphics, Video editing, Image processing\\n\\n\\nAudio\\nDigital audio editor, Audio playback, Mixing, Audio synthesis, Computer music\\n\\n\\nSoftware engineering\\nCompiler, Assembler, Interpreter, Debugger, Text editor, Integrated development environment, Software performance analysis, Revision control, Software configuration management\\n\\n\\nEducational\\nEdutainment, Educational game, Serious game, Flight simulator\\n\\n\\nGames\\nStrategy, Arcade, Puzzle, Simulation, First-person shooter, Platform, Massively multiplayer, Interactive fiction\\n\\n\\nMisc\\nArtificial intelligence, Antivirus software, Malware scanner, Installer/Package management systems, File manager\\n\\nLanguages\\nThere are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.\\n\\n\\nProgramming languages\\n\\n\\nLists of programming languages\\nTimeline of programming languages, List of programming languages by category, Generational list of programming languages, List of programming languages, Non-English-based programming languages\\n\\n\\nCommonly used assembly languages\\nARM, MIPS, x86\\n\\n\\nCommonly used high-level programming languages\\nAda, BASIC, C, C++, C#, COBOL, Fortran, PL/I, REXX, Java, Lisp, Pascal, Object Pascal\\n\\n\\nCommonly used scripting languages\\nBourne script, JavaScript, Python, Ruby, PHP, Perl\\n\\nPrograms\\nThe defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. That is to say that some type of instructions (the program) can be given to the computer, and it will process them. Modern computers based on the von Neumann architecture often have machine code in the form of an imperative programming language. In practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. A typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. Large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.\\n\\nStored program architecture\\nMain articles: Computer program and Computer programming\\n Replica of the Manchester Baby, the world\\'s first electronic stored-program computer, at the Museum of Science and Industry in Manchester, England\\nThis section applies to most common RAM machine–based computers.\\nIn most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. These instructions are read from the computer\\'s memory and are generally carried out (executed) in the order they were given. However, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. These are called \"jump\" instructions (or branches). Furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. Many computers directly support subroutines by providing a type of jump that \"remembers\" the location it jumped from and another instruction to return to the instruction following that jump instruction.\\nProgram execution might be likened to reading a book. While a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. Similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. This is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.\\nComparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. But to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. On the other hand, a computer may be programmed to do this with just a few simple instructions. The following example is written in the MIPS assembly language:\\n\\n\\n  begin:\\n  addi $8, $0, 0           # initialize sum to 0\\n  addi $9, $0, 1           # set first number to add = 1\\n  loop:\\n  slti $10, $9, 1000       # check if the number is less than 1000\\n  beq $10, $0, finish      # if odd number is greater than n then exit\\n  add $8, $8, $9           # update sum\\n  addi $9, $9, 1           # get next number\\n  j loop                   # repeat the summing process\\n  finish:\\n  add $2, $8, $0           # put sum in output register\\n\\nOnce told to run this program, the computer will perform the repetitive addition task without further human intervention. It will almost never make a mistake and a modern PC can complete the task in a fraction of a second.\\n\\nMachine code\\nIn most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). The command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. The simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. Since the computer\\'s memory is able to store numbers, it can also store the instruction codes. This leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. The fundamental concept of storing programs in the computer\\'s memory alongside the data they operate on is the crux of the von Neumann, or stored program[citation needed], architecture. In some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. This is called the Harvard architecture after the Harvard Mark I computer. Modern von Neumann computers display some traits of the Harvard architecture in their designs, such as in CPU caches.\\nWhile it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers,[h] it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. Instead, each basic instruction can be given a short name that is indicative of its function and easy to remember\\xa0– a mnemonic such as ADD, SUB, MULT or JUMP. These mnemonics are collectively known as a computer\\'s assembly language. Converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.\\n\\n A 1970s punched card containing one line from a Fortran program. The card reads: \"Z(1) = Y + W(1)\" and is labeled \"PROJ039\" for identification purposes.\\nProgramming language\\nMain article: Programming language\\nProgramming languages provide various ways of specifying programs for computers to run. Unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. They are purely written languages and are often difficult to read aloud. They are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. Sometimes programs are executed by a hybrid method of the two techniques.\\n\\nLow-level languages\\nMain article: Low-level programming language\\nMachine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer\\'s central processing unit (CPU). For instance, an ARM architecture CPU (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 CPU that might be in a PC.[i] Historically a significant number of other cpu architectures were created and saw extensive use, notably including the MOS Technology 6502 and 6510 in addition to the Zilog Z80.\\n\\nHigh-level languages\\nMain article: High-level programming language\\nAlthough considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. Therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). High level languages are usually \"compiled\" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler.[j] High level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. It is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. This is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.\\n\\nProgram design\\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (July 2012) (Learn how and when to remove this template message)\\nProgram design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. As problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. Large programs involving thousands of line of code and more require formal software methodologies.\\nThe task of developing large software systems presents a significant intellectual challenge. Producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.\\n\\nBugs\\nMain article: Software bug\\n The actual first computer bug, a moth found trapped on a relay of the Harvard Mark II computer\\nErrors in computer programs are called \"bugs\". They may be benign and not affect the usefulness of the program, or have only subtle effects. But in some cases, they may cause the program or the entire system to \"hang\", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash.[100] Otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer\\'s proper execution. Bugs are usually not the fault of the computer. Since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program\\'s design.[k] Admiral Grace Hopper, an American computer scientist and developer of the first compiler, is credited for having first used the term \"bugs\" in computing after a dead moth was found shorting a relay in the Harvard Mark II computer in September 1947.[101]\\n\\nNetworking and the Internet\\nMain articles: Computer networking and Internet\\n Visualization of a portion of the routes on the Internet\\nComputers have been used to coordinate information between multiple locations since the 1950s. The U.S. military\\'s SAGE system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as Sabre.[102] In the 1970s, computer engineers at research institutions throughout the United States began to link their computers together using telecommunications technology. The effort was funded by ARPA (now DARPA), and the computer network that resulted was called the ARPANET.[103] The technologies that made the Arpanet possible spread and evolved.\\nIn time, the network spread beyond academic and military institutions and became known as the Internet. The emergence of networking involved a redefinition of the nature and boundaries of the computer. Computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. Initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the World Wide Web, combined with the development of cheap, fast networking technologies like Ethernet and ADSL saw computer networking become almost ubiquitous. In fact, the number of computers that are networked is growing phenomenally. A very large proportion of personal computers regularly connect to the Internet to communicate and receive information. \"Wireless\" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.\\n\\n\\nUnconventional computers\\nMain article: Human computer\\nSee also: Harvard Computers\\nA computer does not need to be electronic, nor even have a processor, nor RAM, nor even a hard disk. While popular usage of the word \"computer\" is synonymous with a personal electronic computer,[l] the modern definition of a computer is literally: \"A device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information.\"[104] Any device which processes information qualifies as a computer, especially if the processing is purposeful.[citation needed]\\n\\nFuture\\nThere is active research to make computers out of many promising new types of technology, such as optical computers, DNA computers, neural computers, and quantum computers. Most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. However different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.\\n\\nComputer architecture paradigms\\nThere are many types of computer architectures:\\n\\nQuantum computer vs. Chemical computer\\nScalar processor vs. Vector processor\\nNon-Uniform Memory Access (NUMA) computers\\nRegister machine vs. Stack machine\\nHarvard architecture vs. von Neumann architecture\\nCellular architecture\\nOf all these abstract machines, a quantum computer holds the most promise for revolutionizing computing.[105] Logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. The ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. The Church–Turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being Turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. Therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.\\n\\nArtificial intelligence\\nA computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. Computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. Artificial intelligence based products generally fall into two major categories: rule-based systems and pattern recognition systems. Rule-based systems attempt to represent the rules used by human experts and tend to be expensive to develop. Pattern-based systems use data about a problem to generate conclusions. Examples of pattern-based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.\\n\\nProfessions and organizations\\nAs the use of computers has spread throughout society, there are an increasing number of careers involving computers.\\n\\n\\nComputer-related professions\\n\\n\\nHardware-related\\nElectrical engineering, Electronic engineering, Computer engineering, Telecommunications engineering, Optical engineering, Nanoengineering\\n\\n\\nSoftware-related\\nComputer science, Computer engineering, Desktop publishing, Human–computer interaction, Information technology, Information systems, Computational science, Software engineering, Video game industry, Web design\\n\\nThe need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.\\n\\n\\nOrganizations\\n\\n\\nStandards groups\\nANSI, IEC, IEEE, IETF, ISO, W3C\\n\\n\\nProfessional societies\\nACM, AIS, IET, IFIP, BCS\\n\\n\\nFree/open source software groups\\nFree Software Foundation, Mozilla Foundation, Apache Software Foundation\\n\\nSee also\\n\\nGlossary of computers\\nComputability theory\\nComputer security\\nGlossary of computer hardware terms\\nHistory of computer science\\nList of computer term etymologies\\nList of fictional computers\\nList of pioneers in computer science\\nPulse computation\\nTOP500 (list of most powerful computers)\\nUnconventional computing\\n\\nNotes\\n\\n\\n^ According to Schmandt-Besserat 1981, these clay containers contained tokens, the total of which were the count of objects being transferred. The containers thus served as something of a bill of lading or an accounts book. In order to avoid breaking open the containers, first, clay impressions of the tokens were placed on the outside of the containers, for the count; the shapes of the impressions were abstracted into stylized marks; finally, the abstract marks were systematically used as numerals; these numerals were finally formalized as numbers.Eventually the marks on the outside of the containers were all that were needed to convey the count, and the clay containers evolved into clay tablets with marks for the count. Schmandt-Besserat 1999 estimates it took 4000 years.\\n\\n^ The Intel 4004 (1971) die was 12\\xa0mm2, composed of 2300 transistors; by comparison, the Pentium Pro was 306\\xa0mm2, composed of 5.5\\xa0million transistors.[87]\\n\\n^ Most major 64-bit instruction set architectures are extensions of earlier designs. All of the architectures listed in this table, except for Alpha, existed in 32-bit forms before their 64-bit incarnations were introduced.\\n\\n^ The control unit\\'s role in interpreting instructions has varied somewhat in the past. Although the control unit is solely responsible for instruction interpretation in most modern computers, this is not always the case. Some computers have instructions that are partially interpreted by the control unit with further interpretation performed by another device. For example, EDVAC, one of the earliest stored-program computers, used a central control unit that interpreted only four instructions. All of the arithmetic-related instructions were passed on to its arithmetic unit and further decoded there.\\n\\n^ Instructions often occupy more than one memory address, therefore the program counter usually increases by the number of memory locations required to store one instruction.\\n\\n^ Flash memory also may only be rewritten a limited number of times before wearing out, making it less useful for heavy random access usage.[94] \\n\\n^ However, it is also very common to construct supercomputers out of many pieces of cheap commodity hardware; usually individual computers connected by networks. These so-called computer clusters can often provide supercomputer performance at a much lower cost than customized designs. While custom architectures are still used for most of the most powerful supercomputers, there has been a proliferation of cluster computers in recent years.[99] \\n\\n^ Even some later computers were commonly programmed directly in machine code. Some minicomputers like the DEC PDP-8 could be programmed directly from a panel of switches. However, this method was usually used only as part of the booting process. Most modern computers boot entirely automatically by reading a boot program from some non-volatile memory.\\n\\n^ However, there is sometimes some form of machine language compatibility between different computers. An x86-64 compatible microprocessor like the AMD Athlon 64 is able to run most of the same programs that an Intel Core 2 microprocessor can, as well as programs designed for earlier microprocessors like the Intel Pentiums and Intel 80486. This contrasts with very early commercial computers, which were often one-of-a-kind and totally incompatible with other computers.\\n\\n^ High level languages are also often interpreted rather than compiled. Interpreted languages are translated into machine code on the fly, while running, by another program called an interpreter.\\n\\n^ It is not universally true that bugs are solely due to programmer oversight. Computer hardware may fail or may itself have a fundamental problem that produces unexpected results in certain situations. For instance, the Pentium FDIV bug caused some Intel microprocessors in the early 1990s to produce inaccurate results for certain floating point division operations. This was caused by a flaw in the microprocessor design and resulted in a partial recall of the affected devices.\\n\\n^ According to the Shorter Oxford English Dictionary (6th ed, 2007), the word computer dates back to the mid 17th century, when it referred to \"A person who makes calculations; specifically a person employed for this in an observatory etc.\"\\n\\n\\nReferences\\n\\n\\n^ Evans 2018, p.\\xa023.\\n\\n^ a b Smith 2013, p.\\xa06.\\n\\n^ \"computer (n.)\". Online Etymology Dictionary.\\n\\n^ Robson, Eleanor (2008), Mathematics in Ancient Iraq, p.\\xa05, ISBN\\xa0978-0-691-09182-2: calculi were in use in Iraq for primitive accounting systems as early as 3200–3000 BCE, with commodity-specific counting representation systems. Balanced accounting was in use by 3000–2350 BCE, and a sexagesimal number system was in use 2350–2000 BCE.\\n\\n^ Flegg, Graham. (1989). Numbers through the ages. Houndmills, Basingstoke, Hampshire: Macmillan Education. ISBN\\xa00-333-49130-0. OCLC\\xa024660570.\\n\\n^ The Antikythera Mechanism Research Project Archived 28 April 2008 at the Wayback Machine, The Antikythera Mechanism Research Project. Retrieved 1 July 2007.\\n\\n^ Marchant, Jo (1 November 2006). \"In search of lost time\". Nature. 444 (7119): 534–538. Bibcode:2006Natur.444..534M. doi:10.1038/444534a. PMID\\xa017136067. S2CID\\xa04305761. Retrieved 12 March 2022.\\n\\n^ G. Wiet, V. Elisseeff, P. Wolff, J. Naudu (1975). History of Mankind, Vol 3: The Great medieval Civilisations, p. 649. George Allen & Unwin Ltd, UNESCO.\\n\\n^ Fuat Sezgin \"Catalogue of the Exhibition of the Institute for the History of Arabic-Islamic Science (at the Johann Wolfgang Goethe University\", Frankfurt, Germany) Frankfurt Book Fair 2004, pp.\\xa035 & 38.\\n\\n^ Charette, François (2006). \"Archaeology: High tech from Ancient Greece\". Nature. 444 (7119): 551–552. Bibcode:2006Natur.444..551C. doi:10.1038/444551a. PMID\\xa017136077. S2CID\\xa033513516.\\n\\n^ Bedini, Silvio A.; Maddison, Francis R. (1966). \"Mechanical Universe: The Astrarium of Giovanni de\\' Dondi\". Transactions of the American Philosophical Society. 56 (5): 1–69. doi:10.2307/1006002. JSTOR\\xa01006002.\\n\\n^ Price, Derek de S. (1984). \"A History of Calculating Machines\". IEEE Micro. 4 (1): 22–52. doi:10.1109/MM.1984.291305.\\n\\n^ Őren, Tuncer (2001). \"Advances in Computer and Information Sciences: From Abacus to Holonic Agents\" (PDF). Turk J Elec Engin. 9 (1): 63–70.\\n\\n^ Donald Routledge Hill (1985). \"Al-Biruni\\'s mechanical calendar\", Annals of Science 42, pp.\\xa0139–163.\\n\\n^ \"The Writer Automaton, Switzerland\". chonday.com. 11 July 2013.\\n\\n^ a b Ray Girvan, \"The revealed grace of the mechanism: computing after Babbage\" Archived 3 November 2012 at the Wayback Machine, Scientific Computing World, May/June 2003\\n\\n^ Halacy, Daniel Stephen (1970). Charles Babbage, Father of the Computer. Crowell-Collier Press. ISBN\\xa0978-0-02-741370-0.\\n\\n^ \"Babbage\". Online stuff. Science Museum. 19 January 2007. Retrieved 1 August 2012.\\n\\n^ \"Let\\'s build Babbage\\'s ultimate mechanical computer\". opinion. New Scientist. 23 December 2010. Retrieved 1 August 2012.\\n\\n^ a b c d The Modern History of Computing. Stanford Encyclopedia of Philosophy. 2017.\\n\\n^ Zuse, Horst. \"Part 4: Konrad Zuse\\'s Z1 and Z3 Computers\". The Life and Work of Konrad Zuse. EPE Online. Archived from the original on 1 June 2008. Retrieved 17 June 2008.\\n\\n^ Zuse, Konrad (2010) [1984], The Computer – My Life Translated by McKenna, Patricia and Ross, J. Andrew from: Der Computer, mein Lebenswerk (1984), Berlin/Heidelberg: Springer-Verlag, ISBN\\xa0978-3-642-08151-4\\n\\n^ Salz Trautman, Peggy (20 April 1994). \"A Computer Pioneer Rediscovered, 50 Years On\". The New York Times.\\n\\n^ Zuse, Konrad (1993). Der Computer. Mein Lebenswerk (in German) (3rd\\xa0ed.). Berlin: Springer-Verlag. p.\\xa055. ISBN\\xa0978-3-540-56292-4.\\n\\n^ \"Crash! The Story of IT: Zuse\". Archived from the original on 18 September 2016. Retrieved 1 June 2016.\\n\\n^ Rojas, R. (1998). \"How to make Zuse\\'s Z3 a universal computer\". IEEE Annals of the History of Computing. 20 (3): 51–54. doi:10.1109/85.707574. S2CID\\xa014606587.\\n\\n^ Rojas, Raúl. \"How to Make Zuse\\'s Z3 a Universal Computer\" (PDF).\\n\\n^ a b O\\'Regan, Gerard (2010). A Brief History of Computing. Springer Nature. p.\\xa065. ISBN\\xa09783030665999.\\n\\n^ \"notice\". Des Moines Register. 15 January 1941.\\n\\n^ Arthur W. Burks (1989). The First Electronic Computer. ISBN\\xa00472081047.\\n\\n^ a b c d Copeland, Jack (2006), Colossus: The Secrets of Bletchley Park\\'s Codebreaking Computers, Oxford: Oxford University Press, pp.\\xa0101–115, ISBN\\xa0978-0-19-284055-4\\n\\n^ Miller, Joe (10 November 2014). \"The woman who cracked Enigma cyphers\". BBC News. Retrieved 14 October 2018.\\n\\n^ Bearne, Suzanne (24 July 2018). \"Meet the female codebreakers of Bletchley Park\". The Guardian. Retrieved 14 October 2018.\\n\\n^ \"Bletchley\\'s code-cracking Colossus\", BBC News, 2 February 2010, retrieved 19 October 2012\\n\\n^ \"Colossus – The Rebuild Story\". The National Museum of Computing. Archived from the original on 18 April 2015. Retrieved 7 January 2014.\\n\\n^ Randell, Brian; Fensom, Harry; Milne, Frank A. (15 March 1995), \"Obituary: Allen Coombs\", The Independent, retrieved 18 October 2012\\n\\n^ Fensom, Jim (8 November 2010), \"Harry Fensom obituary\", The Guardian, retrieved 17 October 2012\\n\\n^ John Presper Eckert Jr. and John W. Mauchly, Electronic Numerical Integrator and Computer, United States Patent Office, US Patent 3,120,606, filed 26 June 1947, issued 4 February 1964, and invalidated 19 October 1973 after court ruling on Honeywell v. Sperry Rand.\\n\\n^ Evans 2018, p.\\xa039.\\n\\n^ Light 1999, p.\\xa0459.\\n\\n^ \"Generations of Computer\". techiwarehouse.com. Archived from the original on 2 July 2015. Retrieved 7 January 2014.\\n\\n^ Turing, A. M. (1937). \"On Computable Numbers, with an Application to the Entscheidungsproblem\". Proceedings of the London Mathematical Society. 2. 42 (1): 230–265. doi:10.1112/plms/s2-42.1.230.\\n\\n^ Copeland, Jack (2004), The Essential Turing, p.\\xa022: \"von Neumann\\xa0... firmly emphasized to me, and to others I am sure, that the fundamental conception is owing to Turing—insofar as not anticipated by Babbage, Lovelace and others.\" Letter by Stanley Frankel to Brian Randell, 1972.\\n\\n^ Enticknap, Nicholas (Summer 1998), \"Computing\\'s Golden Jubilee\", Resurrection (20), ISSN\\xa00958-7403, archived from the original on 9 January 2012, retrieved 19 April 2008\\n\\n^ \"Early computers at Manchester University\", Resurrection, 1 (4), Summer 1992, ISSN\\xa00958-7403, archived from the original on 28 August 2017, retrieved 7 July 2010\\n\\n^ Early Electronic Computers (1946–51), University of Manchester, archived from the original on 5 January 2009, retrieved 16 November 2008\\n\\n^ Napper, R. B. E., Introduction to the Mark 1, The University of Manchester, archived from the original on 26 October 2008, retrieved 4 November 2008\\n\\n^ Computer Conservation Society, Our Computer Heritage Pilot Study: Deliveries of Ferranti Mark I and Mark I Star computers, archived from the original on 11 December 2016, retrieved 9 January 2010\\n\\n^ Lavington, Simon. \"A brief history of British computers: the first 25 years (1948–1973)\". British Computer Society. Retrieved 10 January 2010.\\n\\n^ Lee, Thomas H. (2003). The Design of CMOS Radio-Frequency Integrated Circuits (PDF). Cambridge University Press. ISBN\\xa09781139643771. Archived from the original (PDF) on 9 December 2019. Retrieved 31 July 2019.\\n\\n^ Puers, Robert; Baldi, Livio; Voorde, Marcel Van de; Nooten, Sebastiaan E. van (2017). Nanoelectronics: Materials, Devices, Applications, 2 Volumes. John Wiley & Sons. p.\\xa014. ISBN\\xa09783527340538.\\n\\n^ a b Moskowitz, Sanford L. (2016). Advanced Materials Innovation: Managing Global Technology in the 21st century. John Wiley & Sons. pp.\\xa0165–167. ISBN\\xa09780470508923.\\n\\n^ Lavington 1998, pp.\\xa034–35.\\n\\n^ a b Cooke-Yarborough, E. H. (June 1998), \"Some early transistor applications in the UK\", Engineering Science & Education Journal, 7 (3): 100–106, doi:10.1049/esej:19980301, ISSN\\xa00963-7346, retrieved 7 June 2009 (subscription required)\\n\\n^ Cooke-Yarborough, E.H. (1957). Introduction to Transistor Circuits. Edinburgh: Oliver and Boyd. p.\\xa0139.\\n\\n^ \"1960: Metal Oxide Semiconductor (MOS) Transistor Demonstrated\". The Silicon Engine: A Timeline of Semiconductors in Computers. Computer History Museum. Retrieved 31 August 2019.\\n\\n^ Motoyoshi, M. (2009). \"Through-Silicon Via (TSV)\". Proceedings of the IEEE. 97 (1): 43–48. doi:10.1109/JPROC.2008.2007462. ISSN\\xa00018-9219. S2CID\\xa029105721.\\n\\n^ \"Transistors Keep Moore\\'s Law Alive\". EETimes. 12 December 2018. Retrieved 18 July 2019.\\n\\n^ \"Who Invented the Transistor?\". Computer History Museum. 4 December 2013. Retrieved 20 July 2019.\\n\\n^ a b Hittinger, William C. (1973). \"Metal-Oxide-Semiconductor Technology\". Scientific American. 229 (2): 48–59. Bibcode:1973SciAm.229b..48H. doi:10.1038/scientificamerican0873-48. ISSN\\xa00036-8733. JSTOR\\xa024923169.\\n\\n^ Malmstadt, Howard V.; Enke, Christie G.; Crouch, Stanley R. (1994). Making the Right Connections: Microcomputers and Electronic Instrumentation. American Chemical Society. p.\\xa0389. ISBN\\xa09780841228610. The relative simplicity and low power requirements of MOSFETs have fostered today\\'s microcomputer revolution.\\n\\n^ Fossum, Jerry G.; Trivedi, Vishal P. (2013). Fundamentals of Ultra-Thin-Body MOSFETs and FinFETs. Cambridge University Press. p.\\xa0vii. ISBN\\xa09781107434493.\\n\\n^ \"Remarks by Director Iancu at the 2019 International Intellectual Property Conference\". United States Patent and Trademark Office. 10 June 2019. Archived from the original on 17 December 2019. Retrieved 20 July 2019.\\n\\n^ \"Dawon Kahng\". National Inventors Hall of Fame. Retrieved 27 June 2019.\\n\\n^ \"Martin Atalla in Inventors Hall of Fame, 2009\". Retrieved 21 June 2013.\\n\\n^ \"Triumph of the MOS Transistor\". YouTube. Computer History Museum. 6 August 2010. Archived from the original on 18 August 2021. Retrieved 21 July 2019.\\n\\n^ \"The Hapless Tale of Geoffrey Dummer\" Archived 11 May 2013 at the Wayback Machine, (n.d.), (HTML), Electronic Product News, accessed 8 July 2008.\\n\\n^ Kilby, Jack (2000), Nobel lecture (PDF), Stockholm: Nobel Foundation, retrieved 15 May 2008\\n\\n^ The Chip that Jack Built, (c. 2008), (HTML), Texas Instruments, Retrieved 29 May 2008.\\n\\n^ Jack S. Kilby, Miniaturized Electronic Circuits, United States Patent Office, US Patent 3,138,743, filed 6 February 1959, issued 23 June 1964.\\n\\n^ Winston, Brian (1998). Media Technology and Society: A History\\xa0: From the Telegraph to the Internet. Routledge. p.\\xa0221. ISBN\\xa0978-0-415-14230-4.\\n\\n^ Saxena, Arjun N. (2009). Invention of Integrated Circuits: Untold Important Facts. World Scientific. p.\\xa0140. ISBN\\xa09789812814456.\\n\\n^ a b \"Integrated circuits\". NASA. Retrieved 13 August 2019.\\n\\n^ Robert Noyce\\'s Unitary circuit, US patent 2981877, \"Semiconductor device-and-lead structure\", issued 1961-04-25,  assigned to Fairchild Semiconductor Corporation\\xa0\\n\\n^ \"1959: Practical Monolithic Integrated Circuit Concept Patented\". Computer History Museum. Retrieved 13 August 2019.\\n\\n^ Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. p.\\xa0120. ISBN\\xa09783540342588.\\n\\n^ Bassett, Ross Knox (2007). To the Digital Age: Research Labs, Start-up Companies, and the Rise of MOS Technology. Johns Hopkins University Press. p.\\xa046. ISBN\\xa09780801886393.\\n\\n^ Huff, Howard R.; Tsuya, H.; Gösele, U. (1998). Silicon Materials Science and Technology: Proceedings of the Eighth International Symposium on Silicon Materials Science and Technology. Electrochemical Society. pp.\\xa0181–182. ISBN\\xa09781566771931.\\n\\n^ Kuo, Yue (1 January 2013). \"Thin Film Transistor Technology—Past, Present, and Future\" (PDF). The Electrochemical Society Interface. 22 (1): 55–61. Bibcode:2013ECSIn..22a..55K. doi:10.1149/2.F06131if. ISSN\\xa01064-8208.\\n\\n^ a b \"Tortoise of Transistors Wins the Race - CHM Revolution\". Computer History Museum. Retrieved 22 July 2019.\\n\\n^ \"1964 – First Commercial MOS IC Introduced\". Computer History Museum.\\n\\n^ \"1968: Silicon Gate Technology Developed for ICs\". Computer History Museum. Retrieved 22 July 2019.\\n\\n^ Kuo, Yue (1 January 2013). \"Thin Film Transistor Technology—Past, Present, and Future\" (PDF). The Electrochemical Society Interface. 22 (1): 55–61. Bibcode:2013ECSIn..22a..55K. doi:10.1149/2.F06131if. ISSN\\xa01064-8208.\\n\\n^ a b \"1971: Microprocessor Integrates CPU Function onto a Single Chip\". Computer History Museum. Retrieved 22 July 2019.\\n\\n^ Colinge, Jean-Pierre; Greer, James C. (2016). Nanowire Transistors: Physics of Devices and Materials in One Dimension. Cambridge University Press. p.\\xa02. ISBN\\xa09781107052406.\\n\\n^ Intel\\'s First Microprocessor—the Intel 4004, Intel Corp., November 1971, archived from the original on 13 May 2008, retrieved 17 May 2008\\n\\n^ Patterson, David; Hennessy, John (1998). Computer Organization and Design. San Francisco: Morgan Kaufmann. pp.\\xa027–39. ISBN\\xa0978-1-55860-428-5.\\n\\n^ Federico Faggin, The Making of the First Microprocessor, IEEE Solid-State Circuits Magazine, Winter 2009, IEEE Xplore\\n\\n^ a b \"7 dazzling smartphone improvements with Qualcomm\\'s Snapdragon 835 chip\". 3 January 2017.\\n\\n^ Chartier, David (23 December 2008). \"Global notebook shipments finally overtake desktops\". Ars Technica.\\n\\n^ IDC (25 July 2013). \"Growth Accelerates in the Worldwide Mobile Phone and Smartphone Markets in the Second Quarter, According to IDC\". Archived from the original on 26 June 2014.\\n\\n^ David J. Eck (2000). The Most Complex Machine: A Survey of Computers and Computing. A K Peters, Ltd. p.\\xa054. ISBN\\xa0978-1-56881-128-4.\\n\\n^ Erricos John Kontoghiorghes (2006). Handbook of Parallel Computing and Statistics. CRC Press. p.\\xa045. ISBN\\xa0978-0-8247-4067-2.\\n\\n^ Verma & Mielke 1988.\\n\\n^ Donald Eadie (1968). Introduction to the Basic Computer. Prentice-Hall. p.\\xa012.\\n\\n^ Arpad Barna; Dan I. Porat (1976). Introduction to Microcomputers and the Microprocessors. Wiley. p.\\xa085. ISBN\\xa0978-0-471-05051-3.\\n\\n^ Jerry Peek; Grace Todino; John Strang (2002). Learning the UNIX Operating System: A Concise Guide for the New User. O\\'Reilly. p.\\xa0130. ISBN\\xa0978-0-596-00261-9.\\n\\n^ Gillian M. Davis (2002). Noise Reduction in Speech Applications. CRC Press. p.\\xa0111. ISBN\\xa0978-0-8493-0949-6.\\n\\n^ TOP500 2006, p.\\xa0[page\\xa0needed].\\n\\n^ \"Why do computers crash?\". Scientific American. Retrieved 3 March 2022.\\n\\n^ Taylor, Alexander L., III (16 April 1984). \"The Wizard Inside the Machine\". Time. Archived from the original on 16 March 2007. Retrieved 17 February 2007.\\n\\n^ Agatha C. Hughes (2000). Systems, Experts, and Computers. MIT Press. p.\\xa0161. ISBN\\xa0978-0-262-08285-3. The experience of SAGE helped make possible the first truly large-scale commercial real-time network: the SABRE computerized airline reservations system\\n\\n^ Leiner, Barry M.; Cerf, Vinton G.; Clark, David D.; Kahn, Robert E.; Kleinrock, Leonard; Lynch, Daniel C.; Postel, Jon; Roberts, Larry G.; Wolf, Stephen (1999). \"A Brief History of the Internet\". arXiv:cs/9901011.\\n\\n^ \"Definition of computer\". Thefreedictionary.com. Retrieved 29 January 2012.\\n\\n^ II, Joseph D. Dumas (2005). Computer Architecture: Fundamentals and Principles of Computer Design. CRC Press. p.\\xa0340. ISBN\\xa09780849327490.\\n\\n\\nSources\\n\\nEvans, Claire L. (2018). Broad Band: The Untold Story of the Women Who Made the Internet. New York: Portfolio/Penguin. ISBN\\xa09780735211759.\\nFuegi, J.; Francis, J. (2003). \"Lovelace & Babbage and the creation of the 1843 \\'notes\\'\". IEEE Annals of the History of Computing. 25 (4): 16. doi:10.1109/MAHC.2003.1253887. S2CID\\xa040077111.\\nKempf, Karl (1961). Historical Monograph: Electronic Computers Within the Ordnance Corps. Aberdeen Proving Ground (United States Army).\\nPhillips, Tony (2000). \"The Antikythera Mechanism I\". American Mathematical Society. Retrieved 5 April 2006.\\nShannon, Claude Elwood (1940). A symbolic analysis of relay and switching circuits (Thesis). Massachusetts Institute of Technology. hdl:1721.1/11173.\\nDigital Equipment Corporation (1972). PDP-11/40 Processor Handbook (PDF). Maynard, MA: Digital Equipment Corporation.\\nSwade, Doron D. (February 1993). \"Redeeming Charles Babbage\\'s Mechanical Computer\". Scientific American. 268 (2): 86–91. Bibcode:1993SciAm.268b..86S. doi:10.1038/scientificamerican0293-86. JSTOR\\xa024941379.\\nMeuer, Hans; Strohmaier, Erich; Simon, Horst; Dongarra, Jack (13 November 2006). \"Architectures Share Over Time\". TOP500. Archived from the original on 20 February 2007. Retrieved 27 November 2006.\\nLavington, Simon (1998). A History of Manchester Computers (2nd\\xa0ed.). Swindon: The British Computer Society. ISBN\\xa0978-0-902505-01-8.\\nLight, Jennifer S. (1999). \"When Computers Were Women\". Technology and Culture. 40 (3): 455–483. doi:10.1353/tech.1999.0128. JSTOR\\xa025147356. S2CID\\xa0108407884.\\nSchmandt-Besserat, Denise (1999). \"Tokens: The Cognitive Significance\". Documenta Praehistorica. XXVI. Archived from the original on 30 January 2012.\\nSchmandt-Besserat, Denise (1981). \"Decipherment of the earliest tablets\". Science. 211 (4479): 283–285. Bibcode:1981Sci...211..283S. doi:10.1126/science.211.4479.283. PMID\\xa017748027.\\nStokes, Jon (2007). Inside the Machine: An Illustrated Introduction to Microprocessors and Computer Architecture. San Francisco: No Starch Press. ISBN\\xa0978-1-59327-104-6.\\nZuse, Konrad (1993). The Computer – My life. Berlin: Pringler-Verlag. ISBN\\xa0978-0-387-56453-1.\\nFelt, Dorr E. (1916). Mechanical arithmetic, or The history of the counting machine. Chicago: Washington Institute.\\nIfrah, Georges (2001). The Universal History of Computing: From the Abacus to the Quantum Computer. New York: John Wiley & Sons. ISBN\\xa0978-0-471-39671-0.\\nBerkeley, Edmund (1949). Giant Brains, or Machines That Think. John Wiley & Sons.\\nCohen, Bernard (2000). \"Howard Aiken, Portrait of a computer pioneer\". Physics Today. Cambridge, Massachusetts: The MIT Press. 53 (3): 74–75. Bibcode:2000PhT....53c..74C. doi:10.1063/1.883007. ISBN\\xa0978-0-262-53179-5.\\nLigonnière, Robert (1987). Préhistoire et Histoire des ordinateurs. Paris: Robert Laffont. ISBN\\xa0978-2-221-05261-7.\\nCouffignal, Louis (1933). Les machines à calculer; leurs principes, leur évolution. Paris: Gauthier-Villars.\\nEssinger, James (2004). Jacquard\\'s Web, How a hand loom led to the birth of the information age. Oxford University Press. ISBN\\xa0978-0-19-280577-5.\\nHyman, Anthony (1985). Charles Babbage: Pioneer of the Computer. Princeton University Press. ISBN\\xa0978-0-691-02377-9.\\nBowden, B. V. (1953). Faster than thought. New York, Toronto, London: Pitman publishing corporation.\\nMoseley, Maboth (1964). Irascible Genius, Charles Babbage, inventor. London: Hutchinson.\\nCollier, Bruce (1970). The little engine that could\\'ve: The calculating machines of Charles Babbage. Garland Publishing. ISBN\\xa0978-0-8240-0043-1.\\nRandell, Brian (1982). \"From Analytical Engine to Electronic Digital Computer: The Contributions of Ludgate, Torres, and Bush\" (PDF). Archived from the original (PDF) on 21 September 2013. Retrieved 29 October 2013.\\nSmith, Erika E. (2013). \"Recognizing a Collective Inheritance through the History of Women in Computing\". CLCWeb: Comparative Literature and Culture. 15 (1): 1–9. doi:10.7771/1481-4374.1972.\\nVerma, G.; Mielke, N. (1988). Reliability performance of ETOX based flash memories. IEEE International Reliability Physics Symposium.\\n\\nExternal links\\n Media related to Computers at Wikimedia Commons\\n Wikiversity has a quiz on this article\\nWarhol & The Computer\\n\\n\\nvteBasic computer componentsInput devicesPointing devices\\nGraphics tablet\\nGame controller\\nLight pen\\nMouse\\nOptical\\nOptical trackpad\\nPointing stick\\nTouchpad\\nTouchscreen\\nTrackball\\nOther\\nKeyboard\\nImage scanner\\nGraphics card\\nGPU\\nMicrophone\\nRefreshable braille display\\nSound card\\nSound chip\\nWebcam\\nSoftcam\\nOutput devices\\nMonitor\\nScreen\\nRefreshable braille display\\nPrinter\\nPlotter\\nSpeakers\\nSound card\\nGraphics card\\nRemovable  data storage\\nDisk pack\\nFloppy disk\\nOptical disc\\nCD\\nDVD\\nBlu-ray\\nFlash memory\\nMemory card\\nUSB flash drive\\nComputer case\\nCentral processing unit\\nMicroprocessor\\nMotherboard\\nMemory\\nRAM\\nBIOS\\nData storage\\nHDD\\nSSD (SATA / NVMe)\\nSSHD\\nPower supply\\nSMPS\\nMOSFET\\nPower MOSFET\\nVRM\\nNetwork interface controller\\nFax modem\\nExpansion card\\nPortsCurrent\\nEthernet\\nUSB\\nThunderbolt\\nAnalog audio jack\\nDisplayPort\\nHDMI\\nObsolete\\nFireWire (IEEE 1394)\\nParallel port\\nSerial port\\nPS/2 port\\neSATA\\nDVI\\nVGA\\n\\nvteDigital electronicsComponents\\nTransistor\\nResistor\\nInductor\\nCapacitor\\nPrinted electronics\\nPrinted circuit board\\nElectronic circuit\\nFlip-flop\\nMemory cell\\nCombinational logic\\nSequential logic\\nLogic gate\\nBoolean circuit\\nIntegrated circuit (IC)\\nHybrid integrated circuit (HIC)\\nMixed-signal integrated circuit\\nThree-dimensional integrated circuit (3D IC)\\nEmitter-coupled logic (ECL)\\nErasable programmable logic device (EPLD)\\nMacrocell array\\nProgrammable logic array (PLA)\\nProgrammable logic device (PLD)\\nProgrammable Array Logic (PAL)\\nGeneric array logic (GAL)\\nComplex programmable logic device (CPLD)\\nField-programmable gate array (FPGA)\\nField-programmable object array (FPOA)\\nApplication-specific integrated circuit (ASIC)\\nTensor Processing Unit (TPU)\\nTheory\\nDigital signal\\nBoolean algebra\\nLogic synthesis\\nLogic in computer science\\nComputer architecture\\nDigital signal\\nDigital signal processing\\nCircuit minimization\\nSwitching circuit theory\\nGate equivalent\\nDesign\\nLogic synthesis\\nPlace and route\\nPlacement\\nRouting\\nRegister-transfer level\\nHardware description language\\nHigh-level synthesis\\nFormal equivalence checking\\nSynchronous logic\\nAsynchronous logic\\nFinite-state machine\\nHierarchical state machine\\nApplications\\nComputer hardware\\nHardware acceleration\\nDigital audio\\nradio\\nDigital photography\\nDigital telephone\\nDigital video\\ncinematography\\ntelevision\\nElectronic literature\\nDesign issues\\nMetastability\\nRunt pulse\\n\\nvteElectronicsBranches\\nAnalog electronics\\nDigital electronics\\nElectronic instrumentation\\nElectronics engineering\\nMicroelectronics\\nOptoelectronics\\nPower electronics\\nPrinted electronics\\nSemiconductor\\nSchematic capture\\nThermal management\\nAdvanced topics\\nAtomtronics\\nBioelectronics\\nFailure of electronic components\\nFlexible electronics\\nLow-power electronics\\nMolecular electronics\\nNanoelectronics\\nOrganic electronics\\nPhotonics\\nPiezotronics\\nQuantum electronics\\nSpintronics\\nElectronic equipment\\nAir conditioner\\nCentral heating\\nClothes dryer\\nComputer/Notebook\\nCamera\\nDishwasher\\nFreezer\\nHome robot\\nHome cinema\\nHome theater PC\\nInformation technologies\\nCooker\\nMicrowave oven\\nMobile phone\\nNetworking hardware\\nPortable media player\\nRadio\\nRefrigerator\\nRobotic vacuum cleaner\\nTablet\\nTelephone\\nTelevision\\nWater heater\\nVideo game console\\nWashing machine\\nApplications\\nAudio electronics\\nAutomotive electronics\\nAvionics\\nControl system\\nData acquisition\\ne-book\\ne-health\\nElectronics industry\\nElectronic warfare\\nEmbedded system\\nHome appliance\\nHome automation\\nIntegrated circuit\\nHome appliance\\nConsumer electronics\\nMajor appliance\\nSmall appliance\\nMicrowave technology\\nMilitary electronics\\nMultimedia\\nNuclear electronics\\nOpen hardware\\nRadar and Radionavigation\\nRadio electronics\\nTerahertz technology\\nVideo hardware\\nWired and Wireless Communications\\n\\nAuthority control National libraries\\nSpain\\nFrance (data)\\nGermany\\nIsrael\\nUnited States\\nJapan\\nOther\\nFaceted Application of Subject Terminology\\nNational Archives (US)\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Computer&oldid=1084472285\"',\n",
       "  'Family of computer operating systems developed by Microsoft\\n\"Windows\" redirects here. For the part of a building, see Window. For other uses, see Windows (disambiguation).\\n\\n\\nMicrosoft WindowsDeveloperMicrosoftSource modelClosed-sourceSource-available (through Shared Source Initiative)Initial releaseNovember\\xa020, 1985; 36 years ago\\xa0(1985-11-20)Latest release21H2 (10.0.22000.613) (April\\xa012, 2022; 12 days ago\\xa0(2022-04-12)[1]) [±]Latest preview10.0.22598.200 (April\\xa019, 2022; 5 days ago\\xa0(2022-04-19)[2]) [±]Marketing targetPersonal computingAvailable in138 languages[3]Update methodWindows UpdateMicrosoft StoreWindows Server Update Services (WSUS)Package managerWindows Installer (.msi, .msix, .msp), Microsoft Store (.appx, .appxbundle),[4] Windows Package ManagerPlatformsIA-32, x86-64, ARM, ARM64 Previously: 16-bit x86, DEC Alpha, MIPS, PowerPC, ItaniumKernel type\\nWindows NT family: Hybrid\\nWindows CE: Hybrid\\nWindows 9x and earlier: Monolithic (MS-DOS)\\nDefaultuser interfaceWindows shellLicenseProprietary commercial softwareOfficial websitemicrosoft.com/windows\\nMicrosoft Windows, commonly referred to as Windows, is a group of several proprietary graphical operating system families, all of which are developed and marketed by Microsoft. Each family caters to a certain sector of the computing industry. Active Microsoft Windows families include Windows NT and Windows IoT; these may encompass subfamilies, (e.g. Windows Server or Windows Embedded Compact) (Windows CE). Defunct Microsoft Windows families include Windows 9x, Windows Mobile and Windows Phone.\\nMicrosoft introduced an operating environment named Windows on November 20, 1985, as a graphical operating system shell for MS-DOS in response to the growing interest in graphical user interfaces (GUIs).[5] Microsoft Windows came to dominate the world\\'s personal computer (PC) market with over 90% market share, overtaking Mac OS, which had been introduced in 1984.\\nApple came to see Windows as an unfair encroachment on their innovation in GUI development as implemented on products such as the Lisa and Macintosh (eventually settled in court in Microsoft\\'s favor in 1993).  On PCs, Windows is still the most popular operating system in all countries.[6][7] However, in 2014, Microsoft admitted losing the majority of the overall operating system market to Android,[8] because of the massive growth in sales of Android smartphones. In 2014, the number of Windows devices sold was less than 25% that of Android devices sold. This comparison, however, may not be fully relevant, as the two operating systems traditionally target different platforms. Still, numbers for server use of Windows (that are comparable to competitors) show one third market share, similar to that for end user use. \\nAs of October\\xa02021[update], the most recent version of Windows for PCs and tablets is Windows 11, version 21H2. The most recent version for embedded devices is Windows 10, version 21H1. The most recent version for server computers is Windows Server 2022, version 21H2.[9] A specialized version of Windows also runs on the Xbox One and Xbox Series X/S video game consoles.[10]\\n\\nContents\\n\\n1 Genealogy\\n\\n1.1 By marketing role\\n\\n\\n2 Version history\\n\\n2.1 Early versions\\n2.2 Windows 3.x\\n2.3 Windows 9x\\n2.4 Windows NT\\n\\n2.4.1 Version history\\n\\n2.4.1.1 Early versions (Windows NT 3.1/3.5/3.51/4.0/2000)\\n2.4.1.2 Windows XP\\n2.4.1.3 Windows Vista\\n2.4.1.4 Windows 7\\n2.4.1.5 Windows 8 and 8.1\\n2.4.1.6 Windows 10\\n2.4.1.7 Windows 11\\n\\n\\n2.4.2 Windows 365\\n2.4.3 Multilingual support\\n2.4.4 Platform support\\n\\n\\n2.5 Windows CE\\n2.6 Xbox OS\\n\\n\\n3 Version control system\\n\\n3.1 VFSForGit\\n\\n\\n4 Timeline of releases\\n5 Usage share and device sales\\n6 Security\\n\\n6.1 File permissions\\n\\n\\n7 Alternative implementations\\n8 See also\\n9 References\\n10 External links\\n\\n\\nGenealogy\\nBy marketing role\\nMicrosoft, the developer of Windows, has registered several trademarks, each of which denotes a family of Windows operating systems that target a specific sector of the computing industry. As of 2014, the following Windows families were being actively developed:\\n\\nWindows NT: Started as a family of operating systems with Windows NT 3.1, an operating system for server computers and workstations. It now consists of three operating system subfamilies that are released almost at the same time and share the same kernel:\\nWindows: The operating system for mainstream personal computers and tablets. The latest version is Windows 11. The main competitor of this family is macOS by Apple for personal computers and iPadOS and Android for tablets (c.f. Usage share of operating systems §\\xa0Market share by category).\\nWindows Server: The operating system for server computers. The latest version is Windows Server 2022. Unlike its client sibling, it has adopted a strong naming scheme. The main competitor of this family is Linux. (c.f. Usage share of operating systems §\\xa0Market share by category)\\nWindows PE: A lightweight version of its Windows sibling, meant to operate as a live operating system, used for installing Windows on bare-metal computers (especially on many computers at once), recovery or troubleshooting purposes. The latest version is Windows PE 10.\\nWindows IoT (previously Windows Embedded): Initially, Microsoft developed Windows CE as a general-purpose operating system for every device that was too resource-limited to be called a full-fledged computer. Eventually, however, Windows CE was renamed Windows Embedded Compact and was folded under Windows Compact trademark which also consists of Windows Embedded Industry, Windows Embedded Professional, Windows Embedded Standard, Windows Embedded Handheld and Windows Embedded Automotive.[11]\\nThe following Windows families are no longer being developed:\\n\\nWindows 9x: An operating system that targeted the consumer market. Discontinued because of suboptimal performance.[citation needed] (PC World called its last version, Windows Me, one of the worst products of all time.[12]) Microsoft now caters to the consumer market with Windows NT.\\nWindows Mobile: The predecessor to Windows Phone, it was a mobile phone operating system. The first version was called Pocket PC 2000; the third version, Windows Mobile 2003 is the first version to adopt the Windows Mobile trademark. The last version is Windows Mobile 6.5.\\nWindows Phone: An operating system sold only to manufacturers of smartphones. The first version was Windows Phone 7, followed by Windows Phone 8, and Windows Phone 8.1. It was succeeded by Windows 10 Mobile, that is now also discontinued.\\nVersion history\\nMain article: History of Microsoft Windows\\nSee also: List of Microsoft Windows versions\\nThe term Windows collectively describes any or all of several generations of Microsoft operating system products. These products are generally categorized as follows:\\n\\nEarly versions\\nMain articles: Windows 1.0, Windows 2.0, and Windows 2.1x\\n Windows 1.0, the first version, released in 1985\\nThe history of Windows dates back to 1981 when Microsoft started work on a program called \"Interface Manager\". It was announced in November 1983 (after the Apple Lisa, but before the Macintosh) under the name \"Windows\", but Windows 1.0 was not released until November 1985.[13] Windows 1.0 was to compete with Apple\\'s operating system, but achieved little popularity.  Windows 1.0 is not a complete operating system; rather, it extends MS-DOS. The shell of Windows 1.0 is a program known as the MS-DOS Executive. Components included Calculator, Calendar, Cardfile, Clipboard Viewer, Clock, Control Panel, Notepad, Paint, Reversi, Terminal and Write. Windows 1.0 does not allow overlapping windows. Instead all windows are tiled. Only modal dialog boxes may appear over other windows. Microsoft sold as included Windows Development libraries with the C development environment, which included numerous windows samples.[14]\\nWindows 2.0 was released in December 1987, and was more popular than its predecessor. It features several improvements to the user interface and memory management.[15] Windows 2.03 changed the OS from tiled windows to overlapping windows. The result of this change led to Apple Computer filing a suit against Microsoft alleging infringement on Apple\\'s copyrights.[16][17] Windows 2.0 also introduced more sophisticated keyboard shortcuts and could make use of expanded memory.\\nWindows 2.1 was released in two different versions: Windows/286 and Windows/386. Windows/386 uses the virtual 8086 mode of the Intel 80386 to multitask several DOS programs and the paged memory model to emulate expanded memory using available extended memory. Windows/286, in spite of its name, runs on both Intel 8086 and Intel 80286 processors. It runs in real mode but can make use of the high memory area.[citation needed]\\nIn addition to full Windows-packages, there were runtime-only versions that shipped with early Windows software from third parties and made it possible to run their Windows software on MS-DOS and without the full Windows feature set.\\nThe early versions of Windows are often thought of as graphical shells, mostly because they ran on top of MS-DOS and use it for file system services.[18] However, even the earliest Windows versions already assumed many typical operating system functions; notably, having their own executable file format and providing their own device drivers (timer, graphics, printer, mouse, keyboard and sound). Unlike MS-DOS, Windows allowed users to execute multiple graphical applications at the same time, through cooperative multitasking. Windows implemented an elaborate, segment-based, software virtual memory scheme, which allows it to run applications larger than available memory: code segments and resources are swapped in and thrown away when memory became scarce; data segments moved in memory when a given application had relinquished processor control.\\n\\nWindows 3.x\\nMain articles: Windows 3.0 and Windows 3.1x\\n Windows 3.0, released in 1990\\nWindows 3.0, released in 1990, improved the design, mostly because of virtual memory and loadable virtual device drivers (VxDs) that allow Windows to share arbitrary devices between multi-tasked DOS applications.[citation needed] Windows 3.0 applications can run in protected mode, which gives them access to several megabytes of memory without the obligation to participate in the software virtual memory scheme. They run inside the same address space, where the segmented memory provides a degree of protection. Windows 3.0 also featured improvements to the user interface. Microsoft rewrote critical operations from C into assembly. Windows 3.0 is the first Microsoft Windows version to achieve broad commercial success, selling 2\\xa0million copies in the first six months.[19][20]\\nWindows 3.1, made generally available on March 1, 1992, featured a facelift. In August 1993, Windows for Workgroups, a special version with integrated peer-to-peer networking features and a version number of 3.11, was released. It was sold along with Windows 3.1. Support for Windows 3.1 ended on December 31, 2001.[21]\\nWindows 3.2, released 1994, is an updated version of the Chinese version of Windows 3.1.[22] The update was limited to this language version, as it fixed only issues related to the complex writing system of the Chinese language.[23] Windows 3.2 was generally sold by computer manufacturers with a ten-disk version of MS-DOS that also had Simplified Chinese characters in basic output and some translated utilities.\\n\\nWindows 9x\\nMain articles: Windows 9x, Windows 95, Windows 98, and Windows Me\\nThe next major consumer-oriented release of Windows, Windows 95, was released on August 24, 1995. While still remaining MS-DOS-based, Windows 95 introduced support for native 32-bit applications, plug and play hardware, preemptive multitasking, long file names of up to 255 characters, and provided increased stability over its predecessors. Windows 95 also introduced a redesigned, object oriented user interface, replacing the previous Program Manager with the Start menu, taskbar, and Windows Explorer shell. Windows 95 was a major commercial success for Microsoft; Ina Fried of CNET remarked that \"by the time Windows 95 was finally ushered off the market in 2001, it had become a fixture on computer desktops around the world.\"[24] Microsoft published four OEM Service Releases (OSR) of Windows 95, each of which was roughly equivalent to a service pack. The first OSR of Windows 95 was also the first version of Windows to be bundled with Microsoft\\'s web browser, Internet Explorer.[25] Mainstream support for Windows 95 ended on December 31, 2000, and extended support for Windows 95 ended on December 31, 2001.[26]\\nWindows 95 was followed up with the release of Windows 98 on June 25, 1998, which introduced the Windows Driver Model, support for USB composite devices, support for ACPI, hibernation, and support for multi-monitor configurations. Windows 98 also included integration with Internet Explorer 4 through Active Desktop and other aspects of the Windows Desktop Update (a series of enhancements to the Explorer shell which were also made available for Windows 95). In May 1999, Microsoft released Windows 98 Second Edition, an updated version of Windows 98. Windows 98 SE added Internet Explorer 5.0 and Windows Media Player 6.2 amongst other upgrades. Mainstream support for Windows 98 ended on June 30, 2002, and extended support for Windows 98 ended on July 11, 2006.[27]\\nOn September 14, 2000, Microsoft released Windows Me (Millennium Edition), the last DOS-based version of Windows. Windows Me incorporated visual interface enhancements from its Windows NT-based counterpart Windows 2000, had faster boot times than previous versions (which however, required the removal of the ability to access a real mode DOS environment, removing compatibility with some older programs),[28] expanded multimedia functionality (including Windows Media Player 7, Windows Movie Maker, and the Windows Image Acquisition framework for retrieving images from scanners and digital cameras), additional system utilities such as System File Protection and System Restore, and updated home networking tools.[29] However, Windows Me was faced with criticism for its speed and instability, along with hardware compatibility issues and its removal of real mode DOS support. PC World considered Windows Me to be one of the worst operating systems Microsoft had ever released, and the 4th worst tech product of all time.[12]\\n\\nWindows NT\\nMain article: Windows NT\\nVersion history\\nEarly versions (Windows NT 3.1/3.5/3.51/4.0/2000)\\nMain articles: Windows NT 3.1, Windows NT 3.5, Windows NT 3.51, Windows NT 4.0, and Windows 2000\\nIn November 1988, a new development team within Microsoft (which included former Digital Equipment Corporation developers Dave Cutler and Mark Lucovsky) began work on a revamped version of IBM and Microsoft\\'s OS/2 operating system known as \"NT OS/2\". NT OS/2 was intended to be a secure, multi-user operating system with POSIX compatibility and a modular, portable kernel with preemptive multitasking and support for multiple processor architectures. However, following the successful release of Windows 3.0, the NT development team decided to rework the project to use an extended 32-bit port of the Windows API known as Win32 instead of those of OS/2. Win32 maintained a similar structure to the Windows APIs (allowing existing Windows applications to easily be ported to the platform), but also supported the capabilities of the existing NT kernel. Following its approval by Microsoft\\'s staff, development continued on what was now Windows NT, the first 32-bit version of Windows. However, IBM objected to the changes, and ultimately continued OS/2 development on its own.[30][31]\\nWindows NT was the first Windows operating system based on a hybrid kernel. The hybrid kernel was designed as a modified microkernel, influenced by the Mach microkernel developed by Richard Rashid at Carnegie Mellon University, but without meeting all of the criteria of a pure microkernel.\\nThe first release of the resulting operating system, Windows NT 3.1 (named to associate it with Windows 3.1) was released in July 1993, with versions for desktop workstations and servers. Windows NT 3.5 was released in September 1994, focusing on performance improvements and support for Novell\\'s NetWare, and was followed up by Windows NT 3.51 in May 1995, which included additional improvements and support for the PowerPC architecture. Windows NT 4.0 was released in June 1996, introducing the redesigned interface of Windows 95 to the NT series. On February 17, 2000, Microsoft released Windows 2000, a successor to NT 4.0. The Windows NT name was dropped at this point in order to put a greater focus on the Windows brand.[31]\\n\\nWindows XP\\nMain article: Windows XP\\nThe next major version of Windows NT, Windows XP, was released on October 25, 2001. The introduction of Windows XP aimed to unify the consumer-oriented Windows 9x series with the architecture introduced by Windows NT, a change which Microsoft promised would provide better performance over its DOS-based predecessors. Windows XP would also introduce a redesigned user interface (including an updated Start menu and a \"task-oriented\" Windows Explorer), streamlined multimedia and networking features, Internet Explorer 6, integration with Microsoft\\'s .NET Passport services, a \"compatibility mode\" to help provide backwards compatibility with software designed for previous versions of Windows, and Remote Assistance functionality.[32][33]\\nAt retail, Windows XP was now marketed in two main editions: the \"Home\" edition was targeted towards consumers, while the \"Professional\" edition was targeted towards business environments and power users, and included additional security and networking features. Home and Professional were later accompanied by the \"Media Center\" edition (designed for home theater PCs, with an emphasis on support for DVD playback, TV tuner cards, DVR functionality, and remote controls), and the \"Tablet PC\" edition (designed for mobile devices meeting its specifications for a tablet computer, with support for stylus pen input and additional pen-enabled applications).[34][35][36] Mainstream support for Windows XP ended on April 14, 2009. Extended support ended on April 8, 2014.[37]\\nAfter Windows 2000, Microsoft also changed its release schedules for server operating systems; the server counterpart of Windows XP, Windows Server 2003, was released in April 2003.[31] It was followed in December 2005, by Windows Server 2003 R2.\\n\\nWindows Vista\\nMain article: Windows Vista\\nAfter a lengthy development process, Windows Vista was released on November 30, 2006, for volume licensing and January 30, 2007, for consumers. It contained a number of new features, from a redesigned shell and user interface to significant technical changes, with a particular focus on security features. It was available in a number of different editions, and has been subject to some criticism, such as drop of performance, longer boot time, criticism of new UAC, and stricter license agreement. Vista\\'s server counterpart, Windows Server 2008 was released in early 2008.\\n\\nWindows 7\\nMain article: Windows 7\\nOn July 22, 2009, Windows 7 and Windows Server 2008 R2 were released as RTM (release to manufacturing) while the former was released to the public 3 months later on October 22, 2009. Unlike its predecessor, Windows Vista, which introduced a large number of new features, Windows 7 was intended to be a more focused, incremental upgrade to the Windows line, with the goal of being compatible with applications and hardware with which Windows Vista was already compatible.[38] Windows 7 has multi-touch support, a redesigned Windows shell with an updated taskbar with revealable jump lists that contain shortcuts to files frequently used with specific applications and shortcuts to tasks within the application,[39] a home networking system called HomeGroup,[40] and performance improvements.\\n\\nWindows 8 and 8.1\\nMain articles: Windows 8 and Windows 8.1\\n Previous Windows logo (2012–2021)\\nWindows 8, the successor to Windows 7, was released generally on October 26, 2012. A number of significant changes were made on Windows 8, including the introduction of a user interface based around Microsoft\\'s Metro design language with optimizations for touch-based devices such as tablets and all-in-one PCs. These changes include the Start screen, which uses large tiles that are more convenient for touch interactions and allow for the display of continually updated information, and a new class of apps which are designed primarily for use on touch-based devices. The new Windows version required a minimum resolution of 1024×768 pixels,[41] effectively making it unfit for netbooks with 800×600-pixel screens.\\nOther changes include increased integration with cloud services and other online platforms (such as social networks and Microsoft\\'s own OneDrive (formerly SkyDrive) and Xbox Live services), the Windows Store service for software distribution, and a new variant known as Windows RT for use on devices that utilize the ARM architecture, and a new keyboard shortcut for screenshots.[42][43][44][45][46][47][48] An update to Windows 8, called Windows 8.1,[49] was released on October 17, 2013, and includes features such as new live tile sizes, deeper OneDrive integration, and many other revisions. Windows 8 and Windows 8.1 have been subject to some criticism, such as removal of the Start menu.\\n\\nWindows 10\\nMain article: Windows 10\\nOn September 30, 2014, Microsoft announced Windows 10 as the successor to Windows 8.1. It was released on July 29, 2015, and addresses shortcomings in the user interface first introduced with Windows 8. Changes on PC include the return of the Start Menu, a virtual desktop system, and the ability to run Windows Store apps within windows on the desktop rather than in full-screen mode. Windows 10 is said to be available to update from qualified Windows 7 with SP1, Windows 8.1 and Windows Phone 8.1 devices from the Get Windows 10 Application (for Windows 7, Windows 8.1) or Windows Update (Windows 7).[50]\\nIn February 2017, Microsoft announced the migration of its Windows source code repository from Perforce to Git. This migration involved 3.5 million separate files in a 300 gigabyte repository.[51] By May 2017, 90 percent of its engineering team was using Git, in about 8500 commits and 1760 Windows builds per day.[51]\\nIn June 2021, shortly before Microsoft\\'s announcement of Windows 11, Microsoft updated their lifecycle policy pages for Windows 10, revealing that support for their last release of Windows 10 will be October 14, 2025.[52][53]\\n\\nWindows 11\\nMain article: Windows 11\\nOn June 24, 2021, Windows 11 was announced as the successor to Windows 10 during a livestream. The new operating system was designed to be more user-friendly and understandable. It was released on October 5, 2021.[54][55] Windows 11 is a free upgrade to some Windows 10 users as of now.\\n\\nWindows 365\\nSee also: Azure Virtual Desktop\\nIn July 2021, Microsoft announced it will start selling subscriptions to virtualized Windows desktops as part of a new Windows 365 service in the following month. It is not a standalone version of Microsoft Windows, but a web service that provides access to Windows 10 and Windows 11 built on top of Azure Virtual Desktop. The new service will allow for cross-platform usage, aiming to make the operating system available for both Apple and Android users. The subscription service will be accessible through any operating system with a web browser. The new service is an attempt at capitalizing on the growing trend, fostered during the COVID-19 pandemic, for businesses to adopt a hybrid remote work environment, in which \"employees split their time between the office and home\". As the service will be accessible through web-browsers, Microsoft will be able to bypass the need to publish the service through Google Play or the Apple App Store.[56][57][58][59][60]\\nMicrosoft announced Windows 365 availability to business and enterprise customers on August 2, 2021.[61]\\n\\nMultilingual support\\nMultilingual support has been built into Windows since Windows 3.0. The language for both the keyboard and the interface can be changed through the Region and Language Control Panel. Components for all supported input languages, such as Input Method Editors, are automatically installed during Windows installation (in Windows XP and earlier, files for East Asian languages, such as Chinese, and right-to-left scripts, such as Arabic, may need to be installed separately, also from the said Control Panel). Third-party IMEs may also be installed if a user feels that the provided one is insufficient for their needs.\\nInterface languages for the operating system are free for download, but some languages are limited to certain editions of Windows. Language Interface Packs (LIPs) are redistributable and may be downloaded from Microsoft\\'s Download Center and installed for any edition of Windows (XP or later)\\xa0–  they translate most, but not all, of the Windows interface, and require a certain base language (the language which Windows originally shipped with). This is used for most languages in emerging markets. Full Language Packs, which translates the complete operating system, are only available for specific editions of Windows (Ultimate and Enterprise editions of Windows Vista and 7, and all editions of Windows 8, 8.1 and RT except Single Language). They do not require a specific base language, and are commonly used for more popular languages such as French or Chinese. These languages cannot be downloaded through the Download Center, but available as optional updates through the Windows Update service (except Windows 8).\\nThe interface language of installed applications is not affected by changes in the Windows interface language. The availability of languages depends on the application developers themselves.\\nWindows 8 and Windows Server 2012 introduces a new Language Control Panel where both the interface and input languages can be simultaneously changed, and language packs, regardless of type, can be downloaded from a central location. The PC Settings app in Windows 8.1 and Windows Server 2012 R2 also includes a counterpart settings page for this. Changing the interface language also changes the language of preinstalled Windows Store apps (such as Mail, Maps and News) and certain other Microsoft-developed apps (such as Remote Desktop). The above limitations for language packs are however still in effect, except that full language packs can be installed for any edition except Single Language, which caters to emerging markets.\\n\\nPlatform support\\nWindows NT included support for several platforms before the x86-based personal computer became dominant in the professional world. Windows NT 4.0 and its predecessors supported PowerPC, DEC Alpha and MIPS R4000 (although some of the platforms implement 64-bit computing, the OS treated them as 32-bit). Windows 2000 dropped support for all platforms, except the third generation x86 (known as IA-32) or newer in 32-bit mode. The client line of Windows NT family still runs on IA-32 but the Windows Server line ceased supporting this platform with the release of Windows Server 2008 R2.\\nWith the introduction of the Intel Itanium architecture (IA-64), Microsoft released new versions of Windows to support it. Itanium versions of Windows XP and Windows Server 2003 were released at the same time as their mainstream x86 counterparts. Windows XP 64-Bit Edition, released in 2005, is the last Windows client operating systems to support Itanium. Windows Server line continues to support this platform until Windows Server 2012; Windows Server 2008 R2 is the last Windows operating system to support Itanium architecture.\\nOn April 25, 2005, Microsoft released Windows XP Professional x64 Edition and Windows Server 2003 x64 Editions to support x86-64 (or simply x64), the 64-bit version of x86 architecture. Windows Vista was the first client version of Windows NT to be released simultaneously in IA-32 and x64 editions. x64 is still supported.\\nAn edition of Windows 8 known as Windows RT was specifically created for computers with ARM architecture and while ARM is still used for Windows smartphones with Windows 10, tablets with Windows RT will not be updated. Starting from Windows 10 Fall Creators Update (version 1709) and later includes support for PCs with ARM architecture.[62]\\nWindows 11 is the first version to drop support for 32-bit hardware.[63]\\n\\nWindows CE\\nMain articles: Windows CE and Windows Phone\\n Windows Embedded Compact 7 displaying a concept media player UI\\nWindows CE (officially known as Windows Embedded Compact), is an edition of Windows that runs on minimalistic computers, like satellite navigation systems and some mobile phones. Windows Embedded Compact is based on its own dedicated kernel, dubbed Windows CE kernel. Microsoft licenses Windows CE to OEMs and device makers. The OEMs and device makers can modify and create their own user interfaces and experiences, while Windows CE provides the technical foundation to do so.\\nWindows CE was used in the Dreamcast along with Sega\\'s own proprietary OS for the console. Windows CE was the core from which Windows Mobile was derived. Its successor, Windows Phone 7, was based on components from both Windows CE 6.0 R3 and Windows CE 7.0. Windows Phone 8 however, is based on the same NT-kernel as Windows 8.\\nWindows Embedded Compact is not to be confused with Windows XP Embedded or Windows NT 4.0 Embedded, modular editions of Windows based on Windows NT kernel.\\n\\nXbox OS\\nMain article: Xbox system software\\nXbox OS is an unofficial name given to the version of Windows that runs on Xbox consoles.[64] From Xbox One onwards it is an implementation with an emphasis on virtualization (using Hyper-V) as it is three operating systems running at once, consisting of the core operating system, a second implemented for games and a more Windows-like environment for applications.[65]\\nMicrosoft updates Xbox One\\'s OS every month, and these updates can be downloaded from the Xbox Live service to the Xbox and subsequently installed, or by using offline recovery images downloaded via a PC.[66] It was originally based on NT 6.2 (Windows 8) kernel, and the latest version runs on an NT 10.0 base. This system is sometimes referred to as \"Windows 10 on Xbox One\" or \"OneCore\".[67][68]\\nXbox One and Xbox Series operating systems also allow limited (due to licensing restrictions and testing resources) backward compatibility with previous generation hardware,[69] and the Xbox 360\\'s system is backwards compatible with the original Xbox.[70]\\n\\nVersion control system\\nUp to and including every version before Windows 2000, Microsoft used an in-house version control system named Source Library Manager (SLM). Shortly after Windows 2000 was released, Microsoft switched to a fork of Perforce named Source Depot.[71]\\n</ref> This system was used up until 2017 once the system couldn\\'t keep up with the size of Windows. Microsoft had begun to integrate Git into Team Foundation Server in 2013, but Windows continued to rely on Source Depot.[citation needed] The Windows code was divided among 65 different repositories with a kind of virtualization layer to produce unified view of all of the code.\\nIn 2017 Microsoft announced that it would start using Git, an open source version control system created by Linus Torvalds and in May 2017 they reported that has completed migration into the Git repository.[72][73][51]\\n\\nVFSForGit\\nBecause of its large, decades-long history, however, the Windows codebase is not especially well suited to the decentralized nature of Linux development that Git was originally created to manage.[citation needed] Each Git repository contains a complete history of all the files, which proved unworkable for Windows developers because cloning the whole repository takes several hours.[citation needed] Microsoft has been working on a new project called the Virtual File System for Git (VFSForGit) to address these challenges.[73]\\nIn 2021 the VFS for Git has been superseded by Scalar.[74]\\n\\nTimeline of releases\\nTable of Windows versions\\nLegend:Old versionOlder version, still maintainedLatest versionLatest preview versionFuture release\\n\\n\\nProduct name\\n\\nLatest version\\n\\nGeneral availability date\\n\\nCodename\\n\\nSupport until[75]\\n\\nLatest version of\\n\\n\\nMainstream\\n\\nExtended\\n\\nIE\\n\\nDirectX\\n\\nEdge\\n\\n\\nOld version, no longer maintained: Windows 1.0\\n\\n1.01\\n\\nNovember 20, 1985\\n\\nInterface Manager\\n\\nDecember 31, 2001\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\n\\nOld version, no longer maintained: Windows 2.0\\n\\n2.03\\n\\nDecember 9, 1987\\n\\nN/A\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows 2.1\\n\\n2.11\\n\\nMay 27, 1988\\n\\nN/A\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows 3.0\\n\\n3.0\\n\\nMay 22, 1990\\n\\nN/A\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows 3.1\\n\\n3.1\\n\\nApril 6, 1992\\n\\nJanus\\n\\nDecember 31, 2001\\n\\n5\\n\\n\\nOld version, no longer maintained: Windows For Workgroups 3.1\\n\\n3.1\\n\\nOctober 1992\\n\\nSparta, Winball\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows NT 3.1\\n\\nNT 3.1.528\\n\\nJuly 27, 1993\\n\\nN/A\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows For Workgroups 3.11\\n\\n3.11\\n\\nAugust 11, 1993\\n\\nSparta, Winball\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows 3.2\\n\\n3.2\\n\\nNovember 22, 1993\\n\\nN/A\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows NT 3.5\\n\\nNT 3.5.807\\n\\nSeptember 21, 1994\\n\\nDaytona\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows NT 3.51\\n\\nNT 3.51.1057\\n\\nMay 30, 1995\\n\\nN/A\\n\\nDecember 31, 2001\\n\\n\\nOld version, no longer maintained: Windows 95\\n\\n4.0.950\\n\\nAugust 24, 1995\\n\\nChicago, 4.0\\n\\nDecember 31, 2000\\n\\nDecember 31, 2001\\n\\n5.5\\n\\n6.1\\n\\n\\nOld version, no longer maintained: Windows NT 4.0\\n\\nNT 4.0.1381\\n\\nJuly 31, 1996\\n\\nCairo\\n\\nJune 30, 2002\\n\\nJune 30, 2004\\n\\n6\\n\\nN/A\\n\\n\\nOld version, no longer maintained: Windows 98\\n\\nOctober 4, 1998\\n\\nJune 25, 1998\\n\\nMemphis, 97, 4.1\\n\\nJune 30, 2002\\n\\nJuly 11, 2006\\n\\n6.1\\n\\n\\nOld version, no longer maintained: Windows 98 SE\\n\\n4.10.2222\\n\\nMay 5, 1999\\n\\nN/A\\n\\nJune 30, 2002\\n\\nJuly 11, 2006\\n\\n\\nOld version, no longer maintained: Windows 2000\\n\\nNT 5.0.2195\\n\\nFebruary 17, 2000\\n\\nN/A\\n\\nJune 30, 2005\\n\\nJuly 13, 2010\\n\\nN/A\\n\\n\\nOld version, no longer maintained: Windows Me\\n\\n4.90.3000\\n\\nSeptember 14, 2000\\n\\nMillennium, 4.9\\n\\nDecember 31, 2003\\n\\nJuly 11, 2006\\n\\n9.0c\\n\\n\\nOld version, no longer maintained: Windows XP\\n\\nNT 5.1.2600\\n\\nOctober 25, 2001\\n\\nWhistler\\n\\nApril 14, 2009\\n\\nApril 8, 2014\\n\\n8\\n\\n\\nOld version, no longer maintained: Windows XP 64-bit Edition\\n\\nNT 5.2.3790\\n\\nMarch 28, 2003\\n\\nN/A\\n\\nApril 14, 2009\\n\\nApril 8, 2014\\n\\n\\nOld version, no longer maintained: Windows Server 2003\\n\\nNT 5.2.3790\\n\\nApril 24, 2003\\n\\nN/A\\n\\nJuly 13, 2010\\n\\nJuly 14, 2015\\n\\n\\nOld version, no longer maintained: Windows XP Professional x64 Edition\\n\\nNT 5.2.3790\\n\\nApril 25, 2005\\n\\nN/A\\n\\nApril 14, 2009\\n\\nApril 8, 2014\\n\\n\\nOld version, no longer maintained: Windows Fundamentals for Legacy PCs\\n\\nNT 5.1.2600\\n\\nJuly 8, 2006\\n\\nEiger, Mönch\\n\\nApril 14, 2009\\n\\nApril 8, 2014\\n\\n\\nOld version, no longer maintained: Windows Vista\\n\\nNT 6.0.6003\\n\\nJanuary 30, 2007\\n\\nLonghorn\\n\\nApril 10, 2012\\n\\nApril 11, 2017\\n\\n9\\n\\n11\\n\\n\\nOld version, no longer maintained: Windows Home Server\\n\\nNT 5.2.4500\\n\\nNovember 4, 2007\\n\\nQuattro\\n\\nJanuary 8, 2013\\n\\n8\\n\\n9.0c\\n\\n\\nOld version, no longer maintained: Windows Server 2008\\n\\nNT 6.0.6003\\n\\nFebruary 27, 2008\\n\\nLonghorn Server\\n\\nJanuary 13, 2015\\n\\nJanuary 14, 2020\\n\\n9\\n\\n11\\n\\n\\nOld version, no longer maintained: Windows 7\\n\\nNT 6.1.7601\\n\\nOctober 22, 2009\\n\\nWindows 7[76]\\n\\nJanuary 13, 2015\\n\\nJanuary 14, 2020\\n\\n11\\n\\n92\\n\\n\\nOld version, no longer maintained: Windows Server 2008 R2\\n\\nNT 6.1.7601\\n\\nOctober 22, 2009\\n\\nN/A\\n\\nJanuary 13, 2015\\n\\nJanuary 14, 2020\\n\\n\\nOld version, no longer maintained: Windows Home Server 2011\\n\\nNT 6.1.8400\\n\\nApril 6, 2011\\n\\nVail\\n\\nApril 12, 2016\\n\\n9\\n\\n\\nOlder version, yet still maintained: Windows Server 2012\\n\\nNT 6.2.9200\\n\\nSeptember 4, 2012\\n\\nServer 8\\n\\nOctober 9, 2018\\n\\nOctober 10, 2023\\n\\n11\\n\\n11.1\\n\\n\\nOld version, no longer maintained: Windows 8\\n\\nNT 6.2.9200\\n\\nOctober 26, 2012\\n\\nN/A\\n\\nJanuary 12, 2016\\n\\n10\\n\\n\\nOlder version, yet still maintained: Windows 8.1\\n\\nNT 6.3.9600\\n\\nOctober 17, 2013\\n\\nBlue\\n\\nJanuary 9, 2018\\n\\nJanuary 10, 2023\\n\\n11\\n\\n11.2\\n\\n\\nOlder version, yet still maintained: Windows Server 2012 R2\\n\\nNT 6.3.9600\\n\\nOctober 18, 2013\\n\\nServer Blue\\n\\nOctober 9, 2018\\n\\nOctober 10, 2023\\n\\n\\nCurrent stable version: Windows 10\\n\\nNT 10.0.19044\\n\\nJuly 29, 2015\\n\\nVarious\\n\\nOctober 14, 2025[52][53]\\n\\n12\\n\\n\\nOlder version, yet still maintained: Windows Server 2016\\n\\nNT 10.0.14393\\n\\nOctober 12, 2016\\n\\nN/A\\n\\nJanuary 11, 2022\\n\\nJanuary 12, 2027\\n\\n\\nCurrent stable version: Windows Server 2019\\n\\nNT 10.0.17763\\n\\nOctober 2, 2018\\n\\nN/A\\n\\nJanuary 9, 2024\\n\\nJanuary 9, 2029\\n\\n\\nCurrent stable version: Windows Server 2022\\n\\nNT 10.0.20348\\n\\nAugust 18, 2021\\n\\nN/A\\n\\nOctober 13, 2026\\n\\nOctober 14, 2031\\n\\n\\nCurrent stable version: Windows 11\\n\\nNT 10.0.22000\\n\\nOctober 5, 2021\\n\\nN/A\\n\\nOctober 10, 2023\\n\\nOctober 8, 2024\\n\\nN/A\\n\\n\\nWindows timeline: Bar chart\\n\\n\\nviewtalkedit\\n\\n The Windows family tree\\nUsage share and device sales\\nMain article: Usage share of operating systems\\n\\nThis box:  viewtalkedit\\nVersion market share\\nAs a percentage of desktop and laptop systems using Windows,[77] according to StatCounter data from January 2022.[78]\\n\\n\\n\\nDesktop OS\\n\\nStatCounter\\n\\n\\nother versions\\n\\n0.21%\\n\\n\\nWindows XP\\n\\n0.49%\\n\\n\\nWindows 7\\n\\n11.92%\\n\\n\\nWindows 8\\n\\n0.69%\\n\\n\\nWindows 8.1\\n\\n2.93%\\n\\n\\nWindows 10\\n\\n81.15%\\n\\n\\nWindows 11\\n\\n2.6%\\n\\n\\n\\n\\nUse of the latest version Windows 10 has exceeded Windows 7 globally since early 2018.[79]\\nFor desktop and laptop computers, according to Net Applications and StatCounter, which track the use of operating systems in devices that are active on the Web, Windows was the most used operating-system family in August 2021, with around 91% usage share according to Net Applications[80] and around 76% usage share according to StatCounter.[81]\\nIncluding personal computers of all kinds (e.g., desktops, laptops, mobile devices, and game consoles), Windows OSes accounted for 32.67% of usage share in August 2021, compared to Android (highest, at 46.03%), iOS\\'s 13.76%, iPadOS\\'s 2.81%, and macOS\\'s 2.51%, according to Net Applications[82] and 30.73% of usage share in August 2021, compared to Android (highest, at 42.56%), iOS/iPadOS\\'s 16.53%, and macOS\\'s 6.51%, according to StatCounter.[83]\\nThose statistics do not include servers (including so-called cloud computing, where Microsoft is known not to be a leader, with Linux used more than Windows), as Net Applications and StatCounter use web browsing as a proxy for all use.\\n\\nSecurity\\nThis section needs to be updated. Please help update this article to reflect recent events or newly available information. (May 2020)\\nConsumer versions of Windows were originally designed for ease-of-use on a single-user PC without a network connection, and did not have security features built in from the outset.[84] However, Windows NT and its successors are designed for security (including on a network) and multi-user PCs, but were not initially designed with Internet security in mind as much, since, when it was first developed in the early 1990s, Internet use was less prevalent.[85]\\nThese design issues combined with programming errors (e.g. buffer overflows) and the popularity of Windows means that it is a frequent target of computer worm and virus writers. In June 2005, Bruce Schneier\\'s Counterpane Internet Security reported that it had seen over 1,000 new viruses and worms in the previous six months.[86] In 2005, Kaspersky Lab found around 11,000 malicious programs\\xa0–  viruses, Trojans, back-doors, and exploits written for Windows.[87]\\nMicrosoft releases security patches through its Windows Update service approximately once a month (usually the second Tuesday of the month), although critical updates are made available at shorter intervals when necessary.[88] In versions of Windows after and including Windows 2000 SP3 and Windows XP, updates can be automatically downloaded and installed if the user selects to do so. As a result, Service Pack 2 for Windows XP, as well as Service Pack 1 for Windows Server 2003, were installed by users more quickly than it otherwise might have been.[89]\\nWhile the Windows 9x series offered the option of having profiles for multiple users, they had no concept of access privileges, and did not allow concurrent access; and so were not true multi-user operating systems. In addition, they implemented only partial memory protection. They were accordingly widely criticised for lack of security.\\nThe Windows NT series of operating systems, by contrast, are true multi-user, and implement absolute memory protection. However, a lot of the advantages of being a true multi-user operating system were nullified by the fact that, prior to Windows Vista, the first user account created during the setup process was an administrator account, which was also the default for new accounts. Though Windows XP did have limited accounts, the majority of home users did not change to an account type with fewer rights\\xa0– partially due to the number of programs which unnecessarily required administrator rights\\xa0– and so most home users ran as administrator all the time.\\nWindows Vista changes this[90] by introducing a privilege elevation system called User Account Control. When logging in as a standard user, a logon session is created and a token containing only the most basic privileges is assigned. In this way, the new logon session is incapable of making changes that would affect the entire system. When logging in as a user in the Administrators group, two separate tokens are assigned. The first token contains all privileges typically awarded to an administrator, and the second is a restricted token similar to what a standard user would receive. User applications, including the Windows shell, are then started with the restricted token, resulting in a reduced privilege environment even under an Administrator account. When an application requests higher privileges or \"Run as administrator\" is clicked, UAC will prompt for confirmation and, if consent is given (including administrator credentials if the account requesting the elevation is not a member of the administrators group), start the process using the unrestricted token.[91]\\nLeaked documents published by WikiLeaks, codenamed Vault 7 and dated from 2013 to 2016, detail the capabilities of the CIA to perform electronic surveillance and cyber warfare,[92] such as the ability to compromise operating systems such as Microsoft Windows.[93]\\nIn August 2019, computer experts reported that the BlueKeep security vulnerability, CVE-2019-0708, that potentially affects older unpatched Microsoft Windows versions via the program\\'s Remote Desktop Protocol, allowing for the possibility of remote code execution, may now include related flaws, collectively named DejaBlue, affecting newer Windows versions (i.e., Windows 7 and all recent versions) as well.[94] In addition, experts reported a Microsoft security vulnerability, CVE-2019-1162, based on legacy code involving Microsoft CTF and ctfmon (ctfmon.exe), that affects all Windows versions from the older Windows XP version to the most recent Windows 10 versions; a patch to correct the flaw is currently available.[95]\\n\\nFile permissions\\nAll Windows versions from Windows NT 3 have been based on a file system permission system referred to as AGDLP (Accounts, Global, Domain Local, Permissions) in which file permissions are applied to the file/folder in the form of a \\'local group\\' which then has other \\'global groups\\' as members. These global groups then hold other groups or users depending on different Windows versions used. This system varies from other vendor products such as Linux and NetWare due to the \\'static\\' allocation of permission being applied directly to the file or folder. However using this process of AGLP/AGDLP/AGUDLP allows a small number of static permissions to be applied and allows for easy changes to the account groups without reapplying the file permissions on the files and folders.\\n\\nAlternative implementations\\nOwing to the operating system\\'s popularity, a number of applications have been released that aim to provide compatibility with Windows applications, either as a compatibility layer for another operating system, or as a standalone system that can run software written for Windows out of the box. These include:\\n\\nWine – a free and open-source implementation of the Windows API, allowing one to run many Windows applications on x86-based platforms, including UNIX, Linux and macOS. Wine developers refer to it as a \"compatibility layer\"[96] and use Windows-style APIs to emulate Windows environment.\\nCrossOver – a Wine package with licensed fonts. Its developers are regular contributors to Wine, and focus on Wine running officially supported applications.\\nCedega – a proprietary fork of Wine by TransGaming Technologies, designed specifically for running Microsoft Windows games on Linux. A version of Cedega known as Cider allows Windows games to run on macOS. Since Wine was licensed under the LGPL, Cedega has been unable to port the improvements made to Wine to their proprietary codebase. Cedega ceased its service in February 2011.\\nDarwine – a port of Wine for macOS and Darwin. Operates by running Wine on QEMU.\\nLinux Unified Kernel – a set of patches to the Linux kernel allowing many Windows executable files in Linux (using Wine DLLs); and some Windows drivers to be used.\\nReactOS – an open-source OS intended to run the same software as Windows, originally designed to simulate Windows NT 4.0, now aiming at Windows 7 compatibility. It has been in the development stage since 1996.\\nLinspire – formerly LindowsOS, a commercial Linux distribution initially created with the goal of running major Windows software. Changed its name to Linspire after Microsoft v. Lindows. Discontinued in favor of Xandros Desktop, that was also later discontinued.\\nFreedows OS\\xa0– an open-source attempt at creating a Windows clone for x86 platforms, intended to be released under the GNU General Public License. Started in 1996, by Reece K. Sellin, the project was never completed, getting only to the stage of design discussions which featured a number of novel concepts until it was suspended in 2002.[97][98][99]\\nSee also\\n\\nArchitecture of Windows NT\\nAzure Sphere, Microsoft\\'s Linux-based operating system\\nBlueKeep\\nDe facto standard\\nDominant design\\nWindows Subsystem for Linux, a subsystem in Windows 10, not using the Linux kernel; reimplementing\\nWintel\\n\\n\\nReferences\\n\\n\\n^ \"April 12, 2022—KB5012592 (OS Build 22000.613)\". Microsoft Support. Microsoft. April 12, 2022.\\n\\n^ \"Announcing Windows 11 Insider Preview Build 22598\". Windows Insider Blog. April 13, 2022.\\n\\n^ \"Listing of available Windows 7 language packs\". Msdn.microsoft.com. Archived from the original on August 2, 2012. Retrieved April 5, 2014.\\n\\n^ \"App packages and deployment (Windows Store apps) (Windows)\". Msdn.microsoft.com. Archived from the original on March 30, 2014. Retrieved April 5, 2014.\\n\\n^ \"The Unusual History of Microsoft Windows\". Retrieved April 22, 2007.\\n\\n^ \"Operating System Market Share Worldwide\". StatCounter Global Stats. Retrieved January 5, 2021.\\n\\n^ \"Desktop Operating System Market Share Worldwide\". StatCounter Global Stats. Retrieved January 5, 2021.\\n\\n^ Keizer, Gregg (July 14, 2014). \"Microsoft gets real, admits its device share is just 14%\". Computerworld. IDG. Archived from the original on August 21, 2016. [Microsoft\\'s chief operating officer] Turner\\'s 14% came from a new forecast released last week by Gartner, which estimated Windows\\' share of the shipped device market last year was 14%, and would decrease slightly to 13.7% in 2014. Android will dominate, Gartner said, with a 48% share this year\\n\\n^ \"Windows Server release information\". docs.microsoft.com. Retrieved July 26, 2021.\\n\\n^ \"Xbox One Architecture Finally Explained - Runs OS \\'Virtually Indistinguishable\\' from Windows 8\". WCCFtech. April 20, 2014. Archived from the original on September 6, 2015.\\n\\n^ \"RTOS: Embedded Real Time Operating Systems\". microsoft.com. Microsoft. Archived from the original on December 15, 2014. Retrieved November 7, 2014.\\n\\n^ a b \"The 25 Worst Tech Products of All Time\". PC World. IDG. May 26, 2006. Archived from the original on February 15, 2012. Retrieved February 10, 2012.\\n\\n^ A history of Windows (at microsoft.com)\\n\\n^ Microsoft C 5.0 C Language Reference Guide, Microsoft Doc410840001-500-R04-0887A, 10/1987 page 250-267\\n\\n^ \"A legacy of Windows, part 1: Windows 1-2-3 - TechRepublic\". TechRepublic. Archived from the original on March 27, 2017. Retrieved March 26, 2017.\\n\\n^ \"The Apple vs. Microsoft GUI Lawsuit\". 2006. Archived from the original on March 4, 2008. Retrieved March 12, 2008.\\n\\n^ \"Apple Computer, Inc. v. MicroSoft Corp., 35 F.3d 1435 (9th Cir. 1994)\". Archived from the original on December 14, 2007. Retrieved March 12, 2008.\\n\\n^ \"Windows Evolution\". Soft32.com News. Archived from the original on February 8, 2008.\\n\\n^ \"Chronology of Personal Computer Software\". Archived from the original on February 11, 2012.\\n\\n^ \"Microsoft Company\". Archived from the original on May 14, 2008.\\n\\n^ \"Windows 3.1 Standard Edition Support Lifecycle\". Archived from the original on January 12, 2012. Retrieved January 3, 2011.\\n\\n^ \"Microsoft Windows Simplified Chinese 3.2 Upgrade Is Available\". microsoft.com. Microsoft. Archived from the original on November 8, 2006.\\n\\n^ \"Microsoft Windows Simplified Chinese 3.2 Upgrade Is Available\". Microsoft. October 30, 2003. Archived from the original on May 24, 2011. Retrieved September 4, 2009.\\n\\n^ \"Windows 95 turns 15: Has Microsoft\\'s OS peaked?\". CNET/CNN Tech. August 25, 2010. Archived from the original on August 26, 2010. Retrieved August 22, 2012.\\n\\n^ \"Microsoft Internet Explorer Web Browser Available on All Major Platforms, Offers Broadest International Support\". News Center. San Jose, California: Microsoft. April 30, 1996. Archived from the original on January 15, 2008. Retrieved February 14, 2011.\\n\\n^ \"Windows 95 Support Lifecycle\". Microsoft. Archived from the original on November 22, 2012. Retrieved January 3, 2011.\\n\\n^ \"Windows 98 Standard Edition Support Lifecycle\". Microsoft. Archived from the original on November 22, 2012. Retrieved January 3, 2011.\\n\\n^ \"Improving \"Cold Boot\" Time for System Manufacturers\". Microsoft. December 4, 2001. Archived from the original on February 13, 2010. Retrieved August 26, 2010.\\n\\n^ \"Windows Millennium Edition: All About Me\". PC World. Archived from the original on August 1, 2013. Retrieved May 21, 2013.\\n\\n^ Custer, Helen (1993). Inside Windows NT. Redmond: Microsoft Press. ISBN\\xa01-55615-481-X.\\n\\n^ a b c Thurrott, Paul (January 24, 2003). \"Windows Server 2003: The Road To Gold - Part One: The Early Years\". Archived from the original on January 1, 2005. Retrieved May 28, 2012.\\n\\n^ \"Windows XP review\". CNET. Archived from the original on May 26, 2013. Retrieved May 24, 2013.\\n\\n^ \"Windows XP Program Compatibility Wizard\". ServerWatch. March 12, 2002. Retrieved November 13, 2021.\\n\\n^ David Coursey (October 25, 2001). \"The 10 top things you MUST know about Win XP\". ZDNet. Archived from the original on April 3, 2009. Retrieved July 22, 2008.\\n\\n^ David Coursey (August 31, 2001). \"Your top Windows XP questions answered! (Part One)\". ZDNet. CNET Networks. Archived from the original on December 19, 2007. Retrieved January 3, 2011.\\n\\n^ \"A Look at Freestyle and Mira\". Paul Thurrott\\'s SuperSite for Windows. Penton. September 3, 2002. Retrieved January 3, 2011.[permanent dead link]\\n\\n^ \"Windows XP Professional Lifecycle Support\". Archived from the original on February 27, 2013. Retrieved January 3, 2011.\\n\\n^ Nash, Mike (October 28, 2008). \"Windows 7 Unveiled Today at PDC 2008\". Windows Experience Blog. Microsoft. Archived from the original on November 1, 2008. Retrieved November 11, 2008.\\n\\n^ Kiriaty, Yochay; Goldshtein, Sasha (2009). \"Windows 7 Taskbar APIs\". docs.microsoft.com. Retrieved August 21, 2021.\\n\\n^ LeBlanc, Brandon (October 28, 2008). \"How Libraries & HomeGroup Work Together in Windows 7\". Windows Experience Blog. Microsoft. Archived from the original on November 2, 2008. Retrieved November 11, 2008.\\n\\n^ \"New Windows 8 hardware specs hint at 7-inch tablets and a Microsoft Reader\". ZDNet. Retrieved March 29, 2013.\\n\\n^ Paul, Ian (July 5, 2021). \"How to Take Screenshots in Windows 10, 8, and 7\".\\n\\n^ Case, Loyd. \"Test Driving Windows 8 RTM\". PC World. IDG. Archived from the original on September 4, 2012. Retrieved September 9, 2012.\\n\\n^ Rosoff, Matt. \"Here\\'s Everything You Wanted To Know About Microsoft\\'s Upcoming iPad Killers\". Business Insider. Archived from the original on January 22, 2013. Retrieved February 10, 2012.\\n\\n^ \"Announcing the Windows 8 Editions\". Microsoft. April 16, 2012. Archived from the original on April 18, 2012. Retrieved April 17, 2012.\\n\\n^ \"Building Windows for the ARM processor architecture\". Microsoft. Archived from the original on November 26, 2012. Retrieved November 21, 2012.\\n\\n^ \"Microsoft talks Windows Store features, Metro app sandboxing for Windows 8 developers\". The Verge. Vox Media. May 17, 2012. Archived from the original on September 10, 2012. Retrieved September 8, 2012.\\n\\n^ Miller, Michael. \"Build: More Details On Building Windows 8 Metro Apps\". PC Magazine. Archived from the original on February 17, 2012. Retrieved February 10, 2012.\\n\\n^ Windows 8.1 now available! Archived October 19, 2013, at the Wayback Machine. Blogs.windows.com. Retrieved on October 31, 2013.\\n\\n^ \"Announcing Windows 10 - Windows Blog\". September 30, 2014. Archived from the original on September 10, 2015. Retrieved September 30, 2014.\\n\\n^ a b c Bright, Peter (May 24, 2017). \"Windows switch to Git almost complete: 8,500 commits and 1,760 builds each day\". Ars Technica. Condé Nast. Archived from the original on May 24, 2017.\\n\\n^ a b \"Window 10 Home and Pro Lifecycle\". Microsoft. Retrieved July 2, 2021.\\n\\n^ a b \"Window 10 Enterprise and Education Lifecycle\". Microsoft. Retrieved July 2, 2021.\\n\\n^ Cox, George. \"Windows 11 release date is October 5\". The Spectrum. Retrieved September 18, 2021.\\n\\n^ Warren, Tom (June 24, 2021). \"Microsoft announces Windows 11, with a new design, Start menu, and more\". The Verge. Retrieved June 24, 2021.\\n\\n^ Foley, Mary Jo (July 14, 2021). \"Microsoft brings Windows to the cloud with Windows 365 and Cloud PC\". ZDNet. Retrieved July 14, 2021.\\n\\n^ Tilley, Aaron (July 14, 2021). \"Microsoft Aims to Put Windows in Hands of Apple, Android Users Through Hybrid Work\". The Wall Street Journal. ISSN\\xa00099-9660.\\n\\n^ Higgins, Tim (June 23, 2021). \"Apple\\'s Fight for Control Over Apps Moves to Congress and EU\". The Wall Street Journal. ISSN\\xa00099-9660.\\n\\n^ \"Microsoft unveils Windows 365, a Windows 10 PC in the cloud\". Engadget. Retrieved July 15, 2021.\\n\\n^ \"Windows 365 Cloud PC | Microsoft\". www.microsoft.com. Retrieved July 15, 2021.\\n\\n^ Hill, Paul (August 2, 2021). \"Microsoft announces the general availability of Windows 365\". Neowin. Retrieved August 2, 2021.\\n\\n^ Bott, Ed (October 7, 2019). \"Windows 10 on Arm: What you need to know before you buy a Surface Pro X\". ZDNet.\\n\\n^ \"Windows 11 Specs and System Requirements | Microsoft\". Windows. Retrieved October 6, 2021.\\n\\n^ Anand Lal Shimpi. \"The Xbox One - Mini Review & Comparison to Xbox 360/PS4\". anandtech.com. Archived from the original on October 12, 2014. Retrieved October 21, 2014.\\n\\n^ \"Xbox One: Hardware and software specs detailed and analyzed - Three operating systems in one\". ExtremeTech. Archived from the original on November 16, 2013. Retrieved December 1, 2013.\\n\\n^ \"How to use the Offline System Update Diagnostic Tool on Xbox One\". Xbox Official Site. Microsoft. Archived from the original on April 27, 2021. Retrieved November 30, 2013.\\n\\n^ \"Xbox One Is \"Literally a Windows Device\"\". GameSpot. Archived from the original on December 27, 2015.\\n\\n^ \"New Xbox One Update Will Make Some Functionality 50 Percent Faster\". GameSpot. Archived from the original on February 2, 2016.\\n\\n^ Tom Warren (June 16, 2015). \"Xbox One dashboard update includes a huge new design and Cortana\". The Verge. Vox Media. Archived from the original on July 8, 2017.\\n\\n^ Eric Qualls. \"Xbox 360 and Xbox Games Backwards Compatibility\". About.com Tech. Archived from the original on September 28, 2015.\\n\\n^ Chen, Raymond (January 22, 2018). \"The history of change-packing tools at Microsoft (so far)\". The Old New Thing. Retrieved April 17, 2022.{{cite web}}:  CS1 maint: url-status (link)\\n\\n^ \"The largest Git repo on the planet\". Brian Harry\\'s Blog. May 24, 2017. Retrieved October 8, 2021.\\n\\n^ a b Bright, Peter (February 6, 2017). \"Microsoft hosts the Windows source in a monstrous 300GB Git repository\". Ars Technica. Archived from the original on December 26, 2017. Retrieved December 26, 2017.\\n\\n^ \"Frequently Asked Questions | VFS for Git\". GitHub. Microsoft. Archived from the original on July 7, 2021. Retrieved July 7, 2021. We transitioned our large repository strategy to focus on using git sparse-checkout instead of filesystem virtualization. We then forked the VFS for Git codebase to create Scalar.\\n\\n^ \"Microsoft Support Lifecycle\". Microsoft. Archived from the original on October 11, 2008.\\n\\n^ Chen, Raymond (July 22, 2019). \"What was the code name for Windows 7?\". The Old New Thing.\\n\\n^ \"Frequently Asked Questions\". StatCounter. \"Are laptops included in the desktop platform?\".\\n\\n^ \"Desktop Windows Version Market Share Worldwide\". StatCounter.\\n\\n^ \"Desktop Windows Version Market Share Worldwide | StatCounter Global Stats\". StatCounter Global Stats. Retrieved November 24, 2019.\\n\\n^ \"Desktop Operating system market share: August 2021\". Net Applications.\\n\\n^ \"Desktop Operating System Market Share Worldwide: August 2021\". StatCounter.\\n\\n^ \"Operating system market share: August 2021\". Net Applications.\\n\\n^ \"Operating System Market Share Worldwide: August 2021\". StatCounter.\\n\\n^ Multi-user memory protection was not introduced until Windows NT and XP, and a computer\\'s default user was an administrator until Windows Vista. Source: UACBlog Archived April 28, 2006, at the Wayback Machine.\\n\\n^ \"Telephones and Internet Users by Country, 1990 and 2005\". Information Please Database. Archived from the original on May 22, 2009. Retrieved June 9, 2009.\\n\\n^ Bruce Schneier (June 15, 2005). \"Crypto-Gram Newsletter\". Counterpane Internet Security, Inc. Archived from the original on June 6, 2007. Retrieved April 22, 2007.\\n\\n^ Andy Patrizio (April 27, 2006). \"Linux Malware On The Rise\". InternetNews. QuinStreet. Archived from the original on February 5, 2012. Retrieved January 3, 2011.\\n\\n^ Ryan Naraine (June 8, 2005). \"Microsoft\\'s Security Response Center: How Little Patches Are Made\". eWeek. Ziff Davis Enterprise. Retrieved January 3, 2011.\\n\\n^ John Foley (October 20, 2004). \"Windows XP SP2 Distribution Surpasses 100 Million\". InformationWeek. UBM TechWeb. Archived from the original on May 27, 2010. Retrieved January 3, 2011.\\n\\n^ Northrup, Tony (June 1, 2005). \"Windows Vista Security and Data Protection Improvements\". TechNet. Microsoft Docs. Retrieved October 20, 2021. In Windows Vista, the User Account Control (UAC) initiative introduces fundamental operating system changes to enhance the experience for the non-administrative user.\\n\\n^ Kenny Kerr (September 29, 2006). \"Windows Vista for Developers\\xa0– Part 4\\xa0– User Account Control\". Archived from the original on March 29, 2007. Retrieved March 15, 2007.\\n\\n^ Greenberg, Andy (March 7, 2017). \"How the CIA Can Hack Your Phone, PC, and TV (Says WikiLeaks)\". WIRED.\\n\\n^ \"Vault 7: Wikileaks reveals details of CIA\\'s hacks of Android, iPhone Windows, Linux, MacOS, and even Samsung TVs\". Computing. March 7, 2017.\\n\\n^ Greenberg, Andy (August 13, 2019). \"DejaBlue: New BlueKeep-Style Bugs Renew The Risk Of A Windows worm\". wired. Retrieved August 15, 2019.\\n\\n^ Seals, Tara (August 14, 2019). \"20-Year-Old Bug in Legacy Microsoft Code Plagues All Windows Users\". ThreatPost.com. Retrieved August 15, 2019.\\n\\n^ \"Wine\". Winehq.org. Archived from the original on April 4, 2014. Retrieved April 5, 2014.\\n\\n^ \"A Student\\'s Dream of Creating A New Operating System Encounters Problems\". The Chronicle of Higher Education. September 18, 1998. Archived from the original on May 12, 2013. Retrieved May 17, 2013.\\n\\n^ \"Older blog entries for chipx86\". Advogato.org. Advogato. June 27, 2002. Archived from the original on May 20, 2013. Retrieved May 17, 2013.\\n\\n^ \"Freedows splits\". Slashdot. Dice Holdings. August 31, 1998. Archived from the original on November 4, 2013. Retrieved May 17, 2013.\\n\\n\\nExternal links\\nMicrosoft Windowsat Wikipedia\\'s sister projectsMedia from CommonsTextbooks from WikibooksResources from Wikiversity\\nOfficial website\\nOfficial Windows Blog\\nMicrosoft Developer Network\\nWindows Developer Center\\nMicrosoft Windows History Timeline\\nPearson Education, InformIT\\xa0– History of Microsoft Windows\\nMicrosoft Business Software Solutions\\nWindows 10 release Information\\nvteMicrosoft Windows\\nComponents\\nHistory\\nTimeline\\nCriticism\\nDOS-based\\nWindows 1.0x\\nWindows 2.0x\\nWindows 2.1x\\nWindows 3.0\\nWindows 3.1x\\nWindows 9x\\nWindows 95\\nWindows 98\\nWindows Me\\nWindows NT\\nNT 3.1\\nNT 3.5\\nNT 3.51\\nNT 4.0\\n2000\\nXP\\nPro x64\\nMedia Center\\nFundamentals for Legacy PCs\\nVista\\n7\\n8, 8.1\\nWindows RT\\n10\\n11\\nWindows Server\\nServer 2003\\nHome Server\\nServer 2008\\nEBS 2008\\nHPC Server 2008\\nServer 2008 R2\\nHome Server 2011\\nServer 2012\\nServer 2012 R2\\nServer 2016\\nServer 2019\\nServer 2022\\nMultiPoint Server\\nServer Essentials\\nSpecialized\\nWindows Preinstallation Environment\\nWindows IoT\\nWindows 365\\nWindows IoT\\nEmbedded Compact\\nCE 5.0\\nEmbedded CE 6.0\\nEmbedded Compact 7\\nEmbedded Automotive\\nEmbedded Industry\\nWindows Mobile\\nPocket PC 2000\\nPocket PC 2002\\nMobile 2003\\nMobile 5.0\\nMobile 6.0\\nMobile 6.1\\nMobile 6.5\\nWindows Phone\\nPhone 7\\nPhone 8\\nPhone 8.1\\n10 Mobile\\nCancelled\\nCairo\\nNashville\\nNeptune\\nOdyssey\\nRelated\\nDevelopment\\n95\\nXP\\nVista\\n10\\n11\\nEditions\\nXP\\nVista\\n7\\n8\\n10\\nNew features\\nXP\\nVista\\n7\\n8\\n10\\n11\\nRemoved features\\nXP\\nVista\\n7\\n8\\n10\\n11\\nVersion history\\nPhone\\n10\\n10 Mobile\\n11\\nCriticism\\nXP\\nVista\\n10\\nVista vs. XP\\n\\n List of versions\\n Comparison\\n Category\\n\\nvteOperating systems by MicrosoftDesktop / Server\\nMicrosoft Windows\\n3.0\\n3.1x\\n9x\\nNT\\nTen\\nMS-DOS\\nMSX-DOS\\nMultitasking MS-DOS 4.0/4.1\\nMS-DOS 7\\nDOS/V\\nZ-DOS\\nOS/2\\nXenix\\nMobile\\nNokia Asha platform\\nNokia X platform\\nKIN OS\\nWindows Mobile\\nWindows Phone\\nZune\\nWindows 10 Mobile\\nEmbedded / IoT\\nAzure RTOS ThreadX\\nAzure Sphere\\nWindows Embedded Automotive\\nWindows Embedded Compact\\nWindows Embedded Industry\\nWindows IoT\\nNetwork\\nMS-Net\\nLAN Manager\\nSONiC\\nOthers\\nBarrelfish\\nBigtop\\nCairo\\nCBL-Mariner\\nHomeOS\\nMidori\\nSingularity\\nVenus\\nVerve\\nXbox system software\\n\\n List\\n Category\\n\\nvteMicrosoft\\nHistory\\nOutline\\nPeopleFounders\\nBill Gates\\nPaul Allen\\nBoard of directors\\nJohn W. Thompson (Chairman)\\nSatya Nadella (CEO)\\nCharles Noski\\nHelmut Panke\\nJohn W. Stanton\\nReid Hoffman\\nSandi Peterson\\nPenny Pritzker\\nCharles Scharf\\nArne Sorenson\\nPadmasree Warrior\\nSenior leadership team\\nSatya Nadella (CEO)\\nScott Guthrie\\nAmy Hood (CFO)\\nBrad Smith (CLO)\\nHarry Shum\\nPhil Spencer\\nKathleen Hogan (CPO)\\nCorporate VPs\\nJoe Belfiore\\nRichard Rashid (SVP)\\nCésar Cernuda\\nPanos Panay (CVP)\\nProductsHardware\\nAzure Kinect\\nHoloLens\\nLifeCam\\nLifeChat\\nSurface\\nHub\\nGo\\nLaptop\\nLaptop Go\\nPro\\nStudio\\nDuo\\nNeo\\nXbox\\nSoftware\\nMicrosoft 365\\nDynamics\\nOpen source software\\nOffice\\nPower Platform\\nServers\\nVisual Studio\\nVisual Studio Code\\nWindows\\nXbox OS\\nProgramming languages\\nBASIC\\nVB.NET\\nVBA\\nVBScript\\nVisual Basic\\nC#\\nC/AL a.k.a Navision Attain\\nF#\\nMVPL\\nPower Fx\\nPowerShell\\nTransact-SQL\\nTypeScript\\nQ#\\nVisual J#\\nVisual J++\\nWeb properties\\nAzure\\nBing\\nDocs\\nChannel 9\\nDeveloper Network\\nTechNet\\nGitHub\\nLinkedIn\\nLinkedIn Learning\\nMSN\\nOutlook.com\\nStore\\nTranslator\\nCompanyConferences\\nBuild\\nIgnite\\nInspire\\nMIX\\nPDC\\nWinHEC\\nDivisions\\nEngineering groups\\nMobile\\nSkype unit\\nDigital Crimes Unit\\nGarage\\nPress\\nResearch\\n.NET Foundation\\nOutercurve Foundation\\nXbox Game Studios\\nEstates\\nMicrosoft Redmond campus\\nMicrosoft Egypt\\nMicrosoft India\\nMicrosoft Japan\\nMicrosoft Theater\\nCampaigns\\nWhere do you want to go today? (1994)\\nChampagne (2002)\\nMojave Experiment (2006)\\nI\\'m a PC (2008)\\nScroogled (2012)\\nCriticism\\nBundling of Microsoft Windows\\nClippy\\niLoo\\nInternet Explorer\\nMicrosoft Bob\\n_NSAKEY\\nWindows\\nXP\\nVista\\n10\\nLitigation\\nAlcatel-Lucent v. Microsoft\\nApple v. Microsoft\\nEuropean Union Microsoft competition case\\nMicrosoft v. Lindows\\nMicrosoft v. MikeRoweSoft\\nMicrosoft v. Shah\\nUnited States v. Microsoft (2001 antitrust case)\\nMicrosoft Ireland case\\nAcquisitions\\n6Wunderkinder\\nAccess Software\\nAcompli\\nAltamira Software\\nAltspaceVR\\naQuantive\\nAzyxxi\\nThe Blue Ribbon SoundWorks\\nBeam\\nBungie\\nCalista Technologies\\nColloquis\\nCompulsion Games\\nConnectix\\nConsumers Software\\nDanger\\nDouble Fine Productions\\nFarecast\\nFASA Studio\\nFast Search & Transfer\\nFirefly\\nForethought\\nGIANT Company Software\\nGitHub\\nGreenButton\\nGroove Networks\\nHigh Heat Major League Baseball\\nHotmail\\ninXile Entertainment\\nJellyfish.com\\nLinkedIn\\nLinkExchange\\nLionhead Studios\\nMaluuba\\nMassive Incorporated\\nMetaswitch\\nMobile Data Labs\\nMojang Studios\\nNinja Theory\\nNokia Devices and Services\\nnpm\\nNuance Communications\\nObsidian Entertainment\\nOnfolio\\nPando Networks\\nPerceptive Pixel\\nPlayground Games\\nPlaceWare\\nPowerset\\nPress Play\\nProClarity\\nRare\\nRevolution Analytics\\nRiskIQ\\nScreenTonic\\nSecure Islands\\nSimplygon\\nSkype\\nSunrise Atelier\\nSwiftKey\\nWinternals Software\\nTeleo\\nTelekinesys Research\\nTellme Networks\\nTwisted Pixel Games\\nUndead Labs\\nVermeer Technologies\\nVisio Corporation\\nVivaty\\nVoloMetrix\\nVXtreme\\nWebTV Networks\\nXamarin\\nYammer\\nYupi\\nZeniMax Media\\n\\n Category\\n\\nvteMicrosoft Windows componentsManagementtools\\nApp Installer\\nCommand Prompt\\nControl Panel\\nApplets\\nDevice Manager\\nDisk Cleanup\\nDisk Defragmenter\\nDriver Verifier\\nDxDiag\\nEvent Viewer\\nIExpress\\nManagement Console\\nNetsh\\nPerformance Monitor\\nRecovery Console\\nResource Monitor\\nSettings\\nSysprep\\nSystem Configuration\\nSystem File Checker\\nSystem Information\\nSystem Policy Editor\\nSystem Restore\\nTask Manager\\nWindows Error Reporting\\nWindows Ink\\nWindows Installer\\nPowerShell\\nWindows Update\\nWindows Insider\\nWinRE\\nWMI\\nApps\\n3D Viewer\\nAlarms & Clock\\nCalculator\\nCalendar\\nCamera\\nCharacter Map\\nCortana\\nEdge\\nFax and Scan\\nFeedback Hub\\nGet Help\\nMagnifier\\nMail\\nMaps\\nMessaging\\nMedia Player\\nWindows 11\\nMovies & TV\\nMobility Center\\nMoney\\nNews\\nNarrator\\nNotepad\\nOneDrive\\nOneNote\\nPaint\\nPaint 3D\\nPeople\\nPhone Link\\nPhotos\\nQuick Assist\\nSnipping Tool\\nSpeech Recognition\\nSkype\\nSports\\nSticky Notes\\nStore\\nTips\\nVoice Recorder\\nWeather\\nWordPad\\nXbox Console Companion\\nShell\\nAction Center\\nAero\\nAutoPlay\\nAutoRun\\nClearType\\nExplorer\\nSearch\\nIndexing Service\\nIFilter\\nSaved search\\nNamespace\\nSpecial folder\\nStart menu\\nTaskbar\\nTask View\\nWindows Spotlight\\nWindows XP visual styles\\nServices\\nService Control Manager\\nBITS\\nCLFS\\nMultimedia Class Scheduler\\nShadow Copy\\nTask Scheduler\\nError Reporting\\nWireless Zero Configuration\\nFile systems\\nCDFS\\nDFS\\nexFAT\\nIFS\\nFAT\\nNTFS\\nHard link\\nlinks\\nMount Point\\nReparse point\\nTxF\\nEFS\\nReFS\\nUDF\\nServer\\nDomains\\nActive Directory\\nDNS\\nGroup Policy\\nRoaming user profiles\\nFolder redirection\\nDistributed Transaction Coordinator\\nMSMQ\\nWindows Media Services\\nActive DRM Services\\nIIS\\nWSUS\\nSharePoint\\nNetwork Access Protection\\nPWS\\nDFS Replication\\nPrint Services for UNIX\\nRemote Desktop Services\\nRemote Differential Compression\\nRemote Installation Services\\nWindows Deployment Services\\nSystem Resource Manager\\nHyper-V\\nServer Core\\nArchitecture\\nArchitecture of Windows NT\\nStartup process\\nNT\\nNT 6\\nCSRSS\\nDesktop Window Manager\\nPortable Executable\\nEXE\\nDLL\\nEnhanced Write Filter\\nGraphics Device Interface\\nhal.dll\\nI/O request packet\\nImaging Format\\nKernel Transaction Manager\\nLibrary files\\nLogical Disk Manager\\nLSASS\\nMinWin\\nNTLDR\\nNtoskrnl.exe\\nObject Manager\\nOpen XML Paper Specification\\nRegistry\\nResource Protection\\nSecurity Account Manager\\nServer Message Block\\nShadow Copy\\nSMSS\\nSystem Idle Process\\nUSER\\nWHEA\\nWin32 console\\nWinlogon\\nWinUSB\\nSecurity\\nSecurity and Maintenance\\nAppLocker\\nBitLocker\\nCredential Guard\\nData Execution Prevention\\nFamily Safety\\nKernel Patch Protection\\nMandatory Integrity Control\\nProtected Media Path\\nUser Account Control\\nUser Interface Privilege Isolation\\nWindows Defender\\nWindows Firewall\\nCompatibility\\nCOMMAND.COM\\nWoW64\\nWindows Subsystem for Linux\\nAPI\\nActive Scripting\\nWSH\\nVBScript\\nJScript\\nCOM\\nActiveX\\nActiveX Document\\nCOM Structured storage\\nDCOM\\nOLE\\nOLE Automation\\nTransaction Server\\nDirectX\\n.NET\\nUniversal Windows Platform\\nWindows Mixed Reality\\nWindows Runtime\\nWinUSB\\nGames\\nSolitaire Collection\\nSurf\\nDiscontinuedGames\\n3D Pinball\\nChess Titans\\nFreeCell\\nHearts\\nInkBall\\nHold \\'Em\\nPurble Place\\nSpider Solitaire\\nSolitaire\\nTinker\\nApps\\nActiveMovie\\nAnytime Upgrade\\nAddress Book\\nBackup and Restore\\nCardfile\\nCardSpace\\nCD Player\\nChat\\nContacts\\nDesktop Gadgets\\nDiagnostics\\nDriveSpace\\nDVD Maker\\nEasy Transfer\\nFax\\nFood & Drink\\nGroove Music\\nHelp and Support Center\\nHealth & Fitness\\nHyperTerminal\\nImaging\\nInternet Explorer\\nJournal\\nMedia Center\\nMeeting Space\\nMessaging\\nMessenger\\nMobile Device Center\\nMovie Maker\\nMSN Dial-up\\nNetMeeting\\nNTBackup\\nOutlook Express\\nPhone Companion\\nPhoto Gallery\\nPhoto Viewer\\nProgram Manager\\nSteps Recorder\\nSyskey\\nTravel\\nWinHelp\\nWrite\\nOthers\\nScanDisk\\nFile Protection\\nMedia Control Interface\\nNext-Generation Secure Computing Base\\nPOSIX subsystem\\nHPFS\\nInterix\\nVideo for Windows\\nVirtual DOS machine\\nWindows on Windows\\nWindows SideShow\\nWindows Services for UNIX\\nWindows System Assessment Tool\\nWindows To Go\\nWinFS\\nSpun off toMicrosoft Store\\nDVD Player\\nFile Manager\\nHover!\\nMahjong\\nMinesweeper\\nDefunct\\nPay\\n\\n\\xa0Category\\n\\xa0List\\n\\nvteOperating systemsGeneral\\nAdvocacy\\nComparison\\nForensic engineering\\nHistory\\nList\\nTimeline\\nUsage share\\nUser features comparison\\nVariants\\nDisk operating system\\nDistributed operating system\\nEmbedded operating system\\nHobbyist operating system\\nJust enough operating system\\nMobile operating system\\nNetwork operating system\\nObject-oriented operating system\\nReal-time operating system\\nSupercomputer operating system\\nKernelArchitectures\\nExokernel\\nHybrid\\nMicrokernel\\nMonolithic\\nvkernel\\nRump kernel\\nUnikernel\\nComponents\\nDevice driver\\nLoadable kernel module\\nUser space and kernel space\\nProcess managementConcepts\\nComputer multitasking (Cooperative, Preemptive)\\nContext switch\\nInterrupt\\nIPC\\nProcess\\nProcess control block\\nReal-time\\nThread\\nTime-sharing\\nSchedulingalgorithms\\nFixed-priority preemptive\\nMultilevel feedback queue\\nRound-robin\\nShortest job next\\nMemory management,resource protection\\nBus error\\nGeneral protection fault\\nMemory protection\\nPaging\\nProtection ring\\nSegmentation fault\\nVirtual memory\\nStorage access,file systems\\nBoot loader\\nDefragmentation\\nDevice file\\nFile attribute\\nInode\\nJournal\\nPartition\\nVirtual file system\\nVirtual tape library\\nSupporting concepts\\nAPI\\nComputer network\\nHAL\\nLive CD\\nLive USB\\nShell\\nCLI\\nGUI\\n3D GUI\\nNUI\\nTUI\\nVUI\\nZUI\\nPXE\\n\\nAuthority control General\\nVIAF\\n1\\nWorldCat (via VIAF)\\nNational libraries\\nFrance (data)\\nGermany\\nUnited States\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Microsoft_Windows&oldid=1083139891\"',\n",
       "  'American business magnate (1955–2011)\\nThis article is about the person. For other uses, see Steve Jobs (disambiguation).\\n\\n\\nSteve JobsJobs presenting the iPhone 4 in June 2010Born(1955-02-24)February 24, 1955San Francisco, California, U.S.DiedOctober 5, 2011(2011-10-05) (aged\\xa056)Palo Alto, California, U.S.Resting placeAlta Mesa Memorial ParkOccupationEntrepreneurindustrial designermedia proprietorinvestorYears\\xa0active1976–2011Known\\xa0for\\nPioneer of the personal computer revolution with Steve Wozniak\\nCo-creator of the Apple II, Macintosh, iPod, iPhone, iPad, and first Apple Stores\\nTitle\\nCo-founder, chairman and CEO of Apple Inc.\\nCo-founder, primary investor and chairman of Pixar\\nFounder, chairman and CEO of NeXT\\nBoard member\\xa0of\\nThe Walt Disney Company[1]\\nApple Inc.\\nSpouse(s)Laurene Powell \\u200b(m.\\xa01991)\\u200bPartner(s)Chrisann Brennan (1972–1977)Children4, including Lisa Brennan-JobsRelativesMona Simpson (sister)Bassma Al Jandaly (cousin)Malek Jandali (cousin)Signature\\nSteven Paul Jobs (February 24, 1955 – October 5, 2011) was an American entrepreneur, inventor, business magnate, media proprietor, and investor. He was the co-founder, chairman, and CEO of Apple; the chairman and majority shareholder of Pixar; a member of The Walt Disney Company\\'s board of directors following its acquisition of Pixar; and the founder, chairman, and CEO of NeXT. He is widely recognized as a pioneer of the personal computer revolution of the 1970s and 1980s, along with his early business partner and fellow Apple co-founder Steve Wozniak.\\nBorn in San Francisco to a Muslim Syrian father and a Catholic German-American mother, Jobs was adopted shortly after his birth. Jobs attended Reed College in 1972 before withdrawing that same year, and traveled through India in 1974 seeking enlightenment and studying Zen Buddhism. He and Wozniak co-founded Apple in 1976 to sell Wozniak\\'s Apple I personal computer. Together, the duo gained fame and wealth a year later with the Apple II, one of the first highly successful mass-produced microcomputers. Jobs saw the commercial potential of the Xerox Alto in 1979, which was mouse-driven and had a graphical user interface (GUI). This led to the development of the unsuccessful Apple Lisa in 1983, followed by the breakthrough Macintosh in 1984, the first mass-produced computer with a GUI. The Macintosh introduced the desktop publishing industry in 1985 with the addition of the Apple LaserWriter, the first laser printer to feature vector graphics.\\nJobs was forced out of Apple in 1985 after a long power struggle with the company\\'s board and its then-CEO John Sculley. That same year, Jobs took a few Apple employees with him to found NeXT, a computer platform development company that specialized in computers for higher-education and business markets. In addition, he helped to develop the visual effects industry when he funded the computer graphics division of George Lucas\\'s Lucasfilm in 1986. The new company was Pixar, which produced the first 3D computer animated feature film Toy Story (1995) and went on to become a major animation studio, producing over 20 films since.\\nJobs became CEO of Apple in 1997, following the company\\'s acquisition of NeXT. He was largely responsible for helping revive Apple, which had been on the verge of bankruptcy. He worked closely with English designer Jony Ive to develop a line of products that had larger cultural ramifications, beginning in 1997 with the \"Think different\" advertising campaign and leading to the Apple Store, App Store, iMac, iPad, iPod, iPhone, iTunes, and iTunes Store. In 2001, the original Mac OS was replaced with the completely new Mac OS X (now known as macOS), based on NeXT\\'s NeXTSTEP platform, giving the OS a modern Unix-based foundation for the first time. Jobs was diagnosed with a pancreatic neuroendocrine tumor in 2003. He died of respiratory arrest related to the tumor at age 56 on October 5, 2011.\\n\\nContents\\n\\n1 Background\\n\\n1.1 Biological and adoptive families\\n1.2 Birth and early life\\n\\n\\n2 Childhood\\n3 Homestead High\\n4 Reed College\\n5 1972–1985\\n\\n5.1 Pre-Apple\\n5.2 Apple (1976–1985)\\n\\n\\n6 1985–1997\\n\\n6.1 NeXT computer\\n6.2 Pixar and Disney\\n\\n\\n7 1997–2011\\n\\n7.1 Return to Apple\\n\\n\\n8 Health problems\\n\\n8.1 Resignation\\n8.2 Death\\n\\n\\n9 Innovations and designs\\n\\n9.1 Apple I\\n9.2 Apple II\\n9.3 Apple Lisa\\n9.4 Macintosh\\n9.5 NeXT Computer\\n9.6 iMac\\n9.7 iTunes\\n9.8 iPod\\n9.9 iPhone\\n9.10 iPad\\n\\n\\n10 Personal life\\n\\n10.1 Marriage\\n10.2 Family\\n10.3 Philanthropy\\n\\n\\n11 Honors and awards\\n12 In popular culture\\n13 See also\\n14 References\\n15 External links\\n\\n\\nBackground\\nBiological and adoptive families\\nSteven Paul Jobs was born in San Francisco, California, on February 24, 1955, the son of Joanne Carole Schieble and Abdulfattah Jandali (Arabic: عبد الفتاح الجندلي). He was adopted by Clara (née Hagopian) and Paul Reinhold Jobs.[2]\\nJandali, Jobs\\'s biological father, was Syrian and went by the name \"John\". He grew up in an Arab Muslim household in Homs.[3] While an undergraduate at the American University of Beirut in Lebanon, he was a student activist and spent time in prison for his political activities.[3] He pursued a PhD at the University of Wisconsin, where he met Schieble, an American Catholic of German and Swiss descent.[3][4] As a doctoral candidate, Jandali was a teaching assistant for a course Schieble was taking, although both were the same age.[5] Novelist Mona Simpson, Jobs\\'s biological sister, noted that Schieble\\'s parents were not happy that their daughter was dating a Muslim.[6] Walter Isaacson, author of the biography Steve Jobs, additionally states that Schieble\\'s father \"threatened to cut her off completely\" if she continued the relationship.[4]\\nJobs\\'s adoptive father was a Coast Guard mechanic.[7] After leaving the Coast Guard, he married Hagopian, an American of Armenian descent, in 1946.[8] Their attempts to start a family were halted after Hagopian had an ectopic pregnancy, leading them to consider adoption in 1955.[7][8][9] Hagopian\\'s parents were survivors of the Armenian Genocide.[10]\\n\\nBirth and early life\\n\\n\\n\"Of all the inventions of humans, the computer is going to rank near or at the top as history unfolds and we look back. It is the most awesome tool that we have ever invented. I feel incredibly lucky to be at exactly the right place in Silicon Valley, at exactly the right time, historically, where this invention has taken form.\"\\n\\n\\n—Steve Jobs, 1995. From the documentary, Steve Jobs: The Lost Interview.[11]\\n\\n\\nSchieble became pregnant with Jobs in 1954, when she and Jandali spent the summer with his family in Homs. According to Jandali, Schieble deliberately did not involve him in the process: \"Without telling me, Joanne upped and left to move to San Francisco to have the baby without anyone knowing, including me.\"[12]\\nSchieble gave birth to Jobs in San Francisco on February 24, 1955, and chose an adoptive couple for him that was \"Catholic, well-educated, and wealthy\",[13][14] but the couple later changed their mind.[13] Jobs was then placed with Paul and Clara Jobs, neither of whom had a college education, and Schieble refused to sign the adoption papers.[15] She then took the matter to court in an attempt to have her baby placed with a different family,[13] and only consented to releasing the baby to Paul and Clara after the couple pledged to pay for the boy\\'s college education.[16] Jobs\\'s cousin, Bassma Al Jandaly, maintains that Jobs\\'s birth name was Abdul Lateef Jandali.[17]\\nIn his youth, Steve\\'s parents took him to a Lutheran church.[18] When Jobs was in high school, Clara admitted to his girlfriend, Chrisann Brennan, that she \"was too frightened to love [Steve] for the first six months of his life ... I was scared they were going to take him away from me. Even after we won the case, Steve was so difficult a child that by the time he was two I felt we had made a mistake. I wanted to return him.\"[13] When Chrisann shared this comment with Steve, he stated that he was already aware,[13] and would later say he was deeply loved and indulged by Paul and Clara.[19][page\\xa0needed] Many years later, Jobs\\'s wife Laurene also noted that \"he felt he had been really blessed by having the two of them as parents.\"[19][page\\xa0needed] Jobs would become upset when Paul and Clara were referred to as his \"adoptive parents\"; he regarded them as his parents \"1,000%\". With regard to his biological parents, Jobs referred to them as \"my sperm and egg bank. That\\'s not harsh, it\\'s just the way it was, a sperm bank thing, nothing more.\"[7]\\n\\nChildhood\\n\\n\\n\"I always thought of myself as a humanities person as a kid, but I liked electronics… then I read something that one of my heroes, Edwin Land of Polaroid, said about the importance of people who could stand at the intersection of humanities and sciences, and I decided that\\'s what I wanted to do.\"\\n\\n\\nFrom Steve Jobs[20]\\n\\n\\nPaul Jobs worked in several jobs that included a try as a machinist,[21]\\nseveral other jobs,[22] and then \"back to work as a machinist.\"\\nPaul and Clara adopted Jobs\\'s sister Patricia in 1957[23] and by 1959 the family had moved to the Monta Loma neighborhood in Mountain View, California.[24] It was during this time that Paul built a workbench in his garage for his son in order to \"pass along his love of mechanics.\"[25] Jobs, meanwhile, admired his father\\'s craftsmanship \"because he knew how to build anything. If we needed a cabinet, he would build it. When he built our fence, he gave me a hammer so I could work with him ... I wasn\\'t that into fixing cars ... but I was eager to hang out with my dad.\"[25] By the time he was ten, Jobs was deeply involved in electronics and befriended many of the engineers who lived in the neighborhood.[26][page\\xa0needed] He had difficulty making friends with children his own age, however, and was seen by his classmates as a \"loner.\"[26][page\\xa0needed]\\n\\n Childhood family home of Steve Jobs on Crist Drive in Los Altos, California, that served as the original site of Apple Computer. The home was added to a list of historic Los Altos sites in 2013.[27]\\nJobs had difficulty functioning in a traditional classroom, tended to resist authority figures, frequently misbehaved, and was suspended a few times.[26][page\\xa0needed] Clara had taught him to read as a toddler, and Jobs stated that he was \"pretty bored in school and [had] turned into a little terror... you should have seen us in the third grade, we basically destroyed the teacher.\"[26][page\\xa0needed] He frequently played pranks on others at Monta Loma Elementary School in Mountain View.[28] His father Paul (who was abused as a child) never reprimanded him, however, and instead blamed the school for not challenging his brilliant son.[28]\\nJobs would later credit his fourth grade teacher, Imogene \"Teddy\" Hill, with turning him around: \"She taught an advanced fourth grade class and it took her about a month to get hip to my situation. She bribed me into learning. She would say, \\'I really want you to finish this workbook. I\\'ll give you five bucks if you finish it.\\' That really kindled a passion in me for learning things! I learned more that year than I think I learned in any other year in school. They wanted me to skip the next two years in grade school and go straight to junior high to learn a foreign language but my parents very wisely wouldn\\'t let it happen.\"[26][page\\xa0needed] Jobs skipped the 5th grade and transferred to the 6th grade at Crittenden Middle School in Mountain View[26][page\\xa0needed] where he became a \"socially awkward loner\".[29] Jobs was often \"bullied\" at Crittenden Middle, and in the middle of 7th grade, he gave his parents an ultimatum: they had to either take him out of Crittenden or he would drop out of school.[30]\\nThough the Jobs family was not well off, they used all their savings in 1967 to buy a new home, allowing Jobs to change schools.[26][page\\xa0needed] The new house (a three-bedroom home on Crist Drive in Los Altos, California) was in the better Cupertino School District, Cupertino, California,[31] and was embedded in an environment that was even more heavily populated with engineering families than the Mountain View area was.[26][page\\xa0needed] The house was declared a historic site in 2013, as it was the first site for Apple Computer;[27] as of 2013, it was owned by Jobs\\'s sister, Patty, and occupied by his step-mother, Marilyn.[32]\\nWhen he was 13 in 1968, Jobs was given a summer job by Bill Hewlett (of Hewlett-Packard) after Jobs cold-called him to ask for parts for an electronics project.[26][page\\xa0needed]\\n\\nHomestead High\\n Jobs\\'s 1972 Homestead High School yearbook photo\\nThe location of the Los Altos home meant that Jobs would be able to attend nearby Homestead High School, which had strong ties to Silicon Valley.[20] He began his first year there in late 1968 along with Bill Fernandez.[26][page\\xa0needed] (Fernandez introduced Jobs to Steve Wozniak, and would later be Apple\\'s first employee.) Neither Jobs nor Fernandez (whose father was a lawyer) came from engineering households and thus decided to enroll in John McCollum\\'s \"Electronics 1.\"[26][page\\xa0needed] McCollum and the rebellious Jobs (who had grown his hair long and become involved in the growing counterculture) would eventually clash and Jobs began to lose interest in the class.[26][page\\xa0needed]\\nHe underwent a change during mid-1970: \"I got stoned for the first time; I discovered Shakespeare, Dylan Thomas, and all that classic stuff. I read Moby Dick and went back as a junior taking creative writing classes.\"[26][page\\xa0needed] Jobs also later noted to his official biographer that \"I started to listen to music a whole lot, and I started to read more outside of just science and technology—Shakespeare, Plato. I loved King Lear ... when I was a senior I had this phenomenal AP English class. The teacher was this guy who looked like Ernest Hemingway. He took a bunch of us snowshoeing in Yosemite.\"[33] During his last two years at Homestead High, Jobs developed two different interests: electronics and literature.[33] These dual interests were particularly reflected during Jobs\\'s senior year as his best friends were Wozniak and his first girlfriend, the artistic Homestead junior Chrisann Brennan.[citation needed]\\nIn 1971 after Wozniak began attending University of California, Berkeley, Jobs would visit him there a few times a week. This experience led him to study in nearby Stanford University\\'s student union. Jobs also decided that rather than join the electronics club, he would put on light shows with a friend for Homestead\\'s avant-garde Jazz program. He was described by a Homestead classmate as \"kind of a brain and kind of a hippie ... but he never fit into either group. He was smart enough to be a nerd, but wasn\\'t nerdy. And he was too intellectual for the hippies, who just wanted to get wasted all the time. He was kind of an outsider. In high school everything revolved around what group you were in, and if you weren\\'t in a carefully defined group, you weren\\'t anybody. He was an individual, in a world where individuality was suspect.\" By his senior year in late 1971, he was taking freshman English class at Stanford and working on a Homestead underground film project with Chrisann Brennan.[26][page\\xa0needed]\\nAround that time, Wozniak designed a low-cost digital \"blue box\" to generate the necessary tones to manipulate the telephone network, allowing free long-distance calls. Jobs decided then to sell them and split the profit with Wozniak. The clandestine sales of the illegal blue boxes went well and perhaps planted the seed in Jobs\\'s mind that electronics could be both fun and profitable.[34] Jobs, in a 1994 interview, recalled that it took six months for him and Wozniak to figure out how to build the blue boxes.[35] Jobs later reflected that had it not been for Wozniak\\'s blue boxes, \"there wouldn\\'t have been an Apple\".[36] He states it showed them that they could take on large companies and beat them.[37][38]\\nBy his senior year of high school, Jobs began using LSD.[39] He later recalled that on one occasion he consumed it in a wheat field outside Sunnyvale, and experienced \"the most wonderful feeling of my life up to that point\".[40] In mid-1972, after graduation and before leaving for Reed College, Jobs and Brennan rented a house from their other roommate, Al.[41]\\n\\nReed College\\n\\n\\n\"I was interested in Eastern mysticism which hit the shores about then. At Reed there was a constant flow of people stopping by – from Timothy Leary and Richard Alpert, to Gary Snyder. There was a constant flow of intellectual questioning about the truth of life. That was the time when every college student in the country read Be Here Now and Diet for a Small Planet.\"\\n\\n\\n—Steve Jobs[26][page\\xa0needed]\\n\\n\\nIn September 1972, Jobs enrolled at Reed College in Portland, Oregon.[42] He insisted on applying only to Reed although it was an expensive school that Paul and Clara could ill afford.[43] Jobs soon befriended Robert Friedland,[44] who was Reed\\'s student body president at that time.[26][page\\xa0needed] Brennan remained involved with Jobs while he was at Reed. He later asked her to come and live with him in a house he rented near the Reed campus, but she refused.\\nAfter just one semester, Jobs dropped out of Reed College without telling his parents.[45] Jobs later explained that he decided to drop out because he did not want to spend his parents\\' money on an education that seemed meaningless to him.[46] He continued to attend by auditing his classes,[46] which included a course on calligraphy that was taught by Robert Palladino. In a 2005 commencement speech at Stanford University, Jobs stated that during this period, he slept on the floor in friends\\' dorm rooms, returned Coke bottles for food money, and got weekly free meals at the local Hare Krishna temple. In that same speech, Jobs said: \"If I had never dropped in on that single calligraphy course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts.\"[47]\\n\\n1972–1985\\n\\n\\nI was lucky to get into computers when it was a very young and idealistic industry. There weren\\'t many degrees offered in computer science, so people in computers were brilliant people from mathematics, physics, music, zoology, whatever. They loved it, and no one was really in it for the money [...] There are people around here who start companies just to make money, but the great companies, well, that\\'s not what they\\'re about.\"\\n\\n\\n—Steve Jobs[48]\\n\\n\\nPre-Apple\\nIn February 1974, Jobs returned to his parents\\' home in Los Altos and began looking for a job.[49] He was soon hired by Atari, Inc. in Los Gatos, California, which gave him a job as a technician.[49][50] Back in 1973, Steve Wozniak designed his own version of the classic video game Pong and gave the board to Jobs. According to Wozniak, Atari only hired Jobs because he took the board down to the company, and they thought that he had built it himself.[51] Atari\\'s cofounder Nolan Bushnell later described him as \"difficult but valuable\", pointing out that \"he was very often the smartest guy in the room, and he would let people know that.\"[52]\\nDuring this period, Jobs and Brennan remained involved with each other while continuing to see other people. By early 1974, Jobs was living what Brennan describes as a \"simple life\" in a Los Gatos cabin, working at Atari, and saving money for his impending trip to India.[citation needed]\\nJobs traveled to India in mid-1974[53] to visit Neem Karoli Baba[54] at his Kainchi ashram with his Reed friend (and eventual Apple employee) Daniel Kottke, in search of spiritual enlightenment. When they got to the Neem Karoli ashram, it was almost deserted because Neem Karoli Baba had died in September 1973.[50] Then they made a long trek up a dry riverbed to an ashram of Haidakhan Babaji.[50]\\nAfter seven months, Jobs left India[55] and returned to the US ahead of Daniel Kottke.[50] Jobs had changed his appearance; his head was shaved and he wore traditional Indian clothing.[56][57] During this time, Jobs experimented with psychedelics, later calling his LSD experiences \"one of the two or three most important things [he had] done in [his] life\".[58][59] He spent a period at the All One Farm, a commune in Oregon that was owned by Robert Friedland. Brennan joined him there for a period.[citation needed]\\nDuring this time period, Jobs and Brennan both became practitioners of Zen Buddhism through the Zen master Kōbun Chino Otogawa. Jobs was living in his parents\\' backyard toolshed, which he had converted into a bedroom.[citation needed] Jobs engaged in lengthy meditation retreats at the Tassajara Zen Mountain Center, the oldest Sōtō Zen monastery in the US.[60] He considered taking up monastic residence at Eihei-ji in Japan, and maintained a lifelong appreciation for Zen.[61]\\nIn mid-1975, after returning to Atari, Jobs was assigned to create a circuit board for the arcade video game Breakout.[62] According to Bushnell, Atari offered US$100 for each TTL chip that was eliminated in the machine. Jobs had little specialized knowledge of circuit board design and made a deal with Wozniak to split the fee evenly between them if Wozniak could minimize the number of chips. Much to the amazement of Atari engineers, Wozniak reduced the TTL count to 46, a design so tight that it was impossible to reproduce on an assembly line.[63] According to Wozniak, Jobs told him that Atari gave them only $700 (instead of the $5,000 paid out), and that Wozniak\\'s share was thus $350.[64] Wozniak did not learn about the actual bonus until ten years later, but said that if Jobs had told him about it and explained that he needed the money, Wozniak would have given it to him.[65]\\nJobs and Wozniak attended meetings of the Homebrew Computer Club in 1975, which was a stepping stone to the development and marketing of the first Apple computer.[14]\\n\\nApple (1976–1985)\\nSee also: History of Apple §\\xa01975–1985: Jobs and Wozniak\\n\\n\\n\"Basically Steve Wozniak and I invented the Apple because we wanted a personal computer. Not only couldn\\'t we afford the computers that were on the market, those computers were impractical for us to use. We needed a Volkswagen. The Volkswagen isn\\'t as fast or comfortable as other ways of traveling, but the VW owners can go where they want, when they want and with whom they want. The VW owners have personal control of their car.\"\\n\\n\\n—Steve Jobs[26][page\\xa0needed]\\n\\n\\nBy March 1976, Wozniak completed the basic design of the Apple I computer and showed it to Jobs, who suggested that they sell it; Wozniak was at first skeptical of the idea but later agreed.[66] In April of that same year, Jobs, Wozniak, and administrative overseer Ronald Wayne founded Apple Computer Company (now called Apple Inc.) as a business partnership in Jobs\\'s parents\\' Crist Drive home on April 1, 1976.[67] The operation originally started in Jobs\\'s bedroom and later moved to the garage.[67][68] Wayne stayed only a short time, leaving Jobs and Wozniak as the active primary cofounders of the company.[69] The two decided on the name \"Apple\" after Jobs returned from the All One Farm commune in Oregon and told Wozniak about his time spent in the farm\\'s apple orchard.[70] Jobs originally planned to produce bare printed circuit boards of the Apple I and sell them to computer hobbyists for $50 each.[71][72] To raise the money they needed to build the first batch of the circuit boards, Wozniak sold his HP scientific calculator and Jobs sold his Volkswagen van.[71][72] Later that year, computer retailer Paul Terrell purchased 50 fully assembled units of the Apple I from them for $500 each.[73][74] Eventually about 200 Apple I computers were produced in total.[75]\\n\\nExternal image Jobs and Steve Wozniak with an Apple I circuit board, c. 1976.\\nA neighbor on Crist Drive recalled Jobs as an odd individual who would greet his clients \"with his underwear hanging out, barefoot and hippie-like\".[32] Another neighbor, Larry Waterland, who had just earned his PhD in chemical engineering at Stanford, recalled dismissing Jobs\\'s budding business: \"\\'You punched cards, put them in a big deck,\\' he said about the mainframe machines of that time. \\'Steve took me over to the garage. He had a circuit board with a chip on it, a DuMont TV set, a Panasonic cassette tape deck and a keyboard. He said, \\'This is an Apple computer.\\' I said, \\'You\\'ve got to be joking.\\' I dismissed the whole idea.\\'\"[32] Jobs\\'s friend from Reed College and India, Daniel Kottke, recalled that as an early Apple employee, he \"was the only person who worked in the garage ... Woz would show up once a week with his latest code. Steve Jobs didn\\'t get his hands dirty in that sense.\" Kottke also stated that much of the early work took place in Jobs\\'s kitchen, where he spent hours on the phone trying to find investors for the company.[32]\\nThey received funding from a then-semi-retired Intel product marketing manager and engineer Mike Markkula.[76] Scott McNealy, one of the cofounders of Sun Microsystems, said that Jobs broke a \"glass age ceiling\" in Silicon Valley because he\\'d created a very successful company at a young age.[38] Markkula brought Apple to the attention of Arthur Rock, which after looking at the crowded Apple booth at the Home Brew Computer Show, started with a $60,000 investment and went on the Apple board.[77] Jobs was not pleased when Markkula recruited Mike Scott from National Semiconductor in February 1977 to serve as the first president and CEO of Apple.[78][79]\\n\\n\\n\\n\"For what characterizes Apple is that its scientific staff always acted and performed like artists – in a field filled with dry personalities limited by the rational and binary worlds they inhabit, Apple\\'s engineering teams had passion. They always believed that what they were doing was important and, most of all, fun. Working at Apple was never just a job; it was also a crusade, a mission, to bring better computer power to people. At its roots that attitude came from Steve Jobs. It was \"Power to the People\", the slogan of the sixties, rewritten in technology for the eighties and called Macintosh.\"\\n\\n\\n—Jeffrey S. Young, 1987. From the book, Steve Jobs: The Journey is the Reward (published 1988).[26][page\\xa0needed]\\n\\n\\nAfter Brennan returned from her own journey to India, she and Jobs fell in love again, as Brennan noted changes in him that she attributes to Kobun (whom she was also still following). It was also at this time that Jobs displayed a prototype Apple I computer for Brennan and his parents in their living room. Brennan notes a shift in this time period, where the two main influences on Jobs were Apple Inc. and Kobun. By early 1977, she and Jobs would spend time together at her home at Duveneck Ranch in Los Altos, which served as a hostel and environmental education center.\\nIn April 1977, Jobs and Wozniak introduced the Apple II at the West Coast Computer Faire.[80] It is the first consumer product to have been sold by Apple Computer. Primarily designed by Wozniak, Jobs oversaw the development of its unusual case and Rod Holt developed the unique power supply.[81] During the design stage, Jobs argued that the Apple II should have two expansion slots, while Wozniak wanted eight. After a heated argument, Wozniak threatened that Jobs should \"go get himself another computer\". They later decided to go with eight slots.[82] The Apple II became one of the first highly successful mass-produced microcomputer products in the world.[83]\\nAs Jobs became more successful with his new company, his relationship with Brennan grew more complex. In 1977, the success of Apple was now a part of their relationship, and Brennan, Daniel Kottke, and Jobs moved into a house near the Apple office in Cupertino.[citation needed] Brennan eventually took a position in the shipping department at Apple.[84] Brennan\\'s relationship with Jobs deteriorated as his position with Apple grew, and she began to consider ending the relationship. In October 1977, Brennan was approached by Rod Holt, who asked her to take \"a paid apprenticeship designing blueprints for the Apples\".[citation needed] Both Holt and Jobs believed that it would be a good position for her, given her artistic abilities. Holt was particularly eager that she take the position and puzzled by her ambivalence toward it. Brennan\\'s decision, however, was overshadowed by the fact that she realized she was pregnant and that Jobs was the father. It took her a few days to tell Jobs, whose face, according to Brennan \"turned ugly\" at the news. At the same time, according to Brennan, at the beginning of her third trimester, Jobs said to her: \"I never wanted to ask that you get an abortion. I just didn\\'t want to do that.\"[citation needed] He also refused to discuss the pregnancy with her.[85] Brennan turned down the internship and decided to leave Apple. She stated that Jobs told her \"If you give up this baby for adoption, you will be sorry\" and \"I am never going to help you.\"[citation needed] According to Brennan, Jobs \"started to seed people with the notion that I slept around and he was infertile, which meant that this could not be his child.\" A few weeks before she was due to give birth, Brennan was invited to deliver her baby at the All One Farm. She accepted the offer.[citation needed] When Jobs was 23 (the same age as his biological parents when they had him)[85] Brennan gave birth to her baby, Lisa Brennan, on May 17, 1978.[86] Jobs went there for the birth after he was contacted by Robert Friedland, their mutual friend and the farm owner. While distant, Jobs worked with her on a name for the baby, which they discussed while sitting in the fields on a blanket. Brennan suggested the name \"Lisa\" which Jobs also liked and notes that Jobs was very attached to the name \"Lisa\" while he \"was also publicly denying paternity.\" She would discover later that during this time, Jobs was preparing to unveil a new kind of computer that he wanted to give a female name (his first choice was \"Claire\" after St. Clare). She also stated that she never gave him permission to use the baby\\'s name for a computer and he hid the plans from her. Jobs also worked with his team to come up with the phrase, \"Local Integrated Software Architecture\" as an alternative explanation for the Apple Lisa.[87] Decades later, however, Jobs admitted to his biographer Walter Isaacson that \"obviously, it was named for my daughter\".[88]\\nWhen Jobs denied paternity, a DNA test established him as Lisa\\'s father.[clarification needed] It required him to give Brennan $385 a month in addition to returning the welfare money she had received. Jobs gave her $500 a month at the time when Apple went public and Jobs became a millionaire. Later, Brennan agreed to give an interview with Michael Moritz for Time magazine for its Time Person of the Year special, released on January 3, 1983, in which she discussed her relationship with Jobs. Rather than name Jobs the Person of the Year, the magazine named the computer[clarification needed] the \"Machine of the Year\".[89] In the issue, Jobs questioned the reliability of the paternity test (which stated that the \"probability of paternity for Jobs, Steven... is 94.1%\").[90] Jobs responded by arguing that \"28% of the male population of the United States could be the father\".[90] Time also noted that \"the baby girl and the machine on which Apple has placed so much hope for the future share the same name: Lisa\".[90]\\nJobs was worth over $1 million in 1978, when he was just 23 years old. His net worth grew to over $250 million by the time he was 25, according to estimates.[91] He was also one of the youngest \"people ever to make the Forbes list of the nation\\'s richest people—and one of only a handful to have done it themselves, without inherited wealth\".[26][page\\xa0needed]\\nIn 1982, Jobs bought an apartment on the top two floors of The San Remo, a Manhattan building with a politically progressive reputation. Although he never lived there,[92] he spent years renovating it with the help of I. M. Pei. In 2003, he sold it to U2 singer Bono.\\nIn 1983, Jobs lured John Sculley away from Pepsi-Cola to serve as Apple\\'s CEO, asking, \"Do you want to spend the rest of your life selling sugared water, or do you want a chance to change the world?\"[93]\\nIn 1984, Jobs bought the Jackling House and estate, and resided there for a decade. After that, he leased it out for several years until 2000 when he stopped maintaining the house, allowing exposure to the weather to degrade it. In 2004, Jobs received permission from the town of Woodside to demolish the house in order to build a smaller contemporary styled one. After a few years in court, the house was finally demolished in 2011, a few months before he died.[94]\\n\\nFrom left to right: Prototype of the original Macintosh from c. 1981 (at the Computer History Museum); Jobs with the Apple Macintosh, January 1984\\nJobs began directing the development of the Macintosh in 1981, when he took over the project from early Apple employee Jef Raskin, who conceived the computer (Wozniak, who with Raskin had heavy influence over the program early on in its development, was on leave during this time due to an airplane crash earlier that year[95]).[96][97] On January 22, 1984, Apple aired a Super Bowl television commercial titled \"1984\", which ended with the words: \"On January 24th, Apple Computer will introduce Macintosh. And you\\'ll see why 1984 won\\'t be like 1984.\"[98] On January 24, 1984, an emotional Jobs introduced the Macintosh to a wildly enthusiastic audience at Apple\\'s annual shareholders meeting held in the Flint Auditorium;[99][100] Macintosh engineer Andy Hertzfeld described the scene as \"pandemonium\".[101] The Macintosh was based on The Lisa (and Xerox PARC\\'s mouse-driven graphical user interface),[102][103] and it was widely acclaimed by the media with strong initial sales supporting it.[104][105] However, the computer\\'s slow processing speed and limited range of available software led to a rapid sales decline in the second half of 1984.[104][105][106]\\n\\nExternal video The Machine That Changed The World, The Paperback Computer; Interview with Steve Jobs, 1990, 50:08, May 14, 1990, WGBH Media Library & Archives[107]\\nSculley\\'s and Jobs\\'s respective visions for the company greatly differed. The former favored open architecture computers like the Apple II, sold to education, small business, and home markets less vulnerable to IBM. Jobs wanted the company to focus on the closed architecture Macintosh as a business alternative to the IBM PC. President and CEO Sculley had little control over chairman of the board Jobs\\'s Macintosh division; it and the Apple II division operated like separate companies, duplicating services.[108] Although its products provided 85 percent of Apple\\'s sales in early 1985, the company\\'s January 1985 annual meeting did not mention the Apple II division or employees. Many left, including Wozniak, who stated that the company had \"been going in the wrong direction for the last five years\" and sold most of his stock.[109] Despite being frustrated with the company\\'s (including Jobs himself) dismissal of the Apple II employees in favor of the Macintosh, Wozniak left amicably and remained an honorary employee of Apple, maintaining a friendship with Jobs until his death.[110][111][112]\\n\\n Jobs (left) with software developer Wendell Brown in 1984\\nBy early 1985, the Macintosh\\'s failure to defeat the IBM PC became clear,[104][105] and it strengthened Sculley\\'s position in the company. In May 1985, Sculley—encouraged by Arthur Rock—decided to reorganize Apple, and proposed a plan to the board that would remove Jobs from the Macintosh group and put him in charge of \"New Product Development\". This move would effectively render Jobs powerless within Apple.[26][page\\xa0needed] In response, Jobs then developed a plan to get rid of Sculley and take over Apple. However, Jobs was confronted after the plan was leaked, and he said that he would leave Apple. The Board declined his resignation and asked him to reconsider. Sculley also told Jobs that he had all of the votes needed to go ahead with the reorganization. A few months later, on September 17, 1985, Jobs submitted a letter of resignation to the Apple Board. Five additional senior Apple employees also resigned and joined Jobs in his new venture, NeXT.[26][page\\xa0needed]\\nThe Macintosh\\'s struggle continued after Jobs left Apple. Though marketed and received in fanfare, the expensive Macintosh was a hard sell.[113]:\\u200a308–309\\u200a In 1985, Bill Gates\\'s then-developing company, Microsoft, threatened to stop developing Mac applications unless it was granted \"a license for the Mac operating system software. Microsoft was developing its graphical user interface ... for DOS, which it was calling Windows and didn\\'t want Apple to sue over the similarities between the Windows GUI and the Mac interface.\"[113]:\\u200a321\\u200a Sculley granted Microsoft the license which later led to problems for Apple.[113]:\\u200a321\\u200a In addition, cheap IBM PC clones that ran on Microsoft software and had a graphical user interface began to appear. Although the Macintosh preceded the clones, it was far more expensive, so \"through the late 1980s, the Windows user interface was getting better and better and was thus taking increasingly more share from Apple\".[113]:\\u200a322\\u200a Windows-based IBM-PC clones also led to the development of additional GUIs such as IBM\\'s TopView or Digital Research\\'s GEM,[113]:\\u200a322\\u200a and thus \"the graphical user interface was beginning to be taken for granted, undermining the most apparent advantage of the Mac...it seemed clear as the 1980s wound down that Apple couldn\\'t go it alone indefinitely against the whole IBM-clone market.\"[113]:\\u200a322\\u200a\\n\\n1985–1997\\nNeXT computer\\nSee also: NeXT\\nFollowing his resignation from Apple in 1985, Jobs founded NeXT Inc.[114] with $7\\xa0million. A year later he was running out of money, and he sought venture capital with no product on the horizon. Eventually, Jobs attracted the attention of billionaire Ross Perot, who invested heavily in the company.[115] The NeXT computer was shown to the world in what was considered Jobs\\'s comeback event,[116] a lavish invitation-only gala launch event[117] that was described as a multimedia extravaganza.[118] The celebration was held at the Louise M. Davies Symphony Hall, San Francisco, California, on Wednesday, October 12, 1988. Steve Wozniak said in a 2013 interview that while Jobs was at NeXT he was \"really getting his head together\".[95]\\nNeXT workstations were first released in 1990 and priced at US$9,999. Like the Apple Lisa, the NeXT workstation was technologically advanced and designed for the education sector, but was largely dismissed as cost-prohibitive for educational institutions.[119] The NeXT workstation was known for its technical strengths, chief among them its object-oriented software development system. Jobs marketed NeXT products to the financial, scientific, and academic community, highlighting its innovative, experimental new technologies, such as the Mach kernel, the digital signal processor chip, and the built-in Ethernet port. Making use of a NeXT computer, English computer scientist Tim Berners-Lee invented the World Wide Web in 1990 at CERN in Switzerland.[120]\\nThe revised, second generation NeXTcube was released in 1990. Jobs touted it as the first \"interpersonal\" computer that would replace the personal computer. With its innovative NeXTMail multimedia email system, NeXTcube could share voice, image, graphics, and video in email for the first time. \"Interpersonal computing is going to revolutionize human communications and groupwork\", Jobs told reporters.[121] Jobs ran NeXT with an obsession for aesthetic perfection, as evidenced by the development of and attention to NeXTcube\\'s magnesium case.[122] This put considerable strain on NeXT\\'s hardware division, and in 1993, after having sold only 50,000 machines, NeXT transitioned fully to software development with the release of NeXTSTEP/Intel.[123] The company reported its first yearly profit of $1.03\\xa0million in 1994.[124] In 1996, NeXT Software, Inc. released WebObjects, a framework for Web application development. After NeXT was acquired by Apple Inc. in 1997, WebObjects was used to build and run the Apple Store,[123] MobileMe services, and the iTunes Store.\\n\\nPixar and Disney\\nExternal video Presentation by Jobs on the future of computer-animated films, March 31, 1998, C-SPAN\\nIn 1986, Jobs funded the spinout of The Graphics Group (later renamed Pixar) from Lucasfilm\\'s computer graphics division for the price of $10\\xa0million, $5\\xa0million of which was given to the company as capital and $5\\xa0million of which was paid to Lucasfilm for technology rights.[125]\\nThe first film produced by Pixar with its Disney partnership, Toy Story (1995), with Jobs credited as executive producer,[citation needed] brought financial success and critical acclaim to the studio when it was released. Over the course of Jobs\\'s life, under Pixar\\'s creative chief John Lasseter, the company produced box-office hits A Bug\\'s Life (1998); Toy Story 2 (1999); Monsters, Inc. (2001); Finding Nemo (2003); The Incredibles (2004); Cars (2006); Ratatouille (2007); WALL-E (2008); Up (2009); Toy Story 3 (2010); and Cars 2 (2011). Brave (2012), Pixar\\'s first film to be produced since Jobs\\'s death, honored him with a tribute for his contributions to the studio.[126] Finding Nemo, The Incredibles, Ratatouille, WALL-E, Up, Toy Story 3 and Brave each received the Academy Award for Best Animated Feature, an award introduced in 2001.[127][128]\\nIn 2003 and 2004, as Pixar\\'s contract with Disney was running out, Jobs and Disney chief executive Michael Eisner tried but failed to negotiate a new partnership,[129] and in January 2004, Jobs announced that he would never deal with Disney again.[130] Pixar would seek a new partner to distribute its films after its contract expired.\\nIn October 2005, Bob Iger replaced Eisner at Disney, and Iger quickly worked to mend relations with Jobs and Pixar. On January 24, 2006, Jobs and Iger announced that Disney had agreed to purchase Pixar in an all-stock transaction worth $7.4\\xa0billion. When the deal closed, Jobs became The Walt Disney Company\\'s largest single shareholder with approximately seven percent of the company\\'s stock.[131] Jobs\\'s holdings in Disney far exceeded those of Eisner, who holds 1.7%, and of Disney family member Roy E. Disney, who until his 2009 death held about 1% of the company\\'s stock and whose criticisms of Eisner—especially that he soured Disney\\'s relationship with Pixar—accelerated Eisner\\'s ousting. Upon completion of the merger, Jobs received 7% of Disney shares, and joined the board of directors as the largest individual shareholder.[131][132][133] Upon Jobs\\'s death his shares in Disney were transferred to the Steven P. Jobs Trust led by Laurene Jobs.[134]\\nAfter Jobs\\'s death Iger recalled in 2019 that many warned him about Jobs, \"that he would bully me and everyone else\". Iger wrote, \"Who wouldn\\'t want Steve Jobs to have influence over how a company is run?\", and that as an active Disney board member \"he rarely created trouble for me. Not never but rarely\". He speculated that they would have seriously considered merging Disney and Apple had Jobs lived.[130] Floyd Norman, of Pixar, described Jobs as a \"mature, mellow individual\" who never interfered with the creative process of the filmmakers.[135] In early June 2014, Pixar cofounder and Walt Disney Animation Studios President Ed Catmull revealed that Jobs once advised him to \"just explain it to them until they understand\" in disagreements. Catmull released the book Creativity, Inc. in 2014, in which he recounts numerous experiences of working with Jobs. Regarding his own manner of dealing with Jobs, Catmull writes:[136][page\\xa0needed]\\n\\nIn all the 26 years with Steve, Steve and I never had one of these loud verbal arguments and it\\'s not my nature to do that. ... but we did disagree fairly frequently about things. ... I would say something to him and he would immediately shoot it down because he could think faster than I could. ... I would then wait a week ... I\\'d call him up and I give my counter argument to what he had said and he\\'d immediately shoot it down. So I had to wait another week, and sometimes this went on for months. But in the end one of three things happened. About a third of the time he said, \\'Oh, I get it, you\\'re right.\\' And that was the end of it. And it was another third of the time in which [I\\'d] say, \\'Actually I think he is right.\\' The other third of the time, where we didn\\'t reach consensus, he just let me do it my way, never said anything more about it.[137]\\n1997–2011\\nReturn to Apple\\nSee also: Apple Inc. §\\xa01997–2007: Return to profitability\\n Jobs onstage at Macworld Conference & Expo, San Francisco, January 11, 2005\\nIn 1996, Apple announced that it would buy NeXT for $427\\xa0million. The deal was finalized in February 1997,[138] bringing Jobs back to the company he had cofounded. Jobs became de facto chief after then-CEO Gil Amelio was ousted in July 1997. He was formally named interim chief executive on September 16.[139] In March 1998, to concentrate Apple\\'s efforts on returning to profitability, Jobs terminated a number of projects, such as Newton, Cyberdog, and OpenDoc. In the coming months, many employees developed a fear of encountering Jobs while riding in the elevator, \"afraid that they might not have a job when the doors opened. The reality was that Jobs\\'s summary executions were rare, but a handful of victims was enough to terrorize a whole company.\"[140] Jobs changed the licensing program for Macintosh clones, making it too costly for the manufacturers to continue making machines.\\nWith the purchase of NeXT, much of the company\\'s technology found its way into Apple products, most notably NeXTSTEP, which evolved into Mac OS X. Under Jobs\\'s guidance, the company increased sales significantly with the introduction of the iMac and other new products; since then, appealing designs and powerful branding have worked well for Apple. At the 2000 Macworld Expo, Jobs officially dropped the \"interim\" modifier from his title at Apple and became permanent CEO.[141] Jobs quipped at the time that he would be using the title \"iCEO\".[142]\\nThe company subsequently branched out, introducing and improving upon other digital appliances. With the introduction of the iPod portable music player, iTunes digital music software, and the iTunes Store, the company made forays into consumer electronics and music distribution. On June 29, 2007, Apple entered the cellular phone business with the introduction of the iPhone, a multi-touch display cell phone, which also included the features of an iPod and, with its own mobile browser, revolutionized the mobile browsing scene. While nurturing open-ended innovation, Jobs also reminded his employees that \"real artists ship\".[143]\\nJobs had a public war of words with Dell Computer CEO Michael Dell, starting in 1987, when Jobs first criticized Dell for making \"un-innovative beige boxes\".[144] On October 6, 1997, at a Gartner Symposium, when Dell was asked what he would do if he ran the then-troubled Apple Computer company, he said: \"I\\'d shut it down and give the money back to the shareholders.\"[145] Then, in 2006, Jobs sent an email to all employees when Apple\\'s market capitalization rose above Dell\\'s. It read:\\n\\nTeam, it turned out that Michael Dell wasn\\'t perfect at predicting the future. Based on today\\'s stock market close, Apple is worth more than Dell. Stocks go up and down, and things may be different tomorrow, but I thought it was worth a moment of reflection today. Steve.[146]\\nJobs was both admired and criticized for his consummate skill at persuasion and salesmanship, which has been dubbed the \"reality distortion field\" and was particularly evident during his keynote speeches (colloquially known as \"Stevenotes\") at Macworld Expos and at Apple Worldwide Developers Conferences.[147]\\nJobs usually went to work wearing a black long-sleeved mock turtleneck made by Issey Miyake, Levi\\'s 501 blue jeans, and New Balance 991 sneakers.[148][149] Jobs told his biographer Walter Isaacson \"...he came to like the idea of having a uniform for himself, both because of its daily convenience (the rationale he claimed) and its ability to convey a signature style.\"[148]\\nJobs was a board member at Gap Inc. from 1999 to 2002.[150]\\n\\n Jobs and Bill Gates at the fifth D: All Things Digital conference (D5) in May 2007\\nIn 2001, Jobs was granted stock options in the amount of 7.5\\xa0million shares of Apple with an exercise price of $18.30. It was alleged that the options had been backdated, and that the exercise price should have been $21.10. It was further alleged that Jobs had thereby incurred taxable income of $20,000,000 that he did not report, and that Apple overstated its earnings by that same amount. As a result, Jobs potentially faced a number of criminal charges and civil penalties. The case was the subject of active criminal and civil government investigations,[151] though an independent internal Apple investigation completed on December 29, 2006 found that Jobs was unaware of these issues and that the options granted to him were returned without being exercised in 2003.[152]\\nIn 2005, Jobs responded to criticism of Apple\\'s poor recycling programs for e-waste in the US by lashing out at environmental and other advocates at Apple\\'s annual meeting in Cupertino in April. A few weeks later, Apple announced it would take back iPods for free at its retail stores. The Computer TakeBack Campaign responded by flying a banner from a plane over the Stanford University graduation at which Jobs was the commencement speaker. The banner read \"Steve, don\\'t be a mini-player—recycle all e-waste.\"\\nIn 2006, he further expanded Apple\\'s recycling programs to any US customer who buys a new Mac. This program includes shipping and \"environmentally friendly disposal\" of their old systems.[153] The success of Apple\\'s unique products and services provided several years of stable financial returns, propelling Apple to become the world\\'s most valuable publicly traded company in 2011.[154]\\nJobs was perceived as a demanding perfectionist[155][156] who always aspired to position his businesses and their products at the forefront of the information technology industry by foreseeing and setting innovation and style trends. He summed up this self-concept at the end of his keynote speech at the Macworld Conference and Expo in January 2007, by quoting ice hockey player Wayne Gretzky:\\n\\nThere\\'s an old Wayne Gretzky quote that I love. \"I skate to where the puck is going to be, not where it has been.\" And we\\'ve always tried to do that at Apple. Since the very, very beginning. And we always will.[157]\\n Jobs demonstrating the iPhone 4 to Russian President Dmitry Medvedev on June 23, 2010\\nOn July 1, 2008, a US$7 billion class action suit was filed against several members of the Apple board of directors for revenue lost because of alleged securities fraud.[158][159]\\nIn a 2011 interview with biographer Walter Isaacson, Jobs revealed that he had met with US President Barack Obama, complained about the nation\\'s shortage of software engineers, and told Obama that he was \"headed for a one-term presidency\".[160] Jobs proposed that any foreign student who got an engineering degree at a US university should automatically be offered a green card. After the meeting, Jobs commented, \"The president is very smart, but he kept explaining to us reasons why things can\\'t get done . . . . It infuriates me.\"[160]\\n\\nHealth problems\\nIn October 2003, Jobs was diagnosed with cancer. In mid 2004, he announced to his employees that he had a cancerous tumor in his pancreas.[161] The prognosis for pancreatic cancer is usually very poor;[162] Jobs stated that he had a rare, much less aggressive type, known as islet cell neuroendocrine tumor.[161]\\nDespite his diagnosis, Jobs resisted his doctors\\' recommendations for medical intervention for nine months,[163] instead relying on alternative medicine to thwart the disease. According to Harvard researcher Ramzi Amri, his choice of alternative treatment \"led to an unnecessarily early death\". Other doctors agree that Jobs\\'s diet was insufficient to address his disease. However, cancer researcher and alternative medicine critic David Gorski wrote that \"it\\'s impossible to know whether and by how much he might have decreased his chances of surviving his cancer through his flirtation with woo. My best guess was that Jobs probably only modestly decreased his chances of survival, if that.\"[164][165] Barrie R. Cassileth, the chief of Memorial Sloan Kettering Cancer Center\\'s integrative medicine department,[166] on the other hand, said, \"Jobs\\'s faith in alternative medicine likely cost him his life\\xa0... He had the only kind of pancreatic cancer that is treatable and curable\\xa0... He essentially committed suicide.\"[167] According to Jobs\\'s biographer, Walter Isaacson, \"for nine months he refused to undergo surgery for his pancreatic cancer – a decision he later regretted as his health declined\".[168] \"Instead, he tried a vegan diet, acupuncture, herbal remedies, and other treatments he found online, and even consulted a psychic. He was also influenced by a doctor who ran a clinic that advised juice fasts, bowel cleansings and other unproven approaches, before finally having surgery in July 2004.\"[169] He underwent a pancreaticoduodenectomy (or \"Whipple procedure\") that appeared to remove the tumor successfully.[170][171] Jobs did not receive chemotherapy or radiation therapy.[161][172] During Jobs\\'s absence, Tim Cook, head of worldwide sales and operations at Apple, ran the company.[161]\\nAs of January\\xa02006[update], only Jobs\\'s wife, his doctors, and Iger and his wife knew that his cancer had returned. Jobs told Iger privately that he hoped to live to see his son Reed\\'s high school graduation in 2010.[130] In early August 2006, Jobs delivered the keynote for Apple\\'s annual Worldwide Developers Conference. His \"thin, almost gaunt\" appearance and unusually \"listless\" delivery,[173][174] together with his choice to delegate significant portions of his keynote to other presenters, inspired a flurry of media and internet speculation about the state of his health.[175] In contrast, according to an Ars Technica journal report, Worldwide Developers Conference (WWDC) attendees who saw Jobs in person said he \"looked fine\".[176] Following the keynote, an Apple spokesperson said that \"Steve\\'s health is robust.\"[177]\\nTwo years later, similar concerns followed Jobs\\'s 2008 WWDC keynote address.[178] Apple officials stated that Jobs was victim to a \"common bug\" and was taking antibiotics,[179] while others surmised his cachectic appearance was due to the Whipple procedure.[172] During a July conference call discussing Apple earnings, participants responded to repeated questions about Jobs\\'s health by insisting that it was a \"private matter\". Others said that shareholders had a right to know more, given Jobs\\'s hands-on approach to running his company.[180][181] Based on an off-the-record phone conversation with Jobs, The New York Times reported, \"While his health problems amounted to a good deal more than \\'a common bug\\', they weren\\'t life-threatening and he doesn\\'t have a recurrence of cancer.\"[182]\\nOn August 28, 2008, Bloomberg mistakenly published a 2500-word obituary of Jobs in its corporate news service, containing blank spaces for his age and cause of death. News carriers customarily stockpile up-to-date obituaries to facilitate news delivery in the event of a well-known figure\\'s death. Although the error was promptly rectified, many news carriers and blogs reported on it,[183] intensifying rumors concerning Jobs\\'s health.[184] Jobs responded at Apple\\'s September 2008 Let\\'s Rock keynote by paraphrasing Mark Twain: \"Reports of my death are greatly exaggerated.\"[185][186] At a subsequent media event, Jobs concluded his presentation with a slide reading \"110/70\", referring to his blood pressure, stating he would not address further questions about his health.[187]\\nOn December 16, 2008, Apple announced that marketing vice-president Phil Schiller would deliver the company\\'s final keynote address at the Macworld Conference and Expo 2009, again reviving questions about Jobs\\'s health.[188][189] In a statement given on January 5, 2009, on Apple.com, Jobs said that he had been suffering from a \"hormone imbalance\" for several months.[190][191]\\nOn January 14, 2009, Jobs wrote in an internal Apple memo that in the previous week he had \"learned that my health-related issues are more complex than I originally thought\".[192] He announced a six-month leave of absence until the end of June 2009, to allow him to better focus on his health. Tim Cook, who previously acted as CEO in Jobs\\'s 2004 absence, became acting CEO of Apple, with Jobs still involved with \"major strategic decisions\".[192]\\nIn 2009, Tim Cook offered a portion of his liver to Jobs, since both share a rare blood type and the donor liver can regenerate tissue after such an operation. Jobs yelled, \"I\\'ll never let you do that. I\\'ll never do that.\"[193]\\nIn April 2009, Jobs underwent a liver transplant at Methodist University Hospital Transplant Institute in Memphis, Tennessee.[194][195][196] Jobs\\'s prognosis was described as \"excellent\".[194]\\n\\nResignation\\nOn January 17, 2011, a year and a half after Jobs returned to work following the liver transplant, Apple announced that he had been granted a medical leave of absence. Jobs announced his leave in a letter to employees, stating his decision was made \"so he could focus on his health\". As it did at the time of his 2009 medical leave, Apple announced that Tim Cook would run day-to-day operations and that Jobs would continue to be involved in major strategic decisions at the company.[197][198] While on leave, Jobs appeared at the iPad 2 launch event on March 2, the WWDC keynote introducing iCloud on June 6, and before the Cupertino City Council on June 7.[199]\\nOn August 24, 2011, Jobs announced his resignation as Apple\\'s CEO, writing to the board, \"I have always said if there ever came a day when I could no longer meet my duties and expectations as Apple\\'s CEO, I would be the first to let you know. Unfortunately, that day has come.\"[200] Jobs became chairman of the board and named Tim Cook as his successor as CEO.[201][202] Jobs continued to work for Apple until the day before his death six weeks later.[203][204][205]\\n\\n\\nDeath\\n Flags flying at half-staff outside Apple HQ in Cupertino, on the evening of Jobs\\'s death\\nJobs died at his Palo Alto, California, home around 3\\xa0p.m. (PDT) on October 5, 2011, due to complications from a relapse of his previously treated islet-cell pancreatic neuroendocrine tumor,[14][206][207] which resulted in respiratory arrest.[208] He had lost consciousness the day before and died with his wife, children, and sisters at his side.[209] His sister, Mona Simpson, described his death thus: \"Steve\\'s final words, hours earlier, were monosyllables, repeated three times. Before embarking, he\\'d looked at his sister Patty, then for a long time at his children, then at his life\\'s partner, Laurene, and then over their shoulders past them. Steve\\'s final words were: \\'Oh wow. Oh wow. Oh wow.\\'\" He then lost consciousness and died several hours later.[209] A small private funeral was held on October 7, 2011, the details of which, out of respect for Jobs\\'s family, were not made public.[210]\\nApple[211] and Pixar each issued announcements of his death.[212] Apple announced on the same day that they had no plans for a public service, but were encouraging \"well-wishers\" to send their remembrance messages to an email address created to receive such messages.[213] Apple and Microsoft both flew their flags at half-staff throughout their respective headquarters and campuses.[214][215]\\nBob Iger ordered all Disney properties, including Walt Disney World and Disneyland, to fly their flags at half-staff from October 6 to 12, 2011.[216] For two weeks  following his death, Apple displayed on its corporate Web site a simple page that showed Jobs\\'s name and lifespan next to his grayscale portrait.[217][218][219] On October 19, 2011, Apple employees held a private memorial service for Jobs on the Apple campus in Cupertino. Jobs\\'s widow, Laurene, was in attendance, as well as Cook, Bill Campbell, Norah Jones, Al Gore, and Coldplay.[220] Some of Apple\\'s retail stores closed briefly so employees could attend the memorial. A video of the service was uploaded to Apple\\'s website.[220]\\nCalifornia Governor Jerry Brown declared Sunday, October 16, 2011, to be \"Steve Jobs Day\".[221] On that day, an invitation-only memorial was held at Stanford University. Those in attendance included Apple and other tech company executives, members of the media, celebrities, close friends of Jobs, and politicians, along with Jobs\\'s family. Bono, Yo-Yo Ma, and Joan Baez performed at the service, which lasted longer than an hour. The service was highly secured, with guards at all of the university\\'s gates, and a helicopter flying overhead from an area news station.[222][223] Each attendee was given a small brown box as a \"farewell gift\" from Jobs. The box contained a copy of the Autobiography of a Yogi by Paramahansa Yogananda.[224]\\nChildhood friend and fellow Apple co-founder Steve Wozniak,[225] former owner of what would become Pixar, George Lucas,[226] former rival, Microsoft co-founder Bill Gates,[227] and President Barack Obama[228] all offered statements in response to his death.\\nPer his request, Jobs is buried in an unmarked grave at Alta Mesa Memorial Park, the only nonsectarian cemetery in Palo Alto.[229][230]\\nOn October 7, 2021, Apple released a commemorative YouTube video on the tenth anniversary of Jobs\\'s passing.[231]\\n\\nInnovations and designs\\nJobs\\'s design aesthetic was influenced by philosophies of Zen and Buddhism. In India, he experienced Buddhism while on his seven-month spiritual journey,[232] and his sense of intuition was influenced by the spiritual people with whom he studied.[232] He also learned from many references and sources, such as modernist architectural style of Joseph Eichler,[citation needed] and the industrial designs of Richard Sapper[233] and Dieter Rams.[citation needed]\\nAccording to Apple co-founder Steve Wozniak, \"Steve didn\\'t ever code. He wasn\\'t an engineer and he didn\\'t do any original design...\"[234][235] Daniel Kottke, one of Apple\\'s earliest employees and a college friend of Jobs\\'s, stated: \"Between Woz and Jobs, Woz was the innovator, the inventor. Steve Jobs was the marketing person.\"[236]\\nHe is listed as either primary inventor or co-inventor in 346 United States patents or patent applications related to a range of technologies from actual computer and portable devices to user interfaces (including touch-based), speakers, keyboards, power adapters, staircases, clasps, sleeves, lanyards and packages. Jobs\\'s contributions to most of his patents were to \"the look and feel of the product\". His industrial design chief Jonathan Ive had his name along with Jobs\\'s name for 200 of the patents.[237] Most of these are design patents (specific product designs; for example, Jobs listed as primary inventor in patents for both original and lamp-style iMacs, as well as PowerBook G4 Titanium) as opposed to utility patents (inventions).[238][239] He has 43 issued US patents on inventions.[238] The patent on the Mac OS X Dock user interface with \"magnification\" feature was issued the day before he died.[240] Although Jobs had little involvement in the engineering and technical side of the original Apple computers,[235] Jobs later used his CEO position to directly involve himself with product design.[241]\\nInvolved in many projects throughout his career was his long-time marketing executive and confidant Joanna Hoffman, known as one of the few employees at Apple and NeXT who could successfully stand up to Jobs while also engaging with him.[242]\\nEven while terminally ill in the hospital, Jobs sketched new devices that would hold the iPad in a hospital bed.[209] He also despised the oxygen monitor on his finger, and suggested ways to revise the design for simplicity.[243]\\nSince his death, the former Apple CEO has won 141 patents, more than most inventors win during their lifetimes. Currently, Jobs holds over 450 patents.[244]\\n\\nApple I\\nMain article: Apple I\\nAlthough entirely designed by Steve Wozniak, Jobs had the idea of selling the desktop computer, which led to the formation of Apple Computer in 1976. Both Jobs and Wozniak constructed several of the first Apple I prototypes by hand, and sold some of their belongings in order to do so. Eventually, 200 units were produced.[75]\\n\\nApple II\\n An Apple II with an external modem, designed primarily by Wozniak\\nMain article: Apple II series\\nThe Apple II is an 8-bit home computer, one of the world\\'s first highly successful mass-produced microcomputer products,[83] designed primarily by Wozniak (though Jobs oversaw the development of the Apple II\\'s unusual case[245] and Rod Holt developed the unique power supply[81]). It was introduced in 1977 at the West Coast Computer Faire by Jobs and Wozniak and was the first consumer product sold by Apple.\\n\\nApple Lisa\\nMain article: Apple Lisa\\nThe Lisa is a personal computer designed by Apple during the early 1980s. It was the first personal computer to offer a graphical user interface in a machine aimed at individual business users. Development of the Lisa began in 1978.[246] The Lisa sold poorly, with only 100,000 units sold.[247]\\nIn 1982, after Jobs was forced out of the Lisa project,[248] he joined the Macintosh project. The Macintosh is not a direct descendant of Lisa, although there are obvious similarities between the systems. The final revision, the Lisa 2/10, was modified and sold as the Macintosh XL.[249]\\n\\nMacintosh\\n Jobs holding up a MacBook Air at the MacWorld Conference & Expo in 2008\\nMain article: Macintosh\\nOnce he joined the original Macintosh team, Jobs took over the project after Wozniak had experienced a traumatic airplane accident and temporarily left the company.[95] Jobs introduced the Macintosh computer on January 24, 1984. This was the first mass-market personal computer featuring an integral graphical user interface and mouse.[250] This first model was later renamed to \"Macintosh 128k\" for uniqueness amongst a populous family of subsequently updated models which are also based on Apple\\'s same proprietary architecture. Since 1998, Apple has largely phased out the Macintosh name in favor of \"Mac\", though the product family has been nicknamed \"Mac\" or \"the Mac\" since the development of the first model. The Macintosh was introduced by a US$1.5\\xa0million Ridley Scott television commercial, \"1984\".[251] It most notably aired during the third quarter of Super Bowl XVIII on January 22, 1984, and some people consider the ad a \"watershed event\"[252] and a \"masterpiece\".[253] Regis McKenna called the ad \"more successful than the Mac itself\".[254] \"1984\" uses an unnamed heroine to represent the coming of the Macintosh (indicated by a Picasso-style picture of the computer on her white tank top) as a means of saving humanity from the conformity of IBM\\'s attempts to dominate the computer industry. The ad alludes to George Orwell\\'s novel, Nineteen Eighty-Four, which describes a dystopian future ruled by a televised \"Big Brother.\"[255][256]\\nThe Macintosh, however, was expensive, which hindered its ability to be competitive in a market already dominated by the Commodore 64 for consumers, as well as the IBM Personal Computer and its accompanying clone market for businesses.[257] Macintosh systems still found success in education and desktop publishing and kept Apple as the second-largest PC manufacturer for the next decade.\\n\\nNeXT Computer\\nMain article: NeXT Computer\\nAfter Jobs was forced out of Apple in 1985, he started NeXT, a workstation computer company. The NeXT Computer was introduced in 1988 at a lavish launch event. Using the NeXT Computer, Tim Berners-Lee created the world\\'s first web browser, the WorldWideWeb. The NeXT Computer\\'s operating system, named NeXTSTEP, begat Darwin, which is now the foundation of most of Apple\\'s products such as Macintosh\\'s macOS and iPhone\\'s iOS.[258][259]\\n\\niMac\\n The original iMac, introduced in 1998, was the first consumer-facing Apple product to debut under Jobs\\'s return.\\nMain article: iMac\\nApple iMac G3 was introduced in 1998 and its innovative design was directly the result of Jobs\\'s return to Apple. Apple boasted \"the back of our computer looks better than the front of anyone else\\'s.\"[260] Described as \"cartoonlike\", the first iMac, clad in Bondi Blue plastic, was unlike any personal computer that came before. In 1999, Apple introduced the Graphite gray Apple iMac and since has varied the shape, color and size considerably while maintaining the all-in-one design. Design ideas were intended to create a connection with the user such as the handle and a \"breathing\" light effect when the computer went to sleep.[261] The Apple iMac sold for $1,299 at that time. The iMac also featured forward-thinking changes, such as eschewing the floppy disk drive and moving exclusively to USB for connecting peripherals. This latter change resulted, through the iMac\\'s success, in the interface being popularized among third-party peripheral makers—as evidenced by the fact that many early USB peripherals were made of translucent plastic (to match the iMac design).[262]\\n\\niTunes\\nMain article: iTunes\\niTunes is a media player, media library, online radio broadcaster, and mobile device management application developed by Apple. It is used to play, download, and organize digital audio and video (as well as other types of media available on the iTunes Store) on personal computers running the macOS and Microsoft Windows operating systems. The iTunes Store is also available on the iPod Touch, iPhone, and iPad.\\nThrough the iTunes Store, users can purchase and download music, music videos, television shows, audiobooks, podcasts, movies, and movie rentals in some countries, and ringtones, available on the iPhone and iPod Touch (fourth generation onward). Application software for the iPhone, iPad and iPod Touch can be downloaded from the App Store.\\n\\niPod\\nMain article: iPod\\nThe first generation of iPod was released October 23, 2001. The major innovation of the iPod was its small size achieved by using a 1.8\" hard drive compared to the 2.5\" drives common to players at that time. The capacity of the first generation iPod ranged from 5\\xa0GB to 10\\xa0GB.[263] The iPod sold for US$399 and more than 100,000 iPods were sold before the end of 2001. The introduction of the iPod resulted in Apple becoming a major player in the music industry.[264] Also, the iPod\\'s success prepared the way for the iTunes music store and the iPhone.[265] After the first few generations of iPod, Apple released the touchscreen iPod Touch, the reduced-size iPod Mini and iPod Nano, and the screenless iPod Shuffle in the following years.[264]\\n\\niPhone\\n Jobs unveiling the iPhone at MacWorld Conference & Expo on January 9, 2007\\nMain article: iPhone\\nApple began work on the first iPhone in 2005 and the first iPhone was released on June 29, 2007. The iPhone created such a sensation that a survey indicated six out of ten Americans were aware of its release. Time declared it \"Invention of the Year\" for 2007 and included it in the All-TIME 100 Gadgets list in 2010, in the category of Communication[266].[267] The completed iPhone had multimedia capabilities and functioned as a quad-band touch screen smartphone.[268] A year later, the iPhone 3G was released in July 2008 with three key features: support for GPS, 3G data and tri-band UMTS/HSDPA. In June 2009, the iPhone 3GS, whose improvements included voice control, a better camera, and a faster processor, was introduced by Phil Schiller.[269] The iPhone 4 was thinner than previous models, had a five megapixel camera capable of recording video in 720p HD, and added a secondary front-facing camera for video calls.[270] A major feature of the iPhone 4S, introduced in October 2011, was Siri, a virtual assistant capable of voice recognition.[267]\\n\\niPad\\n Jobs introducing the iPad in San Francisco on January 27, 2010\\nMain article: iPad\\nThe iPad is an iOS-based line of tablet computers designed and marketed by Apple. The first iPad was released on April 3, 2010. The user interface is built around the device\\'s multi-touch screen, including a virtual keyboard. The iPad includes built-in Wi-Fi and cellular connectivity on select models. As of April 2015[update], more than 250 million iPads have been sold.[271]\\n\\nPersonal life\\n Jobs\\'s house in Palo Alto\\n Jobs\\'s house, as viewed from an adjacent sidewalk. Abundant fruit trees are visible next to the house.\\nMarriage\\nIn 1989, Jobs first met his future wife, Laurene Powell, when he gave a lecture at the Stanford Graduate School of Business, where she was a student. Soon after the event, he stated that Laurene \"was right there in the front row in the lecture hall, and I couldn\\'t take my eyes off of her ... kept losing my train of thought, and started feeling a little giddy.\"[19][page\\xa0needed] After the lecture, Jobs met up with her in the parking lot and invited her out to dinner. From that point forward, they were together, with a few minor exceptions, for the rest of his life.[19][page\\xa0needed]\\nJobs proposed on New Year\\'s Day 1990 with \"a fistful of freshly picked wildflowers\".[19][page\\xa0needed] They married on March 18, 1991, in a Buddhist ceremony at the Ahwahnee Hotel in Yosemite National Park.[19][page\\xa0needed] Fifty people, including Jobs\\'s father, Paul, and his sister Mona, attended. The ceremony was conducted by Jobs\\'s guru, Kobun Chino Otogawa. The vegan wedding cake was in the shape of Yosemite\\'s Half Dome, and the wedding ended with a hike (during which Laurene\\'s brothers had a snowball fight). Jobs is reported to have said to Mona: \"You see, Mona [...], Laurene is descended from Joe Namath, and we\\'re descended from John Muir.\"[272]\\nJobs\\'s and Powell\\'s first child, Reed, was born in September 1991.[273] Jobs\\'s father, Paul, died a year and a half later, on March 5, 1993. Jobs\\'s childhood home remains a tourist attraction and is currently owned by his stepmother (Paul\\'s second wife), Marilyn Jobs.[274]\\nJobs and Powell had two more children, Erin, born in August 1995, and Eve, born in May 1998.[273] The family lived in Palo Alto, California.[275] A journalist who grew up locally remembered him as owning the house with \"the scariest [Halloween] decorations in Palo Alto\\xa0... I don\\'t remember seeing him. I was busy being terrified.\"[276]\\nAlthough a billionaire, Jobs made it known that, like Bill Gates, he had stipulated that most of his monetary fortune would not be left to his children.[277][278] These technology leaders also had in common another family-related area: both men limited their children\\'s access, age appropriate, to social media, computer games and the Internet.[279][280]\\n\\nFamily\\nChrisann Brennan notes that after Jobs was forced out of Apple, \"he apologized many times over for his behavior\" towards her and Lisa. She also states that Jobs \"said that he never took responsibility when he should have, and that he was sorry\".[281] By this time, Jobs had developed a strong relationship with Lisa and when she was nine, Jobs had her name on her birth certificate changed from \"Lisa Brennan\" to \"Lisa Brennan-Jobs\".[13][page\\xa0needed] In addition, Jobs and Brennan developed a working relationship to co-parent Lisa, a change Brennan credits to the influence of his newly found biological sister, Mona Simpson (who worked to repair the relationship between Lisa and Jobs).[13][page\\xa0needed] Jobs found Mona after first finding his birth mother, Joanne Schieble Simpson, shortly after he left Apple.[282]\\nJobs did not contact his birth family during his adoptive mother Clara\\'s lifetime, however. He would later tell his official biographer Walter Isaacson: \"I never wanted [Paul and Clara] to feel like I didn\\'t consider them my parents, because they were totally my parents [...] I loved them so much that I never wanted them to know of my search, and I even had reporters keep it quiet when any of them found out.\"[282] However, in 1986, when Jobs was 31, Clara was diagnosed with lung cancer. He began to spend a great deal of time with her and learned more details about her background and his adoption, information that motivated him to find his biological mother. Jobs found on his birth certificate the name of the San Francisco doctor to whom Schieble had turned when she was pregnant. Although the doctor did not help Jobs while he was alive, he left a letter for Jobs to be opened upon his death. As he died soon afterwards, Jobs was given the letter which stated that \"his mother had been an unmarried graduate student from Wisconsin named Joanne Schieble.\"[282]\\nJobs only contacted Schieble after Clara died in early 1986 and after he received permission from his father, Paul. In addition, out of respect for Paul, he asked the media not to report on his search.[283] Jobs stated that he was motivated to find his birth mother out of both curiosity and a need \"to see if she was okay and to thank her, because I\\'m glad I didn\\'t end up as an abortion. She was twenty-three and she went through a lot to have me.\"[284] Schieble was emotional during their first meeting (though she wasn\\'t familiar with the history of Apple or Jobs\\'s role in it) and told him that she had been pressured into signing the adoption papers. She said that she regretted giving him up and repeatedly apologized to him for it. Jobs and Schieble would develop a friendly relationship throughout the rest of his life and would spend Christmas together.[285]\\nDuring this first visit, Schieble told Jobs that he had a sister, Mona, who was not aware that she had a brother.[284] Schieble then arranged for them to meet in New York where Mona worked. Her first impression of Jobs was that \"he was totally straightforward and lovely, just a normal and sweet guy.\"[286] Simpson and Jobs then went for a long walk to get to know each other.[286] Jobs later told his biographer that \"Mona was not completely thrilled at first to have me in her life and have her mother so emotionally affectionate toward me\\xa0... As we got to know each other, we became really good friends, and she is my family. I don\\'t know what I\\'d do without her. I can\\'t imagine a better sister. My adopted sister, Patty, and I were never close.\"[286]\\n\\n\\n\\n\"I grew up as an only child, with a single mother. Because we were poor and because I knew my father had emigrated from Syria, I imagined he looked like Omar Sharif. I hoped he would be rich and kind and would come into our lives (and our not-yet-furnished apartment) and help us. Later, after I\\'d met my father, I tried to believe he\\'d changed his number and left no forwarding address because he was an idealistic revolutionary, plotting a new world for the Arab people. Even as a feminist, my whole life I\\'d been waiting for a man to love, who could love me. For decades, I\\'d thought that man would be my father. When I was 25, I met that man, and he was my brother.\"\\n\\n\\n—Mona Simpson[209]\\n\\n\\nJobs then learned his family history. Six months after he was given up for adoption, Schieble\\'s father died, she wed Jandali, and they had a daughter, Mona.[3][287] Jandali states that after finishing his PhD he returned to Syria to work and that it was during this period that Schieble left him[3] (they divorced in 1962).[20] He also states that after the divorce he lost contact with Mona for a period of time: I also bear the responsibility for being away from my daughter when she was four years old, as her mother divorced me when I went to Syria, but we got back in touch after 10 years. We lost touch again when her mother moved and I didn\\'t know where she was, but since 10 years ago we\\'ve been in constant contact, and I see her three times a year. I organized a trip for her last year to visit Syria and Lebanon and she went with a relative from Florida.[3] A few years later, Schieble married an ice skating teacher, George Simpson.[287] Mona Jandali took her stepfather\\'s last name and thus became Mona Simpson. In 1970, after divorcing her second husband, Schieble took Mona to Los Angeles and raised her on her own.[287]\\nWhen Simpson found that their father, Abdulfattah Jandali, was living in Sacramento, California, Jobs had no interest in meeting him as he believed Jandali didn\\'t treat his children well.[288] Simpson went to Sacramento alone and met Jandali, who worked in a small restaurant.[289] Jandali and Simpson spoke for several hours, during which time he told her that he had left teaching for the restaurant business.[289] He also said that he and Schieble had given another child away for adoption but that \"we\\'ll never see that baby again. That baby\\'s gone.\"[289] At the request of Jobs, Simpson did not tell Jandali that she had met his son.[289] Jandali further told Simpson that he once managed a Mediterranean restaurant near San Jose and that \"all of the successful technology people used to come there. Even Steve Jobs ... oh yeah, he used to come in, and he was a sweet guy and a big tipper.\"[289]\\nAfter hearing about the visit, Jobs recalled that \"it was amazing ... I had been to that restaurant a few times, and I remember meeting the owner. He was Syrian. Balding. We shook hands.\"[289] However, Jobs still did not want to meet Jandali because \"I was a wealthy man by then, and I didn\\'t trust him not to try to blackmail me or go to the press about it ... I asked Mona not to tell him about me.\"[289] Jandali later discovered his relationship to Jobs through an online blog. He then contacted Simpson and asked \"what is this thing about Steve Jobs?\" Simpson told him that it was true and later commented, \"My father is thoughtful and a beautiful storyteller, but he is very, very passive ... He never contacted Steve.\"[285] Because Simpson herself researched her Syrian roots and began to meet members of the family, she assumed that Jobs would eventually want to meet their father, but he never did.[285] Jobs also never showed an interest in his Syrian heritage or the Middle East.[285] Simpson fictionalized the search for their father in her 1992 novel The Lost Father.[285] Malek Jandali is their cousin.[290]\\n\\nPhilanthropy\\nJobs kept his philanthropic and charitable efforts private; he donated $50 million to Stanford hospital and also contributed to efforts to cure AIDS.[291] He also formed his own charitable foundation called the Steven P. Jobs foundation in 1985.[292]\\n\\nHonors and awards\\n Statue of Jobs at Graphisoft Park, Budapest[293]\\n1985: National Medal of Technology (with Steve Wozniak), awarded by US President Ronald Reagan[294]\\n1987: Jefferson Award for Public Service[295]\\n1989: Entrepreneur of the Decade by Inc. magazine[296]\\n1991: Howard Vollum Award from Reed College[297]\\n2004–2010: Listed among the Time 100 Most Influential People in the World on five separate occasions.[citation needed]\\n2007: Named the most powerful person in business by Fortune magazine[298]\\n2007: Inducted into the California Hall of Fame, located at The California Museum for History, Women and the Arts[299]\\n2012: Grammy Trustees Award, an award for those who have influenced the music industry in areas unrelated to performance[300]\\n2012: Posthumously honored with an Edison Achievement Award for his commitment to innovation throughout his career.[301]\\n2013: Posthumously inducted as a Disney Legend[302]\\n2017: Steve Jobs Theatre opens at Apple Park[303]\\nIn popular culture\\nMain article: List of artistic depictions of Steve Jobs\\nSee also\\n\\n\\nSan Francisco Bay Area portal\\nSeva Foundation\\nTimeline of Steve Jobs media\\n\\nReferences\\n\\n\\n^ \"The Walt Disney Company and Affiliated Companies - Board of Directors\". October 14, 2009. Archived from the original on October 14, 2009. Retrieved September 18, 2018.\\n\\n^ \"Steve Jobs: adopted child who never met his biological father\". Daily Telegraph. October 6, 2011. ISSN\\xa00307-1235. Archived from the original on January 10, 2022. Retrieved September 18, 2018.\\n\\n^ a b c d e f \"The \\'father of invention\\'\". Saudi Gazette. January 18, 2011. Archived from the original on July 1, 2015. Retrieved June 27, 2015.\\n\\n^ a b Graff, Amy (November 18, 2015). \"Social media reminds us Steve Jobs was the son of a Syrian migrant\". SFGate. Hearst Communications. Archived from the original on May 19, 2016. Retrieved May 19, 2016.\\n\\n^ Baig, Edward C. \"Steve Jobs\\' biological father was Syrian migrant, some note\". USA Today. Archived from the original on May 28, 2020. Retrieved February 14, 2020.\\n\\n^ Meer, Ameena (Summer 1987). \"Artists in Conversation: Mona Simpson\". Bomb (20). Archived from the original on July 9, 2015. Retrieved July 7, 2015.\\n\\n^ a b c Shankland, Stephen. \"\\'Steve Jobs\\' biography: A wealth of detail\". CNET. Archived from the original on August 19, 2019. Retrieved August 19, 2019.\\n\\n^ a b Strochlic, Nina (April 23, 2015). \"Steve Jobs Took the Armenian Genocide Personally\". The Daily Beast. Archived from the original on February 7, 2022. Retrieved August 19, 2019 – via www.thedailybeast.com.\\n\\n^ Isaacson 2015, p.\\xa02.\\n\\n^ Pappas, Gregory (April 23, 2015). \"Steve Jobs\\' Almost Greek Connection and the Late Apple Founder\\'s Connection to the Armenian Genocide and the Smyrna Catastrophe\". Archived from the original on July 18, 2021. Retrieved July 18, 2021.\\n\\n^ \"The Lost Interview: Steve Jobs Tells Us What Really Matters\". Forbes. November 17, 2011. Archived from the original on September 24, 2015. Retrieved July 12, 2015.\\n\\n^ \"Steve Jobs: The Exotic And Tragic Family History of Apple\\'s Late Visionary\". HuffPost UK. August 28, 2012. Archived from the original on June 7, 2021. Retrieved June 7, 2021.\\n\\n^ a b c d e f g Brennan, Chrisann (2013). The Bite in the Apple: A Memoir of My Life with Steve Jobs. New York: St. Martin\\'s Press. p.\\xa015. ISBN\\xa09781250038760. Archived from the original on February 7, 2022. Retrieved September 10, 2020.\\n\\n^ a b c Markoff, John (October 5, 2011). \"Steven P. Jobs, 1955–2011: Apple\\'s Visionary Redefined Digital Age\". The New York Times. Archived from the original on December 19, 2020. Retrieved February 18, 2017.\\n\\n^ Isaacson 2011, pp.\\xa03–4.\\n\\n^ \"Even family life was full of drama - Latest News | Gadgets Now\". Gadget Now. Archived from the original on May 20, 2020. Retrieved February 14, 2020.\\n\\n^ \"Steve Jobs: A tribute to the cousin I never met\". gulfnews.com. Archived from the original on June 2, 2021. Retrieved May 30, 2021.\\n\\n^ Isaacson 2011, p.\\xa014.\\n\\n^ a b c d e f Schlender, Brent; Tetzeli, Rick (2015). Becoming Steve Jobs: The Evolution of a Reckless Upstart into a Visionary Leader. Crown (ebook).\\n\\n^ a b c Isaacson 2011, p.\\xa016.\\n\\n^ \"worked as a machinist\" Brashares, Ann (2001). Steve Jobs: Thinks Different. p.\\xa08. ISBN\\xa0978-0761-31393-9.\\n\\n^ \"struggling as a machinist and then a used-car salesman .. finance company ..  earned his realtor\\'s license. (but)\\ndownward spiral\" Malone, Michael S. (1999). Infinite Loop: How the World\\'s Most Insanely Great Computer Company Went Insane. ISBN\\xa00-385-48684-7. Archived from the original on August 7, 2020. Retrieved May 22, 2020.\\n\\n^ Isaacson 2011, p.\\xa05.\\n\\n^ DeBolt, Daniel (October 7, 2011). \"Steve Jobs called Mountain View home as a child\". Mountain View Voice. Archived from the original on December 4, 2019. Retrieved January 22, 2020. Hatt remembers Jobs attending Monta Loma elementary school and according to county property records, the Jobs family owned a house at 286 Diablo Avenue from 1959 to 1967.\\n\\n^ a b Isaacson 2011, pp.\\xa05–6.\\n\\n^ a b c d e f g h i j k l m n o p q r s t u Young, Jeffrey S. (1987). Steve Jobs: The Journey Is the Reward. Amazon Digital Services, 2011 ebook edition (originally Scott Foresman).[pages\\xa0needed]\\n\\n^ a b \"Steve Jobs\\' childhood home becomes a landmark\". mercurynews.com. October 29, 2013. Archived from the original on June 26, 2015. Retrieved June 26, 2015.\\n\\n^ a b Isaacson 2011, pp.\\xa012–13.\\n\\n^ Isaacson 2015, p.\\xa013.\\n\\n^ Isaacson 2011, pp.\\xa013–14.\\n\\n^ Isaacson 2011, pp.\\xa014.\\n\\n^ a b c d \"Steve Jobs\\' old garage about to become a piece of history\". mercurynews.com. September 27, 2013. Archived from the original on June 26, 2015. Retrieved June 26, 2015.\\n\\n^ a b Isaacson 2015, p.\\xa019.\\n\\n^ \"Steve Jobs and the Early Apple Years\". The PC Is Born. Joomla. Archived from the original on June 24, 2012. Retrieved March 27, 2012.\\n\\n^ McBurney, Sally (Director) (2013). Steve Jobs 1994 Uncut Interview with English Subtitles (Video). Menlo Park, California: Silicon Valley Historical Association.\\n\\n^ Isaacson 2015, p.\\xa030.\\n\\n^ Steve Jobs Interview about the Blue Box Story. Silicon Valley Historical Association. January 19, 2009. Archived from the original on April 2, 2013. Retrieved June 14, 2015 – via YouTube.\\n\\n^ a b McBurney, Sally (Director) (2013). Steve Jobs: Visionary Entrepreneur (Video). Menlo Park, California: Silicon Valley Historical Association.\\n\\n^ Isaacson 2011, p.\\xa019.\\n\\n^ Isaacson 2011, pp.\\xa031–32.\\n\\n^ Brennan, Chrisann (October 19, 2011). \"Jobs at 17: Nerd, Poet, Romantic\". Rolling Stone Magazine. Archived from the original on April 25, 2012. Retrieved February 9, 2015.\\n\\n^ Blumenthal, Karen (2012). Steve Jobs The Man Who Thought Different. A&C Black. ISBN\\xa09781408832073. pp.271–272\\n\\n^ Isaacson 2015, p.\\xa033.\\n\\n^ Isaacson 2015, p.\\xa037.\\n\\n^ Schlender 2016, p.\\xa030.\\n\\n^ a b Isaacson 2015, pp.\\xa040–41.\\n\\n^ John Naughton (October 8, 2011). \"Steve Jobs: Stanford commencement address, June 2005\". The Guardian. London. Archived from the original on February 11, 2012.\\n\\n^ Schlender, Brent (November 9, 1998). \"The Three Faces of Steve in this exclusive, personal conversation, Apple\\'s CEO reflects on the turnaround, and on how a wunderkind became an old pro\". Fortune. Archived from the original on April 8, 2015. Retrieved June 27, 2015.\\n\\n^ a b Isaacson 2011, pp.\\xa042–43.\\n\\n^ a b c d \"An exclusive interview with Daniel Kottke\". India Today. September 13, 2011. Archived from the original on May 18, 2012. Retrieved October 27, 2011.\\n\\n^ \"How Steve Wozniak\\'s Breakout Defined Apple\\'s Future\". Gameinformer. June 27, 2013. Archived from the original on November 1, 2013. Retrieved February 13, 2014.\\n\\n^ \"Cassidy on Nolan Bushnell: \\'Steve was difficult,\\' says man who first hired Steve Jobs\". Mercury News. March 29, 2013. Archived from the original on December 6, 2013. Retrieved April 2, 2013.\\n\\n^ \"What really shaped Steve Jobs\\'s view of India – Realms of intuition or the pains of Delhi belly?\". Economic Times. India. September 25, 2011. Archived from the original on May 11, 2012. Retrieved October 27, 2011.\\n\\n^ \"Il santone della Silicon Valley che ha conquistato i tecno-boss\" (in Italian). Repubblica.it. June 9, 2008. Archived from the original on June 24, 2012. Retrieved August 30, 2011.\\n\\n^ \"Wandering in India for 7 months: Steve Jobs\". Yahoo News. October 24, 2011. Archived from the original on June 24, 2012. Retrieved October 27, 2011.\\n\\n^ Andrews, Amanda (January 14, 2009). \"Steve Jobs, Apple\\'s iGod: Profile\". The Daily Telegraph. UK. Archived from the original on May 11, 2012. Retrieved October 29, 2009.\\n\\n^ \"Steve Jobs profile: Apple\\'s hard core\". Edinburgh: News scotsman. January 11, 2009. Archived from the original on September 26, 2011. Retrieved October 29, 2009.\\n\\n^ Markoff, John (2005). What the Dormouse Said: How the Sixties Counterculture Shaped the Personal Computer Industry. Penguin Books. p.\\xa0preface xix. ISBN\\xa0978-0-14-303676-0. Archived from the original on August 19, 2020. Retrieved October 5, 2011.\\n\\n^ \"Jobs\\'s Pentagon papers: kidnap fears, drug use and a speeding ticket\". The Sydney Morning Herald. Archived from the original on June 24, 2012. Retrieved June 12, 2012.\\n\\n^ Silberman, Steve (October 28, 2011). \"What Kind of Buddhist was Steve Jobs, Really?\". NeuroTribes. Archived from the original on June 24, 2012. Retrieved December 29, 2011.\\n\\n^ Burke, Daniel (November 2, 2011). \"Steve Jobs\\' private spirituality now an open book\". USA Today. Archived from the original on September 14, 2012. Retrieved December 29, 2011.\\n\\n^ Isaacson 2011, pp.\\xa052–54.\\n\\n^ Murphy, Conor. \"The History of Breakout\". Big Fish. Big Fish Games, Inc. Archived from the original on May 28, 2015. Retrieved April 22, 2015.\\n\\n^ \"Letters – General Questions Answered\". Woz.org. Archived from the original on June 12, 2011. Retrieved June 20, 2016.Wozniak, Steve (2006). iWoz. W. W. Norton. a: pp. 147–48, b: p. 180. ISBN\\xa0978-0-393-06143-7.Kent, Steven (2001). The Ultimate History of Video Games. Three Rivers. pp.\\xa071–73. ISBN\\xa0978-0-7615-3643-7.\"Breakout\". Arcade History. June 25, 2002. Archived from the original on January 5, 2016. Retrieved April 19, 2010.\"Classic Gaming: A Complete History of Breakout\". GameSpy. Archived from the original on June 23, 2014. Retrieved April 19, 2010.\\n\\n^ Isaacson 2015, pp.\\xa0104–107.\\n\\n^ Linzmayer 2004, pp.\\xa05–6.\\n\\n^ a b Linzmayer 2004, pp.\\xa06–8.\\n\\n^ Linzmayer, Owen W. \"Apple Confidential: The Real Story of Apple Computer, Inc\". The Denver Post. Archived from the original on March 20, 2012.\\n\\n^ Simon, Dan (June 24, 2010). \"The gambling man who co-founded Apple and left for $800\". CNN. Archived from the original on April 10, 2014. Retrieved June 24, 2010.\\n\\n^ \"How Did Apple Computer Get Its Brand Name?\". Branding Strategy Insider. November 17, 2011. Archived from the original on July 4, 2017. Retrieved November 6, 2017.\\n\\n^ a b Linzmayer, pp.\\xa05–7.\\n\\n^ a b Schlender 2016, pp.\\xa039–40.\\n\\n^ Isaacson 2015, pp.\\xa066–68.\\n\\n^ Linzmayer, pp.\\xa07–9.\\n\\n^ a b Williams, Gregg; Moore, Rob (December 1984). \"The Apple Story / Part 1: Early History\". BYTE (interview). p.\\xa0A67. Retrieved November 16, 2019.\\n\\n^ Markoff, John (September 1, 1997). \"An \\'Unknown\\' Co-Founder Leaves After 20 Years of Glory and Turmoil\". The New York Times. Archived from the original on January 2, 2018. Retrieved August 24, 2011.\\n\\n^ \"Done Deals: Venture Capitalists Tell Their Story: Featured HBS Arthur Rock\". HBS Working Knowledge. Archived from the original on August 16, 2019. Retrieved June 23, 2018.\\n\\n^ Isaacson 2011, pp.\\xa081–83.\\n\\n^ Linzmayer 2004, p.\\xa011.\\n\\n^ Linzmayer 2004, p.\\xa012.\\n\\n^ a b Wozniak, Steve. \"woz.org: Comment From e-mail: Why didn\\'t the early Apple II\\'s use Fans?\". woz.org. Archived from the original on December 26, 2015. Retrieved May 10, 2015.\\n\\n^ Wozniak, Steve; Smith, Gina (2006). iWoz: Computer Geek to Cult Icon: How I Invented the Personal Computer, Co-Founded Apple, and Had Fun Doing It. W. W. Norton & Company. ISBN\\xa00-393-06143-4. OCLC\\xa0502898652.\\n\\n^ a b Reimer, Jeremy (December 15, 2005). \"Total share: 30 years of personal computer market share figures\". Ars Technica. Condé Nast. Archived from the original on July 2, 2012. Retrieved May 25, 2010.\\n\\n^ Edwards, Jim (December 26, 2013). \"These Pictures of Apple\\'s First Employees Are Absolutely Wonderful\". Business Insider. Archived from the original on July 31, 2020. Retrieved January 19, 2015.\\n\\n^ a b Isaacson 2015, pp.\\xa088–89.\\n\\n^ Metz, Rachel (October 15, 2013). \"Steve Jobs\\' ex-girlfriend pens memoir on life with \\'vicious\\' Apple founder\". The Guardian. Archived from the original on June 6, 2015. Retrieved January 17, 2015.\\n\\n^ Bullock, Diane (August 31, 2010). \"The Kids of Business Icons: Lisa Brennan-Jobs\". Minyanville. Archived from the original on August 31, 2012. Retrieved October 6, 2011.\\n\\n^ Isaacson 2015, p.\\xa093.\\n\\n^ \"Machine of the Year: The Computer Moves in\". Time, January 3, 1983\\n\\n^ a b c Cocks Jay. Reported by Michael Moritz. \"The Updated Book of Jobs Archived February 9, 2015, at the Wayback Machine\" in \"Machine of the Year: The Computer Moves in\". Time, January 3, 1983:27.\\n\\n^ \"Steve Jobs: Net Worth | Investopedia\". Investopedia. October 14, 2015. Archived from the original on July 30, 2018. Retrieved July 30, 2018.\\n\\n^ \"Photos: The Historic House Steve Jobs Demolished\". Wired. February 17, 2011. Archived from the original on June 3, 2012. Retrieved March 11, 2017.\\n\\n^ Isaacson 2015, pp.\\xa0386–387.\\n\\n^ Lee, Henry K. (February 15, 2011). \"Steve Jobs\\' historic Woodside mansion is torn down\". The San Francisco Chronicle. Archived from the original on December 25, 2011. Retrieved February 7, 2022.\\n\\n^ a b c \"Steve Wozniak on Newton, Tesla, and why the original Macintosh was a \\'lousy\\' product\". June 27, 2013. Archived from the original on March 12, 2016. Retrieved June 28, 2013.\\n\\n^ O\\'Grady, Jason D. (2009). Apple Inc. ABC-CLIO. ISBN\\xa09780313362446. pp. 8–10\\n\\n^ Isaacson 2015, pp.\\xa0109–112.\\n\\n^ Linzmayer 2004, pp.\\xa0110–113.\\n\\n^ Isaacson 2015, pp.\\xa0167–170.\\n\\n^ Schlender, Brent; Tetzeli, Rick (2016). Becoming Steve Jobs: The Evolution of a Reckless Upstart into a Visionary Leader. Crown Business; Reprint edition. ISBN\\xa09780385347426. pp.82–83\\n\\n^ Hertzfeld, Andy. \"The Times They Are A-Changin\\'\". folklore.org. Archived from the original on February 4, 2012.\\n\\n^ Kahney, Leander (January 6, 2004). \"Wired News: We\\'re All Mac Users Now\". Wired News. Archived from the original on January 4, 2014. Retrieved September 20, 2006.\\n\\n^ \"America\\'s Most Admired Companies: Jobs\\' journey timeline\". Fortune. Archived from the original on April 10, 2014. Retrieved May 24, 2010. Jobs and a team of engineers visit Xerox PARC, where they see a demo of mouse and graphical user interface\\n\\n^ a b c Isaacson 2015, pp.\\xa0185–187.\\n\\n^ a b c Schlender 2016, pp.\\xa084–88.\\n\\n^ Linzmayer 2004, p.\\xa098.\\n\\n^ \"Machine That Changed The World, The; Paperback Computer, The; Interview with Steve Jobs, 1990\". Open Vault. WGBH Media Library & Archives. May 14, 1990. Archived from the original on September 20, 2016. Retrieved September 15, 2016.\\n\\n^ Robbeloth, DeWitt (October–November 1985). \"Whither Apple?\". II Computing. p.\\xa08. Retrieved January 28, 2015.\\n\\n^ Rice, Valerie (April 15, 1985). \"Unrecognized Apple II Employees Exit\". InfoWorld. p.\\xa035. Archived from the original on May 14, 2021. Retrieved February 4, 2015.\\n\\n^ Bunnell, David (April 30, 2010). \"Chapter 10: Steve Thumbs his Nose at the Apple II\". My Close Encounters With Steve Jobs. Archived from the original on July 19, 2019. Retrieved November 12, 2019 – via Cult of Mac.\\n\\n^ \"I Never Left Apple\". Woz.org. January 3, 2018. Archived from the original on March 27, 2019. Retrieved November 12, 2019.\\n\\n^ Krishnamoorthy, Anand; Li, Susan (October 6, 2011). \"Jobs\\'s Death Was Like Lennon, JFK Getting Shot, Wozniak Says\". Bloomberg Businessweek. Archived from the original on November 12, 2019. Retrieved November 12, 2019.\\n\\n^ a b c d e f Swaine, Michael and Paul Frieberger. Fire in the Valley: The Birth and Death of the Personal Computer, 3rd Edition, Dallas: Pragmatic Bookshelf, 2014\\n\\n^ Spector, G (September 24, 1985). \"Apple\\'s Jobs Starts New Firm, Targets Education Market\". PC Week. p.\\xa0109.\\n\\n^ Linzmayer 2004, p.\\xa0208.\\n\\n^ Schwartz, John (October 24, 1988). \"Steve Jobs Comes Back\". Newsweek. Palo Alto, California. p.\\xa0Business. Archived from the original on October 14, 2014. Retrieved October 20, 2014.\\n\\n^ \"NeXT Timeline\". Archived from the original on February 3, 2015. Retrieved January 21, 2015.\\n\\n^ Schlender, Brenton R. (October 13, 1988). \"Next Project: Apple Era Behind Him, Steve Jobs Tries Again, Using a New System\". The Wall Street Journal (Western\\xa0ed.). Palo Alto, California: Dow Jones & Company Inc. p.\\xa0Front Page Leader. Archived from the original on October 20, 2014. Retrieved October 20, 2014.\\n\\n^ Rose, F. (April 23, 2009). Rose, Frank (August 24, 2011). \"The End of Innocence at Apple: What Happened After Steve Jobs was Fired\". Wired. Archived from the original on October 7, 2011. Retrieved March 11, 2017.. Wired.\\n\\n^ \"Welcome to info.cern.ch: The website of the world\\'s first-ever web server\". CERN (European Organization for Nuclear Research). 2008. Archived from the original on January 18, 2010. Retrieved November 1, 2011.\\n\\n^ Computimes. (May 31, 1990). Interpersonal computing\\xa0–  the third revolution? Archived April 29, 2016, at the Wayback Machine. New Straits Times. (230), 20; Schlender, B. R., Alpert, M. (February 12, 1990). Schlender, Brenton R. (February 12, 1990). \"Who\\'s ahead in the computer wars\". CNN. Archived from the original on November 29, 2020. Retrieved August 3, 2020.. Fortune.\\n\\n^ Stross, R. E. (1993). Steve Jobs and the NeXT Big Thing. Atheneum. ISBN\\xa0978-0-689-12135-7. pp. 117, 120, 246.\\n\\n^ a b O\\'Grady, J. (2008). Apple Inc. Greenwood Press. ISBN\\xa0978-0-313-36244-6.[pages\\xa0needed]\\n\\n^ Linzmayer 2004, p.\\xa0213.\\n\\n^ Smith, Alvy Ray. \"Pixar Founding Documents\". Alvy Ray Smith Homepage. Archived from the original on April 27, 2005. Retrieved January 11, 2011.\\n\\n^ \"Pixar\\'s \\'Brave\\' Honors Steve Jobs\". The Hollywood Reporter. May 25, 2012. Archived from the original on February 14, 2021. Retrieved February 8, 2021.\\n\\n^ Hill, Jim (February 5, 2012). \"Steve Jobs bio reveals how Michael Eisner actively tried to derail Disney\\'s 2006 acquisition of Pixar\". Jim Hill Media. Archived from the original on June 24, 2012. Retrieved February 10, 2012.\\n\\n^ McClintock, Pamela (February 24, 2013). \"Oscars 2013: Brenda Chapman\\'s \\'Brave\\' Win a Vindication After Being Fired From the Project\". The Hollywood Reporter. Archived from the original on April 20, 2021. Retrieved May 1, 2021.\\n\\n^ Wolff, Michael, \"iPod, Therefore I am\". Vanity Fair. October 10, 2006. Archived from the original on March 28, 2014., Vanity Fair, April 2006. Retrieved September 3, 2010.\\n\\n^ a b c Iger, Robert (September 18, 2019). \"\\'We Could Say Anything to Each Other\\': Bob Iger Remembers Steve Jobs\". Vanity Fair. Archived from the original on March 10, 2021. Retrieved February 7, 2022.\\n\\n^ a b January 25, 2006 \"Disney buys Pixar for $7.4 bn\". Archived from the original on November 9, 2013., rediff.com\\n\\n^ \"The Walt Disney Company – Steve Jobs Biography\". Archived from the original on April 26, 2012. Retrieved June 22, 2008.Holson, Laura M. (January 25, 2006). \"Disney Agrees to Acquire Pixar in a $7.4\\xa0Billion Deal\". The New York Times. Archived from the original on October 9, 2011. Retrieved January 17, 2010.\"Pixar Becomes Unit of Disney\". The New York Times. Associated Press. May 6, 2006. Archived from the original on April 23, 2011. Retrieved January 17, 2010.\\n\\n^ \"Steve Jobs, 1955–2011\". Splashnogly. October 6, 2011. Archived from the original on April 7, 2012. Retrieved January 15, 2012.\\n\\n^ \"Jobs\\'s 7.7% Disney Stake Transfers to Trust Led by Widow Laurene\". Bloomberg. Archived from the original on April 10, 2014.\\n\\n^ Norman, Floyd (January 19, 2009). \"Steve Jobs: A Tough Act to Follow\". Jim Hill Media. Archived from the original on May 8, 2010. Retrieved January 19, 2009.\\n\\n^ Catmull, Edwin; Wallace, Amy (2014). Creativity, Inc.: Overcoming the Unseen Forces That Stand in the Way of True Inspiration. Transworld Publishers Limited. ISBN\\xa0978-0552167260.\\n\\n^ Bort, Julie (June 5, 2014). \"Steve Jobs Taught This Man How To Win Arguments With Really Stubborn People\". Inc. Monsueto Ventures. Archived from the original on June 8, 2014. Retrieved June 8, 2014.\\n\\n^ Apple Computer, Inc. Finalizes Acquisition of NeXT Software Inc. at the Wayback Machine (archive index), Apple Inc., February 7, 1997. Retrieved June 25, 2006.\\n\\n^ \"Apple Formally Names Jobs as Interim Chief\". The New York Times. September 17, 1997. Archived from the original on November 17, 2017. Retrieved June 27, 2011.\\n\\n^ \"The once and future Steve Jobs\". Salon.com. October 11, 2000. Archived from the original on April 16, 2009.\\n\\n^ Norr, Henry (January 6, 2000). \"MacWorld Expo/Permanent Jobs/Apple CEO finally drops \\'interim\\' from title\". San Francisco Chronicle. Archived from the original on November 2, 2011. Retrieved June 27, 2011.\\n\\n^ \"Jobs announces new MacOS, becomes \\'iCEO\\'\". CNN. January 5, 2000. Archived from the original on August 20, 2013.\\n\\n^ Levy, Steven (1995). Insanely Great: The Life and Times of Macintosh, the Computer That Changed Everything. Penguin Books. p.\\xa0312. ISBN\\xa0978-0-14-023237-0. Archived from the original on August 20, 2020. Retrieved May 6, 2020.\\n\\n^ \"If Apple can go home again, why not Dell?\". Archived from the original on October 10, 2011. Retrieved January 5, 2009. CNET News. May 19, 2008.\\n\\n^ \"Dell: Apple should close shop\". CNET. Archived from the original on May 17, 2008.\\n\\n^ Markoff, John (January 16, 2006). \"Michael Dell Should Eat His Words, Apple Chief Suggests\". The New York Times. Archived from the original on June 4, 2012. Retrieved May 24, 2010.\\n\\n^ \"11 Presentation Lessons You Can Still Learn From Steve Jobs\". Forbes. May 28, 2014. Archived from the original on June 5, 2014. Retrieved June 16, 2014.\\n\\n^ a b \"Steve Jobs\\' black turtleneck reportedly explained in biography\". The Los Angeles Times. October 11, 2011. Archived from the original on October 26, 2011. Retrieved October 14, 2011.\\n\\n^ \"Wear the Exact Outfit of Steve Jobs for $458\". Gizmodo. February 28, 2006. Archived from the original on February 4, 2012. Retrieved April 19, 2010.\\n\\n^ Liedtke, Michael (October 5, 2002). \"Steve Jobs resigns from Gap\\'s board\". The Berkeley Daily Planet. Archived from the original on April 19, 2012. Retrieved December 23, 2011.\\n\\n^ \"New questions raised about Steve Jobs\\'s role in Apple stock options scandal\". December 28, 2006. Archived from the original on May 9, 2007.\\n\\n^ \"Apple restates, acknowledges faked documents\". EE Times. December 29, 2006. Archived from the original on May 21, 2013. Retrieved January 1, 2007.\\n\\n^ \"Apple Improves Recycling Plan\". PC Magazine. April 21, 2006. Archived from the original on October 20, 2008.\\n\\n^ Nick Bilton, Bilton, Nick (August 9, 2011). \"Apple Is the Most Valuable Company\". The New York Times. Archived from the original on February 25, 2012. Retrieved February 24, 2012., New York Times, August 9, 2011\\n\\n^ \"7.30\". ABCnet.au. October 6, 2011. Archived from the original on October 9, 2011. Retrieved November 12, 2011.\\n\\n^ \"Lateline: \"Visionary Steve Jobs succumbs to cancer\"\". ABCnet.au. October 6, 2011. Archived from the original on October 9, 2011. Retrieved November 12, 2011.\\n\\n^ \"Live from Macworld 2007: Steve Jobs keynote\". 2007. Archived from the original on June 24, 2012. Retrieved April 19, 2010.\\n\\n^ \"Group Wants $7B USD From Apple, Steve Jobs, Executives Over Securities Fraud\". Archived from the original on February 4, 2012. Retrieved July 2, 2008.\\n\\n^ \"Apple, Steve Jobs, Executives, Board, Sued For Securities Fraud\". Archived from the original on May 19, 2009.\\n\\n^ a b Andrew S. Ross (November 1, 2011). \"Steve Jobs bio sheds light on Obama relationship\". San Francisco Chronicle. Archived from the original on November 4, 2011. Retrieved November 12, 2011.\\n\\n^ a b c d Evangelista, Benny (August 2, 2004). \"Apple\\'s Jobs has cancerous tumor removed\". San Francisco Chronicle. p.\\xa0A1. Archived from the original on August 18, 2006. Retrieved August 9, 2006.\\n\\n^ \"Steve Jobs and the Celebrity Diagnosis Complete Guide to Tumors of the Pancreas\". Celebrity Diagnosis. October 6, 2011. Archived from the original on June 24, 2012. Retrieved November 12, 2011.\\n\\n^ Elkind, Peter (March 5, 2008). \"The trouble with Steve Jobs\". Fortune. Archived from the original on May 18, 2010. Retrieved March 5, 2008.\\n\\n^ Fiore, Kristina (December 28, 2012). \"Jobs Leaves Lessons for Cancer Care\". MedPage Today. Archived from the original on April 10, 2014. Retrieved July 14, 2013.\\n\\n^ Gorski, David (October 31, 2011). \"\"And one more thing\" about Steve Jobs\\' battle with cancer\". Science-Based Medicine. Archived from the original on May 11, 2020. Retrieved October 9, 2020.\\n\\n^ Physician Biography for Barrie R. Cassileth. Archived November 13, 2011, at the Wayback Machine\\n\\n^ Liz Szabo (June 18, 2013). \"Book raises alarms about alternative medicine\". USA Today. Archived from the original on June 18, 2013. Retrieved June 19, 2013.\\n\\n^ Ned Potter. \"Steve Jobs Regretted Delaying Cancer Surgery 9 Months, Biographer Says\". ABC News. Archived from the original on April 10, 2014. ABC News October 20, 2011\\n\\n^ \"Bio Sheds Light on Steve Jobs\\' Decision to Delay Cancer Surgery, Pursue Herbal Remedies\". Fox News. October 20, 2011. Archived from the original on June 26, 2012. Associated Press October 20, 2011\\n\\n^ \"Pancreatic Cancer Treatment\". Mayo Clinic. Archived from the original on February 4, 2012. Retrieved April 19, 2010.\\n\\n^ Markoff, John (July 23, 2008). \"Talk of Chief\\'s Health Weighs on Apple\\'s Share Price\". The New York Times. Archived from the original on March 18, 2017. Retrieved February 18, 2017.\\n\\n^ a b Elmer, Philip (June 13, 2008). \"Steve Jobs and Whipple\". Fortune. Archived from the original on June 24, 2012. Retrieved April 19, 2010.\\n\\n^ Kahney, Leander (August 8, 2006). \"Has Steve Jobs Lost His Magic?\". Cult of Mac. Wired News. Archived from the original on February 4, 2012. Retrieved August 8, 2006. Looking very thin, almost gaunt, Jobs used the 90-minute presentation to introduce a new desktop Mac and preview the next version of Apple\\'s operating system, code-named Leopard.\\n\\n^ Meyers, Michelle. \"Jobs speech wasn\\'t very Jobs-like\". BLOGMA. CNET News.com. Archived from the original on December 25, 2007. Retrieved August 8, 2006. [The audience was] uninspired (and concerned) by Jobs\\'s relatively listless delivery\\n\\n^ Saracevic, Al (August 9, 2006). \"Where\\'s Jobs\\' Mojo?\". San Francisco Chronicle. p.\\xa0C1. Archived from the original on January 28, 2012. Retrieved August 9, 2006.\\n\\n^ Cheng, Jacqui (August 8, 2006). \"What happened to The Steve we know and love?\". Ars Technica. Archived from the original on February 4, 2012. Retrieved August 8, 2006.\\n\\n^ Claburn, Thomas (August 11, 2006). \"Steve Jobs Lives!\". InformationWeek. Archived from the original on February 4, 2012. Retrieved October 9, 2007.\\n\\n^ \"Business Technology: Steve Jobs\\'s Appearance Grabs Notice, Not Just the IPhone\". The Wall Street Journal. Archived from the original on April 26, 2009. Retrieved April 19, 2010.\\n\\n^ \"Apple says Steve Jobs feeling a little under the weather\". Archived from the original on April 10, 2014. in AppleInsider.\\n\\n^ \"Steve Jobs and Apple\". Archived from the original on April 10, 2014. Marketing Doctor Blog. July 24, 2008.\\n\\n^ \"Steve Jobs Did Not Have \\'Pancreatic Cancer\\'\". Medpagetoday.com. January 24, 2011. Archived from the original on June 24, 2012. Retrieved November 12, 2011.\\n\\n^ Joe Nocera (July 26, 2008). \"Apple\\'s Culture of Secrecy\". The New York Times. Archived from the original on March 5, 2017. Retrieved February 18, 2017. While his health problems amounted to a good deal more than \\'a common bug,\\' they weren\\'t life-threatening and he doesn\\'t have a recurrence of cancer.\\n\\n^ \"Steve Jobs\\'s Obituary, As Run By Bloomberg\". Gawker Media. August 27, 2008. Archived from the original on February 4, 2012. Retrieved August 28, 2008.\\n\\n^ \"Bloomberg publishes Jobs obit but why?\". Zdnet Blogs. ZDnet. August 28, 2008. Archived from the original on August 31, 2008. Retrieved August 29, 2008.\\n\\n^ Mikkelson, Barbara (September 26, 2007). \"And Never The Twain Shall Tweet\". Snopes.com. Archived from the original on August 22, 2011. Retrieved November 2, 2012.\\n\\n^ \"Apple posts \\'Lets Rock\\' event video\". Macworld. September 10, 2008. Archived from the original on February 4, 2012. Retrieved September 11, 2008.\\n\\n^ \"Live from Apple\\'s \"spotlight turns to notebooks\" event\". Engadget. October 14, 2008. Archived from the original on June 24, 2012. Retrieved October 14, 2008.\\n\\n^ Stone, Brad (December 17, 2008). \"Apple\\'s Chief to Skip Macworld, Fueling Speculation\". The New York Times. Archived from the original on December 6, 2011. Retrieved May 24, 2010.\\n\\n^ \"Steve Jobs\\' Health Declining Rapidly, Reason for Macworld Cancellation\". Gizmodo. December 30, 2008. Archived from the original on June 24, 2012. Retrieved April 19, 2010.\\n\\n^ \"Apple\\'s Jobs admits poor health\". BBC News. January 5, 2009. Archived from the original on August 25, 2011. Retrieved January 5, 2009.\\n\\n^ Jobs, Steve (January 5, 2009). \"Letter from Apple CEO Steve Jobs\" (Press release). Apple Inc. Archived from the original on February 4, 2012. Retrieved January 20, 2009.\\n\\n^ a b \"Apple Media Advisory\" (Press release). Apple Inc. January 14, 2009. Archived from the original on February 4, 2012. Retrieved January 14, 2009.\\n\\n^ \"I BEG YOU, mighty Jobs, TAKE MY LIVER, Cook told Apple\\'s dying co-founder\". The Register. March 13, 2015. Archived from the original on August 16, 2017. Retrieved August 22, 2017.\\n\\n^ a b \"Steve Jobs recovering after liver transplant\". CNN. June 23, 2009. Archived from the original on March 31, 2014. Retrieved April 19, 2010.\\n\\n^ \"Liver Transplant in Memphis: Jobs\\' was Sickest Patient on Waiting List\". Celebrity Diagnosis. June 24, 2009. Archived from the original on June 24, 2012.\\n\\n^ Grady, Denise; Meier, Barry (June 22, 2009). \"A Transplant That Is Raising Many Questions\". The New York Times. Archived from the original on April 22, 2017. Retrieved February 18, 2017.\\n\\n^ Helft, Miguel (January 17, 2010). \"Apple Says Steve Jobs Will Take a New Medical Leave\". The New York Times. Archived from the original on March 18, 2017. Retrieved January 17, 2010.\\n\\n^ \"Steve Jobs to take medical leave of absence but remain Apple CEO\". Archived from the original on February 4, 2012.\\n\\n^ Abell, John (June 8, 2011). \"Video: Jobs Pitches New \\'Mothership\\' to Approving Cupertino City Council\". Wired. Archived from the original on February 4, 2012. Retrieved June 9, 2011.\\n\\n^ Letter from Steve Jobs To the Apple Board of Directors and the Apple Community (resignation letter August 24, 2011) Archived April 15, 2012, at WebCite\\n\\n^ \"Apple Resignation Letter\" (Press release). Apple Inc. Archived from the original on April 15, 2012. Retrieved August 29, 2011.\\n\\n^ \"Steve Jobs Resigns as CEO of Apple\" (Press release). Apple Inc. August 24, 2011. Archived from the original on April 15, 2012. Retrieved August 24, 2011.\\n\\n^ Biddle, Sam (October 19, 2011). \"Steve Jobs Worked the Day Before He Died\". Gizmodo. Archived from the original on June 24, 2012. Retrieved October 21, 2011.\\n\\n^ Gupta, Poornima (August 18, 2011). \"Steve Jobs Quits\". Reuters. Archived from the original on February 4, 2012. Retrieved August 25, 2011.\\n\\n^ Siegler, M.G. \"Steve Jobs Resigns As CEO of Apple\". TechCrunch. Archived from the original on August 25, 2011. Retrieved August 25, 2011.\\n\\n^ \"Rare Pancreatic Cancer Caused Steve Jobs\\' Death\" (Press release). Voice of America. October 7, 2011. Archived from the original on January 24, 2012. Retrieved October 7, 2011.\\n\\n^ Rushe, Dominic (October 6, 2011). \"Steve Jobs, Apple co-founder, dies at 56\". The Guardian. UK. Archived from the original on June 19, 2013.\\n\\n^ Gullo, Karen (October 10, 2011). \"Steve Jobs Died at Home of Respiratory Arrest Related to Pancreatic Cancer\". Bloomberg L.P. Archived from the original on February 10, 2012. Retrieved February 10, 2012.\\n\\n^ a b c d Simpson, Mona (October 30, 2011). \"A Sister\\'s Eulogy for Steve Jobs\". The New York Times. Archived from the original on September 5, 2012. Retrieved October 30, 2011.\\n\\n^ Ian Sherr; Geoffrey A. Fowler (October 7, 2011). \"Steve Jobs Funeral Is Friday\". The Wall Street Journal. Archived from the original on August 13, 2013.\\n\\n^ Cook, Tim (October 5, 2011). \"Statement by Apple\\'s Board of Directors\" (Press release). Apple Inc. Archived from the original on April 25, 2012. Retrieved October 5, 2011.\\n\\n^ \"Pixar Animation Studios\". Pixar. Archived from the original on June 8, 2012. Retrieved April 18, 2013.\\n\\n^ \"Remembering Steve Jobs\". Apple Inc. Archived from the original on June 24, 2012. Retrieved October 10, 2011.\\n\\n^ \"Apple flies flags at half staff for Steve Jobs\". KOKI-TV. October 6, 2011. Archived from the original on August 13, 2013. Retrieved October 29, 2011.\\n\\n^ \"Microsoft lowers flags to half staff in tribute to Steve Jobs\". Network World. October 6, 2011. Archived from the original on November 9, 2013. Retrieved October 29, 2011.\\n\\n^ \"Disney World flags at half-staff in memory of Steve Jobs\". Bay News 9. October 6, 2011. Archived from the original on December 13, 2011. Retrieved October 29, 2011.\\n\\n^ Pepitone, Julianne (October 6, 2011). \"Steve Jobs: The homepage tributes\". CNN. Archived from the original on April 25, 2012. Retrieved January 10, 2012.\\n\\n^ \"Apple website pays tribute to Steve Jobs\". The Times of India. India. October 5, 2011. Archived from the original on April 25, 2012. Retrieved October 7, 2011.\\n\\n^ \"Remembering Steve Jobs\". Apple Inc. Archived from the original on June 24, 2012. Retrieved October 6, 2011.\\n\\n^ a b \"A Celebration of Steve\\'s Life\". Archived from the original on December 29, 2013. Apple.com Retrieved October 26, 2011\\n\\n^ Fernandez, Sofia M. (October 14, 2011). \"Private Steve Jobs Memorial Set for Oct. 16 – The Hollywood Reporter\". The Hollywood Reporter. Archived from the original on December 31, 2013. Retrieved November 12, 2011.\\n\\n^ \"Steve Jobs Memorial Service To Be Held Oct. 16\". The Wall Street Journal. October 15, 2011. Archived from the original on August 13, 2013. Retrieved November 12, 2011.\\n\\n^ Vascellaro, Jessica E. (October 17, 2011). \"Steve Jobs\\'s Family Gave Moving Words at Sunday Memorial – Digits – WSJ\". The Wall Street Journal. Archived from the original on April 10, 2014. Retrieved November 12, 2011.\\n\\n^ Wadhwa, Hitendra (June 21, 2015). \"Steve Jobs\\'s Secret to Greatness: Yogananda\". Inc. Archived from the original on June 22, 2015. Retrieved June 23, 2015.\\n\\n^ Wozniak Tearfully Remembers His Friend Steve Jobs. YouTube. October 6, 2011. Archived from the original on December 19, 2021.\\n\\n^ Patricia Sellers (October 6, 2011). \"George Lucas on Steve Jobs\". Fortune. Archived from the original on January 28, 2012. Retrieved October 6, 2011.\\n\\n^ \"Steve Jobs\". Thegatesnotes.com. October 5, 2011. Archived from the original on January 27, 2012. Retrieved November 12, 2011.\\n\\n^ \"Statement by the President on the Passing of Steve Jobs\". whitehouse.gov (Press release). October 5, 2011. Archived from the original on February 10, 2021 – via National Archives.\\n\\n^ \"Steve Jobs Died of Respiratory Arrest Amid Pancreatic Tumor\". ABC News. October 10, 2011. Archived from the original on April 25, 2012. Retrieved November 12, 2011.\\n\\n^ Gupta, Poornima (October 10, 2011). \"Steve Jobs died of respiratory arrest, tumor\". Reuters. Archived from the original on April 10, 2014. Retrieved September 21, 2012.\\n\\n^ Celebrating Steve | October 5 | Apple, archived from the original on October 20, 2021, retrieved October 20, 2021\\n\\n^ a b \"Steve Jobs\\' autobiography: a chronicle of a complex genius\". The Hindu. Chennai, India. October 24, 2011. Archived from the original on November 9, 2013.\\n\\n^ Shontell, Alyson. \"This Man Could Have Made $30 Million Per Year As Apple\\'s Designer — But He Turned Steve Jobs Down\". Business Insider. Archived from the original on May 17, 2019. Retrieved May 17, 2019.\\n\\n^ \"What Made Steve Jobs So Great?\". Fast Company. August 24, 2011. Archived from the original on April 10, 2014. Retrieved August 21, 2012.\\n\\n^ a b \"Does Steve Jobs know how to code?\". Archived from the original on October 31, 2013. Retrieved August 21, 2012.\\n\\n^ \"Searching for Magic in India and Silicon Valley: An Interview with Daniel Kottke, Apple Employee #12\". Boing Boing. August 9, 2012. Archived from the original on January 11, 2014. Retrieved August 30, 2012.\\n\\n^ \"Portfolio of over 300 patents underscores Steve Jobs\\' attention to detail\". Archived from the original on April 10, 2014. Retrieved September 26, 2012.\\n\\n^ a b \"U.S. Government patent database\". Archived from the original on June 24, 2012. Retrieved August 29, 2011.\\n\\n^ \"U.S. Government patent application database\". Archived from the original on April 20, 2012. Retrieved August 29, 2011.\\n\\n^ \"United States Patent 8,032,843, Ording, et al., October 4, 2011, \"User interface for providing consolidation and access\"\". Archived from the original on June 24, 2012. Retrieved November 21, 2017.\\n\\n^ \"Steve Jobs Told Me Why He Loved Being A CEO\". Business Insider. Archived from the original on August 6, 2011. Retrieved February 2, 2013. He told me once that part of the reason he wanted to be CEO was so that nobody could tell him that he wasn\\'t allowed to participate in the nitty-gritty of product design\", Reid writes. \"He was right there in the middle of it. All of it. As a team member, not as CEO. He quietly left his CEO hat by the door, and collaborated with us.\\n\\n^ Kachka, Boris (August 26, 2015). \"How Kate Winslet Won a Role in Steve Jobs and Managed All That Sorkin Dialogue\". Vulture. Archived from the original on June 18, 2016. Retrieved December 28, 2017.\\n\\n^ Rosenwald, Michael S. (October 24, 2011). \"Walter Isaacson\\'s \\'Steve Jobs\\' biography shows Apple co-founder\\'s genius, flaws\". The Washington Post. Archived from the original on October 25, 2012. Retrieved September 16, 2012.\\n\\n^ \"Steve Jobs Still Wins Plenty of Patents – MIT Technology Review\". MIT Technology Review. Archived from the original on January 15, 2015. Retrieved January 21, 2015.\\n\\n^ Isaacson 2015, pp.\\xa073–83.\\n\\n^ Christoph Dernbach (October 12, 2007). \"Apple Lisa\". Mac History. Archived from the original on November 3, 2012. Retrieved November 15, 2012.\\n\\n^ \"Apple Lisa computer\". Archived from the original on June 2, 2015. Retrieved May 20, 2015.\\n\\n^ Simon, Jeffrey S.; Young, William L. (April 14, 2006). iCon: Steve Jobs, the greatest second act in the history of business (Newly updated\\xa0ed.). Hoboken, NJ: Wiley. p.\\xa070. ISBN\\xa0978-0471787846.\\n\\n^ Linzmayer 2004, p.\\xa079.\\n\\n^ Polsson, Ken (July 29, 2009). \"Chronology of Apple Computer Personal Computers\". Archived from the original on August 21, 2009. Retrieved August 27, 2009. See May 3, 1984.\\n\\n^ Linzmayer 2004, p.\\xa0113.\\n\\n^ Maney, Kevin (January 28, 2004). \"Apple\\'s \\'1984\\' Super Bowl commercial still stands as watershed event\". USA Today. Archived from the original on April 5, 2016. Retrieved April 11, 2010.\\n\\n^ Leopold, Todd (February 3, 2006). \"Why 2006 isn\\'t like \\'1984\\'\". CNN. Archived from the original on April 5, 2016. Retrieved May 10, 2008.\\n\\n^ Creamer, Matthew (March 1, 2012). \"Apple\\'s First Marketing Guru on Why \\'1984\\' Is Overrated\". Ad Age. Archived from the original on April 19, 2015. Retrieved April 19, 2015.\\n\\n^ Cellini, Adelia (January 2004). \"The Story Behind Apple\\'s \\'1984\\' TV commercial: Big Brother at 20\". MacWorld. Vol.\\xa01, no.\\xa021. p.\\xa018. Archived from the original on June 28, 2009. Retrieved May 9, 2008.\\n\\n^ Long, Tony (January 22, 2007). \"Jan. 22, 1984: Dawn of the Mac\". Wired. Archived from the original on April 16, 2010. Retrieved April 11, 2010.\\n\\n^ Reimer, Jeremy (December 14, 2005). \"Total share: 30 years of personal computer market share figures\". Ars Technica. Archived from the original on May 14, 2021. Retrieved April 16, 2015.\\n\\n^ Carter, Mia. \"Steve Jobs: 10 Products that Define this Tech Legend\". Inventions and Discoveries. Archived from the original on April 4, 2012. Retrieved March 27, 2012.\\n\\n^ \"Steve Jobs Introduces NeXTComputer\". Archived from the original on April 7, 2013. Retrieved April 7, 2013. Steve Jobs unveiled the NeXT, the computer he designed after moving on from Apple Computer Inc...\\n\\n^ Hoppel, Adrian. \"Magical Inventions of Steve Jobs\". Best Inventions of Steve Jobs. Magical Inventions of Steve Jobs. Archived from the original on April 10, 2014. Retrieved March 27, 2012.\\n\\n^ Paola Antonelli, Paola (April 2006). \"iMac – 1998\". MetropolisMag. Archived from the original on May 11, 2013. Retrieved March 28, 2012.\\n\\n^ Michael (August 7, 2007). \"Apple History: Evolution of the iMac\". Apple Gazette. Apple Gazette. Archived from the original on June 24, 2012. Retrieved March 28, 2012.\\n\\n^ \"iPod First Generation\". iPod History. iPod History. Archived from the original on June 24, 2012. Retrieved March 28, 2012.\\n\\n^ a b Block, Ryan. \"The iPod family cemetery\". iPods. EndGadget. Archived from the original on June 24, 2012. Retrieved March 28, 2012.\\n\\n^ Asiado, Tel (August 24, 2011). \"Steve Jobs: 10 Products that Define this Tech Legend\". Inventions and Discoveries. Archived from the original on April 4, 2012. Retrieved March 27, 2012.\\n\\n^ Ha, Peter (October 25, 2010). \"All-TIME 100 Gadgets - TIME\". Time. ISSN\\xa00040-781X. Archived from the original on August 2, 2021. Retrieved October 9, 2021.\\n\\n^ a b \"iPhone History – Read About The iPhone Story Here\". The Apple Biter\\'s Blog. November 4, 2011. Archived from the original on June 24, 2012. Retrieved October 15, 2014.\\n\\n^ \"iPhone History and Development\". iPhone apps, tricks, tips, and hacks. Apple iPhone Blog. Archived from the original on June 24, 2012. Retrieved March 28, 2012.\\n\\n^ \"iPhone 3GS\". iPhone News. iPhoneHistory. Archived from the original on June 24, 2012. Retrieved March 28, 2012.\\n\\n^ \"iPhone 4 Tech Specs\". Apple. Archived from the original on June 24, 2012. Retrieved March 28, 2012.\\n\\n^ \"The iPad\\'s 5th anniversary: a timeline of Apple\\'s category-defining tablet\". The Verge. April 3, 2015. Archived from the original on April 17, 2015. Retrieved April 17, 2015.\\n\\n^ Isaacson 2015, p.\\xa0274.\\n\\n^ a b Linzmayer 2004, p.\\xa081.\\n\\n^ \"Steve Jobs\\' Childhood Home Draws Tourists; Stepmom Laments Resignation\". Los Altos, CA Patch. August 25, 2011. Archived from the original on June 2, 2021. Retrieved May 30, 2021.\\n\\n^ \"Laurene Powell Jobs\\xa0– PARSA\". PARSA Community Foundation. 2006. Archived from the original on September 14, 2010. Retrieved July 8, 2008.\\n\\n^ Kadifa, Margaret (October 29, 2015). \"Halloween at Steve Jobs\\' house\". Houston Chronicle. Archived from the original on December 8, 2015. Retrieved December 2, 2015.\\n\\n^ Gelles, David (February 27, 2020). \"Laurene Powell Jobs Is Putting Her Own Dent in the Universe: An interview with the 35th-richest person in the world\". The New York Times. Archived from the original on May 25, 2020. Retrieved May 25, 2020.\\n\\n^ Hartmans, Avery (February 28, 2020). \"Laurene Powell Jobs says she won\\'t pass on billions to her children\". Business Insider. Archived from the original on June 29, 2020. Retrieved May 25, 2020. It ends with me\\n\\n^ Rabbi Jonathan Schwartz, PsyD. (Spring 1979). \"Reclaiming happiness in the digital age\". Jewish Action (OU). pp.\\xa068–72. Archived from the original on January 20, 2021. Retrieved May 25, 2020. Both Bill Gates and Steve Jobs ... raised their children with serious limits on their Internet, social media and gaming access.\\n\\n^ Akhtar, Allana; Ward, Marguerite (May 15, 2020). \"Bill Gates and Steve Jobs raised their kids with limited tech — and it should have been a red flag about our own smartphone use\". Business Insider. Archived from the original on May 14, 2020. Retrieved May 25, 2020.\\n\\n^ Brennan, Chrisann. The Bite in the Apple: A Memoir of My Life with Steve Jobs. St. Martin\\'s Griffin. p.\\xa0220.\\n\\n^ a b c Isaacson 2011, pp.\\xa0253–255.\\n\\n^ Isaacson 2015, pp.\\xa0253–255.\\n\\n^ a b Isaacson 2015, p.\\xa0254.\\n\\n^ a b c d e Isaacson 2015, p.\\xa0258.\\n\\n^ a b c Isaacson 2015, p.\\xa0255.\\n\\n^ a b c Isaacson 2015, p.\\xa0253.\\n\\n^ Isaacson 2015, p.\\xa0256.\\n\\n^ a b c d e f g Isaacson 2015, p.\\xa0257.\\n\\n^ Conversations: Malek Jandali, Mona Simpson, & James Gelvin Archived April 14, 2018, at the Wayback Machine (UCLA Hammer Museum event). Hammer.UCLA.edu. Retrieved October 2, 2018.\\n\\n^ Nath, Trevir I. (October 6, 2021). \"How Steve Jobs changed the world\". www.investopedia.com. Retrieved March 22, 2022.{{cite web}}:  CS1 maint: url-status (link)\\n\\n^ Whoriskey, Peter (October 6, 2011). \"Record thin on Steve Jobs\\' philanthropy\". www.washingtonpost.com. Retrieved March 22, 2022.{{cite news}}:  CS1 maint: url-status (link)\\n\\n^ \"Steve Jobs statue unveiled in Hungary science park\". GlobalPost. December 21, 2011. Archived from the original on January 10, 2012. Retrieved December 28, 2011.\\n\\n^ \"The National Medal of Technology Recipients 1985 Laureates\". Uspto.gov. Archived from the original on February 4, 2012. Retrieved April 19, 2010.\\n\\n^ \"National Winners | public service awards\". Jefferson Awards.org. Archived from the original on February 4, 2012. Retrieved April 19, 2010.\\n\\n^ Bo Burlingham and George Gendron (April 1, 1989). \"The Entrepreneur of the Decade\". Inc. magazine. Archived from the original on June 24, 2012. Retrieved October 8, 2011.\\n\\n^ \"Reed College Convocation\". Apple iTunes. Portland, Oregon: Reed College. August 27, 1991. Archived from the original on December 11, 2016. Retrieved December 6, 2016.\\n\\n^ \"25 most powerful people in business – #1: Steve Jobs\". Fortune. Archived from the original on April 10, 2014. Retrieved April 19, 2010.\\n\\n^ \"Jobs inducted into California Hall of Fame\". Archived from the original on January 10, 2008., California Museum. Retrieved 2007.\\n\\n^ Arico, Joe (December 22, 2011). \"Steve Jobs Wins Special Grammy\". Mobiledia.com. Archived from the original on September 6, 2012. Retrieved December 28, 2011.\\n\\n^ \"2012 EDISON AWARDS WINNERS ANNOUNCED\" (PDF). p.\\xa01. Archived (PDF) from the original on October 21, 2021. Retrieved October 19, 2021.\\n\\n^ Ford, Rebecca (July 10, 2013). \"Steve Jobs, Billy Crystal to Receive Disney Legends Awards\". The Hollywood Reporter. Archived from the original on April 4, 2014. Retrieved July 18, 2013.\\n\\n^ \"Apple Park\\'s Steve Jobs Theater opens to host 2017 keynote\". Dezeen. September 12, 2017. Archived from the original on January 5, 2018. Retrieved January 4, 2018.\\n\\n\\nSources:\\n\\nIsaacson, Walter (2011). Steve Jobs. Simon and Schuster. ISBN\\xa09781451648546.\\nIsaacson, Walter (2015). Steve Jobs. Simon and Schuster. ISBN\\xa09781501127625.\\nLinzmayer, Owen W. (2004). Apple Confidential 2.0: The Definitive History of the World\\'s Most Colorful Company. No Starch Press. p.\\xa081. ISBN\\xa0978-1-59327-010-0. Retrieved April 15, 2014.\\nExternal links\\nApple\\'s official memorial page for Steve Jobs\\nSteve Jobsat Wikipedia\\'s sister projectsMedia from CommonsNews from WikinewsQuotations from WikiquoteResources from Wikiversity\\n\"Steve Jobs: From Garage to World\\'s Most Valuable Company.\" Computer History Museum.\\nSteve Jobs @ Andy Hertzfeld\\'s The Original Macintosh (folklore.org)\\nSteve Jobs @ Steve Wozniak\\'s woz.org\\nSteve Jobs (1955–2011) at IMDb\\nForbes Profile\\nFBI Records: The Vault – Steven Paul Jobs at vault.fbi.gov\\n2005: Steve Jobs commencement speech at Stanford University\\n1995: Excerpts from an Oral History Interview with Steve Jobs, Founder, NeXT Computer – Smithsonian Institution, April 20, 1995.\\n1994: Steve Jobs in 1994: The Rolling Stone Interview – Rolling Stone\\n1990: Memory and Imagination\\n1983: The \"Lost\" Steve Jobs Speech from 1983; Foreshadowing Wireless Networking, the iPad, and the App Store (audio clip)\\n\\n\\nBusiness positions\\n\\n\\nPreceded\\xa0byGil Amelio\\n\\n CEO of Apple 1997–2011\\n\\nSucceeded\\xa0byTim Cook\\n\\n\\nPreceded\\xa0by\\n\\n Apple Chairman 1985\\n\\nSucceeded\\xa0byMike Markkula\\n\\n\\nPreceded\\xa0by\\n\\n Apple Chairman 2011\\n\\nSucceeded\\xa0byArthur D. Levinson\\n\\n\\nvteSteve JobsCareer\\nTimeline\\nApple Computer\\nhistory\\nMacintosh\\nNeXT\\nPixar\\nReturn to Apple\\n\"Thoughts on Flash\"\\nLegacy\\nArtistic depictions\\nHonors and public recognition\\nBooks about\\nThe Little Kingdom (1984)\\nThe Second Coming of Steve Jobs (2000)\\nICon (2005)\\nSteve Jobs (2011)\\nThe Bite in the Apple (2013)\\nBecoming Steve Jobs (2015)\\nDesigned by Apple in California (2016)\\nSmall Fry (2018)\\nFilms about\\nTriumph of the Nerds (1996)\\nPirates of Silicon Valley (1999)\\nSteve Jobs: The Lost Interview (2012)\\nISteve (2013)\\nJobs (2013)\\nSteve Jobs (2015)\\nSteve Jobs: The Man in the Machine (2015)\\nFamily\\nLaurene Powell Jobs (wife)\\nMona Simpson (sister)\\nChrisann Brennan (mother of his first child)\\nLisa Brennan-Jobs (daughter)\\nRelated\\nStevenote\\nReality distortion field\\nJackling House\\nThe (R)evolution of Steve Jobs\\nSeva Foundation\\nThe Son of a Migrant from Syria (2015 mural)\\nVenus yacht\\n1984 commercial\\nThink different\\nSteve Wozniak\\n\\nvteApple Inc.HistoryOutlineTimeline of productsProductsHardware\\niPhone\\nHardware\\nHistory\\nTV\\nWatch\\nAirPods\\nPro\\nMax\\nAirTag\\nBeats\\nPill\\nPowerbeats Pro\\nHomePod\\nMini\\nSilicon\\nMac\\niMac\\nPro\\nMacBook\\nAir\\nPro\\nMini\\nStudio\\nPro\\nComparison\\niPod\\nClassic\\nMini\\nNano\\nShuffle\\nTouch\\niPad\\nMini\\nAir\\nPro\\nAccessories\\nSoftwareOperatingsystems\\niOS / iPadOS\\nDevices\\nHistory\\nApps\\nmacOS\\nHistory\\nServer\\ntvOS\\nwatchOS\\nbridgeOS\\nDarwin\\nClassic Mac OS\\n\\nCarPlay\\nClassroom\\nHomeKit\\nCore Foundation\\nDeveloper Tools\\nFileMaker\\nFinal Cut Pro\\nX\\nCompressor\\nMotion\\nLogic Pro\\nMainStage\\niLife\\nGarageBand\\niMovie\\niPhoto\\niTunes\\niWork\\nKeynote\\nNumbers\\nPages\\nMail\\nQuickTime\\nSafari\\nShazam\\nSiri\\nSwift\\nXcode\\nServicesFinancial\\nCard\\nPay\\nWallet\\nMedia\\nArcade\\nBooks\\nMusic\\n1\\nBeats Music\\nUp Next\\nFestival\\niTunes Radio\\nApp\\nNews\\nNewsstand\\nPodcasts\\nTV\\n+\\noriginals\\nCommunication\\nFaceTime\\nWalkie-Talkie\\niMessage\\niChat\\nApp\\nGame Center\\nRetail anddigital sales\\nApp Store\\niOS / iPadOS\\nmacOS\\ntvOS\\niTunes Store\\nConnect\\nStore\\nApple Fifth Avenue\\nSupport\\nAppleCare\\nSpecialist\\nCertifications\\nGenius Bar\\nProCare\\nOne to One\\nOther\\nID\\nSign in with Apple\\nOne\\nDeveloper\\niAd\\nTestFlight\\nWWDC\\niCloud\\nMobileMe\\nFind My\\nFitness\\nPhotos\\nMaps\\nLook Around\\nCompaniesSubsidiaries\\nAnobit\\nApple IMC\\nApple Studios\\nBeats\\nBeddit\\nBraeburn Capital\\nClaris\\nAcquisitions\\nList\\nAnobit\\nAuthenTec\\nBeats\\nBeddit\\nCue\\nEditGrid\\nEmagic\\nFingerWorks\\nIntrinsity\\nInVisage Technologies\\nThe Keyboard Company\\nLala\\nMetaio\\nNeXT\\nNothing Real\\nP.A. Semi\\nPrimeSense\\nShazam Entertainment Limited\\nSiri\\nSpotsetter\\nTexture\\nTopsy\\nPartnerships\\nAIM alliance\\nKaleida Labs\\nTaligent\\nAkamai\\nArm Ltd.\\nDiDi\\nDigital Ocean\\niFund\\nImagination\\nRockstar Consortium\\nRelated\\nAdvertising\\n\"1984\"\\n\"Think different\"\\n\"Get a Mac\"\\niPod\\nProduct Red\\nEcosystem\\nEvents\\nHeadquarters\\nCampus\\nPark\\nUniversity\\nDesign\\nIDg\\nTypography\\nBook\\nHistory\\nCodenames\\nCommunity\\nAppleMasters\\nCriticism\\nLitigation\\nFBI–Apple encryption dispute\\niOS app approvals\\nWorker organizations\\nArtistic depictions of Steve Jobs\\nPeopleExecutivesCurrent\\nTim Cook (CEO)\\nJeff Williams (COO)\\nLuca Maestri (CFO)\\nKatherine Adams (General Counsel)\\nEddy Cue\\nCraig Federighi\\nIsabel Ge Mahe\\nJohn Giannandrea\\nLisa Jackson\\nGreg Joswiak\\nDeirdre O\\'Brien\\nDan Riccio\\nPhil Schiller\\nJohny Srouji\\nFormer\\nMichael Scott (CEO)\\nMike Markkula (CEO)\\nJohn Sculley (CEO)\\nMichael Spindler (CEO)\\nGil Amelio (CEO)\\nSteve Jobs (CEO)\\nJony Ive (CDO)\\nAngela Ahrendts\\nFred D. Anderson\\nJohn Browett\\nGuerrino De Luca\\nPaul Deneve\\nAl Eisenstat\\nTony Fadell\\nScott Forstall\\nEllen Hancock\\nNancy R. Heinen\\nRon Johnson\\nDavid Nagel\\nPeter Oppenheimer\\nMark Papermaster\\nJon Rubinstein\\nBertrand Serlet\\nBruce Sewell\\nSina Tamaddon\\nAvie Tevanian\\nRonald Wayne\\nSteve Wozniak\\nBoard ofdirectorsCurrent\\nArthur D. Levinson (Chairman)\\nTim Cook (CEO)\\nJames A. Bell\\nAlbert Gore Jr.\\nAndrea Jung\\nRonald D. Sugar\\nSusan L. Wagner\\nFormer\\nMike Markkula (Chairman)\\nJohn Sculley (Chairman)\\nSteve Jobs (Chairman)\\nGil Amelio\\nFred D. Anderson\\nBill Campbell\\nMickey Drexler\\nAl Eisenstat\\nLarry Ellison\\nRobert A. Iger\\nDelano Lewis\\nArthur Rock\\nEric Schmidt\\nMichael Scott\\nMichael Spindler\\nEdgar S. Woolard Jr.\\nJerry York\\nFounders\\nSteve Jobs\\nSteve Wozniak\\nRonald Wayne\\nItalics indicate discontinued products, services, or defunct companies.\\n Category\\n Commons\\nvteKey figures in the history of Apple Inc.Founders\\nSteve Jobs\\nSteve Wozniak\\nRonald Wayne\\nCEOs\\nMichael Scott (1977–1981)\\nMike Markkula (1981–1983)\\nJohn Sculley (1983–1993)\\nMichael Spindler (1993–1996)\\nGil Amelio (1996–1997)\\nSteve Jobs (1997–2011)\\nTim Cook (2011–present)\\nCurrentemployees\\nKatherine L. Adams\\nEddy Cue\\nChris Espinosa\\nCraig Federighi\\nLisa P. Jackson\\nGreg Joswiak\\nLuca Maestri\\nBob Mansfield\\nDan Riccio\\nPhil Schiller\\nJohny Srouji\\nBud Tribble\\nJeff Williams\\nSteve Wozniak\\nFormeremployees\\nGil Amelio\\nAngela Ahrendts\\nFred D. Anderson\\nBill Atkinson\\nSusan Barnes\\nChrisann Brennan\\nSteve Capps\\nSatjiv S. Chahil\\nGeorge Crow\\nTony Fadell\\nBill Fernandez\\nScott Forstall\\nJean-Louis Gassée\\nEllen Hancock\\nNancy R. Heinen\\nAndy Hertzfeld\\nJoanna Hoffman\\nRod Holt\\nBruce Horn\\nJony Ive\\nSteve Jobs\\nRon Johnson\\nSusan Kare\\nGuy Kawasaki\\nAlan Kay\\nDaniel Kottke\\nChris Lattner\\nGuerrino De Luca\\nMike Markkula\\nDavid Nagel\\nIke Nassi\\nDon Norman\\nPeter Oppenheimer\\nRich Page\\nMark Papermaster\\nJef Raskin\\nJon Rubinstein\\nMichael Scott\\nJohn Sculley\\nBertrand Serlet\\nBruce Sewell\\nBurrell Smith\\nMichael Spindler\\nSina Tamaddon\\nAvie Tevanian\\nRonald Wayne\\nDel Yocam\\n\\nvteOriginal Macintosh developer team\\nBill Atkinson\\nSteve Capps\\nGeorge Crow\\nChris Espinosa\\nAndy Hertzfeld\\nJoanna Hoffman\\nBruce Horn\\nSteve Jobs\\nSusan Kare\\nJef Raskin\\nBurrell Smith\\nBud Tribble\\nSteve Wozniak\\nRandy Wigginton\\n\\nvteNeXTCorporate directors\\nSteve Jobs\\nRoss Perot\\nJohn Patrick Crecine\\nTeam members\\nSusan Barnes\\nGeorge Crow\\nJoanna Hoffman\\nSteve Jobs\\nSusan Kare\\nRich Page\\nBud Tribble\\nHardware products\\nNeXT Computer\\nNeXTcube\\nNeXTcube Turbo\\nNeXTstation\\nNeXTdimension\\nNeXT MegaPixel Display\\nNeXT Laser Printer\\nSoftware products\\nNeXTSTEP\\nOpenStep\\nWebObjects\\nInterface Builder\\n\\n Category\\n Commons\\n\\nvtePixar Animation StudiosA subsidiary of Walt Disney Studios, a division of The Walt Disney Company.Feature filmsComputer animated\\nToy Story (1995)\\nA Bug\\'s Life (1998)\\nToy Story 2 (1999)\\nMonsters, Inc. (2001)\\nFinding Nemo (2003)\\nThe Incredibles (2004)\\nCars (2006)\\nRatatouille (2007)\\nWALL-E (2008)\\nUp (2009)\\nToy Story 3 (2010)\\nCars 2 (2011)\\nBrave (2012)\\nMonsters University (2013)\\nInside Out (2015)\\nThe Good Dinosaur (2015)\\nFinding Dory (2016)\\nCars 3 (2017)\\nCoco (2017)\\nIncredibles 2 (2018)\\nToy Story 4 (2019)\\nOnward (2020)\\nSoul (2020)\\nLuca (2021)\\nTurning Red (2022)\\nTraditionally animated\\nBuzz Lightyear of Star Command: The Adventure Begins (2000)\\nUpcoming\\nLightyear (2022)\\nShort filmsTheatrical\\nThe Adventures of André & Wally B. (1984)\\nLuxo Jr. (1986)\\nRed\\'s Dream (1987)\\nTin Toy (1988)\\nKnick Knack (1989)\\nGeri\\'s Game (1997)\\nFor the Birds (2000)\\nBoundin\\' (2003)\\nOne Man Band (2005)\\nLifted (2006)\\nPresto (2008)\\nPartly Cloudy (2009)\\nDay & Night (2010)\\nLa Luna (2011)\\nThe Blue Umbrella (2013)\\nLava (2014)\\nSanjay\\'s Super Team (2015)\\nPiper (2016)\\nLou (2017)\\nBao (2018)\\nSparkShorts\\nPurl (2019)\\nSmash and Grab (2019)\\nKitbull (2019)\\nFloat (2019)\\nWind (2019)\\nLoop (2020)\\nOut (2020)\\nBurrow (2020)\\nTwenty Something (2021)\\nNona (2021)\\nFeature-related\\nMike\\'s New Car (2002)\\nExploring the Reef (2003)\\nJack-Jack Attack (2005)\\nMr. Incredible and Pals (2005)\\nMater and the Ghostlight (2006)\\nYour Friend the Rat (2007)\\nBURN-E (2008)\\nDug\\'s Special Mission (2009)\\nGeorge and A.J. (2009)\\nThe Legend of Mor\\'du (2012)\\nParty Central (2013)\\nRiley\\'s First Date? (2015)\\nMarine Life Interviews (2016)\\nMiss Fritter\\'s Racing Skoool (2017)\\nAuntie Edna (2018)\\nLamp Life (2020)\\n22 vs. Earth (2021)\\nCiao Alberto (2021)\\nSeries\\nCars Toons (2008–14)\\nToy Story Toons (2011–12)\\nForky Asks a Question (2019–20)\\nDug Days (2021)\\nCompilations\\nTiny Toy Stories (1996)\\nPixar Short Films Collection, Volume 1 (2007)\\nCars Toons: Mater\\'s Tall Tales  (2010)\\nPixar Short Films Collection, Volume 2 (2012)\\nPixar Short Films Collection, Volume 3 (2018)\\nOther works\\nBeach Chair (1986)\\nFlags and Waves (1986)\\nLight & Heavy (1990)\\nSurprise (1991)\\nTelevision series\\nBuzz Lightyear of Star Command (2000–2001)\\nUpcoming\\nCars on the Road (2022)\\n\\nTelevision specials\\nToy Story of Terror! (2013)\\nToy Story That Time Forgot (2014)\\nFranchises\\nToy Story\\nMonsters, Inc.\\nFinding Nemo\\nThe Incredibles\\nCars\\nAssociatedproductions\\nPlanes (2013)\\nPlanes: Fire & Rescue (2014)\\nBorrowed Time (2016)\\nMonsters at Work (television series; 2021–present)\\nDocumentaries\\nThe Pixar Story (2007)\\nInside Pixar (2020–21; docuseries)\\nA Spark Story (2021)\\nEmbrace the Panda: Making Turning Red (2022)\\nDisney attractionsand experiences\\nIt\\'s Tough to Be a Bug! (1998)\\nA Bug\\'s Land (2002)\\nTurtle Talk with Crush (2004)\\nThe Seas with Nemo & Friends (2007)\\nCrush\\'s Coaster (2007)\\nFinding Nemo Submarine Voyage (2007)\\nToy Story Mania! (2008)\\nToy Story Land (2010)\\nRC Racer (2010)\\nSlinky Dog Zigzag Spin (2010)\\nToy Soldiers Parachute Drop (2010)\\nAlien Swirling Saucers (2018)\\nNemo & Friends SeaRider (2017)\\nPixar Pier (2018)\\nGames of Pixar Pier (2018)\\nIncredicoaster (2018)\\nPixar Pal-A-Round (2018)\\nJessie\\'s Critter Carousel (2019)\\nInside Out: Emotional Whirlwind (2019)\\nInside Out: Joyful Sweets (2022)\\nProducts\\nPixar Image Computer\\nRenderMan\\nPresto Animation System\\nPeople\\nJohn Lasseter\\nEdwin Catmull\\nSteve Jobs\\nAlvy Ray Smith\\nJim Morris\\nPete Docter\\nSee also\\nList of Pixar characters\\nLuxo Jr.\\nList of Pixar awards and nominations\\nfeature films\\nshort films\\nList of Pixar film references\\nComputer Graphics Lab\\nIndustrial Light & Magic\\nLucasfilm Animation\\nCircle Seven Animation\\nPixar Canada\\nPixar Photoscience Team\\nComputer Animation Production System\\nA Computer Animated Hand\\nThe Works\\nThe Shadow King\\nKingdom Hearts III\\nWalt Disney Animation Studios\\n20th Century Animation\\nBlue Sky Studios\\nThe Walt Disney Studios\\n\\n Category\\n\\nvteDisney Legends Awards (2010s)2011\\nJodi Benson\\nBarton “Bo” Boyd*\\nJim Henson*\\nLinda Larkin\\nPaige O\\'Hara\\nRegis Philbin\\nAnika Noni Rose\\nLea Salonga\\nRaymond Watson\\nGuy Williams*\\nBonita Granville Wrather*\\nJack Wrather*\\n2013\\nTony Baxter\\nCollin Campbell\\nDick Clark\\nBilly Crystal\\nJohn Goodman\\nSteve Jobs*\\nGlen Keane\\nEd Wynn*\\n2015\\nGeorge Bodenheimer\\nJulie Reihm Casaletto\\nAndreas Deja\\nJohnny Depp\\nEyvind Earle*\\nDanny Elfman\\nSusan Lucci\\nGeorge Lucas\\nCarson Van Osten\\n2017\\nClyde Geronimi*\\nWhoopi Goldberg\\nManuel Gonzales*\\nCarrie Fisher*\\nMark Hamill\\nJack Kirby*\\nWayne Jackson\\nStan Lee\\nGarry Marshall*\\nJulie Taymor\\nOprah Winfrey\\n2019\\nChristina Aguilera\\nWing T. Chao\\nRobert Downey Jr.\\nJon Favreau\\nJames Earl Jones\\nBette Midler\\nKenny Ortega\\nBarnette Ricci\\nRobin Roberts\\nDiane Sawyer\\nMing-Na Wen\\nHans Zimmer\\n* Awarded posthumously\\nComplete list\\n1980s\\n1990s\\n2000s\\n2010s\\nAuthority control General\\nISNI\\n1\\nVIAF\\n1\\nWorldCat\\nNational libraries\\nNorway\\nSpain\\nFrance (data)\\nArgentina\\nCatalonia\\nGermany\\nItaly\\nIsrael\\nUnited States\\nLatvia\\nJapan\\nCzech Republic\\nAustralia\\n2\\nGreece\\nKorea\\nCroatia\\nNetherlands\\nPoland\\nSweden\\nArt research institutes\\nArtist Names (Getty)\\nScientific databases\\nCiNii (Japan)\\nOther\\nFaceted Application of Subject Terminology\\nMusicBrainz artist\\nSocial Networks and Archival Context\\nSUDOC (France)\\n1\\nTrove (Australia)\\n1\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Steve_Jobs&oldid=1084433497\"']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"scrapped_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
